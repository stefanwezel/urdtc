{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "As we're luckily standing on the shoulders of giants, we can do some imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import imageio\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "Let's load and convert the data, so we can use it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = ['cifar10', 'mnist', 'cub', 'awa2',\n",
    "            'imagenetfeatures', 'apyfeatures', 'zero_shot_cub']\n",
    "# dataset = 'awa2'\n",
    "# dataset = 'cub'\n",
    "dataset = 'zero_shot_cub'\n",
    "\n",
    "data_path = '/home/swezel/projects/urdtc/data/'\n",
    "figure_path = data_path + '../thesis/images/'\n",
    "\n",
    "\n",
    "# attribute name lookup (first attr_id is 0) \n",
    "with open (data_path + 'cub/attributes.txt', 'r') as f:\n",
    "    attributes=f.readlines()\n",
    "attribute_name_dict = {str(int(attr.split(' ')[0])-1): attr.split(' ')[1] for attr in attributes}\n",
    "\n",
    "def get_dataset_config(dataset, cnn_type, max_iters):\n",
    "    input_channels = None\n",
    "    if dataset == 'mnist':\n",
    "        input_channels = 1\n",
    "        if cnn_type == 'cnn':\n",
    "            cnn_output_size = 4*4*100\n",
    "        elif cnn_type == 'resnet':\n",
    "            cnn_output_size = 512\n",
    "        elif cnn_type == 'shallowcnn':\n",
    "            cnn_output_size = 4*4*64\n",
    "        out_freq = 100\n",
    "        #assert max_iters > 4\n",
    "    elif dataset == 'cifar10':\n",
    "        input_channels = 3\n",
    "        if cnn_type == 'cnn':\n",
    "            cnn_output_size = 8*8*32\n",
    "        elif cnn_type == 'resnet' or cnn_type == 'resnet18':\n",
    "            cnn_output_size = 512\n",
    "        elif cnn_type == 'shallowcnn':\n",
    "            cnn_output_size = 4*4*64\n",
    "        out_freq = 100\n",
    "        #assert max_iters > 4\n",
    "    elif dataset == 'cub':\n",
    "        input_channels = 3\n",
    "        if cnn_type == 'cnn':\n",
    "            # cnn_output_size = 32*32*32\n",
    "            cnn_output_size = 280900 # the above does not work? Maybe because of dataloader issue?\n",
    "        elif cnn_type == 'resnet' or cnn_type == 'resnet152':\n",
    "            cnn_output_size = 2048\n",
    "        out_freq = 10\n",
    "    elif dataset == 'zero_shot_cub':\n",
    "        input_channels = 3\n",
    "        if cnn_type == 'cnn':\n",
    "            # cnn_output_size = 32*32*32\n",
    "            cnn_output_size = 280900 # the above does not work? Maybe because of dataloader issue?\n",
    "        elif cnn_type == 'resnet' or cnn_type == 'resnet152':\n",
    "            cnn_output_size = 2048\n",
    "        out_freq = 10\n",
    "        #assert max_iters > 8\n",
    "    elif dataset == 'awa2':\n",
    "        input_channels = 3\n",
    "        if cnn_type == 'cnn':\n",
    "#             cnn_output_size = 32*32*32  # TODO: check\n",
    "            cnn_output_size = 2048\n",
    "        elif cnn_type == 'resnet' or cnn_type == 'resnet152':\n",
    "            cnn_output_size = 2048\n",
    "        out_freq = 10\n",
    "        #assert max_iters > 6\n",
    "    elif dataset == 'imagenetfeatures':\n",
    "        cnn_output_size = 2048\n",
    "        out_freq = 100\n",
    "        #assert max_iters > 10\n",
    "    elif dataset == 'apyfeatures':\n",
    "        cnn_output_size = 2048\n",
    "        out_freq = 10\n",
    "        #assert max_iters > 5\n",
    "\n",
    "    return input_channels, cnn_output_size, out_freq\n",
    "\n",
    "class DataLoader(object):\n",
    "    def __init__(self, dataset='mnist'):\n",
    "        assert dataset in DATASETS\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def load_data(self, batch_size=100, num_workers=4, root='./data/'):\n",
    "\n",
    "        if self.dataset == 'mnist':\n",
    "            #transform_train = transforms.ToTensor()\n",
    "            #transform_test = transforms.ToTensor()\n",
    "            class AddGaussianNoise(object):\n",
    "                def __init__(self, mean=0., std=1.):\n",
    "                    self.std = std\n",
    "                    self.mean = mean\n",
    "\n",
    "                def __call__(self, tensor):\n",
    "                    output = tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "                    return output.clamp(0., 1.)\n",
    "\n",
    "                def __repr__(self):\n",
    "                    return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
    "\n",
    "            transform_train = transforms.Compose([\n",
    "               transforms.ToTensor(),\n",
    "               #AddGaussianNoise(0., 0.2)\n",
    "               #transforms.Normalize((0.1307,), (0.3081,))\n",
    "            ])\n",
    "            transform_test = transforms.Compose([\n",
    "               transforms.ToTensor(),\n",
    "               #AddGaussianNoise(0., 0.2)\n",
    "               #transforms.Normalize((0.1307,), (0.3081,))\n",
    "            ])\n",
    "            classes = [i for i in range(10)]\n",
    "            dataset_class = dsets.MNIST\n",
    "\n",
    "        elif self.dataset == 'cifar10':\n",
    "            transform_train = transforms.Compose([\n",
    "                transforms.RandomCrop(32, padding=4),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "            ])\n",
    "            transform_test = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "            ])\n",
    "            classes = ('plane', 'car', 'bird', 'cat',\n",
    "                       'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "            dataset_class = dsets.CIFAR10\n",
    "\n",
    "        elif self.dataset == 'cub':\n",
    "\n",
    "            transform_train = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                  transforms.RandomResizedCrop(224),\n",
    "                                                  transforms.RandomHorizontalFlip(),\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                                       std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "            transform_test = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                 transforms.Resize(224),\n",
    "                                                 transforms.CenterCrop(224),\n",
    "                                                 transforms.ToTensor(),\n",
    "                                                 transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                                      std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "            dataset_class = CUB\n",
    "            classes = list(range(200))\n",
    "\n",
    "        elif self.dataset == 'zero_shot_cub':\n",
    "\n",
    "            transform_train = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                  transforms.RandomResizedCrop(224),\n",
    "                                                  transforms.RandomHorizontalFlip(),\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                                       std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "            transform_test = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                 transforms.Resize(224),\n",
    "                                                 transforms.CenterCrop(224),\n",
    "                                                 transforms.ToTensor(),\n",
    "                                                 transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                                      std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "            dataset_class = ZeroShotCUB\n",
    "            classes = list(range(200))            \n",
    "            \n",
    "            \n",
    "\n",
    "        elif self.dataset == 'awa2':\n",
    "            transform_train = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                  transforms.RandomResizedCrop(224),\n",
    "                                                  transforms.RandomHorizontalFlip(),\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                                       std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "            transform_test = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                 transforms.Resize(224),\n",
    "                                                 transforms.CenterCrop(224),\n",
    "                                                 transforms.ToTensor(),\n",
    "                                                 transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                                      std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "            dataset_class = AWA2\n",
    "            classes = list(range(50))\n",
    "\n",
    "        elif self.dataset == 'apyfeatures':\n",
    "            transform_train = transforms.ToTensor()\n",
    "            transform_test = transforms.ToTensor()\n",
    "\n",
    "            dataset_class = APYFeatures\n",
    "            classes = list(range(32))\n",
    "\n",
    "        elif self.dataset == 'imagenetfeatures':\n",
    "            transform_train = transforms.ToTensor()\n",
    "            transform_test = transforms.ToTensor()\n",
    "\n",
    "            dataset_class = ImageNetFeatures\n",
    "            classes = list(range(1000))\n",
    "\n",
    "        train_dataset = dataset_class(root=root,\n",
    "                                      train=True,\n",
    "                                      transform=transform_train,\n",
    "                                      download=True)\n",
    "\n",
    "        test_dataset = dataset_class(root=root,\n",
    "                                     train=False,\n",
    "                                     transform=transform_test)\n",
    "\n",
    "        val_size = int(len(train_dataset) * 0.1)\n",
    "        train_size = len(train_dataset) - val_size\n",
    "\n",
    "        train_dataset, val_dataset = torch.utils.data.dataset.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   shuffle=True,\n",
    "                                                   num_workers=num_workers)\n",
    "\n",
    "        val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 shuffle=False,\n",
    "                                                 num_workers=num_workers)\n",
    "\n",
    "        test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  shuffle=False,\n",
    "                                                  num_workers=num_workers)\n",
    "\n",
    "        dataloaders = {'train': train_loader,\n",
    "                       'val': val_loader,\n",
    "                       'test': test_loader}\n",
    "\n",
    "        return dataloaders, classes\n",
    "\n",
    "class CUB(Dataset):\n",
    "    \"\"\"CUB200-2011 dataset.\"\"\"\n",
    "    attribute_file = 'attributes/class_attribute_labels_continuous.txt'\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, normalize=True,\n",
    "                 download=None):\n",
    "        self.root = os.path.join(root, 'cub')\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.data_dir = os.path.join(self.root, 'images')\n",
    "\n",
    "        train_test_split = pd.read_csv(os.path.join(self.root, 'train_test_split.txt'),\n",
    "                                       sep=' ', index_col=0, header=None)\n",
    "        if train:\n",
    "            is_train_image = 1\n",
    "        else:\n",
    "            is_train_image = 0\n",
    "        self.img_ids = train_test_split[train_test_split[1] == is_train_image].index.tolist()\n",
    "        self.id_to_img = pd.read_csv(os.path.join(self.root, 'images.txt'),\n",
    "                                     sep=' ', index_col=0, header=None)\n",
    "\n",
    "        raw_mtx = np.loadtxt(os.path.join(self.root,\n",
    "                                          self.attribute_file))\n",
    "        raw_mtx[raw_mtx == -1] = 0\n",
    "        raw_mtx = raw_mtx / raw_mtx.max()\n",
    "        self.attribute_mtx = torch.tensor(raw_mtx, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_ids[idx]\n",
    "        img_name = self.id_to_img[self.id_to_img.index == img_id].values[0][0]\n",
    "        img_path = os.path.join(self.data_dir, img_name)\n",
    "\n",
    "        img = imageio.imread(img_path, pilmode='RGB')\n",
    "        label = int(img_name[:3]) - 1\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label, img_path\n",
    "\n",
    "    \n",
    "class ZeroShotCUB(Dataset):\n",
    "    \"\"\"CUB200-2011 dataset.\"\"\"\n",
    "    attribute_file = 'attributes/class_attribute_labels_continuous.txt'\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, normalize=True,\n",
    "                 download=None):\n",
    "        self.root = os.path.join(root, 'cub')\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.data_dir = os.path.join(self.root, 'images')\n",
    "\n",
    "        train_test_split = pd.read_csv(os.path.join(self.root, 'zero_shot_train_test_split.txt'),\n",
    "                                       sep=' ', index_col=0, header=None)\n",
    "        if train:\n",
    "            is_train_image = 1\n",
    "        else:\n",
    "            is_train_image = 0\n",
    "        self.img_ids = train_test_split[train_test_split[1] == is_train_image].index.tolist()\n",
    "        self.id_to_img = pd.read_csv(os.path.join(self.root, 'images.txt'),\n",
    "                                     sep=' ', index_col=0, header=None)\n",
    "\n",
    "        raw_mtx = np.loadtxt(os.path.join(self.root,\n",
    "                                          self.attribute_file))\n",
    "        raw_mtx[raw_mtx == -1] = 0\n",
    "        raw_mtx = raw_mtx / raw_mtx.max()\n",
    "        self.attribute_mtx = torch.tensor(raw_mtx, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_ids[idx]\n",
    "        img_name = self.id_to_img[self.id_to_img.index == img_id].values[0][0]\n",
    "        img_path = os.path.join(self.data_dir, img_name)\n",
    "\n",
    "        img = imageio.imread(img_path, pilmode='RGB')\n",
    "        label = int(img_name[:3]) - 1\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label, img_path\n",
    "    \n",
    "    \n",
    "class AWA2(Dataset):\n",
    "    \"\"\"Animals with Attributes 2 dataset.\"\"\"\n",
    "    split_file = 'train_test_classification_split.txt'\n",
    "    data_dir = 'awa2'\n",
    "    attribute_file = 'predicate-matrix-continuous.txt'\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, normalize=True,\n",
    "                 download=None):\n",
    "        self.root = os.path.join(root, self.data_dir)\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "\n",
    "        meta_data = pd.read_csv(os.path.join(self.root,\n",
    "                                             self.split_file),\n",
    "                                sep=' ', index_col=0, header=None)\n",
    "        if train:\n",
    "            is_train_image = 1\n",
    "        else:\n",
    "            is_train_image = 0\n",
    "        self.img_ids = meta_data[meta_data[3] == is_train_image].index.tolist()\n",
    "        self.id_to_img = meta_data\n",
    "\n",
    "        raw_mtx = np.loadtxt(os.path.join(self.root,\n",
    "                                          self.attribute_file))\n",
    "        raw_mtx[raw_mtx == -1] = 0\n",
    "        raw_mtx = raw_mtx / raw_mtx.max()\n",
    "        self.attribute_mtx = torch.tensor(raw_mtx, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_ids[idx]\n",
    "        img_meta_data = self.id_to_img[self.id_to_img.index == img_id]\n",
    "        img_name = img_meta_data.values[0][0]\n",
    "        img_path = os.path.join(self.root, img_name)\n",
    "\n",
    "        img = imageio.imread(img_path, pilmode='RGB')\n",
    "        label = img_meta_data.values[0][1] - 1\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "# device = torch.device('cpu')\n",
    "\n",
    "# create dataloader objects for train, val and test\n",
    "dl = DataLoader(dataset=dataset)\n",
    "# dataloaders, classes = dl.load_data(4, 4, data_path)# 128 insted of \n",
    "dataloaders, classes = dl.load_data(64, 4, data_path)# 128 insted of \n",
    "\n",
    "# attributes (312 column vectors with 200 rows) -> each class can be described with 312 attributes\n",
    "# percentage of time, human annotator thought, the attribute was present\n",
    "attribute_mtx = dataloaders['train'].dataset.dataset.attribute_mtx\n",
    "\n",
    "# create binary encoding for class attributes\n",
    "attribute_mtx[attribute_mtx < 0.5] = 0.0\n",
    "attribute_mtx[attribute_mtx >= 0.5] = 1.0\n",
    "attribute_mtx = attribute_mtx.to(device) # cuda\n",
    "attribute_size = attribute_mtx.size(1) # number of available attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Models\n",
    "Here, we continue by defining the various models that our uRDTC consists of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Conv2d(in_channels, 20, kernel_size=3, stride=1),\n",
    "                                 nn.ReLU(True),\n",
    "                                 nn.BatchNorm2d(20),\n",
    "                                 nn.Conv2d(20, 50, kernel_size=5, stride=2),\n",
    "                                 nn.ReLU(True),\n",
    "                                 nn.BatchNorm2d(50),\n",
    "                                 nn.Conv2d(50, 100, kernel_size=5, stride=2),\n",
    "                                 nn.ReLU(True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class DropoutCNN(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 20, kernel_size=3, stride=1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, kernel_size=5, stride=2)\n",
    "        self.conv3 = nn.Conv2d(50, 100, kernel_size=5, stride=2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.dropout2d(F.relu(self.conv1(x)), 0.2)\n",
    "        x = F.dropout2d(F.relu(self.conv2(x)), 0.2)\n",
    "        x = F.dropout2d(F.relu(self.conv3(x)), 0.2)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def get_cnn(in_channels, type='cnn', pretrained_cnn_weights=None,\n",
    "            freeze_weights=False, default_pretrained=False):\n",
    "    TYPES = ['cnn', 'dropoutcnn', 'resnet152'] # TYPES = ['cnn', 'shallowcnn', 'resnet', 'resnet152']\n",
    "    assert type in TYPES\n",
    "\n",
    "    if type == 'cnn':\n",
    "        cnn = CNN(in_channels)\n",
    "    if type == 'dropoutcnn':\n",
    "        cnn = DropoutCNN(in_channels)\n",
    "#     if type == 'resnet152':\n",
    "#         cnn = models.resnet152(pretrained=default_pretrained)\n",
    "    else:\n",
    "        cnn = Identity()\n",
    "\n",
    "    # if pretrained_cnn_weights:\n",
    "    #     if type == 'resnet152':\n",
    "    #         cnn.fc = nn.Linear(cnn.fc.in_features, pretrained_cnn_weights['fc.weight'].size(0))\n",
    "    #     cnn.load_state_dict(pretrained_cnn_weights)\n",
    "    if pretrained_cnn_weights:\n",
    "        cnn.load_state_dict(pretrained_cnn_weights)\n",
    "    \n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OC(nn.Module):\n",
    "    def __init__(self, model_type, num_classes, cnn_type, input_channels, cnn_out_size,\n",
    "                 dataset, decision_size=2, max_iters=20, attribute_size=20, attribute_mtx=None, attribute_coef=0.5, hidden_size=100,\n",
    "                 tau_initial=5, tau_target=0.5, use_pretrained=False, shallow=False, strategy='aRDTC'):\n",
    "        super(OC, self).__init__()\n",
    "        assert model_type in ['xoc'] #, 'ioc']\n",
    "        self.model_type = model_type\n",
    "        self.num_classes = num_classes\n",
    "        self.attribute_size = attribute_size\n",
    "        self.attribute_mtx = attribute_mtx\n",
    "        self.attribute_coef = attribute_coef if attribute_mtx is not None else 0.\n",
    "        self.decision_size = decision_size # change keyword default to 3?\n",
    "        self.tau_initial = tau_initial\n",
    "        self.tau_target = tau_target\n",
    "        self.max_iters = max_iters\n",
    "        self.shallow = shallow\n",
    "        self.stats = defaultdict(list)\n",
    "        self.reduced_vocab_size = 2\n",
    "        self.strategy = strategy\n",
    "\n",
    "        self.no_lstm = False\n",
    "\n",
    "        #self.init_attribute_matrix(attribute_mtx, attribute_size, attribute_coef, use_bin_attr)\n",
    "\n",
    "        self.cnn = self.init_cnn(cnn_type, input_channels, dataset, use_pretrained)\n",
    "        self.init_network(hidden_size, decision_size, num_classes, attribute_size, cnn_out_size, shallow)\n",
    "\n",
    "        self.init_losses()\n",
    "\n",
    "\n",
    "\n",
    "        self.phase = 'train'\n",
    "\n",
    "        # for stats\n",
    "        self.logits_list = []\n",
    "        self.sigmas_list = []\n",
    "#         self.labels_list\n",
    "        self.binary_features_list = []\n",
    "        self.labels_list = []\n",
    "        self.used_attributes_list = []\n",
    "        self.certain_attrs = []\n",
    "        self.attribute_accuracies = []\n",
    "        self.drop_ratios = []\n",
    "        self.mean_sigmas = []\n",
    "        \n",
    "\n",
    "    def init_network(self, hidden_size, decision_size, num_classes, attribute_size, cnn_out_size, shallow):\n",
    "        assert decision_size > 1\n",
    "\n",
    "        # LSTM initialization parameters\n",
    "        if self.no_lstm:\n",
    "            self.init_h0 = nn.Parameter(torch.zeros(attribute_size * decision_size), requires_grad=False)\n",
    "            self.init_c0 = nn.Parameter(torch.zeros(attribute_size * decision_size), requires_grad=False)\n",
    "        else:\n",
    "            self.init_h0 = nn.Parameter(torch.zeros(hidden_size).uniform_(-0.01, 0.01), requires_grad=True)\n",
    "            self.init_c0 = nn.Parameter(torch.zeros(hidden_size).uniform_(-0.01, 0.01), requires_grad=True)\n",
    "\n",
    "        if self.no_lstm:\n",
    "            self.lstm = lambda x, y: (None, (x.squeeze(), x.squeeze()))\n",
    "        else:\n",
    "            self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "\n",
    "        if self.no_lstm:\n",
    "            classifier_in = attribute_size * decision_size\n",
    "        else:\n",
    "            classifier_in = attribute_size * decision_size\n",
    "\n",
    "        self.classifier = nn.Sequential(#nn.BatchNorm1d(classifier_in) if not self.no_lstm else Identity(),\n",
    "                                        nn.Linear(classifier_in, hidden_size),\n",
    "                                        nn.ReLU(inplace=True),\n",
    "                                        nn.BatchNorm1d(hidden_size),\n",
    "                                        nn.Linear(hidden_size, num_classes))\n",
    "\n",
    "        if self.model_type == 'xoc':\n",
    "            if self.no_lstm:\n",
    "                feat_select_in_size = attribute_size * decision_size\n",
    "            else:\n",
    "                feat_select_in_size = hidden_size\n",
    "            feat_select_out_size = attribute_size\n",
    "            pre_lstm_size = attribute_size * decision_size * 2\n",
    "\n",
    "            bin_feat_type = 'shallow' if shallow else 'dropoutmlp' #'mlp'\n",
    "            feat_select_type = 'mlp_small'\n",
    "\n",
    "        elif self.model_type == 'ioc':\n",
    "            bin_feat_type = 'identity'\n",
    "            feat_select_type = 'mlp_big'\n",
    "\n",
    "            if not shallow:\n",
    "                feat_select_in_size = cnn_out_size + hidden_size\n",
    "                feat_select_out_size = decision_size\n",
    "                pre_lstm_size = feat_select_out_size\n",
    "            else:\n",
    "                feat_select_in_size = hidden_size\n",
    "                feat_select_out_size = cnn_out_size * decision_size\n",
    "                pre_lstm_size = decision_size\n",
    "\n",
    "        if feat_select_type == 'mlp_small':\n",
    "            self.feature_selection = nn.Sequential(nn.BatchNorm1d(feat_select_in_size) if not self.no_lstm else Identity(),\n",
    "                                                   nn.Linear(feat_select_in_size , hidden_size),\n",
    "                                                   nn.ReLU(inplace=True),\n",
    "                                                   nn.BatchNorm1d(hidden_size),\n",
    "                                                   nn.Linear(hidden_size, feat_select_out_size))\n",
    "        elif feat_select_type == 'mlp_big':\n",
    "            self.feature_selection = nn.Sequential(nn.BatchNorm1d(feat_select_in_size) if not self.no_lstm else Identity(),\n",
    "                                                   nn.Linear(feat_select_in_size, hidden_size),\n",
    "                                                   nn.ReLU(inplace=True),\n",
    "                                                   nn.BatchNorm1d(hidden_size),\n",
    "                                                   nn.Linear(hidden_size, hidden_size),\n",
    "                                                   nn.ReLU(inplace=True),\n",
    "                                                   nn.BatchNorm1d(hidden_size),\n",
    "                                                   nn.Linear(hidden_size, feat_select_out_size))\n",
    "\n",
    "        if bin_feat_type == 'identity':\n",
    "            self.binary_features = Identity()\n",
    "        elif bin_feat_type == 'shallow':\n",
    "            class AddZeros(nn.Module):\n",
    "                def __init__(self):\n",
    "                    super().__init__()\n",
    "\n",
    "                def forward(self, x):\n",
    "                    zeros = torch.zeros_like(x).unsqueeze(2)\n",
    "                    return torch.cat((x.unsqueeze(2), zeros), dim=2)\n",
    "\n",
    "            self.binary_features = AddZeros()\n",
    "        elif bin_feat_type == 'mlp':\n",
    "            self.binary_features = nn.Sequential(nn.BatchNorm1d(cnn_out_size), # use dropout\n",
    "                                                 nn.Linear(cnn_out_size, hidden_size),\n",
    "                                                 nn.ReLU(inplace=True),\n",
    "                                                 nn.BatchNorm1d(hidden_size), # use dropout\n",
    "                                                 nn.Linear(hidden_size, hidden_size),\n",
    "                                                 nn.ReLU(inplace=True),\n",
    "                                                 nn.BatchNorm1d(hidden_size), # use dropout\n",
    "                                                 nn.Linear(hidden_size, attribute_size * self.reduced_vocab_size))\n",
    "        elif bin_feat_type == 'dropoutmlp':\n",
    "            self.binary_features = nn.Sequential(\n",
    "                                                nn.Linear(cnn_out_size, hidden_size),\n",
    "                                                nn.ReLU(inplace=False),\n",
    "                                                nn.Dropout(0.2, inplace=False),\n",
    "                                                nn.Linear(hidden_size, hidden_size),\n",
    "                                                nn.ReLU(inplace=False),\n",
    "                                                nn.Dropout(0.2, inplace=False),\n",
    "                                                nn.Linear(hidden_size, attribute_size * self.reduced_vocab_size)\n",
    "                                                )\n",
    "\n",
    "        if self.no_lstm:\n",
    "            self.pre_lstm = Identity()\n",
    "        else:\n",
    "            self.pre_lstm = nn.Sequential(#nn.BatchNorm1d(pre_lstm_size),\n",
    "                                          nn.Linear(pre_lstm_size, hidden_size),\n",
    "                                          nn.ReLU(inplace=True),\n",
    "                                          nn.BatchNorm1d(hidden_size))\n",
    "\n",
    "\n",
    "        # Temperature parameters\n",
    "        self.binary_features.tau = nn.Parameter(torch.tensor([self.tau_initial], dtype=torch.float), requires_grad=True)\n",
    "        self.feature_selection.tau = nn.Parameter(torch.tensor([self.tau_initial], dtype=torch.float), requires_grad=True)\n",
    "        #self.init_weights()\n",
    "\n",
    "    \n",
    "    \n",
    "    def get_attribute_uncertainty(self, image_features, n=10, batch_size=64):\n",
    "        outputs = torch.zeros((n, batch_size, attribute_size * self.reduced_vocab_size), device=device)\n",
    "        \n",
    "        if self.phase == 'train':\n",
    "            for i in range(n):\n",
    "                outputs[i] = F.softmax(self.binary_features(image_features))\n",
    "#                 outputs[i] = self.binary_features(image_features)\n",
    "\n",
    "        if self.phase == 'test':\n",
    "            for layer in self.binary_features:\n",
    "                if isinstance(layer, torch.nn.modules.dropout._DropoutNd):\n",
    "                    layer.train()\n",
    "#             self.binary_features.train()\n",
    "            for i in range(n):\n",
    "                outputs[i] = F.softmax(self.binary_features(image_features))\n",
    "#                 outputs[i] = self.binary_features(image_features)\n",
    "\n",
    "            for layer in self.binary_features:\n",
    "                if isinstance(layer, torch.nn.modules.dropout._DropoutNd):\n",
    "                    layer.eval()\n",
    "#             self.binary_features.eval()\n",
    "        \n",
    "        sigmas = outputs.var(dim=0)\n",
    "#         sigmas += (0.01**2 * 0.5)/(2 * image_features.size(0) * weight_decay)\n",
    "            \n",
    "            \n",
    "        return sigmas\n",
    "    \n",
    "    def get_attribute_uncertainty_new(self, image_features, n=10, batch_size=64):\n",
    "        outputs = torch.zeros((n, batch_size, attribute_size * self.reduced_vocab_size), device=device)\n",
    "        \n",
    "        if self.phase == 'train':\n",
    "            for i in range(n):\n",
    "                outputs[i] = F.softmax(self.binary_features(image_features), dim=1)\n",
    "#                 outputs[i] = self.binary_features(image_features)\n",
    "\n",
    "        if self.phase == 'test':\n",
    "            for layer in self.binary_features:\n",
    "                if isinstance(layer, torch.nn.modules.dropout._DropoutNd):\n",
    "                    layer.train()\n",
    "#             self.binary_features.train()\n",
    "            for i in range(n):\n",
    "                outputs[i] = F.softmax(self.binary_features(image_features), dim=1)\n",
    "#                 outputs[i] = self.binary_features(image_features)\n",
    "\n",
    "            for layer in self.binary_features:\n",
    "                if isinstance(layer, torch.nn.modules.dropout._DropoutNd):\n",
    "                    layer.eval()\n",
    "#             self.binary_features.eval()\n",
    "        \n",
    "        decision_sigma = outputs.var(dim=0)\n",
    "        attribute_sigma = decision_sigma.view(batch_size, -1, 2).mean(dim=2)\n",
    "#         attribute_sigma += (0.01**2 * 0.5)/(2 * batch_size * weight_decay)\n",
    "            \n",
    "        return attribute_sigma\n",
    "  \n",
    "    def init_attribute_matrix(self, attribute_mtx, attribute_size, attribute_coef, use_bin_attr):\n",
    "        if attribute_coef > 0.:\n",
    "            if use_bin_attr:\n",
    "                attribute_mtx[attribute_mtx < 0.5] = 0.\n",
    "                attribute_mtx[attribute_mtx >= 0.5] = 1.\n",
    "            self.attribute_mtx = nn.Parameter(attribute_mtx, requires_grad=False)\n",
    "            self.attribute_size = attribute_mtx.size(1)\n",
    "        else:\n",
    "            self.attribute_mtx = None\n",
    "            self.attribute_size = attribute_size\n",
    "\n",
    "    def toggle_update_schedule(self):\n",
    "        # TODO: see a few lines below\n",
    "        #self.update_binary_features = not self.update_binary_features\n",
    "        pass\n",
    "\n",
    "    def get_param_groups(self):\n",
    "        cnn_params = []\n",
    "        tree_params = []\n",
    "        for n, p in self.named_parameters():\n",
    "            if p.requires_grad:\n",
    "                # TODO: introduce parameter that allows to switch between training alternatingly\n",
    "                # Currently commented out, so both groups contain the same parameters\n",
    "                \"\"\"\n",
    "                if n.startswith('cnn') or n.startswith('binary_features'):\n",
    "                    print('CNN', n)\n",
    "                    cnn_params.append(p)\n",
    "                else:\n",
    "                    print('OTHER', n)\n",
    "                    tree_params.append(p)\n",
    "                \"\"\"\n",
    "                cnn_params.append(p)\n",
    "                tree_params.append(p)\n",
    "        return tree_params, cnn_params\n",
    "\n",
    "    def set_optimizer(self, optimizers):\n",
    "        self.tree_optimizer = optimizers[0]\n",
    "        self.cnn_optimizer = optimizers[1]\n",
    "\n",
    "    def set_scheduler(self, schedulers):\n",
    "        self.tree_scheduler = schedulers[0]\n",
    "        self.cnn_scheduler = schedulers[1]\n",
    "\n",
    "    def get_optimizer(self):\n",
    "        if self.update_binary_features:\n",
    "            return self.cnn_optimizer\n",
    "        else:\n",
    "            return self.tree_optimizer\n",
    "\n",
    "    def get_scheduler(self):\n",
    "        if self.update_binary_features:\n",
    "            return self.cnn_scheduler\n",
    "        else:\n",
    "            return self.tree_scheduler\n",
    "\n",
    "    def init_losses(self):\n",
    "        self.cls_loss = nn.CrossEntropyLoss()\n",
    "        self.attr_loss = nn.BCEWithLogitsLoss()\n",
    "        self.update_binary_features = False\n",
    "\n",
    "    def init_cnn(self, cnn_type, input_channels, dataset, use_pretrained):\n",
    "        if cnn_type == 'None':\n",
    "            cnn = Identity()\n",
    "        else:\n",
    "            if use_pretrained:\n",
    "                # TODO add data_path and change state dict name \n",
    "                # cnn_state_dict = torch.load('pretrained/{}_{}.pth'.format(dataset, cnn_type))\n",
    "#                 cnn_state_dict = torch.load('pretrained/cub_resnet152.pkl')# .format(dataset, cnn_type)\n",
    "                cnn_state_dict = torch.load('pretrained/{}_resnet152.pkl'.format(dataset))# .format(dataset, cnn_type)\n",
    "\n",
    "                cnn = get_cnn(input_channels, cnn_type, cnn_state_dict, freeze_weights=True)\n",
    "            else:\n",
    "                cnn = get_cnn(input_channels, cnn_type)\n",
    "\n",
    "        return cnn\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight.data)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.fill_(0.1)\n",
    "\n",
    "    def set_tau(self, epoch):\n",
    "        annealing_factor = epoch / 100\n",
    "        self.tau = self.tau_initial\n",
    "        self.tau -= (self.tau_initial - self.tau_target) * annealing_factor\n",
    "        self.tau = max(self.tau, self.tau_target)\n",
    "\n",
    "    def process_images_new(self, images):\n",
    "        batch_size = images.size(0)\n",
    "        img_feats = self.cnn(images)\n",
    "        img_feats = img_feats.view(img_feats.size(0), -1)\n",
    "        image_features = self.binary_features(img_feats) \n",
    "        with torch.no_grad():\n",
    "            attribute_uncertainties = self.get_attribute_uncertainty_new(img_feats, n=5, batch_size=images.size(0))\n",
    "        \n",
    "        if self.model_type == 'xoc':\n",
    "            attribute_logits = image_features.view(-1, 2)\n",
    "\n",
    "\n",
    "            attributes_softmax = F.softmax(attribute_logits / self.binary_features.tau, dim=1)\n",
    "            attributes_hard = self.argmax(attributes_softmax, dim=1)\n",
    "            image_features = attributes_hard.view(images.size(0), -1, 2)\n",
    "\n",
    "            # TODO: generalize to different decision sizes\n",
    "            bin_attribute_logits = attribute_logits - attribute_logits[:, 1].unsqueeze(-1)\n",
    "            self.attribute_logits = bin_attribute_logits[:, 0].view(images.size(0), -1)\n",
    "\n",
    "            self.collect_hist_stats('AttributesSoft', F.softmax(attribute_logits, dim=1))\n",
    "            self.collect_hist_stats('AttributesSoftTemp', attributes_softmax)\n",
    "            self.collect_hist_stats('AttributesHard', attributes_hard.max(dim=1)[1])\n",
    "\n",
    "        return image_features, attribute_uncertainties\n",
    "\n",
    "\n",
    "    def process_images(self, images):\n",
    "        batch_size = images.size(0)\n",
    "        img_feats = self.cnn(images)\n",
    "        img_feats = img_feats.view(img_feats.size(0), -1)\n",
    "        image_features = self.binary_features(img_feats)\n",
    "        # print(image_features.size())\n",
    "        ################## remove attrs code\n",
    "#         sigmas = self.get_attribute_uncertainty_batch(img_feats,n=100, batch_size=batch_size)\n",
    "        \n",
    "        if self.strategy == 'remRDTC':\n",
    "            with torch.no_grad():\n",
    "                sigmas = self.get_attribute_uncertainty(img_feats, n=5, batch_size=images.size(0))\n",
    "            uncertain_attrs = (sigmas > 0.03925).float() # get binary uncertain attrs\n",
    "            certain_attrs = 1. - uncertain_attrs\n",
    "            mask = certain_attrs.detach()\n",
    "            inv_mask = 1-mask\n",
    "            min_value = image_features.min()\n",
    "            image_features = image_features * mask # put zeros where uncertain attts are\n",
    "            image_features = image_features - (inv_mask.detach()*min_value.detach()) #*-500\n",
    "\n",
    "#         sigmas.detach()\n",
    "#         sigmas.cuda()\n",
    "#         self.mean_sigmas.append(sigmas.mean().item())\n",
    "#         drop_ratio = (sigmas>0.005).float().sum()/(images.size(0)*attribute_size*2.)\n",
    "#         min_value = image_features.min()\n",
    "#         min_value.detach()\n",
    "#         self.drop_ratios.append(drop_ratio)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #############################################################\n",
    "#         if not self.training:\n",
    "\n",
    "#             self.sigmas_list.append(sigmas)\n",
    "            # self.logits_list.append(image_features)\n",
    "            # image_features = torch.cat((attribute_logits, sigmas),1)\n",
    "        \n",
    "        \n",
    "        ################## remove attrs\n",
    "#         uncertain_attrs = (sigmas > 0.005).float() # get binary uncertain attrs\n",
    "#         certain_attrs = 1. - uncertain_attrs\n",
    "#         mask = certain_attrs.detach()#(torch.FloatTensor(image_features.size()).uniform_() > 0.050).float().to(device)\n",
    "        if self.strategy == 'randRDTC':\n",
    "            mask = (torch.FloatTensor(image_features.size()).uniform_() > 0.050).float().to(device)\n",
    "            inv_mask = 1-mask\n",
    "#         self.drop_ratios.append((inv_mask.sum()/39936.0).item())\n",
    "#         mask.detach()\n",
    "            min_value = image_features.min()\n",
    "            image_features = image_features * mask # put zeros where uncertain attts are\n",
    "            image_features = image_features - (inv_mask.detach()*min_value.detach()) #*-500\n",
    "        ##############################################################\n",
    "\n",
    "        if self.model_type == 'xoc':\n",
    "            attribute_logits = image_features.view(-1, 2)\n",
    "\n",
    "\n",
    "            attributes_softmax = F.softmax(attribute_logits / self.binary_features.tau, dim=1)\n",
    "            attributes_hard = self.argmax(attributes_softmax, dim=1)\n",
    "            image_features = attributes_hard.view(images.size(0), -1, 2)\n",
    "\n",
    "            # TODO: generalize to different decision sizes\n",
    "            bin_attribute_logits = attribute_logits - attribute_logits[:, 1].unsqueeze(-1)\n",
    "            self.attribute_logits = bin_attribute_logits[:, 0].view(images.size(0), -1)\n",
    "\n",
    "            self.collect_hist_stats('AttributesSoft', F.softmax(attribute_logits, dim=1))\n",
    "            self.collect_hist_stats('AttributesSoftTemp', attributes_softmax)\n",
    "            self.collect_hist_stats('AttributesHard', attributes_hard.max(dim=1)[1])\n",
    "\n",
    "        return image_features\n",
    "\n",
    "    def make_decision(self, lstm_out, binary_features, iter, sigma=[], max_uncertainty=0.2):\n",
    "        if self.model_type == 'xoc':\n",
    "            # Perform categorical feature selection\n",
    "            selection_logits = self.feature_selection(lstm_out)\n",
    "            \n",
    "            if self.strategy == 'remRDTC':\n",
    "                \n",
    "                uncertain_attributes = (sigma > 2e-4).float()\n",
    "#                 dummy = torch.zeros((sigma.size()), device=device)\n",
    "#                 dummy[uncertain_attributes] = -np.inf\n",
    "# #                 print(np.quantile(sigma.cpu().numpy(),0.99))\n",
    "# #                 attribute_uncertainties = torch.rand(binary_features.size(0), attribute_size, device=device, requires_grad=False)\n",
    "#                 self.mean_sigmas.append(sigma.mean().item())\n",
    "\n",
    "                \n",
    "                certain_attributes = 1. - uncertain_attributes\n",
    "                selection_logits = certain_attributes.detach() * selection_logits + uncertain_attributes.detach() * -100\n",
    "#             else:\n",
    "#                 new_selection_logits = selection_logits    \n",
    "#                 selection_probs = torch.softmax((selection_logits+dummy)/0.01, dim=1)\n",
    "    \n",
    "                if self.training:\n",
    "                    hard_selection = F.gumbel_softmax(selection_logits, tau=self.feature_selection.tau, hard=True)\n",
    "                else:\n",
    "#                     print(sigma.mean())\n",
    "                    hard_selection = self.argmax(selection_logits, dim=1)\n",
    "#                     print(hard_selection)\n",
    "\n",
    "            \n",
    "            else: # if another strategy is used\n",
    "                if self.training:\n",
    "                    hard_selection = F.gumbel_softmax(selection_logits, tau=self.feature_selection.tau, hard=True)\n",
    "                else:\n",
    "                    hard_selection = self.argmax(selection_logits, dim=1)\n",
    "\n",
    "\n",
    "            # Get single decision\n",
    "            self.saved_attribute_selection = hard_selection.max(dim=1)[1]\n",
    "            \n",
    "\n",
    "            decision = (hard_selection.unsqueeze(2) * binary_features).view(-1, self.attribute_size * self.decision_size)\n",
    "            # print(decision[0])\n",
    "        elif self.model_type == 'ioc':\n",
    "            if not self.shallow:\n",
    "                features = torch.cat((lstm_out, binary_features), dim=1)\n",
    "                selection_logits = self.feature_selection(features)\n",
    "            else:\n",
    "                shallow_weights = self.feature_selection(lstm_out)\n",
    "                shallow_weights = shallow_weights.view(lstm_out.size(0), -1, self.decision_size)\n",
    "                selection_logits = torch.bmm(binary_features.unsqueeze(1), shallow_weights)\n",
    "                selection_logits = selection_logits.squeeze()\n",
    "\n",
    "            soft_decision = F.softmax(selection_logits / self.tau_selection, dim=1)\n",
    "            hard_selection = self.argmax(soft_decision, dim=1)\n",
    "            decision = hard_selection\n",
    "\n",
    "        # Collect statistics\n",
    "        self.collect_hist_stats('SelectionSoft', F.softmax(selection_logits, dim=1).max(dim=1)[0], iter)\n",
    "        self.collect_hist_stats('SelectionSoftTemp', F.softmax(selection_logits / self.feature_selection.tau, dim=1).max(dim=1)[0], iter)\n",
    "        self.collect_hist_stats('SelectionHard', hard_selection.max(dim=1)[1], iter)\n",
    "\n",
    "        return decision\n",
    "\n",
    "    def get_initial_state(self, batch_size):\n",
    "        h0 = self.init_h0.view(1, 1, -1).expand(-1, batch_size, -1)\n",
    "        c0 = self.init_c0.view(1, 1, -1).expand(-1, batch_size, -1)\n",
    "        state = (h0.contiguous(), c0.contiguous())\n",
    "        return state\n",
    "\n",
    "    def argmax(self, y_soft, dim):\n",
    "        index = y_soft.max(dim, keepdim=True)[1]\n",
    "        y_hard = torch.zeros_like(y_soft).scatter_(dim, index, 1.0)\n",
    "        argmax = y_hard - y_soft.detach() + y_soft\n",
    "        return argmax\n",
    "\n",
    "    def collect_hist_stats(self, name, data, i=None):\n",
    "        # TODO: investigate performance impact of collecting these statistics,\n",
    "        # make option to disable and/or autodisable if tree is too large\n",
    "        if 'Hard' in name:\n",
    "            stat_str = 'Hist/' + name\n",
    "            data = data.detach().cpu()\n",
    "            self.stats[stat_str].append(data)\n",
    "            if i is not None:\n",
    "                stat_str += str(i)\n",
    "                self.stats[stat_str].append(data)\n",
    "\n",
    "    def get_hist_stats(self, reset=True):\n",
    "        stats = self.stats\n",
    "        if reset:\n",
    "            self.stats = defaultdict(list)\n",
    "        #return None\n",
    "        return stats\n",
    "\n",
    "    def reset_stats(self):\n",
    "        self.unique_attributes = [set() for i in range(self.max_iters)]\n",
    "        if self.attribute_coef > 0.:\n",
    "            self.attr_pred_correct = [0 for i in range(self.max_iters)]\n",
    "\n",
    "    def update_unique_attributes(self, unique_attributes, iter):\n",
    "        for attr in unique_attributes:\n",
    "            self.unique_attributes[iter].add(attr.item())\n",
    "\n",
    "    def get_unique_attributes(self):\n",
    "        uniq_per_iter = []\n",
    "        for i in range(self.max_iters):\n",
    "            iter_set = self.unique_attributes[i]\n",
    "            for j in range(i+1):\n",
    "                if j == i:\n",
    "                    continue\n",
    "                iter_set = iter_set.union(self.unique_attributes[j])\n",
    "            uniq_per_iter.append(len(iter_set))\n",
    "        return uniq_per_iter\n",
    "\n",
    "    def update_attr_preds(self, attr_correct, iter):\n",
    "        self.attr_pred_correct[iter] += attr_correct\n",
    "\n",
    "    def get_attr_acc(self, total_cnt):\n",
    "        correct_cumsum = np.cumsum(self.attr_pred_correct)\n",
    "        cnt_per_iter = (np.arange(self.max_iters) + 1) * total_cnt\n",
    "        return correct_cumsum / cnt_per_iter\n",
    "\n",
    "    def init_tree_stats(self):\n",
    "        # TODO: investigate performance impact of collecting these statistics,\n",
    "        # make option to disable and/or autodisable if tree is too large\n",
    "\n",
    "        # Would be nice if this worked with sparse tensors\n",
    "        n_possible_states = self.reduced_vocab_size** self.max_iters\n",
    "        self.label_stats = torch.zeros((n_possible_states * self.reduced_vocab_size,\n",
    "                                        self.num_classes), dtype=torch.int32)\n",
    "                                       #layout=torch.sparse_coo)\n",
    "        self.selection_stats = torch.zeros((n_possible_states,\n",
    "                                            self.attribute_size),\n",
    "                                           dtype=torch.int32)\n",
    "                                           #layout=torch.sparse_coo)\n",
    "\n",
    "    def update_tree_stats(self, attribute_selection, attribute_decisions, labels, iter):\n",
    "        # TODO: investigate performance impact of collecting these statistics,\n",
    "        # make option to disable and/or autodisable if tree is too large\n",
    "\n",
    "        if iter == 0:\n",
    "            self.batch_states = torch.zeros_like(labels)\n",
    "            for i in range(labels.size(0)):\n",
    "                self.label_stats[self.batch_states[i], labels[i]] += 1\n",
    "\n",
    "        for i in range(labels.size(0)):\n",
    "            self.selection_stats[self.batch_states[i], attribute_selection[i]] += 1\n",
    "            self.batch_states[i] += (attribute_decisions[i] + 1) * self.decision_size ** iter\n",
    "            self.label_stats[self.batch_states[i], labels[i]] += 1\n",
    "\n",
    "    def run_iteration(self, binary_features, state, decision_hist, iter, sigma=[]): # also pass sigma here\n",
    "        lstm_out = state[0].squeeze(0)\n",
    "\n",
    "        # Make binary decision\n",
    "        decision = self.make_decision(lstm_out, binary_features, iter, sigma)\n",
    "\n",
    "        if decision_hist is None:\n",
    "            decision_hist = decision\n",
    "        else:\n",
    "            decision_hist = (decision_hist + decision).clamp(0., 1.)\n",
    "\n",
    "        scaled_dh = decision_hist / decision_hist.sum(dim=1).unsqueeze(1).detach()\n",
    "        if self.no_lstm:\n",
    "            lstm_in = scaled_dh\n",
    "        else:\n",
    "            lstm_in = torch.cat((scaled_dh, decision), dim=1)\n",
    "\n",
    "        # Update LSTM state\n",
    "        lstm_in = self.pre_lstm(lstm_in).unsqueeze(1)\n",
    "        _, state = self.lstm(lstm_in, state)\n",
    "\n",
    "        # Get current classification\n",
    "        classifier_in = scaled_dh\n",
    "        #classifier_in = state[1].squeeze(0)\n",
    "        #classifier_in = torch.cat((decision_hist, self.lstm_state_bn(lstm_state)), dim=1)\n",
    "        classification = self.classifier(classifier_in)\n",
    "\n",
    "        return classification, state, decision_hist\n",
    "\n",
    "    def tree_rollout(self, images, labels, keep_tree_stats=False):\n",
    "        # Set initial state\n",
    "        state = self.get_initial_state(images.size(0))\n",
    "\n",
    "        # Get categorical features once\n",
    "#         binary_features = self.process_images(images)\n",
    "        \n",
    "        binary_features, attribute_uncertainties = self.process_images_new(images)\n",
    "#         print(alt_binary_features.size())\n",
    "#         print(attribute_uncertainties.size())\n",
    "        # collect attribute stats\n",
    "\n",
    "#         attr_acc = (binary_features[:,:,0] == attribute_mtx[labels]).sum().long() / 19968.0 #/ (312*labels.size(0))\n",
    "#         attr_acc = (binary_features[:,:,0] == attribute_mtx[labels]).sum().long() / float((attribute_size*labels.size(0)))    \n",
    "#         print(attr_acc)\n",
    "#         self.attribute_accuracies.append(attr_acc.item())\n",
    "#         self.mean_sigmas.append(attribute_uncertainties.mean().item())\n",
    "#         uncertain_attributes = (attribute_uncertainties > 2e-4).float()\n",
    "#         self.drop_ratios.append((uncertain_attributes.sum()/19968.0).item())\n",
    "        self.sigmas_list.append(attribute_uncertainties)\n",
    "        self.labels_list.append(labels)\n",
    "\n",
    "\n",
    "        ######################### extended vocab code \n",
    "        if self.strategy == 'extRDTC':\n",
    "#             if not self.training:\n",
    "#                 self.sigmas_list.append(attribute_uncertainties)\n",
    "#                 self.labels_list.append(labels)\n",
    "#                 self.binary_features_list.append(binary_features)\n",
    "#                 self.labels_list.append(labels)\n",
    "\n",
    "\n",
    "            uncertain_attributes = (attribute_uncertainties>2e-5).float().unsqueeze(2)\n",
    "#             print(uncertain_attributes.size())\n",
    "#             print()\n",
    "#             self.drop_ratios.append((uncertain_attributes.sum()/19968.0).item())\n",
    "\n",
    "            # obtain uncertainty and append to decision\n",
    "            new_attribute_decisions = torch.cat([binary_features, torch.zeros_like(uncertain_attributes, device=device)], dim=2)\n",
    "            certain_decisions = 1. - uncertain_attributes\n",
    "            uncertain_onehot = torch.tensor([[0., 0., 1.]], device=device).repeat(images.size(0), attribute_size, 1)\n",
    "            uncertain_attrs_removed = certain_decisions.detach() * new_attribute_decisions\n",
    "            shaped_uncertain_attrs = uncertain_attributes.detach() * uncertain_onehot\n",
    "            final_attribute_decisions = uncertain_attrs_removed + shaped_uncertain_attrs\n",
    "            binary_features = final_attribute_decisions\n",
    "#         ######################### extended vocab code end\n",
    "        \n",
    "        \n",
    "\n",
    "        loss = 0\n",
    "        j = 0\n",
    "        # stats\n",
    "        all_classifications = []\n",
    "        all_chosen_attr = []\n",
    "        all_attribute_preds = []\n",
    "\n",
    "        decision_hist = None\n",
    "        while j < self.max_iters:\n",
    "            classification, state, decision_hist = self.run_iteration(binary_features, state, decision_hist, j+1, sigma=attribute_uncertainties)\n",
    "            loss += (1. - self.attribute_coef) * self.cls_loss(classification, labels)\n",
    "            all_classifications.append(classification)\n",
    "\n",
    "            self.update_unique_attributes(self.saved_attribute_selection.unique(), j)\n",
    "\n",
    "            if self.model_type == 'xoc' and self.attribute_coef > 0.:\n",
    "                chosen_attribtutes = self.saved_attribute_selection\n",
    "                attribute_logits = self.attribute_logits\n",
    "\n",
    "                attribute_target = self.attribute_mtx[labels, :].gather(1, chosen_attribtutes.unsqueeze(1)).squeeze()\n",
    "                attribute_pred = attribute_logits.gather(1, chosen_attribtutes.unsqueeze(1)).squeeze()\n",
    "                loss += self.attribute_coef * self.attr_loss(attribute_pred,\n",
    "                                                             attribute_target)\n",
    "                \n",
    "\n",
    "\n",
    "                attribute_pred_bin = (attribute_pred > 0.).long()\n",
    "                self.update_attr_preds((attribute_pred_bin == attribute_target).sum().item(), j)\n",
    "\n",
    "                \n",
    "            if keep_tree_stats:\n",
    "                attribute_pred = self.attribute_logits.gather(1, self.saved_attribute_selection.unsqueeze(1)).squeeze()\n",
    "                self.update_tree_stats(self.saved_attribute_selection, (attribute_pred > 0.).long(),labels, j)\n",
    "\n",
    "                # all_chosen_attr.append(self.saved_attribute_selection)\n",
    "                all_attribute_preds.append((attribute_pred > 0.).long())\n",
    "\n",
    "            j += 1\n",
    "        \n",
    "            all_chosen_attr.append(self.saved_attribute_selection)\n",
    "\n",
    "\n",
    "        self.tmp_saved_chosen_attr = torch.stack(all_chosen_attr, dim=1)\n",
    "\n",
    "        if keep_tree_stats:\n",
    "            self.tmp_saved_cls = torch.stack(all_classifications, dim=1)\n",
    "#             self.tmp_saved_chosen_attr = torch.stack(all_chosen_attr, dim=1)\n",
    "            self.tmp_saved_attr_pred = torch.stack(all_attribute_preds, dim=1)\n",
    "        # else:\n",
    "        #     self.tmp_saved_chosen_attr = None\n",
    "\n",
    "        loss = loss / self.max_iters\n",
    "                ####################################\n",
    "        self.used_attributes_list.append(self.tmp_saved_chosen_attr)\n",
    "#         if binary_features.size(0)==64:\n",
    "#             chosen_attributes_binary = torch.tensor([[1 if x in [int(attr) for attr in self.tmp_saved_chosen_attr[row,:]] else 0 for x in range(312)] for row in range(64)])\n",
    "#             self.used_attributes_list.append(chosen_attributes_binary)\n",
    "\n",
    "\n",
    "        return all_classifications, loss, self.tmp_saved_chosen_attr\n",
    "\n",
    "    def forward(self, images, labels, keep_tree_stats=False):\n",
    "        classification, loss, chosen_attribtutes = self.tree_rollout(images, labels, keep_tree_stats)\n",
    "        # classification, loss, chosen_attributes = self.tree_rollout(images, labels, keep_tree_stats)\n",
    "\n",
    "        return classification, loss#, chosen_attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "After defining our models, we can continue by training it. For this, we first set some hyperparameters and then continue by defining a trainer class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake input arguments\n",
    "model_type = 'xoc'\n",
    "cnn_type = 'uncertain'\n",
    "# cnn_type = 'resnet'\n",
    "attribute_coef = 0.2\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.#0.0001\n",
    "step_size = 50\n",
    "num_epochs = 2\n",
    "max_iters = 10\n",
    "hidden_size = 1000\n",
    "cnn_out_size = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, dataloaders, num_epochs, device, log_freq, log_path): # todo remove stats dict\n",
    "\n",
    "        self.model = model\n",
    "        self.dataloaders = dataloaders\n",
    "        self.num_epochs = num_epochs\n",
    "        self.device = device\n",
    "        self.log_freq = log_freq\n",
    "        self.log_path = log_path\n",
    "        \n",
    "        self.logger = SummaryWriter(self.log_path)\n",
    "\n",
    "        #### TODO remove this workaround and use tensorboard\n",
    "#         with open('/content/drive/My Drive/rdtc/data/' + 'logs/' + 'stats_dict.json') as json_file:\n",
    "#             self.stats_dict = json.load(json_file)\n",
    "        \n",
    "        self.classifications_dict = {'correct':{'num':0, 'uncertainty':0},\n",
    "                                     'incorrect':{'num':0, 'uncertainty':0}}\n",
    "\n",
    "        self.uncertainty_stats = {'epoch_{}'.format(epoch):{'used_attributes':[],'sigmas':[], 'num_attrs_discarded':0} for epoch in range(num_epochs+2)}\n",
    "        self.mean_attr_accs = []\n",
    "        self.mean_drop_ratio = []\n",
    "        self.mean_sigmas = []\n",
    "        ############\n",
    "\n",
    "    def train(self):\n",
    "        self.model.phase = 'train'\n",
    "        self.train_model(self.dataloaders['train'])\n",
    "\n",
    "    def test(self):\n",
    "        self.model.phase = 'test'\n",
    "        self.test_model(self.dataloaders['test'], 'test', None, hard=False) # was: hard=True\n",
    "        self.model.phase = 'train'\n",
    "#         return self.model.label_stats, self.model.selection_stats\n",
    "\n",
    "    def topk_correct(self, output, target, topk=(1,)):\n",
    "        maxk = max(topk)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        target_masks = []\n",
    "        target_cnt = []\n",
    "        for i in range(self.model.num_classes):\n",
    "            target_masks.append((target == i).unsqueeze(0))\n",
    "            target_cnt.append(target_masks[i].sum().item())\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = [(correct[:k] * tm).view(-1).float().sum(0, keepdim=True).item() for tm in target_masks]\n",
    "            res.append(np.array(correct_k))\n",
    "        return res, np.array(target_cnt)\n",
    "\n",
    "    def log_stats(self, phase, epoch, epoch_stats, hist_stats,\n",
    "                  unique_attr_stats, attr_acc):\n",
    "        for k in range(len(epoch_stats[0])):\n",
    "        # for k in range(1):\n",
    "\n",
    "            self.logger.add_scalar('Top1Accuracy{}/{}'.format(k+1, phase), epoch_stats[0][k], epoch)\n",
    "            # self.logger.add_scalar('Top5Accuracy{}/{}'.format(k+1, phase), epoch_stats[1][k], epoch)\n",
    "            # self.logger.add_scalar('Top1MeanClassAccuracy{}/{}'.format(k+1, phase), epoch_stats[3][k], epoch)\n",
    "            # self.logger.add_scalar('Top5MeanClassAccuracy{}/{}'.format(k+1, phase), epoch_stats[4][k], epoch)\n",
    "            # if unique_attr_stats is not None:\n",
    "            #     self.logger.add_scalar('UniqueAttributes{}/{}'.format(k+1, phase), unique_attr_stats[k], epoch)\n",
    "            # if attr_acc is not None:\n",
    "            #     self.logger.add_scalar('AttributeAccuracy{}/{}'.format(k+1, phase), attr_acc[k], epoch)\n",
    "        self.logger.add_scalar('Loss/'+phase, epoch_stats[2], epoch)\n",
    "\n",
    "        if hist_stats is not None:\n",
    "            for name, data in hist_stats.items():\n",
    "                data = torch.cat(data, dim=0).flatten()\n",
    "                if name.startswith('SelectionHard'):\n",
    "                    bins = self.model.attribute_size\n",
    "                elif name.startswith('AttributesHard'):\n",
    "                    bins = self.model.decision_size\n",
    "                else:\n",
    "                    bins = 'tensorflow'\n",
    "                self.logger.add_histogram(name, data, epoch, bins=bins)\n",
    "\n",
    "    def test_model(self, data_loader, phase, epoch, hard=False):\n",
    "        # Test the Model\n",
    "        self.model.eval()  # Change model to 'eval' mode (BN uses moving mean/var).\n",
    "        n_stats = self.model.max_iters if hasattr(self.model, 'max_iters') else 1\n",
    "        correct_1 = np.zeros((n_stats, self.model.num_classes))\n",
    "        correct_5 = np.zeros((n_stats, self.model.num_classes))\n",
    "        total = 0\n",
    "        total_cnt = np.zeros((1, self.model.num_classes))\n",
    "        total_loss = 0\n",
    "\n",
    "        if isinstance(self.model, OC):\n",
    "            self.model.reset_stats()\n",
    "            if hard:\n",
    "                self.model.init_tree_stats()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for idx, data in enumerate(data_loader):\n",
    "                if len(data) == 2:\n",
    "                    images, labels = data\n",
    "                    attributes = None\n",
    "                else:\n",
    "                    images, labels, attributes = data\n",
    "                    #attributes = attributes.to(self.device)\n",
    "                images = images.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                \n",
    "                classification, loss = self.model(images, labels, hard)\n",
    "                #####################################\n",
    "#                 print(labels.size())\n",
    "#                 print(labels[0].item())\n",
    "                #####################################\n",
    "\n",
    "                # Collect stats\n",
    "                total_loss += loss.item()\n",
    "                total += labels.size(0)\n",
    "                for k in range(len(classification)):\n",
    "                    ######################\n",
    "                    # print(classification[k].data)\n",
    "                    # print(labels[k])\n",
    "                    # print()\n",
    "                    # print(classification[k].data.size())\n",
    "                    # print(labels.size())\n",
    "                    # print()\n",
    "                    # values, indices = torch.max(classification[k], -1)\n",
    "                    # for i in range(classification[k].size(0)):\n",
    "\n",
    "                        # print(indices[i].item(),labels[i].item())\n",
    "                        # if indices[i].item()==labels[i].item():\n",
    "                        #     self.classifications_dict['correct']+=1\n",
    "                        # if indices[i].item()!=labels[i].item():\n",
    "                        #     self.classifications_dict['incorrect']+=1              \n",
    "          \n",
    "                    ######################\n",
    "                    ctopk, target_cnt = self.topk_correct(classification[k].data, labels, (1, 5))\n",
    "                    c1, c5 = ctopk\n",
    "                    # print(target_cnt)\n",
    "                    correct_1[k] += c1\n",
    "                    correct_5[k] += c5\n",
    "                total_cnt[0] += target_cnt\n",
    "\n",
    "                \n",
    "     \n",
    "        stats = [correct_1.sum(axis=1) / total, correct_5.sum(axis=1) / total, total_loss / total, (correct_1 / total_cnt).mean(axis=1), (correct_5 / total_cnt).mean(axis=1)]\n",
    "        print('Accuracy ({}), Top1: {:.2%}, Top5: {:.2%}'.format(phase, stats[0][-1], stats[1][-1]))\n",
    "        self.model.train()  # Change model to 'train' mode\n",
    "\n",
    "        unique_attr_stats = None\n",
    "        attr_acc = None\n",
    "        if epoch is not None:\n",
    "            if isinstance(self.model, OC):\n",
    "                hist_stats = self.model.get_hist_stats()\n",
    "                unique_attr_stats = self.model.get_unique_attributes()\n",
    "                if self.model.attribute_coef > 0.:\n",
    "                    attr_acc = self.model.get_attr_acc(total)\n",
    "                else:\n",
    "                    attr_acc = None\n",
    "            else:\n",
    "                hist_stats = None\n",
    "            self.log_stats(phase, epoch, stats, hist_stats, unique_attr_stats, attr_acc)\n",
    "\n",
    "        return stats[0][-1], stats, unique_attr_stats, attr_acc\n",
    "\n",
    "    def train_model(self, data_laoder):\n",
    "        max_accuracy = 0\n",
    "        max_agg_accuracy = 0\n",
    "        max_ma_accuracy = 0\n",
    "        max_ma_agg_accuracy = 0\n",
    "\n",
    "        if isinstance(self.model, OC):\n",
    "            self.model.reset_stats()\n",
    "\n",
    "        # Train the Model       \n",
    "        for epoch in range(self.num_epochs):\n",
    "            #self.model.set_tau(epoch)\n",
    "            optimizer = self.model.get_optimizer()\n",
    "            n_stats = self.model.max_iters if hasattr(self.model, 'max_iters') else 1\n",
    "            correct_1 = np.zeros((n_stats, self.model.num_classes))\n",
    "            correct_5 = np.zeros((n_stats, self.model.num_classes))\n",
    "            total = 0\n",
    "            total_cnt = np.zeros((1, self.model.num_classes))\n",
    "            total_loss = 0\n",
    "\n",
    "            for i, data in enumerate(data_laoder):\n",
    "                \n",
    "                if len(data) == 2:\n",
    "                    images, labels = data\n",
    "                    attributes = None\n",
    "                else:\n",
    "                    images, labels, attributes = data\n",
    "                    #attributes = attributes.to(self.device)\n",
    "                images = images.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                classification, loss = self.model(images, labels)\n",
    "                \n",
    "\n",
    "                if loss.grad_fn is not None:\n",
    "                \n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # Collect stats\n",
    "                total_loss += loss.item()\n",
    "                total += labels.size(0)\n",
    "                for k in range(len(classification)):\n",
    "                    ctopk, target_cnt = self.topk_correct(classification[k].data, labels, (1, 5))\n",
    "                    c1, c5 = ctopk\n",
    "                    correct_1[k] += c1\n",
    "                    correct_5[k] += c5\n",
    "                total_cnt[0] += target_cnt\n",
    "\n",
    "                if (i+1) % self.log_freq == 0:\n",
    "                    print('Epoch [{}/{}], Iter [{}/{}] Loss: {:.4f}'\n",
    "                            .format(epoch+1, self.num_epochs, i+1, len(data_laoder)//images.size(0),\n",
    "                                    loss.item()))\n",
    "                    ##### TODO remove workaround and use tensurboard\n",
    "                    # self.stats_dict[configuration]['losses'].append(loss.item())\n",
    "            \n",
    "        # with open(data_path + '/logs/' + 'stats_dict.json', 'w') as json_file:\n",
    "        #     json.dump(self.stats_dict, json_file)\n",
    "        #     print('stats dict saved...')\n",
    "                    #############################################\n",
    "\n",
    "            self.model.get_scheduler().step()\n",
    "            # if isinstance(self.model, NeuralDecisionForest) or isinstance(self.model, OC):\n",
    "            #     self.model.toggle_update_schedule()\n",
    "\n",
    "            stats = [correct_1.sum(axis=1) / total, correct_5.sum(axis=1) / total, total_loss / total, (correct_1 / total_cnt).mean(axis=1), (correct_5 / total_cnt).mean(axis=1)]\n",
    "\n",
    "            if isinstance(self.model, OC):\n",
    "                hist_stats = self.model.get_hist_stats()\n",
    "                unique_attr_stats = self.model.get_unique_attributes()\n",
    "                if self.model.attribute_coef > 0.:\n",
    "                    attr_acc = self.model.get_attr_acc(total)\n",
    "                else:\n",
    "                    attr_acc = None\n",
    "            else:\n",
    "                hist_stats = None\n",
    "                unique_attr_stats = None\n",
    "                attr_acc = None\n",
    "            self.log_stats('train', epoch, stats, hist_stats, unique_attr_stats, attr_acc)\n",
    "            print('Accuracy (train), Top1: {:.2%}, Top5: {:.2%}'.format(stats[0][-1], stats[1][-1]))\n",
    "            self.model.phase = 'test'\n",
    "            val_accuracy, val_stats, _, _ = self.test_model(self.dataloaders['val'],\n",
    "                                                            'val', epoch+1)\n",
    "            val_agg_accuracy = val_stats[0].sum()\n",
    "            val_ma_accuracy = val_stats[3][-1]\n",
    "            val_ma_agg_accuracy = val_stats[3].sum()\n",
    "\n",
    "            # reset model stats\n",
    "            model.sigmas_list = []\n",
    "            model.labels_list = []\n",
    "            model.used_attributes_list = []\n",
    "            model.attribute_accuracies = []\n",
    "            model.drop_ratios = []\n",
    "#             self.model.phase = 'test'\n",
    "            _, test_stats, unique_attr_stats, attr_acc = self.test_model(self.dataloaders['test'], 'test', epoch+1)\n",
    "            \n",
    "#             if model.drop_ratios[0].size(0) == 64:\n",
    "            self.mean_drop_ratio.append(sum(model.drop_ratios)/(len(model.drop_ratios)+1))\n",
    "            mean_attribute_accuracy = sum(model.attribute_accuracies)/(len(model.attribute_accuracies)+1)\n",
    "            self.mean_sigmas.append(sum(model.mean_sigmas)/(len(model.mean_sigmas)+1))\n",
    "            self.mean_attr_accs.append(mean_attribute_accuracy)\n",
    "#             print(mean_attribute_accuracy)\n",
    "#             print()\n",
    "            # # collect uncertainty stats\n",
    "            # self.uncertainty_stats['epoch_{}'.format(epoch)]['used_attributes']=self.model.used_attributes_list\n",
    "            # self.model.used_attributes_list = []\n",
    "            # self.uncertainty_stats['epoch_{}'.format(epoch)]['sigmas']=self.model.sigmas_list\n",
    "            # self.model.sigmas_list = []           \n",
    "            \n",
    "            \n",
    "            \n",
    "            self.model.phase = 'train'\n",
    "            if val_accuracy > max_accuracy:\n",
    "                max_accuracy = val_accuracy\n",
    "#                 self.save_model('best', test_stats, 0, unique_attr_stats, attr_acc, epoch)\n",
    "            if val_ma_accuracy > max_ma_accuracy:\n",
    "                max_ma_accuracy = val_ma_accuracy\n",
    "#                 self.save_model('best_ma', test_stats, 3, unique_attr_stats, attr_acc, epoch)\n",
    "            if val_agg_accuracy > max_agg_accuracy and isinstance(self.model, OC):\n",
    "                max_agg_accuracy = val_agg_accuracy\n",
    "                self.save_model('best_agg', test_stats, 0, unique_attr_stats, attr_acc, epoch)\n",
    "            if val_ma_agg_accuracy > max_ma_agg_accuracy and isinstance(self.model, OC):\n",
    "                max_ma_agg_accuracy = val_ma_agg_accuracy\n",
    "#                 self.save_model('best_ma_agg', test_stats, 3, unique_attr_stats, attr_acc, epoch)\n",
    "\n",
    "            self.save_model('latest', test_stats, 0, unique_attr_stats, attr_acc, epoch)\n",
    "        # with open(data_path + '/logs/' + 'stats_dict.json', 'w') as json_file:\n",
    "        #     json.dump(self.stats_dict, json_file)\n",
    "        #     print('stats dict saved...')\n",
    "\n",
    "\n",
    "    def write_stats_file(self, stats_list, name, epoch, is_float=True):\n",
    "        fstr = '{:.2f}' if is_float else '{}'\n",
    "        with open(os.path.join(self.log_path, '{}.txt'.format(name)), 'a') as f:\n",
    "            acc_str = [fstr.format(100*c1 if is_float else c1) for c1 in stats_list]\n",
    "            f.write('{} '.format(epoch) + ' '.join(acc_str))\n",
    "            f.write('\\n')\n",
    "\n",
    "    def save_model(self, name, test_stats, stats_idx, unique_attr_stats, attr_acc, epoch):\n",
    "        torch.save(self.model.state_dict(),\n",
    "                   os.path.join(self.log_path, '{}.pth'.format(name)))\n",
    "        \n",
    "        # save state dict for vision model separately\n",
    "        torch.save(self.model.cnn.state_dict(), os.path.join(self.log_path, '{}_vision_model.pth'.format(name)))\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.write_stats_file(test_stats[stats_idx], name, epoch)\n",
    "\n",
    "        # if isinstance(self.model, NeuralDecisionForest):\n",
    "        #     _, test_stats_hard, _, _ = self.test_model(self.dataloaders['test'],\n",
    "        #                                                'test', epoch+1, hard=True)\n",
    "        #     self.write_stats_file(test_stats_hard[stats_idx], name+'_hard', epoch)\n",
    "\n",
    "        if unique_attr_stats is not None:\n",
    "            self.write_stats_file(unique_attr_stats, name+'_uniqattr', epoch,\n",
    "                                  is_float=False)\n",
    "\n",
    "        if attr_acc is not None:\n",
    "            self.write_stats_file(attr_acc, name+'_attracc', epoch)\n",
    "\n",
    "        if name != 'latest':\n",
    "            print('Saved {} model'.format(name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's instance our models..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the configuraion parameters of our dataset\n",
    "in_channels, cnn_out_size, log_freq = get_dataset_config(dataset, 'cnn', 40 )\n",
    "cnn_out_size = 2048\n",
    "\n",
    "# initiate the observer classifier model\n",
    "model = OC('xoc', len(classes), 'dropoutcnn', in_channels,\n",
    "            cnn_out_size, dataset, 2, 40, # 13 worked\n",
    "            attribute_size, attribute_mtx, attribute_coef,\n",
    "            hidden_size, tau_initial=5,\n",
    "            use_pretrained=False, shallow=False)\n",
    "\n",
    "# load pretrained resnet backbone\n",
    "model.cnn = models.resnet152(pretrained=False)\n",
    "model.cnn.fc = nn.Linear(model.cnn.fc.in_features, torch.load('/home/swezel/projects/urdtc/pretrained/cub_resnet152.pkl')['fc.weight'].size(0))\n",
    "model.cnn.load_state_dict(torch.load('/home/swezel/projects/urdtc/pretrained/cub_resnet152.pkl'))\n",
    "# model.cnn.fc = nn.Linear(model.cnn.fc.in_features, torch.load('/home/swezel/projects/urdtc/pretrained/{}_resnet152.pkl'.format(dataset))['fc.weight'].size(0))\n",
    "# model.cnn.load_state_dict(torch.load('/home/swezel/projects/urdtc/pretrained/{}_resnet152.pkl'.format(dataset)))\n",
    "\n",
    "\n",
    "model.cnn.fc = nn.Identity()\n",
    "\n",
    "# set attribute head\n",
    "model.binary_features = nn.Sequential(nn.BatchNorm1d(cnn_out_size),\n",
    "                                        nn.Linear(cnn_out_size, hidden_size),\n",
    "                                        nn.ReLU(inplace=True),\n",
    "                                        nn.BatchNorm1d(hidden_size),\n",
    "                                        nn.Dropout(0.5, inplace=False), # dropout after batchnorm\n",
    "                                        nn.Linear(hidden_size, hidden_size),\n",
    "                                        nn.ReLU(inplace=True),\n",
    "                                        nn.BatchNorm1d(hidden_size),\n",
    "                                        nn.Dropout(0.5, inplace=False),\n",
    "                                        nn.Linear(hidden_size, attribute_size * 2))\n",
    "\n",
    "model.binary_features.tau = nn.Parameter(torch.tensor([5], dtype=torch.float), requires_grad=True)\n",
    "model.to(device);\n",
    "\n",
    "# freeze resnet backbone for faster training but make all other weights trainable\n",
    "for param in model.lstm.parameters():\n",
    "    param.requires_grad=True\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad=True\n",
    "for param in model.feature_selection.parameters():\n",
    "    param.requires_grad=True\n",
    "for param in model.binary_features.parameters():\n",
    "    param.requires_grad=True\n",
    "for param in model.pre_lstm.parameters():\n",
    "    param.requires_grad=True\n",
    "    \n",
    "for param in model.cnn.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.cnn.fc.parameters():\n",
    "    param.requires_grad=True\n",
    "    \n",
    "# initiate optimizers\n",
    "tree_params, cnn_params = model.get_param_groups()\n",
    "tree_optimizer = torch.optim.Adam(tree_params, lr = learning_rate, weight_decay=weight_decay)\n",
    "cnn_optimizer = torch.optim.Adam(cnn_params, lr = learning_rate, weight_decay=weight_decay)\n",
    "optimizer = [tree_optimizer, cnn_optimizer]\n",
    "# and schedulers\n",
    "tree_scheduler = torch.optim.lr_scheduler.StepLR(tree_optimizer, step_size=step_size, gamma=0.1)\n",
    "cnn_scheduler = torch.optim.lr_scheduler.StepLR(cnn_optimizer, step_size=step_size, gamma=0.1)\n",
    "scheduler = [tree_scheduler, cnn_scheduler]\n",
    "\n",
    "model.set_optimizer(optimizer)\n",
    "# model.init_tree_stats()\n",
    "model.set_scheduler(scheduler)\n",
    "##h\n",
    "# model.strategy = 'randRDTC'\n",
    "model.strategy = 'remRDTC'\n",
    "# model.strategy = 'extRDTC'\n",
    "##hook\n",
    "# model.strategy = 'aRDTC'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and finally train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/40], Iter [10/1] Loss: 4.4171\n",
      "Epoch [1/40], Iter [20/1] Loss: 4.3464\n",
      "Epoch [1/40], Iter [30/1] Loss: 4.3419\n",
      "Epoch [1/40], Iter [40/1] Loss: 4.2603\n",
      "Epoch [1/40], Iter [50/1] Loss: 4.0353\n",
      "Epoch [1/40], Iter [60/1] Loss: 3.7984\n",
      "Epoch [1/40], Iter [70/1] Loss: 3.9971\n",
      "Epoch [1/40], Iter [80/1] Loss: 3.6387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-71d8c572b2e5>:228: RuntimeWarning: invalid value encountered in true_divide\n",
      "  stats = [correct_1.sum(axis=1) / total, correct_5.sum(axis=1) / total, total_loss / total, (correct_1 / total_cnt).mean(axis=1), (correct_5 / total_cnt).mean(axis=1)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (train), Top1: 3.67%, Top5: 13.33%\n",
      "Accuracy (val), Top1: 7.63%, Top5: 17.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-71d8c572b2e5>:143: RuntimeWarning: invalid value encountered in true_divide\n",
      "  stats = [correct_1.sum(axis=1) / total, correct_5.sum(axis=1) / total, total_loss / total, (correct_1 / total_cnt).mean(axis=1), (correct_5 / total_cnt).mean(axis=1)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (test), Top1: 2.53%, Top5: 10.07%\n",
      "Saved best_agg model\n",
      "Epoch [2/40], Iter [10/1] Loss: 3.5750\n",
      "Epoch [2/40], Iter [20/1] Loss: 3.5526\n",
      "Epoch [2/40], Iter [30/1] Loss: 3.1012\n",
      "Epoch [2/40], Iter [40/1] Loss: 3.1002\n",
      "Epoch [2/40], Iter [50/1] Loss: 3.3699\n",
      "Epoch [2/40], Iter [60/1] Loss: 3.2843\n",
      "Epoch [2/40], Iter [70/1] Loss: 3.1268\n",
      "Epoch [2/40], Iter [80/1] Loss: 3.0302\n",
      "Accuracy (train), Top1: 14.33%, Top5: 43.46%\n",
      "Accuracy (val), Top1: 20.00%, Top5: 53.56%\n",
      "Accuracy (test), Top1: 10.41%, Top5: 28.33%\n",
      "Saved best_agg model\n",
      "Epoch [3/40], Iter [10/1] Loss: 3.0725\n",
      "Epoch [3/40], Iter [20/1] Loss: 2.8953\n",
      "Epoch [3/40], Iter [30/1] Loss: 2.8256\n",
      "Epoch [3/40], Iter [40/1] Loss: 2.8012\n",
      "Epoch [3/40], Iter [50/1] Loss: 2.6252\n",
      "Epoch [3/40], Iter [60/1] Loss: 2.7016\n",
      "Epoch [3/40], Iter [70/1] Loss: 2.5418\n",
      "Epoch [3/40], Iter [80/1] Loss: 2.6836\n",
      "Accuracy (train), Top1: 27.92%, Top5: 63.05%\n",
      "Accuracy (val), Top1: 22.37%, Top5: 58.14%\n",
      "Accuracy (test), Top1: 13.23%, Top5: 32.94%\n",
      "Saved best_agg model\n",
      "Epoch [4/40], Iter [10/1] Loss: 2.8599\n",
      "Epoch [4/40], Iter [20/1] Loss: 2.5530\n",
      "Epoch [4/40], Iter [30/1] Loss: 2.7828\n",
      "Epoch [4/40], Iter [40/1] Loss: 2.8252\n",
      "Epoch [4/40], Iter [50/1] Loss: 2.4827\n",
      "Epoch [4/40], Iter [60/1] Loss: 2.2634\n",
      "Epoch [4/40], Iter [70/1] Loss: 2.3375\n",
      "Epoch [4/40], Iter [80/1] Loss: 2.0288\n",
      "Accuracy (train), Top1: 35.75%, Top5: 71.85%\n",
      "Accuracy (val), Top1: 35.42%, Top5: 71.53%\n",
      "Accuracy (test), Top1: 21.00%, Top5: 39.57%\n",
      "Saved best_agg model\n",
      "Epoch [5/40], Iter [10/1] Loss: 2.1738\n",
      "Epoch [5/40], Iter [20/1] Loss: 2.2751\n",
      "Epoch [5/40], Iter [30/1] Loss: 2.1923\n",
      "Epoch [5/40], Iter [40/1] Loss: 2.4550\n",
      "Epoch [5/40], Iter [50/1] Loss: 2.3615\n",
      "Epoch [5/40], Iter [60/1] Loss: 2.1442\n",
      "Epoch [5/40], Iter [70/1] Loss: 2.4288\n",
      "Epoch [5/40], Iter [80/1] Loss: 2.2717\n",
      "Accuracy (train), Top1: 42.84%, Top5: 77.13%\n",
      "Accuracy (val), Top1: 44.58%, Top5: 77.97%\n",
      "Accuracy (test), Top1: 26.16%, Top5: 42.52%\n",
      "Saved best_agg model\n",
      "Epoch [6/40], Iter [10/1] Loss: 2.0943\n",
      "Epoch [6/40], Iter [20/1] Loss: 2.3237\n",
      "Epoch [6/40], Iter [30/1] Loss: 2.3746\n",
      "Epoch [6/40], Iter [40/1] Loss: 2.0729\n",
      "Epoch [6/40], Iter [50/1] Loss: 2.3858\n",
      "Epoch [6/40], Iter [60/1] Loss: 2.2747\n",
      "Epoch [6/40], Iter [70/1] Loss: 2.2520\n",
      "Epoch [6/40], Iter [80/1] Loss: 2.3138\n",
      "Accuracy (train), Top1: 48.48%, Top5: 80.31%\n",
      "Accuracy (val), Top1: 47.97%, Top5: 80.00%\n",
      "Accuracy (test), Top1: 28.98%, Top5: 44.85%\n",
      "Saved best_agg model\n",
      "Epoch [7/40], Iter [10/1] Loss: 1.9452\n",
      "Epoch [7/40], Iter [20/1] Loss: 2.2065\n",
      "Epoch [7/40], Iter [30/1] Loss: 2.1591\n",
      "Epoch [7/40], Iter [40/1] Loss: 2.0674\n",
      "Epoch [7/40], Iter [50/1] Loss: 2.3550\n",
      "Epoch [7/40], Iter [60/1] Loss: 2.2587\n",
      "Epoch [7/40], Iter [70/1] Loss: 2.1186\n",
      "Epoch [7/40], Iter [80/1] Loss: 2.2211\n",
      "Accuracy (train), Top1: 51.05%, Top5: 82.40%\n",
      "Accuracy (val), Top1: 53.56%, Top5: 82.54%\n",
      "Accuracy (test), Top1: 32.93%, Top5: 45.66%\n",
      "Saved best_agg model\n",
      "Epoch [8/40], Iter [10/1] Loss: 2.0658\n",
      "Epoch [8/40], Iter [20/1] Loss: 2.0620\n",
      "Epoch [8/40], Iter [30/1] Loss: 2.0450\n",
      "Epoch [8/40], Iter [40/1] Loss: 1.9905\n",
      "Epoch [8/40], Iter [50/1] Loss: 2.0654\n",
      "Epoch [8/40], Iter [60/1] Loss: 1.8680\n",
      "Epoch [8/40], Iter [70/1] Loss: 1.8377\n",
      "Epoch [8/40], Iter [80/1] Loss: 2.2674\n",
      "Accuracy (train), Top1: 55.08%, Top5: 83.58%\n",
      "Accuracy (val), Top1: 51.19%, Top5: 82.03%\n",
      "Accuracy (test), Top1: 29.63%, Top5: 44.66%\n",
      "Epoch [9/40], Iter [10/1] Loss: 1.9656\n",
      "Epoch [9/40], Iter [20/1] Loss: 2.0726\n",
      "Epoch [9/40], Iter [30/1] Loss: 1.8702\n",
      "Epoch [9/40], Iter [40/1] Loss: 2.9986\n",
      "Epoch [9/40], Iter [50/1] Loss: 1.9385\n",
      "Epoch [9/40], Iter [60/1] Loss: 2.1974\n",
      "Epoch [9/40], Iter [70/1] Loss: 2.0459\n",
      "Epoch [9/40], Iter [80/1] Loss: 2.2720\n",
      "Accuracy (train), Top1: 56.30%, Top5: 84.54%\n",
      "Accuracy (val), Top1: 56.10%, Top5: 84.07%\n",
      "Accuracy (test), Top1: 33.33%, Top5: 45.73%\n",
      "Saved best_agg model\n",
      "Epoch [10/40], Iter [10/1] Loss: 2.1145\n",
      "Epoch [10/40], Iter [20/1] Loss: 2.0962\n",
      "Epoch [10/40], Iter [30/1] Loss: 1.8553\n",
      "Epoch [10/40], Iter [40/1] Loss: 1.8761\n",
      "Epoch [10/40], Iter [50/1] Loss: 1.9235\n",
      "Epoch [10/40], Iter [60/1] Loss: 2.0599\n",
      "Epoch [10/40], Iter [70/1] Loss: 2.1537\n",
      "Epoch [10/40], Iter [80/1] Loss: 1.6795\n",
      "Accuracy (train), Top1: 58.07%, Top5: 84.47%\n",
      "Accuracy (val), Top1: 58.64%, Top5: 85.08%\n",
      "Accuracy (test), Top1: 32.72%, Top5: 45.36%\n",
      "Saved best_agg model\n",
      "Epoch [11/40], Iter [10/1] Loss: 1.8843\n",
      "Epoch [11/40], Iter [20/1] Loss: 1.6757\n",
      "Epoch [11/40], Iter [30/1] Loss: 1.8549\n",
      "Epoch [11/40], Iter [40/1] Loss: 1.7484\n",
      "Epoch [11/40], Iter [50/1] Loss: 1.7148\n",
      "Epoch [11/40], Iter [60/1] Loss: 2.0703\n",
      "Epoch [11/40], Iter [70/1] Loss: 1.9207\n",
      "Epoch [11/40], Iter [80/1] Loss: 1.9032\n",
      "Accuracy (train), Top1: 59.98%, Top5: 85.95%\n",
      "Accuracy (val), Top1: 55.25%, Top5: 84.07%\n",
      "Accuracy (test), Top1: 32.82%, Top5: 45.68%\n",
      "Epoch [12/40], Iter [10/1] Loss: 1.9723\n",
      "Epoch [12/40], Iter [20/1] Loss: 2.2247\n",
      "Epoch [12/40], Iter [30/1] Loss: 1.7942\n",
      "Epoch [12/40], Iter [40/1] Loss: 1.7278\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model, dataloaders, 40, device, log_freq, data_path + '/../log/')\n",
    "torch.cuda.empty_cache()\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0]\n",
      "\n",
      "[0.0]\n",
      "\n",
      "[0.0]\n"
     ]
    }
   ],
   "source": [
    "print(trainer.mean_attr_accs)\n",
    "print()\n",
    "print(trainer.mean_drop_ratio)\n",
    "print()\n",
    "print(trainer.mean_sigmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect behaviour on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seen:\n",
      "1.862794463313169e-08\n",
      "4.676016720051466e-08\n",
      "\n",
      "unseen:\n",
      "9.01135930692519e-08\n",
      "9.826735659356458e-08\n",
      "\n",
      "2965\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seen_sigmas = []\n",
    "unseen_sigmas = []\n",
    "\n",
    "for batch_index in range(len(model.labels_list)):\n",
    "    for inner_batch_index in range(model.labels_list[batch_index].size(0)):\n",
    "        class_label = model.labels_list[batch_index][inner_batch_index].item()\n",
    "        if class_label < 151:\n",
    "#         if class_label not in [11,18,19,25,26,28,30,31,32,41,74,75,98,113,138,139,161,177,180,182,183,192,199,177]:\n",
    "            seen_sigmas.append(model.sigmas_list[batch_index][inner_batch_index].median().item())\n",
    "        else:\n",
    "            unseen_sigmas.append(model.sigmas_list[batch_index][inner_batch_index].median().item())\n",
    "\n",
    "            \n",
    "seen_sigmas = np.array(seen_sigmas)\n",
    "unseen_sigmas = np.array(unseen_sigmas)\n",
    "print('seen:')\n",
    "print(seen_sigmas.mean())\n",
    "print(seen_sigmas.std())\n",
    "print('\\nunseen:')\n",
    "print(unseen_sigmas.mean())\n",
    "print(unseen_sigmas.std())\n",
    "# for plotting\n",
    "sns.set_style('darkgrid')\n",
    "x_min = np.concatenate((seen_sigmas, unseen_sigmas)).min()\n",
    "x_max = np.concatenate((seen_sigmas, unseen_sigmas)).max()\n",
    "x = np.linspace(x_min, x_max, 100)\n",
    "y_seen = scipy.stats.expon.pdf(x,seen_sigmas.mean(),seen_sigmas.std())\n",
    "y_unseen = scipy.stats.expon.pdf(x,unseen_sigmas.mean(), unseen_sigmas.std())\n",
    "plt.plot(x,y_unseen, color='#AC454A', label = 'unseen')\n",
    "plt.fill_between(x, y_unseen,color='#AC454A', alpha=0.66)\n",
    "plt.plot(x,y_seen, color='#F67941', label = 'seen')\n",
    "plt.fill_between(x, y_seen,color='#F67941', alpha=0.66)\n",
    "\n",
    "# plt.hist([seen_sigmas, unseen_sigmas], color=['#F67941','#AC454A'], density=[True, True], label=['seen', 'unseen'])\n",
    "\n",
    "# plt.plot(x,y_seen, color='#F67941', label = 'seen')\n",
    "# plt.plot(x,y_unseen, color='#AC454A', label = 'unseen')\n",
    "plt.legend()\n",
    "# plt.savefig(figure_path + 'zero_shot_class_uncertainty.pdf',bbox_inches='tight')\n",
    "print()\n",
    "print(len(seen_sigmas))\n",
    "# print(np.max(unseen_sigmas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "(11788, 1)\n"
     ]
    }
   ],
   "source": [
    "split_df = pd.read_csv(data_path + '/cub/zero_shot_train_test_split.txt', sep=' ', index_col=0, header=None)\n",
    "print(split_df.iloc[8850:,0].sum())\n",
    "print(split_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2965\n",
      "2915\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cell 3\n",
    "# plt.hist(unseen_sigmas)\n",
    "# plt.hist(seen_sigmas)\n",
    "# plt.hist(unseen_sigmas_means)\n",
    "# plt.hist(seen_sigmas_means)\n",
    "print(len(seen_sigmas))\n",
    "print(len(unseen_sigmas))\n",
    "# plt.hist(np.array(unseen_sigmas_means),\n",
    "#          bins = np.arange(0.0, 0.005, 0.001),\n",
    "#          color='#AC454A',\n",
    "#          density=True,\n",
    "#          label='unseen',\n",
    "#          weights=np.ones_like(np.array(unseen_sigmas_means)))\n",
    "\n",
    "# plt.hist(np.array(seen_sigmas_means),\n",
    "# #          bins = np.arange(0.075, 0.15, 0.0025),\n",
    "#          bins = np.arange(0.0, 0.005, 0.001),\n",
    "#          color='#F67941',\n",
    "#          density=True,\n",
    "#          label='seen',\n",
    "#          alpha=0.7\n",
    "#         )\n",
    "\n",
    "\n",
    "plt.hist([np.array(unseen_sigmas), np.array(seen_sigmas)],\n",
    "#          bins = np.arange(0.001, 0.005, 0.001),\n",
    "         color=['#AC454A','#F67941'],\n",
    "         density=[True, True],\n",
    "         label=['unseen', 'seen'],\n",
    "#          weights=[np.ones_like(np.array(unseen_sigmas_means)),np.ones_like(np.array(unseen_sigmas_means))]\n",
    "        )\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "# plt.savefig(figure_path + 'zero_shot_class_uncertainty_hist.pdf',bbox_inches='tight')\n",
    "\n",
    "\n",
    "\n",
    "print(trainer.mean_attr_accs)\n",
    "print()\n",
    "print(trainer.mean_drop_ratio)\n",
    "print()\n",
    "print(trainer.mean_sigmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_channels, cnn_out_size, log_freq = get_dataset_config(dataset, 'cnn', 40 )\n",
    "# # cnn_out_size=2048\n",
    "# model.load_state_dict(torch.load(data_path + '/../log/extRDTC_best_agg.pth'))#,  map_location=lambda storage, loc: storage)\n",
    "# model.cnn.load_state_dict(torch.load(data_path + '/../log/extRDTC_best_agg_vision_model.pth'))\n",
    "# # model.train()\n",
    "# # model.eval()\n",
    "# # print(model.n_possible_states)\n",
    "# trainer = Trainer(model, dataloaders, 3, device, log_freq, data_path + '/../log/')\n",
    "# # model.reset_stats()\n",
    "# # model.init_tree_stats()\n",
    "# trainer.test();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accumulated_error = torch.zeros(312, device=device)\n",
    "# accumulated_sigmas = torch.zeros(312, device=device)\n",
    "# accumulated_usage = torch.zeros(312, device=device)\n",
    "# num_batches = len(model.binary_features_list)\n",
    "# batch_size = model.binary_features_list[0].size(0)\n",
    "\n",
    "\n",
    "# for batch_index in range(num_batches):\n",
    "#     if model.binary_features_list[batch_index].size(0)==64:\n",
    "\n",
    "#         # iterate over single batch\n",
    "#         for i in range(batch_size):\n",
    "#             predicted_attributes = model.binary_features_list[batch_index][i].T[0]  \n",
    "#             class_label = model.labels_list[batch_index][i].item()\n",
    "#             ground_truth_attributes = attribute_mtx[class_label]\n",
    "\n",
    "#             diff = (ground_truth_attributes - predicted_attributes)**2\n",
    "#             accumulated_error += diff\n",
    "\n",
    "#             accumulated_sigmas += sigmas[batch_index][i]#[:312]\n",
    "#             # print(model.used_attributes_list[batch_index][i])\n",
    "#             accumulated_usage += model.used_attributes_list[batch_index][i].cuda()\n",
    "# # for i in range(len(model.used_attributes_list)):\n",
    "# #     accumulated_usage += model.used_attributes_list[i][:312]\n",
    "\n",
    "\n",
    "\n",
    "# mean_accumulated_error = accumulated_error/(batch_size * num_batches)\n",
    "# mean_accumulated_sigmas = accumulated_sigmas/(batch_size * num_batches)\n",
    "# mean_accumulated_usage = accumulated_usage/(batch_size * num_batches)# (batch_size * num_batches)\n",
    "\n",
    "\n",
    "\n",
    "# # print(accumulated_error.mean(dim=-1).size())\n",
    "# error_and_sigma = torch.stack([mean_accumulated_error, mean_accumulated_sigmas, mean_accumulated_usage], dim=0)\n",
    "# d = {'misclassification\\nrate':error_and_sigma[0].cpu().numpy(), 'uncertainty':error_and_sigma[1].cpu().numpy(), 'usage':error_and_sigma[2].cpu().numpy()}\n",
    "# df = pd.DataFrame(d)\n",
    "# # df.head()\n",
    "# df_short = df.loc[df['usage']>0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.colors as clr\n",
    "# sns.set(rc={'figure.figsize':(15,1)})\n",
    "\n",
    "# # cmap = clr.LinearSegmentedColormap.from_list('custom blue', [\"#EAD296\", \"#F67941\", \"#AC454A\", \"#5A005B\", \"#4999F2\"], N=256)\n",
    "# cmap = clr.LinearSegmentedColormap.from_list('custom blue', [\"#EAD296\", \"#F67941\", \"#AC454A\"], N=256)\n",
    "\n",
    "# sns.heatmap(df_short.to_numpy().T, #annot=True,\n",
    "#             xticklabels=df.loc[df['usage']>0].index,\n",
    "#             yticklabels=['misclassification rate', 'uncertainty', 'usage'],\n",
    "#            cmap=cmap)#sns.color_palette(\"YlOrBr\"))\n",
    "# plt.xticks(rotation=90)\n",
    "# # plt.show()\n",
    "# # plt.savefig(figure_path + 'attr_heatmap_short.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sns.set(rc={'figure.figsize':(6,5)})\n",
    "# sns.heatmap(df_short.corr(), annot=True, center = 0.5, cmap=cmap)#sns.color_palette(\"icefire\"))\n",
    "# # plt.show()\n",
    "\n",
    "# # plt.savefig(figure_path + 'corr_matrix.pdf',bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.scatterplot(x='misclassification\\nrate', y='uncertainty',\n",
    "# #                 hue='usage',\n",
    "#                 size='usage',\n",
    "#                 legend=False,\n",
    "#                 color='#AC454A',\n",
    "# #                 cmap=cmap,\n",
    "#                 linewidth=0,\n",
    "#                 data=df_short)\n",
    "\n",
    "\n",
    "# # sns.FacetGrid(df_short, row=\"error\", col=\"uncertainty\", hue=\"usage\")\n",
    "# # plt.legend()\n",
    "# # plt.show()\n",
    "\n",
    "# # plt.savefig(figure_path + 'error_sigma_corr_all.pdf',bbox_inches='tight')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
