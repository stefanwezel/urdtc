{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "As we're luckily standing on the shoulders of giants, we can do some imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import imageio\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "Let's load and convert the data, so we can use it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = ['cifar10', 'mnist', 'cub', 'awa2',\n",
    "            'imagenetfeatures', 'apyfeatures', 'zero_shot_cub']\n",
    "# dataset = 'awa2'\n",
    "# dataset = 'cub'\n",
    "dataset = 'zero_shot_cub'\n",
    "\n",
    "data_path = '/home/swezel/projects/urdtc/data/'\n",
    "figure_path = data_path + '../thesis/images/'\n",
    "\n",
    "\n",
    "# attribute name lookup (first attr_id is 0) \n",
    "with open (data_path + 'cub/attributes.txt', 'r') as f:\n",
    "    attributes=f.readlines()\n",
    "attribute_name_dict = {str(int(attr.split(' ')[0])-1): attr.split(' ')[1] for attr in attributes}\n",
    "\n",
    "def get_dataset_config(dataset, cnn_type, max_iters):\n",
    "    input_channels = None\n",
    "    if dataset == 'mnist':\n",
    "        input_channels = 1\n",
    "        if cnn_type == 'cnn':\n",
    "            cnn_output_size = 4*4*100\n",
    "        elif cnn_type == 'resnet':\n",
    "            cnn_output_size = 512\n",
    "        elif cnn_type == 'shallowcnn':\n",
    "            cnn_output_size = 4*4*64\n",
    "        out_freq = 100\n",
    "        #assert max_iters > 4\n",
    "    elif dataset == 'cifar10':\n",
    "        input_channels = 3\n",
    "        if cnn_type == 'cnn':\n",
    "            cnn_output_size = 8*8*32\n",
    "        elif cnn_type == 'resnet' or cnn_type == 'resnet18':\n",
    "            cnn_output_size = 512\n",
    "        elif cnn_type == 'shallowcnn':\n",
    "            cnn_output_size = 4*4*64\n",
    "        out_freq = 100\n",
    "        #assert max_iters > 4\n",
    "    elif dataset == 'cub':\n",
    "        input_channels = 3\n",
    "        if cnn_type == 'cnn':\n",
    "            # cnn_output_size = 32*32*32\n",
    "            cnn_output_size = 280900 # the above does not work? Maybe because of dataloader issue?\n",
    "        elif cnn_type == 'resnet' or cnn_type == 'resnet152':\n",
    "            cnn_output_size = 2048\n",
    "        out_freq = 10\n",
    "    elif dataset == 'zero_shot_cub':\n",
    "        input_channels = 3\n",
    "        if cnn_type == 'cnn':\n",
    "            # cnn_output_size = 32*32*32\n",
    "            cnn_output_size = 280900 # the above does not work? Maybe because of dataloader issue?\n",
    "        elif cnn_type == 'resnet' or cnn_type == 'resnet152':\n",
    "            cnn_output_size = 2048\n",
    "        out_freq = 10\n",
    "        #assert max_iters > 8\n",
    "    elif dataset == 'awa2':\n",
    "        input_channels = 3\n",
    "        if cnn_type == 'cnn':\n",
    "#             cnn_output_size = 32*32*32  # TODO: check\n",
    "            cnn_output_size = 2048\n",
    "        elif cnn_type == 'resnet' or cnn_type == 'resnet152':\n",
    "            cnn_output_size = 2048\n",
    "        out_freq = 10\n",
    "        #assert max_iters > 6\n",
    "    elif dataset == 'imagenetfeatures':\n",
    "        cnn_output_size = 2048\n",
    "        out_freq = 100\n",
    "        #assert max_iters > 10\n",
    "    elif dataset == 'apyfeatures':\n",
    "        cnn_output_size = 2048\n",
    "        out_freq = 10\n",
    "        #assert max_iters > 5\n",
    "\n",
    "    return input_channels, cnn_output_size, out_freq\n",
    "\n",
    "class DataLoader(object):\n",
    "    def __init__(self, dataset='mnist'):\n",
    "        assert dataset in DATASETS\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def load_data(self, batch_size=100, num_workers=4, root='./data/'):\n",
    "\n",
    "        if self.dataset == 'mnist':\n",
    "            #transform_train = transforms.ToTensor()\n",
    "            #transform_test = transforms.ToTensor()\n",
    "            class AddGaussianNoise(object):\n",
    "                def __init__(self, mean=0., std=1.):\n",
    "                    self.std = std\n",
    "                    self.mean = mean\n",
    "\n",
    "                def __call__(self, tensor):\n",
    "                    output = tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "                    return output.clamp(0., 1.)\n",
    "\n",
    "                def __repr__(self):\n",
    "                    return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
    "\n",
    "            transform_train = transforms.Compose([\n",
    "               transforms.ToTensor(),\n",
    "               #AddGaussianNoise(0., 0.2)\n",
    "               #transforms.Normalize((0.1307,), (0.3081,))\n",
    "            ])\n",
    "            transform_test = transforms.Compose([\n",
    "               transforms.ToTensor(),\n",
    "               #AddGaussianNoise(0., 0.2)\n",
    "               #transforms.Normalize((0.1307,), (0.3081,))\n",
    "            ])\n",
    "            classes = [i for i in range(10)]\n",
    "            dataset_class = dsets.MNIST\n",
    "\n",
    "        elif self.dataset == 'cifar10':\n",
    "            transform_train = transforms.Compose([\n",
    "                transforms.RandomCrop(32, padding=4),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "            ])\n",
    "            transform_test = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "            ])\n",
    "            classes = ('plane', 'car', 'bird', 'cat',\n",
    "                       'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "            dataset_class = dsets.CIFAR10\n",
    "\n",
    "        elif self.dataset == 'cub':\n",
    "\n",
    "            transform_train = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                  transforms.RandomResizedCrop(224),\n",
    "                                                  transforms.RandomHorizontalFlip(),\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                                       std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "            transform_test = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                 transforms.Resize(224),\n",
    "                                                 transforms.CenterCrop(224),\n",
    "                                                 transforms.ToTensor(),\n",
    "                                                 transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                                      std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "            dataset_class = CUB\n",
    "            classes = list(range(200))\n",
    "\n",
    "        elif self.dataset == 'zero_shot_cub':\n",
    "\n",
    "            transform_train = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                  transforms.RandomResizedCrop(224),\n",
    "                                                  transforms.RandomHorizontalFlip(),\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                                       std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "            transform_test = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                 transforms.Resize(224),\n",
    "                                                 transforms.CenterCrop(224),\n",
    "                                                 transforms.ToTensor(),\n",
    "                                                 transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                                      std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "            dataset_class = ZeroShotCUB\n",
    "            classes = list(range(200))            \n",
    "            \n",
    "            \n",
    "\n",
    "        elif self.dataset == 'awa2':\n",
    "            transform_train = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                  transforms.RandomResizedCrop(224),\n",
    "                                                  transforms.RandomHorizontalFlip(),\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                                       std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "            transform_test = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                 transforms.Resize(224),\n",
    "                                                 transforms.CenterCrop(224),\n",
    "                                                 transforms.ToTensor(),\n",
    "                                                 transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                                      std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "            dataset_class = AWA2\n",
    "            classes = list(range(50))\n",
    "\n",
    "        elif self.dataset == 'apyfeatures':\n",
    "            transform_train = transforms.ToTensor()\n",
    "            transform_test = transforms.ToTensor()\n",
    "\n",
    "            dataset_class = APYFeatures\n",
    "            classes = list(range(32))\n",
    "\n",
    "        elif self.dataset == 'imagenetfeatures':\n",
    "            transform_train = transforms.ToTensor()\n",
    "            transform_test = transforms.ToTensor()\n",
    "\n",
    "            dataset_class = ImageNetFeatures\n",
    "            classes = list(range(1000))\n",
    "\n",
    "        train_dataset = dataset_class(root=root,\n",
    "                                      train=True,\n",
    "                                      transform=transform_train,\n",
    "                                      download=True)\n",
    "\n",
    "        test_dataset = dataset_class(root=root,\n",
    "                                     train=False,\n",
    "                                     transform=transform_test)\n",
    "\n",
    "        val_size = int(len(train_dataset) * 0.1)\n",
    "        train_size = len(train_dataset) - val_size\n",
    "\n",
    "        train_dataset, val_dataset = torch.utils.data.dataset.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   shuffle=True,\n",
    "                                                   num_workers=num_workers)\n",
    "\n",
    "        val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 shuffle=False,\n",
    "                                                 num_workers=num_workers)\n",
    "\n",
    "        test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  shuffle=False,\n",
    "                                                  num_workers=num_workers)\n",
    "\n",
    "        dataloaders = {'train': train_loader,\n",
    "                       'val': val_loader,\n",
    "                       'test': test_loader}\n",
    "\n",
    "        return dataloaders, classes\n",
    "\n",
    "class CUB(Dataset):\n",
    "    \"\"\"CUB200-2011 dataset.\"\"\"\n",
    "    attribute_file = 'attributes/class_attribute_labels_continuous.txt'\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, normalize=True,\n",
    "                 download=None):\n",
    "        self.root = os.path.join(root, 'cub')\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.data_dir = os.path.join(self.root, 'images')\n",
    "\n",
    "        train_test_split = pd.read_csv(os.path.join(self.root, 'train_test_split.txt'),\n",
    "                                       sep=' ', index_col=0, header=None)\n",
    "        if train:\n",
    "            is_train_image = 1\n",
    "        else:\n",
    "            is_train_image = 0\n",
    "        self.img_ids = train_test_split[train_test_split[1] == is_train_image].index.tolist()\n",
    "        self.id_to_img = pd.read_csv(os.path.join(self.root, 'images.txt'),\n",
    "                                     sep=' ', index_col=0, header=None)\n",
    "\n",
    "        raw_mtx = np.loadtxt(os.path.join(self.root,\n",
    "                                          self.attribute_file))\n",
    "        raw_mtx[raw_mtx == -1] = 0\n",
    "        raw_mtx = raw_mtx / raw_mtx.max()\n",
    "        self.attribute_mtx = torch.tensor(raw_mtx, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_ids[idx]\n",
    "        img_name = self.id_to_img[self.id_to_img.index == img_id].values[0][0]\n",
    "        img_path = os.path.join(self.data_dir, img_name)\n",
    "\n",
    "        img = imageio.imread(img_path, pilmode='RGB')\n",
    "        label = int(img_name[:3]) - 1\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label, img_path\n",
    "\n",
    "    \n",
    "class ZeroShotCUB(Dataset):\n",
    "    \"\"\"CUB200-2011 dataset.\"\"\"\n",
    "    attribute_file = 'attributes/class_attribute_labels_continuous.txt'\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, normalize=True,\n",
    "                 download=None):\n",
    "        self.root = os.path.join(root, 'cub')\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.data_dir = os.path.join(self.root, 'images')\n",
    "\n",
    "        train_test_split = pd.read_csv(os.path.join(self.root, 'zero_attr_train_test_split.txt'),\n",
    "                                       sep=' ', index_col=0, header=None)\n",
    "        if train:\n",
    "            is_train_image = 1\n",
    "        else:\n",
    "            is_train_image = 0\n",
    "        self.img_ids = train_test_split[train_test_split[1] == is_train_image].index.tolist()\n",
    "        self.id_to_img = pd.read_csv(os.path.join(self.root, 'images.txt'),\n",
    "                                     sep=' ', index_col=0, header=None)\n",
    "\n",
    "        raw_mtx = np.loadtxt(os.path.join(self.root,\n",
    "                                          self.attribute_file))\n",
    "        raw_mtx[raw_mtx == -1] = 0\n",
    "        raw_mtx = raw_mtx / raw_mtx.max()\n",
    "        self.attribute_mtx = torch.tensor(raw_mtx, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_ids[idx]\n",
    "        img_name = self.id_to_img[self.id_to_img.index == img_id].values[0][0]\n",
    "        img_path = os.path.join(self.data_dir, img_name)\n",
    "\n",
    "        img = imageio.imread(img_path, pilmode='RGB')\n",
    "        label = int(img_name[:3]) - 1\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label, img_path\n",
    "    \n",
    "    \n",
    "class AWA2(Dataset):\n",
    "    \"\"\"Animals with Attributes 2 dataset.\"\"\"\n",
    "    split_file = 'train_test_classification_split.txt'\n",
    "    data_dir = 'awa2'\n",
    "    attribute_file = 'predicate-matrix-continuous.txt'\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, normalize=True,\n",
    "                 download=None):\n",
    "        self.root = os.path.join(root, self.data_dir)\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "\n",
    "        meta_data = pd.read_csv(os.path.join(self.root,\n",
    "                                             self.split_file),\n",
    "                                sep=' ', index_col=0, header=None)\n",
    "        if train:\n",
    "            is_train_image = 1\n",
    "        else:\n",
    "            is_train_image = 0\n",
    "        self.img_ids = meta_data[meta_data[3] == is_train_image].index.tolist()\n",
    "        self.id_to_img = meta_data\n",
    "\n",
    "        raw_mtx = np.loadtxt(os.path.join(self.root,\n",
    "                                          self.attribute_file))\n",
    "        raw_mtx[raw_mtx == -1] = 0\n",
    "        raw_mtx = raw_mtx / raw_mtx.max()\n",
    "        self.attribute_mtx = torch.tensor(raw_mtx, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_ids[idx]\n",
    "        img_meta_data = self.id_to_img[self.id_to_img.index == img_id]\n",
    "        img_name = img_meta_data.values[0][0]\n",
    "        img_path = os.path.join(self.root, img_name)\n",
    "\n",
    "        img = imageio.imread(img_path, pilmode='RGB')\n",
    "        label = img_meta_data.values[0][1] - 1\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "# device = torch.device('cpu')\n",
    "\n",
    "# create dataloader objects for train, val and test\n",
    "dl = DataLoader(dataset=dataset)\n",
    "# dataloaders, classes = dl.load_data(4, 4, data_path)# 128 insted of \n",
    "dataloaders, classes = dl.load_data(64, 4, data_path)# 128 insted of \n",
    "\n",
    "# attributes (312 column vectors with 200 rows) -> each class can be described with 312 attributes\n",
    "# percentage of time, human annotator thought, the attribute was present\n",
    "attribute_mtx = dataloaders['train'].dataset.dataset.attribute_mtx\n",
    "\n",
    "# create binary encoding for class attributes\n",
    "attribute_mtx[attribute_mtx < 0.5] = 0.0\n",
    "attribute_mtx[attribute_mtx >= 0.5] = 1.0\n",
    "attribute_mtx = attribute_mtx.to(device) # cuda\n",
    "attribute_size = attribute_mtx.size(1) # number of available attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "18\n",
      "19\n",
      "25\n",
      "26\n",
      "41\n",
      "74\n",
      "75\n",
      "98\n",
      "113\n",
      "138\n",
      "139\n",
      "161\n",
      "180\n",
      "182\n",
      "183\n",
      "199\n",
      "\n",
      "183\n"
     ]
    }
   ],
   "source": [
    "# print(attribute_mtx[0])\n",
    "\n",
    "c = 0\n",
    "\n",
    "\n",
    "for class_id in range(attribute_mtx.size(0)):\n",
    "#     for attr_id in range(attribute_mtx.size(1)):\n",
    "#         print('...')\n",
    "#     attr_values = [attribute_mtx[class_id][x].item() for x in range(6)]\n",
    "#     if attr_values == [0.0 for x in range(6)]:\n",
    "        \n",
    "    if (attribute_mtx[class_id][308].item()==0) or (attribute_mtx[class_id][236].item()==0) or (attribute_mtx[class_id][235].item()==0.)or (attribute_mtx[class_id][145].item()==0.)or (attribute_mtx[class_id][151].item()==0.):\n",
    "\n",
    "#         print(class_id)\n",
    "        c+=1\n",
    "    else:\n",
    "        print(class_id)\n",
    "#     print(attr_values)\n",
    "#     if (attribute_mtx[class_id][3].item()==0) & (attribute_mtx[class_id][1].item()==0.) & (attribute_mtx[class_id][1].item()==0.):\n",
    "#         c += 1\n",
    "print()\n",
    "print(c)\n",
    "# print(attribute_mtx[82][40])\n",
    "\n",
    "#1\n",
    "#308\n",
    "# 101\n",
    "# 235\n",
    "# 145\n",
    "# 151"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.0\n",
      "\n",
      "1\n",
      "15.0\n",
      "\n",
      "2\n",
      "0.0\n",
      "\n",
      "3\n",
      "4.0\n",
      "\n",
      "4\n",
      "15.0\n",
      "\n",
      "5\n",
      "2.0\n",
      "\n",
      "6\n",
      "77.0\n",
      "\n",
      "7\n",
      "45.0\n",
      "\n",
      "8\n",
      "4.0\n",
      "\n",
      "9\n",
      "8.0\n",
      "\n",
      "10\n",
      "46.0\n",
      "\n",
      "11\n",
      "0.0\n",
      "\n",
      "12\n",
      "0.0\n",
      "\n",
      "13\n",
      "0.0\n",
      "\n",
      "14\n",
      "46.0\n",
      "\n",
      "15\n",
      "12.0\n",
      "\n",
      "16\n",
      "1.0\n",
      "\n",
      "17\n",
      "1.0\n",
      "\n",
      "18\n",
      "0.0\n",
      "\n",
      "19\n",
      "0.0\n",
      "\n",
      "20\n",
      "84.0\n",
      "\n",
      "21\n",
      "39.0\n",
      "\n",
      "22\n",
      "2.0\n",
      "\n",
      "23\n",
      "21.0\n",
      "\n",
      "24\n",
      "9.0\n",
      "\n",
      "25\n",
      "47.0\n",
      "\n",
      "26\n",
      "0.0\n",
      "\n",
      "27\n",
      "0.0\n",
      "\n",
      "28\n",
      "0.0\n",
      "\n",
      "29\n",
      "48.0\n",
      "\n",
      "30\n",
      "17.0\n",
      "\n",
      "31\n",
      "2.0\n",
      "\n",
      "32\n",
      "1.0\n",
      "\n",
      "33\n",
      "0.0\n",
      "\n",
      "34\n",
      "0.0\n",
      "\n",
      "35\n",
      "76.0\n",
      "\n",
      "36\n",
      "34.0\n",
      "\n",
      "37\n",
      "3.0\n",
      "\n",
      "38\n",
      "25.0\n",
      "\n",
      "39\n",
      "3.0\n",
      "\n",
      "40\n",
      "12.0\n",
      "\n",
      "41\n",
      "0.0\n",
      "\n",
      "42\n",
      "0.0\n",
      "\n",
      "43\n",
      "0.0\n",
      "\n",
      "44\n",
      "15.0\n",
      "\n",
      "45\n",
      "30.0\n",
      "\n",
      "46\n",
      "0.0\n",
      "\n",
      "47\n",
      "0.0\n",
      "\n",
      "48\n",
      "0.0\n",
      "\n",
      "49\n",
      "1.0\n",
      "\n",
      "50\n",
      "31.0\n",
      "\n",
      "51\n",
      "91.0\n",
      "\n",
      "52\n",
      "8.0\n",
      "\n",
      "53\n",
      "22.0\n",
      "\n",
      "54\n",
      "131.0\n",
      "\n",
      "55\n",
      "6.0\n",
      "\n",
      "56\n",
      "11.0\n",
      "\n",
      "57\n",
      "12.0\n",
      "\n",
      "58\n",
      "9.0\n",
      "\n",
      "59\n",
      "39.0\n",
      "\n",
      "60\n",
      "0.0\n",
      "\n",
      "61\n",
      "0.0\n",
      "\n",
      "62\n",
      "0.0\n",
      "\n",
      "63\n",
      "43.0\n",
      "\n",
      "64\n",
      "12.0\n",
      "\n",
      "65\n",
      "2.0\n",
      "\n",
      "66\n",
      "2.0\n",
      "\n",
      "67\n",
      "0.0\n",
      "\n",
      "68\n",
      "0.0\n",
      "\n",
      "69\n",
      "58.0\n",
      "\n",
      "70\n",
      "21.0\n",
      "\n",
      "71\n",
      "3.0\n",
      "\n",
      "72\n",
      "21.0\n",
      "\n",
      "73\n",
      "1.0\n",
      "\n",
      "74\n",
      "0.0\n",
      "\n",
      "75\n",
      "48.0\n",
      "\n",
      "76\n",
      "0.0\n",
      "\n",
      "77\n",
      "2.0\n",
      "\n",
      "78\n",
      "0.0\n",
      "\n",
      "79\n",
      "7.0\n",
      "\n",
      "80\n",
      "31.0\n",
      "\n",
      "81\n",
      "0.0\n",
      "\n",
      "82\n",
      "0.0\n",
      "\n",
      "83\n",
      "0.0\n",
      "\n",
      "84\n",
      "28.0\n",
      "\n",
      "85\n",
      "6.0\n",
      "\n",
      "86\n",
      "1.0\n",
      "\n",
      "87\n",
      "1.0\n",
      "\n",
      "88\n",
      "0.0\n",
      "\n",
      "89\n",
      "0.0\n",
      "\n",
      "90\n",
      "58.0\n",
      "\n",
      "91\n",
      "23.0\n",
      "\n",
      "92\n",
      "3.0\n",
      "\n",
      "93\n",
      "13.0\n",
      "\n",
      "94\n",
      "0.0\n",
      "\n",
      "95\n",
      "0.0\n",
      "\n",
      "96\n",
      "2.0\n",
      "\n",
      "97\n",
      "1.0\n",
      "\n",
      "98\n",
      "0.0\n",
      "\n",
      "99\n",
      "8.0\n",
      "\n",
      "100\n",
      "2.0\n",
      "\n",
      "101\n",
      "41.0\n",
      "\n",
      "102\n",
      "4.0\n",
      "\n",
      "103\n",
      "0.0\n",
      "\n",
      "104\n",
      "10.0\n",
      "\n",
      "105\n",
      "4.0\n",
      "\n",
      "106\n",
      "12.0\n",
      "\n",
      "107\n",
      "0.0\n",
      "\n",
      "108\n",
      "0.0\n",
      "\n",
      "109\n",
      "0.0\n",
      "\n",
      "110\n",
      "15.0\n",
      "\n",
      "111\n",
      "26.0\n",
      "\n",
      "112\n",
      "1.0\n",
      "\n",
      "113\n",
      "0.0\n",
      "\n",
      "114\n",
      "0.0\n",
      "\n",
      "115\n",
      "1.0\n",
      "\n",
      "116\n",
      "36.0\n",
      "\n",
      "117\n",
      "74.0\n",
      "\n",
      "118\n",
      "8.0\n",
      "\n",
      "119\n",
      "17.0\n",
      "\n",
      "120\n",
      "4.0\n",
      "\n",
      "121\n",
      "3.0\n",
      "\n",
      "122\n",
      "0.0\n",
      "\n",
      "123\n",
      "0.0\n",
      "\n",
      "124\n",
      "0.0\n",
      "\n",
      "125\n",
      "10.0\n",
      "\n",
      "126\n",
      "21.0\n",
      "\n",
      "127\n",
      "0.0\n",
      "\n",
      "128\n",
      "0.0\n",
      "\n",
      "129\n",
      "0.0\n",
      "\n",
      "130\n",
      "0.0\n",
      "\n",
      "131\n",
      "39.0\n",
      "\n",
      "132\n",
      "72.0\n",
      "\n",
      "133\n",
      "7.0\n",
      "\n",
      "134\n",
      "7.0\n",
      "\n",
      "135\n",
      "0.0\n",
      "\n",
      "136\n",
      "0.0\n",
      "\n",
      "137\n",
      "0.0\n",
      "\n",
      "138\n",
      "0.0\n",
      "\n",
      "139\n",
      "0.0\n",
      "\n",
      "140\n",
      "1.0\n",
      "\n",
      "141\n",
      "0.0\n",
      "\n",
      "142\n",
      "0.0\n",
      "\n",
      "143\n",
      "0.0\n",
      "\n",
      "144\n",
      "1.0\n",
      "\n",
      "145\n",
      "190.0\n",
      "\n",
      "146\n",
      "3.0\n",
      "\n",
      "147\n",
      "3.0\n",
      "\n",
      "148\n",
      "0.0\n",
      "\n",
      "149\n",
      "68.0\n",
      "\n",
      "150\n",
      "7.0\n",
      "\n",
      "151\n",
      "124.0\n",
      "\n",
      "152\n",
      "10.0\n",
      "\n",
      "153\n",
      "22.0\n",
      "\n",
      "154\n",
      "0.0\n",
      "\n",
      "155\n",
      "0.0\n",
      "\n",
      "156\n",
      "0.0\n",
      "\n",
      "157\n",
      "17.0\n",
      "\n",
      "158\n",
      "15.0\n",
      "\n",
      "159\n",
      "0.0\n",
      "\n",
      "160\n",
      "0.0\n",
      "\n",
      "161\n",
      "0.0\n",
      "\n",
      "162\n",
      "0.0\n",
      "\n",
      "163\n",
      "60.0\n",
      "\n",
      "164\n",
      "17.0\n",
      "\n",
      "165\n",
      "10.0\n",
      "\n",
      "166\n",
      "3.0\n",
      "\n",
      "167\n",
      "7.0\n",
      "\n",
      "168\n",
      "22.0\n",
      "\n",
      "169\n",
      "0.0\n",
      "\n",
      "170\n",
      "0.0\n",
      "\n",
      "171\n",
      "0.0\n",
      "\n",
      "172\n",
      "20.0\n",
      "\n",
      "173\n",
      "10.0\n",
      "\n",
      "174\n",
      "0.0\n",
      "\n",
      "175\n",
      "0.0\n",
      "\n",
      "176\n",
      "0.0\n",
      "\n",
      "177\n",
      "0.0\n",
      "\n",
      "178\n",
      "69.0\n",
      "\n",
      "179\n",
      "29.0\n",
      "\n",
      "180\n",
      "2.0\n",
      "\n",
      "181\n",
      "10.0\n",
      "\n",
      "182\n",
      "10.0\n",
      "\n",
      "183\n",
      "24.0\n",
      "\n",
      "184\n",
      "0.0\n",
      "\n",
      "185\n",
      "0.0\n",
      "\n",
      "186\n",
      "0.0\n",
      "\n",
      "187\n",
      "32.0\n",
      "\n",
      "188\n",
      "13.0\n",
      "\n",
      "189\n",
      "0.0\n",
      "\n",
      "190\n",
      "0.0\n",
      "\n",
      "191\n",
      "0.0\n",
      "\n",
      "192\n",
      "0.0\n",
      "\n",
      "193\n",
      "44.0\n",
      "\n",
      "194\n",
      "35.0\n",
      "\n",
      "195\n",
      "7.0\n",
      "\n",
      "196\n",
      "16.0\n",
      "\n",
      "197\n",
      "3.0\n",
      "\n",
      "198\n",
      "9.0\n",
      "\n",
      "199\n",
      "0.0\n",
      "\n",
      "200\n",
      "0.0\n",
      "\n",
      "201\n",
      "0.0\n",
      "\n",
      "202\n",
      "15.0\n",
      "\n",
      "203\n",
      "27.0\n",
      "\n",
      "204\n",
      "0.0\n",
      "\n",
      "205\n",
      "0.0\n",
      "\n",
      "206\n",
      "0.0\n",
      "\n",
      "207\n",
      "1.0\n",
      "\n",
      "208\n",
      "24.0\n",
      "\n",
      "209\n",
      "86.0\n",
      "\n",
      "210\n",
      "5.0\n",
      "\n",
      "211\n",
      "17.0\n",
      "\n",
      "212\n",
      "86.0\n",
      "\n",
      "213\n",
      "9.0\n",
      "\n",
      "214\n",
      "0.0\n",
      "\n",
      "215\n",
      "0.0\n",
      "\n",
      "216\n",
      "2.0\n",
      "\n",
      "217\n",
      "0.0\n",
      "\n",
      "218\n",
      "130.0\n",
      "\n",
      "219\n",
      "1.0\n",
      "\n",
      "220\n",
      "37.0\n",
      "\n",
      "221\n",
      "15.0\n",
      "\n",
      "222\n",
      "0.0\n",
      "\n",
      "223\n",
      "0.0\n",
      "\n",
      "224\n",
      "0.0\n",
      "\n",
      "225\n",
      "9.0\n",
      "\n",
      "226\n",
      "0.0\n",
      "\n",
      "227\n",
      "7.0\n",
      "\n",
      "228\n",
      "4.0\n",
      "\n",
      "229\n",
      "0.0\n",
      "\n",
      "230\n",
      "6.0\n",
      "\n",
      "231\n",
      "0.0\n",
      "\n",
      "232\n",
      "0.0\n",
      "\n",
      "233\n",
      "0.0\n",
      "\n",
      "234\n",
      "0.0\n",
      "\n",
      "235\n",
      "121.0\n",
      "\n",
      "236\n",
      "93.0\n",
      "\n",
      "237\n",
      "7.0\n",
      "\n",
      "238\n",
      "24.0\n",
      "\n",
      "239\n",
      "14.0\n",
      "\n",
      "240\n",
      "84.0\n",
      "\n",
      "241\n",
      "3.0\n",
      "\n",
      "242\n",
      "6.0\n",
      "\n",
      "243\n",
      "21.0\n",
      "\n",
      "244\n",
      "152.0\n",
      "\n",
      "245\n",
      "5.0\n",
      "\n",
      "246\n",
      "7.0\n",
      "\n",
      "247\n",
      "5.0\n",
      "\n",
      "248\n",
      "9.0\n",
      "\n",
      "249\n",
      "33.0\n",
      "\n",
      "250\n",
      "0.0\n",
      "\n",
      "251\n",
      "0.0\n",
      "\n",
      "252\n",
      "0.0\n",
      "\n",
      "253\n",
      "36.0\n",
      "\n",
      "254\n",
      "28.0\n",
      "\n",
      "255\n",
      "1.0\n",
      "\n",
      "256\n",
      "2.0\n",
      "\n",
      "257\n",
      "0.0\n",
      "\n",
      "258\n",
      "1.0\n",
      "\n",
      "259\n",
      "49.0\n",
      "\n",
      "260\n",
      "40.0\n",
      "\n",
      "261\n",
      "5.0\n",
      "\n",
      "262\n",
      "18.0\n",
      "\n",
      "263\n",
      "0.0\n",
      "\n",
      "264\n",
      "0.0\n",
      "\n",
      "265\n",
      "0.0\n",
      "\n",
      "266\n",
      "0.0\n",
      "\n",
      "267\n",
      "0.0\n",
      "\n",
      "268\n",
      "39.0\n",
      "\n",
      "269\n",
      "0.0\n",
      "\n",
      "270\n",
      "0.0\n",
      "\n",
      "271\n",
      "0.0\n",
      "\n",
      "272\n",
      "0.0\n",
      "\n",
      "273\n",
      "6.0\n",
      "\n",
      "274\n",
      "53.0\n",
      "\n",
      "275\n",
      "0.0\n",
      "\n",
      "276\n",
      "3.0\n",
      "\n",
      "277\n",
      "21.0\n",
      "\n",
      "278\n",
      "0.0\n",
      "\n",
      "279\n",
      "1.0\n",
      "\n",
      "280\n",
      "0.0\n",
      "\n",
      "281\n",
      "0.0\n",
      "\n",
      "282\n",
      "0.0\n",
      "\n",
      "283\n",
      "19.0\n",
      "\n",
      "284\n",
      "5.0\n",
      "\n",
      "285\n",
      "0.0\n",
      "\n",
      "286\n",
      "0.0\n",
      "\n",
      "287\n",
      "0.0\n",
      "\n",
      "288\n",
      "6.0\n",
      "\n",
      "289\n",
      "94.0\n",
      "\n",
      "290\n",
      "0.0\n",
      "\n",
      "291\n",
      "3.0\n",
      "\n",
      "292\n",
      "9.0\n",
      "\n",
      "293\n",
      "10.0\n",
      "\n",
      "294\n",
      "26.0\n",
      "\n",
      "295\n",
      "0.0\n",
      "\n",
      "296\n",
      "0.0\n",
      "\n",
      "297\n",
      "0.0\n",
      "\n",
      "298\n",
      "20.0\n",
      "\n",
      "299\n",
      "11.0\n",
      "\n",
      "300\n",
      "0.0\n",
      "\n",
      "301\n",
      "0.0\n",
      "\n",
      "302\n",
      "0.0\n",
      "\n",
      "303\n",
      "0.0\n",
      "\n",
      "304\n",
      "65.0\n",
      "\n",
      "305\n",
      "16.0\n",
      "\n",
      "306\n",
      "9.0\n",
      "\n",
      "307\n",
      "4.0\n",
      "\n",
      "308\n",
      "58.0\n",
      "\n",
      "309\n",
      "9.0\n",
      "\n",
      "310\n",
      "31.0\n",
      "\n",
      "311\n",
      "43.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for i in range(312):\n",
    "#     print(i)\n",
    "#     print(attribute_mtx[:,i].sum(dim=0).item())\n",
    "#     print()\n",
    "# # print(attribute_mtx.sum(dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Models\n",
    "Here, we continue by defining the various models that our uRDTC consists of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Conv2d(in_channels, 20, kernel_size=3, stride=1),\n",
    "                                 nn.ReLU(True),\n",
    "                                 nn.BatchNorm2d(20),\n",
    "                                 nn.Conv2d(20, 50, kernel_size=5, stride=2),\n",
    "                                 nn.ReLU(True),\n",
    "                                 nn.BatchNorm2d(50),\n",
    "                                 nn.Conv2d(50, 100, kernel_size=5, stride=2),\n",
    "                                 nn.ReLU(True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class DropoutCNN(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 20, kernel_size=3, stride=1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, kernel_size=5, stride=2)\n",
    "        self.conv3 = nn.Conv2d(50, 100, kernel_size=5, stride=2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.dropout2d(F.relu(self.conv1(x)), 0.2)\n",
    "        x = F.dropout2d(F.relu(self.conv2(x)), 0.2)\n",
    "        x = F.dropout2d(F.relu(self.conv3(x)), 0.2)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def get_cnn(in_channels, type='cnn', pretrained_cnn_weights=None,\n",
    "            freeze_weights=False, default_pretrained=False):\n",
    "    TYPES = ['cnn', 'dropoutcnn', 'resnet152'] # TYPES = ['cnn', 'shallowcnn', 'resnet', 'resnet152']\n",
    "    assert type in TYPES\n",
    "\n",
    "    if type == 'cnn':\n",
    "        cnn = CNN(in_channels)\n",
    "    if type == 'dropoutcnn':\n",
    "        cnn = DropoutCNN(in_channels)\n",
    "#     if type == 'resnet152':\n",
    "#         cnn = models.resnet152(pretrained=default_pretrained)\n",
    "    else:\n",
    "        cnn = Identity()\n",
    "\n",
    "    # if pretrained_cnn_weights:\n",
    "    #     if type == 'resnet152':\n",
    "    #         cnn.fc = nn.Linear(cnn.fc.in_features, pretrained_cnn_weights['fc.weight'].size(0))\n",
    "    #     cnn.load_state_dict(pretrained_cnn_weights)\n",
    "    if pretrained_cnn_weights:\n",
    "        cnn.load_state_dict(pretrained_cnn_weights)\n",
    "    \n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OC(nn.Module):\n",
    "    def __init__(self, model_type, num_classes, cnn_type, input_channels, cnn_out_size,\n",
    "                 dataset, decision_size=2, max_iters=20, attribute_size=20, attribute_mtx=None, attribute_coef=0.5, hidden_size=100,\n",
    "                 tau_initial=5, tau_target=0.5, use_pretrained=False, shallow=False, strategy='aRDTC'):\n",
    "        super(OC, self).__init__()\n",
    "        assert model_type in ['xoc'] #, 'ioc']\n",
    "        self.model_type = model_type\n",
    "        self.num_classes = num_classes\n",
    "        self.attribute_size = attribute_size\n",
    "        self.attribute_mtx = attribute_mtx\n",
    "        self.attribute_coef = attribute_coef if attribute_mtx is not None else 0.\n",
    "        self.decision_size = decision_size # change keyword default to 3?\n",
    "        self.tau_initial = tau_initial\n",
    "        self.tau_target = tau_target\n",
    "        self.max_iters = max_iters\n",
    "        self.shallow = shallow\n",
    "        self.stats = defaultdict(list)\n",
    "        self.reduced_vocab_size = 2\n",
    "        self.strategy = strategy\n",
    "\n",
    "        self.no_lstm = False\n",
    "\n",
    "        #self.init_attribute_matrix(attribute_mtx, attribute_size, attribute_coef, use_bin_attr)\n",
    "\n",
    "        self.cnn = self.init_cnn(cnn_type, input_channels, dataset, use_pretrained)\n",
    "        self.init_network(hidden_size, decision_size, num_classes, attribute_size, cnn_out_size, shallow)\n",
    "\n",
    "        self.init_losses()\n",
    "\n",
    "\n",
    "\n",
    "        self.phase = 'train'\n",
    "\n",
    "        # for stats\n",
    "        self.logits_list = []\n",
    "        self.sigmas_list = []\n",
    "#         self.labels_list\n",
    "        self.binary_features_list = []\n",
    "        self.labels_list = []\n",
    "        self.used_attributes_list = []\n",
    "        self.certain_attrs = []\n",
    "        self.attribute_accuracies = []\n",
    "        self.drop_ratios = []\n",
    "        self.mean_sigmas = []\n",
    "        \n",
    "\n",
    "    def init_network(self, hidden_size, decision_size, num_classes, attribute_size, cnn_out_size, shallow):\n",
    "        assert decision_size > 1\n",
    "\n",
    "        # LSTM initialization parameters\n",
    "        if self.no_lstm:\n",
    "            self.init_h0 = nn.Parameter(torch.zeros(attribute_size * decision_size), requires_grad=False)\n",
    "            self.init_c0 = nn.Parameter(torch.zeros(attribute_size * decision_size), requires_grad=False)\n",
    "        else:\n",
    "            self.init_h0 = nn.Parameter(torch.zeros(hidden_size).uniform_(-0.01, 0.01), requires_grad=True)\n",
    "            self.init_c0 = nn.Parameter(torch.zeros(hidden_size).uniform_(-0.01, 0.01), requires_grad=True)\n",
    "\n",
    "        if self.no_lstm:\n",
    "            self.lstm = lambda x, y: (None, (x.squeeze(), x.squeeze()))\n",
    "        else:\n",
    "            self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "\n",
    "        if self.no_lstm:\n",
    "            classifier_in = attribute_size * decision_size\n",
    "        else:\n",
    "            classifier_in = attribute_size * decision_size\n",
    "\n",
    "        self.classifier = nn.Sequential(#nn.BatchNorm1d(classifier_in) if not self.no_lstm else Identity(),\n",
    "                                        nn.Linear(classifier_in, hidden_size),\n",
    "                                        nn.ReLU(inplace=True),\n",
    "                                        nn.BatchNorm1d(hidden_size),\n",
    "                                        nn.Linear(hidden_size, num_classes))\n",
    "\n",
    "        if self.model_type == 'xoc':\n",
    "            if self.no_lstm:\n",
    "                feat_select_in_size = attribute_size * decision_size\n",
    "            else:\n",
    "                feat_select_in_size = hidden_size\n",
    "            feat_select_out_size = attribute_size\n",
    "            pre_lstm_size = attribute_size * decision_size * 2\n",
    "\n",
    "            bin_feat_type = 'shallow' if shallow else 'dropoutmlp' #'mlp'\n",
    "            feat_select_type = 'mlp_small'\n",
    "\n",
    "        elif self.model_type == 'ioc':\n",
    "            bin_feat_type = 'identity'\n",
    "            feat_select_type = 'mlp_big'\n",
    "\n",
    "            if not shallow:\n",
    "                feat_select_in_size = cnn_out_size + hidden_size\n",
    "                feat_select_out_size = decision_size\n",
    "                pre_lstm_size = feat_select_out_size\n",
    "            else:\n",
    "                feat_select_in_size = hidden_size\n",
    "                feat_select_out_size = cnn_out_size * decision_size\n",
    "                pre_lstm_size = decision_size\n",
    "\n",
    "        if feat_select_type == 'mlp_small':\n",
    "            self.feature_selection = nn.Sequential(nn.BatchNorm1d(feat_select_in_size) if not self.no_lstm else Identity(),\n",
    "                                                   nn.Linear(feat_select_in_size , hidden_size),\n",
    "                                                   nn.ReLU(inplace=True),\n",
    "                                                   nn.BatchNorm1d(hidden_size),\n",
    "                                                   nn.Linear(hidden_size, feat_select_out_size))\n",
    "        elif feat_select_type == 'mlp_big':\n",
    "            self.feature_selection = nn.Sequential(nn.BatchNorm1d(feat_select_in_size) if not self.no_lstm else Identity(),\n",
    "                                                   nn.Linear(feat_select_in_size, hidden_size),\n",
    "                                                   nn.ReLU(inplace=True),\n",
    "                                                   nn.BatchNorm1d(hidden_size),\n",
    "                                                   nn.Linear(hidden_size, hidden_size),\n",
    "                                                   nn.ReLU(inplace=True),\n",
    "                                                   nn.BatchNorm1d(hidden_size),\n",
    "                                                   nn.Linear(hidden_size, feat_select_out_size))\n",
    "\n",
    "        if bin_feat_type == 'identity':\n",
    "            self.binary_features = Identity()\n",
    "        elif bin_feat_type == 'shallow':\n",
    "            class AddZeros(nn.Module):\n",
    "                def __init__(self):\n",
    "                    super().__init__()\n",
    "\n",
    "                def forward(self, x):\n",
    "                    zeros = torch.zeros_like(x).unsqueeze(2)\n",
    "                    return torch.cat((x.unsqueeze(2), zeros), dim=2)\n",
    "\n",
    "            self.binary_features = AddZeros()\n",
    "        elif bin_feat_type == 'mlp':\n",
    "            self.binary_features = nn.Sequential(nn.BatchNorm1d(cnn_out_size), # use dropout\n",
    "                                                 nn.Linear(cnn_out_size, hidden_size),\n",
    "                                                 nn.ReLU(inplace=True),\n",
    "                                                 nn.BatchNorm1d(hidden_size), # use dropout\n",
    "                                                 nn.Linear(hidden_size, hidden_size),\n",
    "                                                 nn.ReLU(inplace=True),\n",
    "                                                 nn.BatchNorm1d(hidden_size), # use dropout\n",
    "                                                 nn.Linear(hidden_size, attribute_size * self.reduced_vocab_size))\n",
    "        elif bin_feat_type == 'dropoutmlp':\n",
    "            self.binary_features = nn.Sequential(\n",
    "                                                nn.Linear(cnn_out_size, hidden_size),\n",
    "                                                nn.ReLU(inplace=False),\n",
    "                                                nn.Dropout(0.2, inplace=False),\n",
    "                                                nn.Linear(hidden_size, hidden_size),\n",
    "                                                nn.ReLU(inplace=False),\n",
    "                                                nn.Dropout(0.2, inplace=False),\n",
    "                                                nn.Linear(hidden_size, attribute_size * self.reduced_vocab_size)\n",
    "                                                )\n",
    "\n",
    "        if self.no_lstm:\n",
    "            self.pre_lstm = Identity()\n",
    "        else:\n",
    "            self.pre_lstm = nn.Sequential(#nn.BatchNorm1d(pre_lstm_size),\n",
    "                                          nn.Linear(pre_lstm_size, hidden_size),\n",
    "                                          nn.ReLU(inplace=True),\n",
    "                                          nn.BatchNorm1d(hidden_size))\n",
    "\n",
    "\n",
    "        # Temperature parameters\n",
    "        self.binary_features.tau = nn.Parameter(torch.tensor([self.tau_initial], dtype=torch.float), requires_grad=True)\n",
    "        self.feature_selection.tau = nn.Parameter(torch.tensor([self.tau_initial], dtype=torch.float), requires_grad=True)\n",
    "        #self.init_weights()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    def get_attribute_uncertainty_batch(self, image_features, n=100, batch_size=64):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "\n",
    "            outputs = torch.zeros((n, batch_size, attribute_size * self.reduced_vocab_size), device=device) # init outputs with dummy values\n",
    "\n",
    "    #         if self.phase=='test':\n",
    "    #         print(self.binary_features.training)\n",
    "\n",
    "            if not self.binary_features.training:\n",
    "                current_phase = 'test'\n",
    "                self.binary_features.train()\n",
    "\n",
    "            else:\n",
    "                current_phase = 'train'\n",
    "    #         print(self.binary_features.training)\n",
    "    #         print()\n",
    "\n",
    "    #             for layer in self.binary_features:\n",
    "    #                 if isinstance(layer, torch.nn.modules.dropout._DropoutNd):\n",
    "    #                     layer.train()\n",
    "\n",
    "            for i in range(n):\n",
    "                outputs[i] = F.softmax(self.binary_features(image_features))\n",
    "\n",
    "            if current_phase=='test':\n",
    "    #         if self.phase=='test':\n",
    "                self.binary_features.eval()\n",
    "    #             for layer in self.binary_features:\n",
    "    #                 if isinstance(layer, torch.nn.modules.dropout._DropoutNd):\n",
    "    #                     layer.eval()\n",
    "    #                 else:\n",
    "    #                     layer.train()\n",
    "\n",
    "            sigmas = outputs.std(dim=0)\n",
    "\n",
    "            return sigmas\n",
    "    \n",
    "    \n",
    "    def get_attribute_uncertainty(self, image_features, n=10, batch_size=64):\n",
    "        outputs = torch.zeros((n, batch_size, attribute_size * self.reduced_vocab_size), device=device)\n",
    "        \n",
    "        if self.phase == 'train':\n",
    "            for i in range(n):\n",
    "                outputs[i] = F.softmax(self.binary_features(image_features))\n",
    "#                 outputs[i] = self.binary_features(image_features)\n",
    "\n",
    "        if self.phase == 'test':\n",
    "            for layer in self.binary_features:\n",
    "                if isinstance(layer, torch.nn.modules.dropout._DropoutNd):\n",
    "                    layer.train()\n",
    "#             self.binary_features.train()\n",
    "            for i in range(n):\n",
    "                outputs[i] = F.softmax(self.binary_features(image_features))\n",
    "#                 outputs[i] = self.binary_features(image_features)\n",
    "\n",
    "            for layer in self.binary_features:\n",
    "                if isinstance(layer, torch.nn.modules.dropout._DropoutNd):\n",
    "                    layer.eval()\n",
    "#             self.binary_features.eval()\n",
    "        \n",
    "        sigmas = outputs.var(dim=0)\n",
    "        sigmas += (0.01**2 * 0.5)/(2 * image_features.size(0) * weight_decay)\n",
    "#         print(sigmas.mean())\n",
    "\n",
    "        return sigmas\n",
    "  \n",
    "    def init_attribute_matrix(self, attribute_mtx, attribute_size, attribute_coef, use_bin_attr):\n",
    "        if attribute_coef > 0.:\n",
    "            if use_bin_attr:\n",
    "                attribute_mtx[attribute_mtx < 0.5] = 0.\n",
    "                attribute_mtx[attribute_mtx >= 0.5] = 1.\n",
    "            self.attribute_mtx = nn.Parameter(attribute_mtx, requires_grad=False)\n",
    "            self.attribute_size = attribute_mtx.size(1)\n",
    "        else:\n",
    "            self.attribute_mtx = None\n",
    "            self.attribute_size = attribute_size\n",
    "\n",
    "    def toggle_update_schedule(self):\n",
    "        # TODO: see a few lines below\n",
    "        #self.update_binary_features = not self.update_binary_features\n",
    "        pass\n",
    "\n",
    "    def get_param_groups(self):\n",
    "        cnn_params = []\n",
    "        tree_params = []\n",
    "        for n, p in self.named_parameters():\n",
    "            if p.requires_grad:\n",
    "                # TODO: introduce parameter that allows to switch between training alternatingly\n",
    "                # Currently commented out, so both groups contain the same parameters\n",
    "                \"\"\"\n",
    "                if n.startswith('cnn') or n.startswith('binary_features'):\n",
    "                    print('CNN', n)\n",
    "                    cnn_params.append(p)\n",
    "                else:\n",
    "                    print('OTHER', n)\n",
    "                    tree_params.append(p)\n",
    "                \"\"\"\n",
    "                cnn_params.append(p)\n",
    "                tree_params.append(p)\n",
    "        return tree_params, cnn_params\n",
    "\n",
    "    def set_optimizer(self, optimizers):\n",
    "        self.tree_optimizer = optimizers[0]\n",
    "        self.cnn_optimizer = optimizers[1]\n",
    "\n",
    "    def set_scheduler(self, schedulers):\n",
    "        self.tree_scheduler = schedulers[0]\n",
    "        self.cnn_scheduler = schedulers[1]\n",
    "\n",
    "    def get_optimizer(self):\n",
    "        if self.update_binary_features:\n",
    "            return self.cnn_optimizer\n",
    "        else:\n",
    "            return self.tree_optimizer\n",
    "\n",
    "    def get_scheduler(self):\n",
    "        if self.update_binary_features:\n",
    "            return self.cnn_scheduler\n",
    "        else:\n",
    "            return self.tree_scheduler\n",
    "\n",
    "    def init_losses(self):\n",
    "        self.cls_loss = nn.CrossEntropyLoss()\n",
    "        self.attr_loss = nn.BCEWithLogitsLoss()\n",
    "        self.update_binary_features = False\n",
    "\n",
    "    def init_cnn(self, cnn_type, input_channels, dataset, use_pretrained):\n",
    "        if cnn_type == 'None':\n",
    "            cnn = Identity()\n",
    "        else:\n",
    "            if use_pretrained:\n",
    "                # TODO add data_path and change state dict name \n",
    "                # cnn_state_dict = torch.load('pretrained/{}_{}.pth'.format(dataset, cnn_type))\n",
    "#                 cnn_state_dict = torch.load('pretrained/cub_resnet152.pkl')# .format(dataset, cnn_type)\n",
    "                cnn_state_dict = torch.load('pretrained/{}_resnet152.pkl'.format(dataset))# .format(dataset, cnn_type)\n",
    "\n",
    "                cnn = get_cnn(input_channels, cnn_type, cnn_state_dict, freeze_weights=True)\n",
    "            else:\n",
    "                cnn = get_cnn(input_channels, cnn_type)\n",
    "\n",
    "        return cnn\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight.data)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.fill_(0.1)\n",
    "\n",
    "    def set_tau(self, epoch):\n",
    "        annealing_factor = epoch / 100\n",
    "        self.tau = self.tau_initial\n",
    "        self.tau -= (self.tau_initial - self.tau_target) * annealing_factor\n",
    "        self.tau = max(self.tau, self.tau_target)\n",
    "\n",
    "    def process_images(self, images):\n",
    "        batch_size = images.size(0)\n",
    "        img_feats = self.cnn(images)\n",
    "        img_feats = img_feats.view(img_feats.size(0), -1)\n",
    "        image_features = self.binary_features(img_feats)\n",
    "        # print(image_features.size())\n",
    "        ################## remove attrs code\n",
    "#         sigmas = self.get_attribute_uncertainty_batch(img_feats,n=100, batch_size=batch_size)\n",
    "        \n",
    "        if self.strategy == 'remRDTC':\n",
    "            with torch.no_grad():\n",
    "                sigmas = self.get_attribute_uncertainty(img_feats, n=5, batch_size=images.size(0))\n",
    "            uncertain_attrs = (sigmas > 0.005).float() # get binary uncertain attrs\n",
    "            certain_attrs = 1. - uncertain_attrs\n",
    "            mask = certain_attrs.detach()\n",
    "            inv_mask = 1-mask\n",
    "            min_value = image_features.min()\n",
    "            image_features = image_features * mask # put zeros where uncertain attts are\n",
    "            image_features = image_features - (inv_mask.detach()*min_value.detach()) #*-500\n",
    "\n",
    "#         sigmas.detach()\n",
    "#         sigmas.cuda()\n",
    "#         self.mean_sigmas.append(sigmas.mean().item())\n",
    "#         drop_ratio = (sigmas>0.005).float().sum()/(images.size(0)*attribute_size*2.)\n",
    "#         min_value = image_features.min()\n",
    "#         min_value.detach()\n",
    "#         self.drop_ratios.append(drop_ratio)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #############################################################\n",
    "#         if not self.training:\n",
    "\n",
    "#             self.sigmas_list.append(sigmas)\n",
    "            # self.logits_list.append(image_features)\n",
    "            # image_features = torch.cat((attribute_logits, sigmas),1)\n",
    "        \n",
    "        \n",
    "        ################## remove attrs\n",
    "#         uncertain_attrs = (sigmas > 0.005).float() # get binary uncertain attrs\n",
    "#         certain_attrs = 1. - uncertain_attrs\n",
    "#         mask = certain_attrs.detach()#(torch.FloatTensor(image_features.size()).uniform_() > 0.050).float().to(device)\n",
    "        if self.strategy == 'randRDTC':\n",
    "            mask = (torch.FloatTensor(image_features.size()).uniform_() > 0.050).float().to(device)\n",
    "            inv_mask = 1-mask\n",
    "#         self.drop_ratios.append((inv_mask.sum()/39936.0).item())\n",
    "#         mask.detach()\n",
    "            min_value = image_features.min()\n",
    "            image_features = image_features * mask # put zeros where uncertain attts are\n",
    "            image_features = image_features - (inv_mask.detach()*min_value.detach()) #*-500\n",
    "        ##############################################################\n",
    "\n",
    "        if self.model_type == 'xoc':\n",
    "            attribute_logits = image_features.view(-1, 2)\n",
    "\n",
    "\n",
    "            attributes_softmax = F.softmax(attribute_logits / self.binary_features.tau, dim=1)\n",
    "            attributes_hard = self.argmax(attributes_softmax, dim=1)\n",
    "            image_features = attributes_hard.view(images.size(0), -1, 2)\n",
    "\n",
    "            # TODO: generalize to different decision sizes\n",
    "            bin_attribute_logits = attribute_logits - attribute_logits[:, 1].unsqueeze(-1)\n",
    "            self.attribute_logits = bin_attribute_logits[:, 0].view(images.size(0), -1)\n",
    "\n",
    "            self.collect_hist_stats('AttributesSoft', F.softmax(attribute_logits, dim=1))\n",
    "            self.collect_hist_stats('AttributesSoftTemp', attributes_softmax)\n",
    "            self.collect_hist_stats('AttributesHard', attributes_hard.max(dim=1)[1])\n",
    "\n",
    "        return image_features\n",
    "\n",
    "    def make_decision(self, lstm_out, binary_features, iter, sigma=[], max_uncertainty=0.2):\n",
    "        if self.model_type == 'xoc':\n",
    "            # Perform categorical feature selection\n",
    "            selection_logits = self.feature_selection(lstm_out)\n",
    "            # print(selection_logits[0][:10])\n",
    "            if self.training:\n",
    "                hard_selection = F.gumbel_softmax(selection_logits, tau=self.feature_selection.tau, hard=True)\n",
    "            else:\n",
    "               \n",
    "                # sigma = self.get_attribute_uncertainty(binary_features)\n",
    "                # sigma = sigma[:,:312]#.squeeze() \n",
    "                # certain_logits = torch.where(sigma>max_uncertainty,\n",
    "                #                              selection_logits,\n",
    "                #                              torch.zeros_like(selection_logits).new_full(selection_logits.size(), -10000)) # -10000\n",
    "                hard_selection = self.argmax(selection_logits, dim=1)\n",
    "                # print(hard_selection.size())\n",
    "                # print(binary_features.size())\n",
    "                # print(hard_selection.unsqueeze(2).size())\n",
    "\n",
    "\n",
    "            # Get single decision\n",
    "            self.saved_attribute_selection = hard_selection.max(dim=1)[1]\n",
    "            \n",
    "\n",
    "            decision = (hard_selection.unsqueeze(2) * binary_features).view(-1, self.attribute_size * self.decision_size)\n",
    "            # print(decision[0])\n",
    "        elif self.model_type == 'ioc':\n",
    "            if not self.shallow:\n",
    "                features = torch.cat((lstm_out, binary_features), dim=1)\n",
    "                selection_logits = self.feature_selection(features)\n",
    "            else:\n",
    "                shallow_weights = self.feature_selection(lstm_out)\n",
    "                shallow_weights = shallow_weights.view(lstm_out.size(0), -1, self.decision_size)\n",
    "                selection_logits = torch.bmm(binary_features.unsqueeze(1), shallow_weights)\n",
    "                selection_logits = selection_logits.squeeze()\n",
    "\n",
    "            soft_decision = F.softmax(selection_logits / self.tau_selection, dim=1)\n",
    "            hard_selection = self.argmax(soft_decision, dim=1)\n",
    "            decision = hard_selection\n",
    "\n",
    "        # Collect statistics\n",
    "        self.collect_hist_stats('SelectionSoft', F.softmax(selection_logits, dim=1).max(dim=1)[0], iter)\n",
    "        self.collect_hist_stats('SelectionSoftTemp', F.softmax(selection_logits / self.feature_selection.tau, dim=1).max(dim=1)[0], iter)\n",
    "        self.collect_hist_stats('SelectionHard', hard_selection.max(dim=1)[1], iter)\n",
    "\n",
    "        return decision\n",
    "\n",
    "    def get_initial_state(self, batch_size):\n",
    "        h0 = self.init_h0.view(1, 1, -1).expand(-1, batch_size, -1)\n",
    "        c0 = self.init_c0.view(1, 1, -1).expand(-1, batch_size, -1)\n",
    "        state = (h0.contiguous(), c0.contiguous())\n",
    "        return state\n",
    "\n",
    "    def argmax(self, y_soft, dim):\n",
    "        index = y_soft.max(dim, keepdim=True)[1]\n",
    "        y_hard = torch.zeros_like(y_soft).scatter_(dim, index, 1.0)\n",
    "        argmax = y_hard - y_soft.detach() + y_soft\n",
    "        return argmax\n",
    "\n",
    "    def collect_hist_stats(self, name, data, i=None):\n",
    "        # TODO: investigate performance impact of collecting these statistics,\n",
    "        # make option to disable and/or autodisable if tree is too large\n",
    "        if 'Hard' in name:\n",
    "            stat_str = 'Hist/' + name\n",
    "            data = data.detach().cpu()\n",
    "            self.stats[stat_str].append(data)\n",
    "            if i is not None:\n",
    "                stat_str += str(i)\n",
    "                self.stats[stat_str].append(data)\n",
    "\n",
    "    def get_hist_stats(self, reset=True):\n",
    "        stats = self.stats\n",
    "        if reset:\n",
    "            self.stats = defaultdict(list)\n",
    "        #return None\n",
    "        return stats\n",
    "\n",
    "    def reset_stats(self):\n",
    "        self.unique_attributes = [set() for i in range(self.max_iters)]\n",
    "        if self.attribute_coef > 0.:\n",
    "            self.attr_pred_correct = [0 for i in range(self.max_iters)]\n",
    "\n",
    "    def update_unique_attributes(self, unique_attributes, iter):\n",
    "        for attr in unique_attributes:\n",
    "            self.unique_attributes[iter].add(attr.item())\n",
    "\n",
    "    def get_unique_attributes(self):\n",
    "        uniq_per_iter = []\n",
    "        for i in range(self.max_iters):\n",
    "            iter_set = self.unique_attributes[i]\n",
    "            for j in range(i+1):\n",
    "                if j == i:\n",
    "                    continue\n",
    "                iter_set = iter_set.union(self.unique_attributes[j])\n",
    "            uniq_per_iter.append(len(iter_set))\n",
    "        return uniq_per_iter\n",
    "\n",
    "    def update_attr_preds(self, attr_correct, iter):\n",
    "        self.attr_pred_correct[iter] += attr_correct\n",
    "\n",
    "    def get_attr_acc(self, total_cnt):\n",
    "        correct_cumsum = np.cumsum(self.attr_pred_correct)\n",
    "        cnt_per_iter = (np.arange(self.max_iters) + 1) * total_cnt\n",
    "        return correct_cumsum / cnt_per_iter\n",
    "\n",
    "    def init_tree_stats(self):\n",
    "        # TODO: investigate performance impact of collecting these statistics,\n",
    "        # make option to disable and/or autodisable if tree is too large\n",
    "\n",
    "        # Would be nice if this worked with sparse tensors\n",
    "        n_possible_states = self.decision_size ** self.max_iters\n",
    "        self.label_stats = torch.zeros((n_possible_states * self.decision_size,\n",
    "                                        self.num_classes), dtype=torch.int32)\n",
    "                                       #layout=torch.sparse_coo)\n",
    "        self.selection_stats = torch.zeros((n_possible_states,\n",
    "                                            self.attribute_size),\n",
    "                                           dtype=torch.int32)\n",
    "                                           #layout=torch.sparse_coo)\n",
    "\n",
    "    def update_tree_stats(self, attribute_selection, attribute_decisions, labels, iter):\n",
    "        # TODO: investigate performance impact of collecting these statistics,\n",
    "        # make option to disable and/or autodisable if tree is too large\n",
    "\n",
    "        if iter == 0:\n",
    "            self.batch_states = torch.zeros_like(labels)\n",
    "            for i in range(labels.size(0)):\n",
    "                self.label_stats[self.batch_states[i], labels[i]] += 1\n",
    "\n",
    "        for i in range(labels.size(0)):\n",
    "            self.selection_stats[self.batch_states[i], attribute_selection[i]] += 1\n",
    "            self.batch_states[i] += (attribute_decisions[i] + 1) * self.decision_size ** iter\n",
    "            self.label_stats[self.batch_states[i], labels[i]] += 1\n",
    "\n",
    "    def run_iteration(self, binary_features, state, decision_hist, iter, sigma=[]): # also pass sigma here\n",
    "        lstm_out = state[0].squeeze(0)\n",
    "\n",
    "        # Make binary decision\n",
    "        decision = self.make_decision(lstm_out, binary_features, iter, sigma)\n",
    "\n",
    "        if decision_hist is None:\n",
    "            decision_hist = decision\n",
    "        else:\n",
    "            decision_hist = (decision_hist + decision).clamp(0., 1.)\n",
    "\n",
    "        scaled_dh = decision_hist / decision_hist.sum(dim=1).unsqueeze(1).detach()\n",
    "        if self.no_lstm:\n",
    "            lstm_in = scaled_dh\n",
    "        else:\n",
    "            lstm_in = torch.cat((scaled_dh, decision), dim=1)\n",
    "\n",
    "        # Update LSTM state\n",
    "        lstm_in = self.pre_lstm(lstm_in).unsqueeze(1)\n",
    "        _, state = self.lstm(lstm_in, state)\n",
    "\n",
    "        # Get current classification\n",
    "        classifier_in = scaled_dh\n",
    "        #classifier_in = state[1].squeeze(0)\n",
    "        #classifier_in = torch.cat((decision_hist, self.lstm_state_bn(lstm_state)), dim=1)\n",
    "        classification = self.classifier(classifier_in)\n",
    "\n",
    "        return classification, state, decision_hist\n",
    "\n",
    "    def tree_rollout(self, images, labels, keep_tree_stats=False):\n",
    "        # Set initial state\n",
    "        state = self.get_initial_state(images.size(0))\n",
    "\n",
    "        # Get categorical features once\n",
    "        binary_features = self.process_images(images)\n",
    "        # collect attribute stats\n",
    "        # self.binary_features_list.append(binary_features)\n",
    "        # self.labels_list.append(labels)\n",
    "\n",
    "#         attr_acc = (binary_features[:,:,0] == attribute_mtx[labels]).sum().long() / 19968.0 #/ (312*labels.size(0))\n",
    "        attr_acc = (binary_features[:,:,0] == attribute_mtx[labels]).sum().long() / float((attribute_size*labels.size(0)))    \n",
    "#         print(attr_acc)\n",
    "        self.attribute_accuracies.append(attr_acc.item())\n",
    "\n",
    "        ######################### extended vocab code \n",
    "        if self.strategy == 'extRDTC':\n",
    "            with torch.no_grad():\n",
    "                img_feats = self.cnn(images)\n",
    "                img_feats = img_feats.view(img_feats.size(0), -1)\n",
    "    #             image_features = self.binary_features(img_feats) # maybe do those with no grad as well\n",
    "                sigmas = self.get_attribute_uncertainty(img_feats, n=5, batch_size=images.size(0))\n",
    "            if not self.training:\n",
    "                self.sigmas_list.append(sigmas)\n",
    "                self.labels_list.append(labels)\n",
    "    #         sigmas.detach()\n",
    "        \n",
    "#         ########### remove attrs code\n",
    "#         uncertain_attrs = (sigmas > 0.005).float()\n",
    "#         certain_attrs = 1. - uncertain_attrs\n",
    "#         uncertain_attrs = uncertain_attrs.view(images.size(0), attribute_size, 2)\n",
    "#         certain_attrs = certain_attrs.view(images.size(0), attribute_size, 2)\n",
    "# #         print(certain_attrs[0])\n",
    "#         mask = torch.bernoulli(torch.empty(binary_features.size(), device=device).uniform_(1, 1))\n",
    "        \n",
    "#         binary_features = binary_features * mask#certain_attrs.detach() # clean binary_features from uncertain attrs (replace with 0)\n",
    "        \n",
    "        \n",
    "\n",
    "#         ######################################### remove attrs code end\n",
    "        \n",
    "# #         self.mean_sigmas.append(sigmas.mean().item())\n",
    "            sigmas = (sigmas > 0.005).float() # 0.004\n",
    "            sigmas_new = torch.zeros(images.size(0), attribute_size,1, device=device)\n",
    "            sigmas_new += sigmas.view(images.size(0),attribute_size,2)[:,:,0].unsqueeze(2)\n",
    "            sigmas_new += sigmas.view(images.size(0),attribute_size,2)[:,:,1].unsqueeze(2)\n",
    "            sigmas_new = (sigmas_new > 0.0).float() # <- denotes uncertain attributes\n",
    "\n",
    "            self.drop_ratios.append((sigmas_new.sum()/19968.0).item())\n",
    "\n",
    "            # obtain uncertainty and append to decision\n",
    "            new_attribute_decisions = torch.cat([binary_features, torch.zeros_like(sigmas_new, device=device)], dim=2)\n",
    "            certain_decisions = 1. - sigmas_new\n",
    "            uncertain_onehot = torch.tensor([[0., 0., 1.]], device=device).repeat(images.size(0), attribute_size, 1)\n",
    "            uncertain_attrs_removed = certain_decisions.detach() * new_attribute_decisions\n",
    "            shaped_uncertain_attrs = sigmas_new.detach() * uncertain_onehot\n",
    "            final_attribute_decisions = uncertain_attrs_removed + shaped_uncertain_attrs\n",
    "#             binary_features = final_attribute_decisions\n",
    "#         ######################### extended vocab code end\n",
    "        \n",
    "        \n",
    "\n",
    "        loss = 0\n",
    "        j = 0\n",
    "        # stats\n",
    "        all_classifications = []\n",
    "        all_chosen_attr = []\n",
    "        all_attribute_preds = []\n",
    "\n",
    "        decision_hist = None\n",
    "        while j < self.max_iters:\n",
    "            classification, state, decision_hist = self.run_iteration(binary_features, state, decision_hist, j+1)\n",
    "            loss += (1. - self.attribute_coef) * self.cls_loss(classification, labels)\n",
    "            all_classifications.append(classification)\n",
    "\n",
    "            self.update_unique_attributes(self.saved_attribute_selection.unique(), j)\n",
    "\n",
    "            if self.model_type == 'xoc' and self.attribute_coef > 0.:\n",
    "                chosen_attribtutes = self.saved_attribute_selection\n",
    "                attribute_logits = self.attribute_logits\n",
    "\n",
    "                attribute_target = self.attribute_mtx[labels, :].gather(1, chosen_attribtutes.unsqueeze(1)).squeeze()\n",
    "                attribute_pred = attribute_logits.gather(1, chosen_attribtutes.unsqueeze(1)).squeeze()\n",
    "                loss += self.attribute_coef * self.attr_loss(attribute_pred,\n",
    "                                                             attribute_target)\n",
    "                \n",
    "\n",
    "\n",
    "                attribute_pred_bin = (attribute_pred > 0.).long()\n",
    "                self.update_attr_preds((attribute_pred_bin == attribute_target).sum().item(), j)\n",
    "\n",
    "                \n",
    "            if keep_tree_stats:\n",
    "                attribute_pred = self.attribute_logits.gather(1, self.saved_attribute_selection.unsqueeze(1)).squeeze()\n",
    "                self.update_tree_stats(self.saved_attribute_selection, (attribute_pred > 0.).long(),labels, j)\n",
    "\n",
    "                # all_chosen_attr.append(self.saved_attribute_selection)\n",
    "                all_attribute_preds.append((attribute_pred > 0.).long())\n",
    "\n",
    "            j += 1\n",
    "        \n",
    "            all_chosen_attr.append(self.saved_attribute_selection)\n",
    "\n",
    "        self.tmp_saved_chosen_attr = torch.stack(all_chosen_attr, dim=1)\n",
    "\n",
    "        if keep_tree_stats:\n",
    "            self.tmp_saved_cls = torch.stack(all_classifications, dim=1)\n",
    "            # self.tmp_saved_chosen_attr = torch.stack(all_chosen_attr, dim=1)\n",
    "            self.tmp_saved_attr_pred = torch.stack(all_attribute_preds, dim=1)\n",
    "        # else:\n",
    "        #     self.tmp_saved_chosen_attr = None\n",
    "\n",
    "        loss = loss / self.max_iters\n",
    "\n",
    "\n",
    "        ####################################\n",
    "        # if binary_features.size(0)==64:\n",
    "            # self.used_attributes_list.append(self.tmp_saved_chosen_attr)\n",
    "            # self.certain_attrs.append(certain_decisions)\n",
    "            # chosen_attributes_binary = torch.tensor([1 if x in [int(attr) for attr in self.tmp_saved_chosen_attr[:,x]] else 0 for x in range(312)], device=device)\n",
    "            # self.used_attributes_list.append(chosen_attributes_binary)\n",
    "            # self.sigmas_list.append(sigmas_all)\n",
    "        ####################################\n",
    "        return all_classifications, loss, self.tmp_saved_chosen_attr\n",
    "\n",
    "    def forward(self, images, labels, keep_tree_stats=False):\n",
    "        classification, loss, chosen_attribtutes = self.tree_rollout(images, labels, keep_tree_stats)\n",
    "        # classification, loss, chosen_attributes = self.tree_rollout(images, labels, keep_tree_stats)\n",
    "\n",
    "        return classification, loss#, chosen_attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "After defining our models, we can continue by training it. For this, we first set some hyperparameters and then continue by defining a trainer class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake input arguments\n",
    "model_type = 'xoc'\n",
    "cnn_type = 'uncertain'\n",
    "# cnn_type = 'resnet'\n",
    "attribute_coef = 0.2\n",
    "# attribute_size = 85#312 #1024\n",
    "# attribute_size = 312 #1024\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.00001\n",
    "step_size = 50\n",
    "num_epochs = 2\n",
    "max_iters = 10\n",
    "hidden_size = 1000\n",
    "cnn_out_size = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, dataloaders, num_epochs, device, log_freq, log_path): # todo remove stats dict\n",
    "\n",
    "        self.model = model\n",
    "        self.dataloaders = dataloaders\n",
    "        self.num_epochs = num_epochs\n",
    "        self.device = device\n",
    "        self.log_freq = log_freq\n",
    "        self.log_path = log_path\n",
    "        \n",
    "        self.logger = SummaryWriter(self.log_path)\n",
    "\n",
    "        #### TODO remove this workaround and use tensorboard\n",
    "#         with open('/content/drive/My Drive/rdtc/data/' + 'logs/' + 'stats_dict.json') as json_file:\n",
    "#             self.stats_dict = json.load(json_file)\n",
    "        \n",
    "        self.classifications_dict = {'correct':{'num':0, 'uncertainty':0},\n",
    "                                     'incorrect':{'num':0, 'uncertainty':0}}\n",
    "\n",
    "        self.uncertainty_stats = {'epoch_{}'.format(epoch):{'used_attributes':[],'sigmas':[], 'num_attrs_discarded':0} for epoch in range(num_epochs+2)}\n",
    "        self.mean_attr_accs = []\n",
    "        self.mean_drop_ratio = []\n",
    "        self.mean_sigmas = []\n",
    "        ############\n",
    "\n",
    "    def train(self):\n",
    "        self.model.phase = 'train'\n",
    "        self.train_model(self.dataloaders['train'])\n",
    "\n",
    "    def test(self):\n",
    "        self.model.phase = 'test'\n",
    "        self.test_model(self.dataloaders['test'], 'test', None, hard=False) # was: hard=True\n",
    "        self.model.phase = 'train'\n",
    "        return self.model.label_stats, self.model.selection_stats\n",
    "\n",
    "    def topk_correct(self, output, target, topk=(1,)):\n",
    "        maxk = max(topk)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        target_masks = []\n",
    "        target_cnt = []\n",
    "        for i in range(self.model.num_classes):\n",
    "            target_masks.append((target == i).unsqueeze(0))\n",
    "            target_cnt.append(target_masks[i].sum().item())\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = [(correct[:k] * tm).view(-1).float().sum(0, keepdim=True).item() for tm in target_masks]\n",
    "            res.append(np.array(correct_k))\n",
    "        return res, np.array(target_cnt)\n",
    "\n",
    "    def log_stats(self, phase, epoch, epoch_stats, hist_stats,\n",
    "                  unique_attr_stats, attr_acc):\n",
    "        for k in range(len(epoch_stats[0])):\n",
    "        # for k in range(1):\n",
    "\n",
    "            self.logger.add_scalar('Top1Accuracy{}/{}'.format(k+1, phase), epoch_stats[0][k], epoch)\n",
    "            # self.logger.add_scalar('Top5Accuracy{}/{}'.format(k+1, phase), epoch_stats[1][k], epoch)\n",
    "            # self.logger.add_scalar('Top1MeanClassAccuracy{}/{}'.format(k+1, phase), epoch_stats[3][k], epoch)\n",
    "            # self.logger.add_scalar('Top5MeanClassAccuracy{}/{}'.format(k+1, phase), epoch_stats[4][k], epoch)\n",
    "            # if unique_attr_stats is not None:\n",
    "            #     self.logger.add_scalar('UniqueAttributes{}/{}'.format(k+1, phase), unique_attr_stats[k], epoch)\n",
    "            # if attr_acc is not None:\n",
    "            #     self.logger.add_scalar('AttributeAccuracy{}/{}'.format(k+1, phase), attr_acc[k], epoch)\n",
    "        self.logger.add_scalar('Loss/'+phase, epoch_stats[2], epoch)\n",
    "\n",
    "        if hist_stats is not None:\n",
    "            for name, data in hist_stats.items():\n",
    "                data = torch.cat(data, dim=0).flatten()\n",
    "                if name.startswith('SelectionHard'):\n",
    "                    bins = self.model.attribute_size\n",
    "                elif name.startswith('AttributesHard'):\n",
    "                    bins = self.model.decision_size\n",
    "                else:\n",
    "                    bins = 'tensorflow'\n",
    "                self.logger.add_histogram(name, data, epoch, bins=bins)\n",
    "\n",
    "    def test_model(self, data_loader, phase, epoch, hard=False):\n",
    "        # Test the Model\n",
    "        self.model.eval()  # Change model to 'eval' mode (BN uses moving mean/var).\n",
    "        n_stats = self.model.max_iters if hasattr(self.model, 'max_iters') else 1\n",
    "        correct_1 = np.zeros((n_stats, self.model.num_classes))\n",
    "        correct_5 = np.zeros((n_stats, self.model.num_classes))\n",
    "        total = 0\n",
    "        total_cnt = np.zeros((1, self.model.num_classes))\n",
    "        total_loss = 0\n",
    "\n",
    "        if isinstance(self.model, OC):\n",
    "            self.model.reset_stats()\n",
    "            if hard:\n",
    "                self.model.init_tree_stats()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for idx, data in enumerate(data_loader):\n",
    "                if len(data) == 2:\n",
    "                    images, labels = data\n",
    "                    attributes = None\n",
    "                else:\n",
    "                    images, labels, attributes = data\n",
    "                    #attributes = attributes.to(self.device)\n",
    "                images = images.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                \n",
    "                classification, loss = self.model(images, labels, hard)\n",
    "                #####################################\n",
    "#                 print(labels.size())\n",
    "#                 print(labels[0].item())\n",
    "                #####################################\n",
    "\n",
    "                # Collect stats\n",
    "                total_loss += loss.item()\n",
    "                total += labels.size(0)\n",
    "                for k in range(len(classification)):\n",
    "                    ######################\n",
    "                    # print(classification[k].data)\n",
    "                    # print(labels[k])\n",
    "                    # print()\n",
    "                    # print(classification[k].data.size())\n",
    "                    # print(labels.size())\n",
    "                    # print()\n",
    "                    # values, indices = torch.max(classification[k], -1)\n",
    "                    # for i in range(classification[k].size(0)):\n",
    "\n",
    "                        # print(indices[i].item(),labels[i].item())\n",
    "                        # if indices[i].item()==labels[i].item():\n",
    "                        #     self.classifications_dict['correct']+=1\n",
    "                        # if indices[i].item()!=labels[i].item():\n",
    "                        #     self.classifications_dict['incorrect']+=1              \n",
    "          \n",
    "                    ######################\n",
    "                    ctopk, target_cnt = self.topk_correct(classification[k].data, labels, (1, 5))\n",
    "                    c1, c5 = ctopk\n",
    "                    # print(target_cnt)\n",
    "                    correct_1[k] += c1\n",
    "                    correct_5[k] += c5\n",
    "                total_cnt[0] += target_cnt\n",
    "\n",
    "                \n",
    "                # if classification[-1].size(0)==64:\n",
    "                #     values, indices = torch.max(classification[-1], -1)\n",
    "                #     image_features_ = self.model.cnn(images)\n",
    "                #     image_features_ = image_features_.view(image_features_.size(0), -1)\n",
    "                #     # self.model.binary_features = self.model.binary_features.train()\n",
    "                #     sigmas = self.model.get_attribute_uncertainty_batch(image_features_, batch_size=64)\n",
    "                #     sigmas.cuda()\n",
    "                #     # self.model.binary_features = self.model.binary_features.eval()\n",
    "                #     _, _, attributes_used = self.model.tree_rollout(images, labels, True)\n",
    "                #     for i in range(classification[-1].size(0)): # iterate over batch\n",
    "                #         chosen_attributes_binary = torch.tensor([1 if x in [int(attr) for attr in attributes_used[i]] else 0 for x in range(624)], device=device)\n",
    "                #         self.model.used_attributes_list.append(chosen_attributes_binary)\n",
    "                #         # chosen_attributes_binary.cuda()\n",
    "                #         used_sigmas = sigmas[i] * chosen_attributes_binary\n",
    "                #         if indices[i].item()==labels[i].item():\n",
    "                #             self.classifications_dict['correct']['num'] += 1\n",
    "                #             self.classifications_dict['correct']['uncertainty'] += used_sigmas.sum().item()\n",
    "                #         if indices[i].item()!=labels[i].item():\n",
    "                #             self.classifications_dict['incorrect']['num'] += 1\n",
    "                #             self.classifications_dict['incorrect']['uncertainty'] += used_sigmas.sum().item()\n",
    "                \n",
    "        # collect uncertainty stats#############################\n",
    "        # num_batches = len(model.used_attributes_list)\n",
    "\n",
    "        # attribute_zeros = torch.zeros(num_batches,624)\n",
    "        # # attrs_discarded_zeros = torch.zeros(num_batches, 624)\n",
    "        # sigma_zeros = torch.zeros(1, 624, device=device)\n",
    "        # num_attrs_discarded = 0\n",
    "        # for i in range(num_batches):\n",
    "        #     for batch_index in range(64):\n",
    "        #         example_attrs = [int(attr) for attr in model.used_attributes_list[i][batch_index]] # \n",
    "        #         attribute_zeros[i] += torch.tensor([1 if x in example_attrs else 0 for x in range(624)]) # used attrs binary\n",
    "        #         used_attrs_binary = torch.tensor([1 if x in example_attrs else 0 for x in range(624)]) # for that example\n",
    "        #         certain_attrs = model.certain_attrs[i][batch_index]\n",
    "        #         used_certain_attrs = used_attrs_binary.detach().cpu()[:312] * certain_attrs.detach().cpu()\n",
    "        #         num_attrs_discarded += torch.abs(used_attrs_binary.sum() - used_certain_attrs.sum())\n",
    "        #     sigma_zeros += model.sigmas_list[i].mean(dim=0) # add average of batch\n",
    "        #     # num_attrs_discarded += model.num_attrs_discarded_list[i]\n",
    "\n",
    "        \n",
    "        # self.uncertainty_stats['epoch_{}'.format(epoch)]['used_attributes']= attribute_zeros.sum(dim=0)\n",
    "        # self.model.used_attributes_list = []\n",
    "        # self.uncertainty_stats['epoch_{}'.format(epoch)]['sigmas'] = sigma_zeros/num_batches\n",
    "        # self.model.sigmas_list = []\n",
    "        # self.uncertainty_stats['epoch_{}'.format(epoch)]['num_attrs_discarded'] += num_attrs_discarded\n",
    "        # model.certain_attrs = []\n",
    "        # #####################################################################################\n",
    "\n",
    "        stats = [correct_1.sum(axis=1) / total, correct_5.sum(axis=1) / total, total_loss / total, (correct_1 / total_cnt).mean(axis=1), (correct_5 / total_cnt).mean(axis=1)]\n",
    "        print('Accuracy ({}), Top1: {:.2%}, Top5: {:.2%}'.format(phase, stats[0][-1], stats[1][-1]))\n",
    "        self.model.train()  # Change model to 'train' mode\n",
    "\n",
    "        unique_attr_stats = None\n",
    "        attr_acc = None\n",
    "        if epoch is not None:\n",
    "            if isinstance(self.model, OC):\n",
    "                hist_stats = self.model.get_hist_stats()\n",
    "                unique_attr_stats = self.model.get_unique_attributes()\n",
    "                if self.model.attribute_coef > 0.:\n",
    "                    attr_acc = self.model.get_attr_acc(total)\n",
    "                else:\n",
    "                    attr_acc = None\n",
    "            else:\n",
    "                hist_stats = None\n",
    "            self.log_stats(phase, epoch, stats, hist_stats, unique_attr_stats, attr_acc)\n",
    "\n",
    "        return stats[0][-1], stats, unique_attr_stats, attr_acc\n",
    "\n",
    "    def train_model(self, data_laoder):\n",
    "        max_accuracy = 0\n",
    "        max_agg_accuracy = 0\n",
    "        max_ma_accuracy = 0\n",
    "        max_ma_agg_accuracy = 0\n",
    "\n",
    "        if isinstance(self.model, OC):\n",
    "            self.model.reset_stats()\n",
    "\n",
    "        # Train the Model\n",
    "        ############### remove this workaround\n",
    "#         configuration = self.log_path.split('logs/')[1].split('/')[0]\n",
    "        # self.stats_dict[configuration]['losses'] = []\n",
    "        ###############################################\n",
    "        \n",
    "        for epoch in range(self.num_epochs):\n",
    "            #self.model.set_tau(epoch)\n",
    "            optimizer = self.model.get_optimizer()\n",
    "            n_stats = self.model.max_iters if hasattr(self.model, 'max_iters') else 1\n",
    "            correct_1 = np.zeros((n_stats, self.model.num_classes))\n",
    "            correct_5 = np.zeros((n_stats, self.model.num_classes))\n",
    "            total = 0\n",
    "            total_cnt = np.zeros((1, self.model.num_classes))\n",
    "            total_loss = 0\n",
    "\n",
    "            for i, data in enumerate(data_laoder):\n",
    "                \n",
    "                if len(data) == 2:\n",
    "                    images, labels = data\n",
    "                    attributes = None\n",
    "                else:\n",
    "                    images, labels, attributes = data\n",
    "                    #attributes = attributes.to(self.device)\n",
    "                images = images.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                classification, loss = self.model(images, labels)\n",
    "                \n",
    "\n",
    "                if loss.grad_fn is not None:\n",
    "                \n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # Collect stats\n",
    "                total_loss += loss.item()\n",
    "                total += labels.size(0)\n",
    "                for k in range(len(classification)):\n",
    "                    ctopk, target_cnt = self.topk_correct(classification[k].data, labels, (1, 5))\n",
    "                    c1, c5 = ctopk\n",
    "                    correct_1[k] += c1\n",
    "                    correct_5[k] += c5\n",
    "                total_cnt[0] += target_cnt\n",
    "\n",
    "                if (i+1) % self.log_freq == 0:\n",
    "                    print('Epoch [{}/{}], Iter [{}/{}] Loss: {:.4f}'\n",
    "                            .format(epoch+1, self.num_epochs, i+1, len(data_laoder)//images.size(0),\n",
    "                                    loss.item()))\n",
    "                    ##### TODO remove workaround and use tensurboard\n",
    "                    # self.stats_dict[configuration]['losses'].append(loss.item())\n",
    "            \n",
    "        # with open(data_path + '/logs/' + 'stats_dict.json', 'w') as json_file:\n",
    "        #     json.dump(self.stats_dict, json_file)\n",
    "        #     print('stats dict saved...')\n",
    "                    #############################################\n",
    "\n",
    "            self.model.get_scheduler().step()\n",
    "            # if isinstance(self.model, NeuralDecisionForest) or isinstance(self.model, OC):\n",
    "            #     self.model.toggle_update_schedule()\n",
    "\n",
    "            stats = [correct_1.sum(axis=1) / total, correct_5.sum(axis=1) / total, total_loss / total, (correct_1 / total_cnt).mean(axis=1), (correct_5 / total_cnt).mean(axis=1)]\n",
    "\n",
    "            if isinstance(self.model, OC):\n",
    "                hist_stats = self.model.get_hist_stats()\n",
    "                unique_attr_stats = self.model.get_unique_attributes()\n",
    "                if self.model.attribute_coef > 0.:\n",
    "                    attr_acc = self.model.get_attr_acc(total)\n",
    "                else:\n",
    "                    attr_acc = None\n",
    "            else:\n",
    "                hist_stats = None\n",
    "                unique_attr_stats = None\n",
    "                attr_acc = None\n",
    "            self.log_stats('train', epoch, stats, hist_stats, unique_attr_stats, attr_acc)\n",
    "            print('Accuracy (train), Top1: {:.2%}, Top5: {:.2%}'.format(stats[0][-1], stats[1][-1]))\n",
    "            self.model.phase = 'test'\n",
    "            val_accuracy, val_stats, _, _ = self.test_model(self.dataloaders['val'],\n",
    "                                                            'val', epoch+1)\n",
    "            val_agg_accuracy = val_stats[0].sum()\n",
    "            val_ma_accuracy = val_stats[3][-1]\n",
    "            val_ma_agg_accuracy = val_stats[3].sum()\n",
    "\n",
    "            # reset model stats\n",
    "            model.sigmas_list = []\n",
    "            model.labels_list = []\n",
    "            model.used_attributes_list = []\n",
    "            model.attribute_accuracies = []\n",
    "            model.drop_ratios = []\n",
    "#             self.model.phase = 'test'\n",
    "            _, test_stats, unique_attr_stats, attr_acc = self.test_model(self.dataloaders['test'], 'test', epoch+1)\n",
    "            \n",
    "#             if model.drop_ratios[0].size(0) == 64:\n",
    "            self.mean_drop_ratio.append(sum(model.drop_ratios)/(len(model.drop_ratios)+1))\n",
    "            mean_attribute_accuracy = sum(model.attribute_accuracies)/len(model.attribute_accuracies)\n",
    "            self.mean_sigmas.append(sum(model.mean_sigmas)/(len(model.mean_sigmas)+1))\n",
    "            self.mean_attr_accs.append(mean_attribute_accuracy)\n",
    "#             print(mean_attribute_accuracy)\n",
    "#             print()\n",
    "            # # collect uncertainty stats\n",
    "            # self.uncertainty_stats['epoch_{}'.format(epoch)]['used_attributes']=self.model.used_attributes_list\n",
    "            # self.model.used_attributes_list = []\n",
    "            # self.uncertainty_stats['epoch_{}'.format(epoch)]['sigmas']=self.model.sigmas_list\n",
    "            # self.model.sigmas_list = []           \n",
    "            \n",
    "            \n",
    "            \n",
    "            self.model.phase = 'train'\n",
    "            if val_accuracy > max_accuracy:\n",
    "                max_accuracy = val_accuracy\n",
    "#                 self.save_model('best', test_stats, 0, unique_attr_stats, attr_acc, epoch)\n",
    "            if val_ma_accuracy > max_ma_accuracy:\n",
    "                max_ma_accuracy = val_ma_accuracy\n",
    "#                 self.save_model('best_ma', test_stats, 3, unique_attr_stats, attr_acc, epoch)\n",
    "            if val_agg_accuracy > max_agg_accuracy and isinstance(self.model, OC):\n",
    "                max_agg_accuracy = val_agg_accuracy\n",
    "                self.save_model('best_agg', test_stats, 0, unique_attr_stats, attr_acc, epoch)\n",
    "            if val_ma_agg_accuracy > max_ma_agg_accuracy and isinstance(self.model, OC):\n",
    "                max_ma_agg_accuracy = val_ma_agg_accuracy\n",
    "#                 self.save_model('best_ma_agg', test_stats, 3, unique_attr_stats, attr_acc, epoch)\n",
    "\n",
    "            self.save_model('latest', test_stats, 0, unique_attr_stats, attr_acc, epoch)\n",
    "        # with open(data_path + '/logs/' + 'stats_dict.json', 'w') as json_file:\n",
    "        #     json.dump(self.stats_dict, json_file)\n",
    "        #     print('stats dict saved...')\n",
    "\n",
    "\n",
    "    def write_stats_file(self, stats_list, name, epoch, is_float=True):\n",
    "        fstr = '{:.2f}' if is_float else '{}'\n",
    "        with open(os.path.join(self.log_path, '{}.txt'.format(name)), 'a') as f:\n",
    "            acc_str = [fstr.format(100*c1 if is_float else c1) for c1 in stats_list]\n",
    "            f.write('{} '.format(epoch) + ' '.join(acc_str))\n",
    "            f.write('\\n')\n",
    "\n",
    "    def save_model(self, name, test_stats, stats_idx, unique_attr_stats, attr_acc, epoch):\n",
    "        torch.save(self.model.state_dict(),\n",
    "                   os.path.join(self.log_path, '{}.pth'.format(name)))\n",
    "        \n",
    "        # save state dict for vision model separately\n",
    "        torch.save(self.model.cnn.state_dict(), os.path.join(self.log_path, '{}_vision_model.pth'.format(name)))\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.write_stats_file(test_stats[stats_idx], name, epoch)\n",
    "\n",
    "        # if isinstance(self.model, NeuralDecisionForest):\n",
    "        #     _, test_stats_hard, _, _ = self.test_model(self.dataloaders['test'],\n",
    "        #                                                'test', epoch+1, hard=True)\n",
    "        #     self.write_stats_file(test_stats_hard[stats_idx], name+'_hard', epoch)\n",
    "\n",
    "        if unique_attr_stats is not None:\n",
    "            self.write_stats_file(unique_attr_stats, name+'_uniqattr', epoch,\n",
    "                                  is_float=False)\n",
    "\n",
    "        if attr_acc is not None:\n",
    "            self.write_stats_file(attr_acc, name+'_attracc', epoch)\n",
    "\n",
    "        if name != 'latest':\n",
    "            print('Saved {} model'.format(name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's instance our models..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the configuraion parameters of our dataset\n",
    "in_channels, cnn_out_size, log_freq = get_dataset_config(dataset, 'cnn', 40 )\n",
    "cnn_out_size = 2048\n",
    "\n",
    "# initiate the observer classifier model\n",
    "model = OC('xoc', len(classes), 'dropoutcnn', in_channels,\n",
    "            cnn_out_size, dataset, 2, 40, # 13 worked\n",
    "            attribute_size, attribute_mtx, attribute_coef,\n",
    "            hidden_size, tau_initial=5,\n",
    "            use_pretrained=False, shallow=False)\n",
    "\n",
    "# load pretrained resnet backbone\n",
    "model.cnn = models.resnet152(pretrained=False)\n",
    "model.cnn.fc = nn.Linear(model.cnn.fc.in_features, torch.load('/home/swezel/projects/urdtc/pretrained/cub_resnet152.pkl')['fc.weight'].size(0))\n",
    "model.cnn.load_state_dict(torch.load('/home/swezel/projects/urdtc/pretrained/cub_resnet152.pkl'))\n",
    "# model.cnn.fc = nn.Linear(model.cnn.fc.in_features, torch.load('/home/swezel/projects/urdtc/pretrained/{}_resnet152.pkl'.format(dataset))['fc.weight'].size(0))\n",
    "# model.cnn.load_state_dict(torch.load('/home/swezel/projects/urdtc/pretrained/{}_resnet152.pkl'.format(dataset)))\n",
    "\n",
    "\n",
    "model.cnn.fc = nn.Identity()\n",
    "\n",
    "# set attribute head\n",
    "model.binary_features = nn.Sequential(nn.BatchNorm1d(cnn_out_size),\n",
    "                                        nn.Linear(cnn_out_size, hidden_size),\n",
    "                                        nn.ReLU(inplace=True),\n",
    "                                        nn.BatchNorm1d(hidden_size),\n",
    "                                        nn.Dropout(0.5, inplace=False), # dropout after batchnorm\n",
    "                                        nn.Linear(hidden_size, hidden_size),\n",
    "                                        nn.ReLU(inplace=True),\n",
    "                                        nn.BatchNorm1d(hidden_size),\n",
    "                                        nn.Dropout(0.5, inplace=False),\n",
    "                                        nn.Linear(hidden_size, attribute_size * 2))\n",
    "\n",
    "model.binary_features.tau = nn.Parameter(torch.tensor([5], dtype=torch.float), requires_grad=True)\n",
    "model.to(device);\n",
    "\n",
    "# freeze resnet backbone for faster training but make all other weights trainable\n",
    "for param in model.lstm.parameters():\n",
    "    param.requires_grad=True\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad=True\n",
    "for param in model.feature_selection.parameters():\n",
    "    param.requires_grad=True\n",
    "for param in model.binary_features.parameters():\n",
    "    param.requires_grad=True\n",
    "for param in model.pre_lstm.parameters():\n",
    "    param.requires_grad=True\n",
    "    \n",
    "for param in model.cnn.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.cnn.fc.parameters():\n",
    "    param.requires_grad=True\n",
    "    \n",
    "# initiate optimizers\n",
    "tree_params, cnn_params = model.get_param_groups()\n",
    "tree_optimizer = torch.optim.Adam(tree_params, lr = learning_rate, weight_decay=weight_decay)\n",
    "cnn_optimizer = torch.optim.Adam(cnn_params, lr = learning_rate, weight_decay=weight_decay)\n",
    "optimizer = [tree_optimizer, cnn_optimizer]\n",
    "# and schedulers\n",
    "tree_scheduler = torch.optim.lr_scheduler.StepLR(tree_optimizer, step_size=step_size, gamma=0.1)\n",
    "cnn_scheduler = torch.optim.lr_scheduler.StepLR(cnn_optimizer, step_size=step_size, gamma=0.1)\n",
    "scheduler = [tree_scheduler, cnn_scheduler]\n",
    "\n",
    "model.set_optimizer(optimizer)\n",
    "# model.init_tree_stats()\n",
    "model.set_scheduler(scheduler)\n",
    "##hook\n",
    "# torch.load('/home/swezel/projects/urdtc/pretrained/awa2_resnet152.pkl')\n",
    "\n",
    "# model.strategy = 'randRDTC'\n",
    "# model.strategy = 'remRDTC'\n",
    "model.strategy = 'extRDTC'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and finally train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-259-f002911457a5>:207: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs[i] = F.softmax(self.binary_features(image_features))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Iter [10/1] Loss: 4.4211\n",
      "Epoch [1/20], Iter [20/1] Loss: 4.3990\n",
      "Epoch [1/20], Iter [30/1] Loss: 4.3598\n",
      "Epoch [1/20], Iter [40/1] Loss: 4.2598\n",
      "Epoch [1/20], Iter [50/1] Loss: 4.1925\n",
      "Epoch [1/20], Iter [60/1] Loss: 4.1276\n",
      "Epoch [1/20], Iter [70/1] Loss: 3.8989\n",
      "Epoch [1/20], Iter [80/1] Loss: 4.0064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-261-070f05ede296>:280: RuntimeWarning: invalid value encountered in true_divide\n",
      "  stats = [correct_1.sum(axis=1) / total, correct_5.sum(axis=1) / total, total_loss / total, (correct_1 / total_cnt).mean(axis=1), (correct_5 / total_cnt).mean(axis=1)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (train), Top1: 2.39%, Top5: 9.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-259-f002911457a5>:216: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs[i] = F.softmax(self.binary_features(image_features))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (val), Top1: 2.08%, Top5: 11.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-261-070f05ede296>:190: RuntimeWarning: invalid value encountered in true_divide\n",
      "  stats = [correct_1.sum(axis=1) / total, correct_5.sum(axis=1) / total, total_loss / total, (correct_1 / total_cnt).mean(axis=1), (correct_5 / total_cnt).mean(axis=1)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (test), Top1: 1.48%, Top5: 10.71%\n",
      "Saved best_agg model\n",
      "Epoch [2/20], Iter [10/1] Loss: 3.6411\n",
      "Epoch [2/20], Iter [20/1] Loss: 3.8225\n",
      "Epoch [2/20], Iter [30/1] Loss: 3.5042\n",
      "Epoch [2/20], Iter [40/1] Loss: 3.5315\n",
      "Epoch [2/20], Iter [50/1] Loss: 3.2036\n",
      "Epoch [2/20], Iter [60/1] Loss: 3.3883\n",
      "Epoch [2/20], Iter [70/1] Loss: 3.2744\n",
      "Epoch [2/20], Iter [80/1] Loss: 3.5148\n",
      "Accuracy (train), Top1: 11.27%, Top5: 35.97%\n",
      "Accuracy (val), Top1: 9.90%, Top5: 34.20%\n",
      "Accuracy (test), Top1: 8.17%, Top5: 30.94%\n",
      "Saved best_agg model\n",
      "Epoch [3/20], Iter [10/1] Loss: 3.4048\n",
      "Epoch [3/20], Iter [20/1] Loss: 3.3235\n",
      "Epoch [3/20], Iter [30/1] Loss: 3.2061\n",
      "Epoch [3/20], Iter [40/1] Loss: 3.0788\n",
      "Epoch [3/20], Iter [50/1] Loss: 3.0330\n",
      "Epoch [3/20], Iter [60/1] Loss: 2.9455\n",
      "Epoch [3/20], Iter [70/1] Loss: 2.9389\n",
      "Epoch [3/20], Iter [80/1] Loss: 2.7610\n",
      "Accuracy (train), Top1: 21.43%, Top5: 57.55%\n",
      "Accuracy (val), Top1: 23.44%, Top5: 57.64%\n",
      "Accuracy (test), Top1: 21.89%, Top5: 51.56%\n",
      "Saved best_agg model\n",
      "Epoch [4/20], Iter [10/1] Loss: 2.6976\n",
      "Epoch [4/20], Iter [20/1] Loss: 2.5857\n",
      "Epoch [4/20], Iter [30/1] Loss: 2.9229\n",
      "Epoch [4/20], Iter [40/1] Loss: 2.6093\n",
      "Epoch [4/20], Iter [50/1] Loss: 2.5292\n",
      "Epoch [4/20], Iter [60/1] Loss: 2.6046\n",
      "Epoch [4/20], Iter [70/1] Loss: 2.6839\n",
      "Epoch [4/20], Iter [80/1] Loss: 2.5750\n",
      "Accuracy (train), Top1: 30.50%, Top5: 70.85%\n",
      "Accuracy (val), Top1: 31.77%, Top5: 68.75%\n",
      "Accuracy (test), Top1: 27.90%, Top5: 60.31%\n",
      "Saved best_agg model\n",
      "Epoch [5/20], Iter [10/1] Loss: 2.5732\n",
      "Epoch [5/20], Iter [20/1] Loss: 2.4178\n",
      "Epoch [5/20], Iter [30/1] Loss: 2.7310\n",
      "Epoch [5/20], Iter [40/1] Loss: 2.5900\n",
      "Epoch [5/20], Iter [50/1] Loss: 2.4474\n",
      "Epoch [5/20], Iter [60/1] Loss: 2.3931\n",
      "Epoch [5/20], Iter [70/1] Loss: 2.5033\n",
      "Epoch [5/20], Iter [80/1] Loss: 2.5452\n",
      "Accuracy (train), Top1: 37.90%, Top5: 76.05%\n",
      "Accuracy (val), Top1: 41.49%, Top5: 76.74%\n",
      "Accuracy (test), Top1: 37.94%, Top5: 67.57%\n",
      "Saved best_agg model\n",
      "Epoch [6/20], Iter [10/1] Loss: 2.6860\n",
      "Epoch [6/20], Iter [20/1] Loss: 2.4591\n",
      "Epoch [6/20], Iter [30/1] Loss: 2.3409\n",
      "Epoch [6/20], Iter [40/1] Loss: 2.2692\n",
      "Epoch [6/20], Iter [50/1] Loss: 2.3209\n",
      "Epoch [6/20], Iter [60/1] Loss: 2.5157\n",
      "Epoch [6/20], Iter [70/1] Loss: 2.3944\n",
      "Epoch [6/20], Iter [80/1] Loss: 2.2403\n",
      "Accuracy (train), Top1: 42.68%, Top5: 79.09%\n",
      "Accuracy (val), Top1: 42.88%, Top5: 82.64%\n",
      "Accuracy (test), Top1: 44.60%, Top5: 70.21%\n",
      "Saved best_agg model\n",
      "Epoch [7/20], Iter [10/1] Loss: 2.4416\n",
      "Epoch [7/20], Iter [20/1] Loss: 2.4253\n",
      "Epoch [7/20], Iter [30/1] Loss: 2.3974\n",
      "Epoch [7/20], Iter [40/1] Loss: 2.4774\n",
      "Epoch [7/20], Iter [50/1] Loss: 2.0871\n",
      "Epoch [7/20], Iter [60/1] Loss: 2.0920\n",
      "Epoch [7/20], Iter [70/1] Loss: 2.2401\n",
      "Epoch [7/20], Iter [80/1] Loss: 2.3154\n",
      "Accuracy (train), Top1: 48.11%, Top5: 80.33%\n",
      "Accuracy (val), Top1: 54.86%, Top5: 82.12%\n",
      "Accuracy (test), Top1: 46.70%, Top5: 70.47%\n",
      "Saved best_agg model\n",
      "Epoch [8/20], Iter [10/1] Loss: 2.3043\n",
      "Epoch [8/20], Iter [20/1] Loss: 2.1058\n",
      "Epoch [8/20], Iter [30/1] Loss: 1.8411\n",
      "Epoch [8/20], Iter [40/1] Loss: 2.3573\n",
      "Epoch [8/20], Iter [50/1] Loss: 2.6031\n",
      "Epoch [8/20], Iter [60/1] Loss: 2.2696\n",
      "Epoch [8/20], Iter [70/1] Loss: 2.0357\n",
      "Epoch [8/20], Iter [80/1] Loss: 2.2956\n",
      "Accuracy (train), Top1: 52.49%, Top5: 82.74%\n",
      "Accuracy (val), Top1: 54.17%, Top5: 83.33%\n",
      "Accuracy (test), Top1: 50.05%, Top5: 71.44%\n",
      "Saved best_agg model\n",
      "Epoch [9/20], Iter [10/1] Loss: 2.3262\n",
      "Epoch [9/20], Iter [20/1] Loss: 2.2395\n",
      "Epoch [9/20], Iter [30/1] Loss: 2.3595\n",
      "Epoch [9/20], Iter [40/1] Loss: 2.1784\n",
      "Epoch [9/20], Iter [50/1] Loss: 2.0220\n",
      "Epoch [9/20], Iter [60/1] Loss: 2.5063\n",
      "Epoch [9/20], Iter [70/1] Loss: 2.2493\n",
      "Epoch [9/20], Iter [80/1] Loss: 2.0422\n",
      "Accuracy (train), Top1: 53.45%, Top5: 82.89%\n",
      "Accuracy (val), Top1: 57.47%, Top5: 84.03%\n",
      "Accuracy (test), Top1: 51.30%, Top5: 71.79%\n",
      "Saved best_agg model\n",
      "Epoch [10/20], Iter [10/1] Loss: 2.2186\n",
      "Epoch [10/20], Iter [20/1] Loss: 2.1779\n",
      "Epoch [10/20], Iter [30/1] Loss: 2.3468\n",
      "Epoch [10/20], Iter [40/1] Loss: 2.3304\n",
      "Epoch [10/20], Iter [50/1] Loss: 1.8287\n",
      "Epoch [10/20], Iter [60/1] Loss: 2.1750\n",
      "Epoch [10/20], Iter [70/1] Loss: 2.0684\n",
      "Epoch [10/20], Iter [80/1] Loss: 1.9425\n",
      "Accuracy (train), Top1: 54.99%, Top5: 83.83%\n",
      "Accuracy (val), Top1: 61.46%, Top5: 88.37%\n",
      "Accuracy (test), Top1: 54.40%, Top5: 72.38%\n",
      "Saved best_agg model\n",
      "Epoch [11/20], Iter [10/1] Loss: 2.3826\n",
      "Epoch [11/20], Iter [20/1] Loss: 1.9916\n",
      "Epoch [11/20], Iter [30/1] Loss: 2.3145\n",
      "Epoch [11/20], Iter [40/1] Loss: 2.0041\n",
      "Epoch [11/20], Iter [50/1] Loss: 1.9284\n",
      "Epoch [11/20], Iter [60/1] Loss: 2.2269\n",
      "Epoch [11/20], Iter [70/1] Loss: 2.0763\n",
      "Epoch [11/20], Iter [80/1] Loss: 1.8043\n",
      "Accuracy (train), Top1: 56.45%, Top5: 84.07%\n",
      "Accuracy (val), Top1: 59.90%, Top5: 84.90%\n",
      "Accuracy (test), Top1: 51.78%, Top5: 71.77%\n",
      "Epoch [12/20], Iter [10/1] Loss: 1.9424\n",
      "Epoch [12/20], Iter [20/1] Loss: 2.1305\n",
      "Epoch [12/20], Iter [30/1] Loss: 2.0151\n",
      "Epoch [12/20], Iter [40/1] Loss: 1.9679\n",
      "Epoch [12/20], Iter [50/1] Loss: 2.0859\n",
      "Epoch [12/20], Iter [60/1] Loss: 1.9783\n",
      "Epoch [12/20], Iter [70/1] Loss: 2.0748\n",
      "Epoch [12/20], Iter [80/1] Loss: 2.1181\n",
      "Accuracy (train), Top1: 58.98%, Top5: 85.45%\n",
      "Accuracy (val), Top1: 60.59%, Top5: 86.28%\n",
      "Accuracy (test), Top1: 54.87%, Top5: 72.33%\n",
      "Epoch [13/20], Iter [10/1] Loss: 2.4541\n",
      "Epoch [13/20], Iter [20/1] Loss: 2.0513\n",
      "Epoch [13/20], Iter [30/1] Loss: 1.7727\n",
      "Epoch [13/20], Iter [40/1] Loss: 1.8080\n",
      "Epoch [13/20], Iter [50/1] Loss: 1.6705\n",
      "Epoch [13/20], Iter [60/1] Loss: 2.4579\n",
      "Epoch [13/20], Iter [70/1] Loss: 1.8192\n",
      "Epoch [13/20], Iter [80/1] Loss: 1.5577\n",
      "Accuracy (train), Top1: 59.92%, Top5: 85.32%\n",
      "Accuracy (val), Top1: 62.15%, Top5: 84.03%\n",
      "Accuracy (test), Top1: 57.14%, Top5: 72.82%\n",
      "Epoch [14/20], Iter [10/1] Loss: 2.3540\n",
      "Epoch [14/20], Iter [20/1] Loss: 2.2602\n",
      "Epoch [14/20], Iter [30/1] Loss: 2.3178\n",
      "Epoch [14/20], Iter [40/1] Loss: 1.9877\n",
      "Epoch [14/20], Iter [50/1] Loss: 1.7261\n",
      "Epoch [14/20], Iter [60/1] Loss: 2.0360\n",
      "Epoch [14/20], Iter [70/1] Loss: 2.0349\n",
      "Epoch [14/20], Iter [80/1] Loss: 2.1305\n",
      "Accuracy (train), Top1: 59.61%, Top5: 85.03%\n",
      "Accuracy (val), Top1: 66.49%, Top5: 86.98%\n",
      "Accuracy (test), Top1: 57.31%, Top5: 73.13%\n",
      "Saved best_agg model\n",
      "Epoch [15/20], Iter [10/1] Loss: 2.3610\n",
      "Epoch [15/20], Iter [20/1] Loss: 2.1476\n",
      "Epoch [15/20], Iter [30/1] Loss: 2.4343\n",
      "Epoch [15/20], Iter [40/1] Loss: 2.1920\n",
      "Epoch [15/20], Iter [50/1] Loss: 1.8920\n",
      "Epoch [15/20], Iter [60/1] Loss: 1.7977\n",
      "Epoch [15/20], Iter [70/1] Loss: 1.9122\n",
      "Epoch [15/20], Iter [80/1] Loss: 1.6818\n",
      "Accuracy (train), Top1: 61.85%, Top5: 86.18%\n",
      "Accuracy (val), Top1: 59.03%, Top5: 83.16%\n",
      "Accuracy (test), Top1: 55.68%, Top5: 72.60%\n",
      "Epoch [16/20], Iter [10/1] Loss: 1.9962\n",
      "Epoch [16/20], Iter [20/1] Loss: 2.0617\n",
      "Epoch [16/20], Iter [30/1] Loss: 2.0497\n",
      "Epoch [16/20], Iter [40/1] Loss: 1.8754\n",
      "Epoch [16/20], Iter [50/1] Loss: 1.9831\n",
      "Epoch [16/20], Iter [60/1] Loss: 1.8672\n",
      "Epoch [16/20], Iter [70/1] Loss: 1.9301\n",
      "Epoch [16/20], Iter [80/1] Loss: 1.9083\n",
      "Accuracy (train), Top1: 62.22%, Top5: 85.65%\n",
      "Accuracy (val), Top1: 65.80%, Top5: 86.11%\n",
      "Accuracy (test), Top1: 57.75%, Top5: 73.20%\n",
      "Epoch [17/20], Iter [10/1] Loss: 1.5154\n",
      "Epoch [17/20], Iter [20/1] Loss: 1.8987\n",
      "Epoch [17/20], Iter [30/1] Loss: 1.4909\n",
      "Epoch [17/20], Iter [40/1] Loss: 2.0665\n",
      "Epoch [17/20], Iter [50/1] Loss: 2.0866\n",
      "Epoch [17/20], Iter [60/1] Loss: 1.9139\n",
      "Epoch [17/20], Iter [70/1] Loss: 1.6599\n",
      "Epoch [17/20], Iter [80/1] Loss: 1.8799\n",
      "Accuracy (train), Top1: 62.91%, Top5: 85.95%\n",
      "Accuracy (val), Top1: 63.37%, Top5: 84.55%\n",
      "Accuracy (test), Top1: 58.29%, Top5: 73.33%\n",
      "Epoch [18/20], Iter [10/1] Loss: 1.7320\n",
      "Epoch [18/20], Iter [20/1] Loss: 1.7385\n",
      "Epoch [18/20], Iter [30/1] Loss: 1.7339\n",
      "Epoch [18/20], Iter [40/1] Loss: 2.0191\n",
      "Epoch [18/20], Iter [50/1] Loss: 1.9532\n",
      "Epoch [18/20], Iter [60/1] Loss: 1.6197\n",
      "Epoch [18/20], Iter [70/1] Loss: 1.9544\n",
      "Epoch [18/20], Iter [80/1] Loss: 1.8325\n",
      "Accuracy (train), Top1: 63.45%, Top5: 85.82%\n",
      "Accuracy (val), Top1: 66.49%, Top5: 87.85%\n",
      "Accuracy (test), Top1: 58.02%, Top5: 72.85%\n",
      "Saved best_agg model\n",
      "Epoch [19/20], Iter [10/1] Loss: 1.5447\n",
      "Epoch [19/20], Iter [20/1] Loss: 2.1368\n",
      "Epoch [19/20], Iter [30/1] Loss: 1.7269\n",
      "Epoch [19/20], Iter [40/1] Loss: 2.3784\n",
      "Epoch [19/20], Iter [50/1] Loss: 1.5692\n",
      "Epoch [19/20], Iter [60/1] Loss: 2.2441\n",
      "Epoch [19/20], Iter [70/1] Loss: 1.6184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Iter [80/1] Loss: 1.8021\n",
      "Accuracy (train), Top1: 64.99%, Top5: 86.86%\n",
      "Accuracy (val), Top1: 66.67%, Top5: 87.67%\n",
      "Accuracy (test), Top1: 58.59%, Top5: 73.12%\n",
      "Saved best_agg model\n",
      "Epoch [20/20], Iter [10/1] Loss: 2.0159\n",
      "Epoch [20/20], Iter [20/1] Loss: 1.9775\n",
      "Epoch [20/20], Iter [30/1] Loss: 1.6295\n",
      "Epoch [20/20], Iter [40/1] Loss: 1.8501\n",
      "Epoch [20/20], Iter [50/1] Loss: 1.7039\n",
      "Epoch [20/20], Iter [60/1] Loss: 1.6786\n",
      "Epoch [20/20], Iter [70/1] Loss: 1.6042\n",
      "Epoch [20/20], Iter [80/1] Loss: 1.9402\n",
      "Accuracy (train), Top1: 64.57%, Top5: 86.67%\n",
      "Accuracy (val), Top1: 68.23%, Top5: 87.85%\n",
      "Accuracy (test), Top1: 59.70%, Top5: 73.02%\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model, dataloaders, 20, device, log_freq, data_path + '/../log/')\n",
    "torch.cuda.empty_cache()\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seen:\n",
      "0.039380110512494036\n",
      "0.00021236080341905416\n",
      "\n",
      "unseen:\n",
      "0.04217024260453315\n",
      "0.03223300108340782\n",
      "\n",
      "0.04025932401418686\n",
      "0.4174756705760956\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seen_sigmas = []\n",
    "unseen_sigmas = []\n",
    "\n",
    "for batch_index in range(len(model.labels_list)):\n",
    "    for inner_batch_index in range(model.labels_list[batch_index].size(0)):\n",
    "        class_label = model.labels_list[batch_index][inner_batch_index].item()\n",
    "#         if class_label <= 151:\n",
    "        if class_label not in [11,18,19,25,26,28,30,31,32,41,74,75,98,113,138,139,161,177,180,182,183,192,199,177]:\n",
    "            seen_sigmas.append(model.sigmas_list[batch_index][inner_batch_index].mean().item())\n",
    "        else:\n",
    "            unseen_sigmas.append(model.sigmas_list[batch_index][inner_batch_index].mean().item())\n",
    "            \n",
    "seen_sigmas = np.array(seen_sigmas)\n",
    "unseen_sigmas = np.array(unseen_sigmas)\n",
    "print('seen:')\n",
    "print(seen_sigmas.mean())\n",
    "print(seen_sigmas.std())\n",
    "print('\\nunseen:')\n",
    "print(unseen_sigmas.mean())\n",
    "print(unseen_sigmas.std())\n",
    "# for plotting\n",
    "sns.set_style('darkgrid')\n",
    "x_min = 0.038#np.concatenate((seen_sigmas, unseen_sigmas)).min()\n",
    "x_max = 0.05#np.concatenate((seen_sigmas, unseen_sigmas)).max()\n",
    "x = np.linspace(x_min, x_max, 100)\n",
    "y_seen = scipy.stats.expon.pdf(x,seen_sigmas.mean(),seen_sigmas.std()/10)\n",
    "y_unseen = scipy.stats.expon.pdf(x,unseen_sigmas.mean(), unseen_sigmas.std()/10)\n",
    "plt.plot(x,y_unseen, color='#AC454A', label = 'unseen')\n",
    "plt.plot(x,y_seen, color='#F67941', label = 'seen')\n",
    "# plt.hist([seen_sigmas, unseen_sigmas], color=['#F67941','#AC454A'], density=[True, True], label=['seen', 'unseen'])\n",
    "\n",
    "# plt.plot(x,y_seen, color='#F67941', label = 'seen')\n",
    "# plt.plot(x,y_unseen, color='#AC454A', label = 'unseen')\n",
    "plt.legend()\n",
    "plt.savefig(figure_path + 'zero_shot_class_uncertainty.pdf',bbox_inches='tight')\n",
    "print()\n",
    "print(np.max(seen_sigmas))\n",
    "print(np.max(unseen_sigmas))\n",
    "\n",
    "# print(model.sigmas_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08514898966284508\n",
      "0.07866149883665921\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(model.sigmas_list[0])\n",
    "\n",
    "# unseen_attrs = [101-1, 145-1, 151-1, 235 -1,308-1, 312+101-1, 312+145-1, 312+151-1, 312+235 -1,312+308-1]\n",
    "unseen_attrs = [101, 145, 151, 235 ,308]#, 312+101, 312+145, 312+151, 312+235 ,312+308]\n",
    "# unseen_attrs = [101+1, 145+1, 151+1, 235 +1,308+1, 312+101+1, 312+145+1, 312+151+1, 312+235 +1,312+308+1]\n",
    "# unseen_attrs = [101, 101+1, 145, 145+1, 151, 151+1, 235,235 +1,308,308+1]\n",
    "seen_attrs = [i for i in range(312)if i not in unseen_attrs]\n",
    "unseen_mask = torch.tensor([1 if x in unseen_attrs else 0 for x in range(312)], device=device).repeat(model.sigmas_list[0].size(0),1)\n",
    "# print(unseen_mask.size())\n",
    "\n",
    "seen_mask = 1. - unseen_mask\n",
    "# print(seen_mask.size())\n",
    "unseen_sigmas_means = []\n",
    "\n",
    "seen_sigmas_means = []\n",
    "\n",
    "\n",
    "for batch_index in range(len(model.sigmas_list)):\n",
    "# for batch_index in range(2):\n",
    "    if model.sigmas_list[batch_index].size(0)==64:\n",
    "        sigmas = model.sigmas_list[batch_index]\n",
    "        sigmas_new = torch.zeros(64, 312, 1,device=device)\n",
    "        sigmas_new += sigmas.view(64,-1,2)[:,:,0].unsqueeze(2)\n",
    "        sigmas_new += sigmas.view(64,-1,2)[:,:,1].unsqueeze(2)\n",
    "        sigmas = sigmas_new[:,:,0]\n",
    "#         print(sigmas.size())\n",
    "        unseen_sigmas = sigmas * unseen_mask\n",
    "        unseen_sigmas_means += unseen_sigmas.mean(dim=0)[[unseen_attrs]].tolist()\n",
    "        seen_sigmas = sigmas * seen_mask\n",
    "        seen_sigmas_means += seen_sigmas.mean(dim=0)[[seen_attrs]].tolist()\n",
    "#         print(seen_sigmas.mean())\n",
    "\n",
    "\n",
    "print(np.mean(unseen_sigmas_means))\n",
    "print(np.mean(seen_sigmas_means))\n",
    "\n",
    "\n",
    "x_min = 0.03#min(np.array(unseen_sigmas_means).min(), np.array(seen_sigmas_means).min())\n",
    "x_max = 0.13\n",
    "#min(np.array(unseen_sigmas_means).max(), np.array(seen_sigmas_means).max())\n",
    "\n",
    "\n",
    "# x_min = np.concatenate((unseen_sigmas_means, unseen_sigmas)).min()\n",
    "# x_max = np.concatenate((seen_sigmas, unseen_sigmas)).max()\n",
    "x = np.linspace(0.075, x_max, 100)\n",
    "y_unseen = scipy.stats.expon.pdf(x,np.mean(unseen_sigmas_means),np.std(unseen_sigmas_means))\n",
    "y_seen = scipy.stats.expon.pdf(x,np.mean(seen_sigmas_means),np.std(seen_sigmas_means))\n",
    "plt.plot(x,y_unseen, color='#AC454A', label = 'unseen')\n",
    "plt.plot(x,y_seen, color='#F67941', label = 'seen')\n",
    "plt.legend()\n",
    "\n",
    "# uncertain_onehot = torch.tensor([[0., 0., 1.]], device=device).repeat(images.size(0), attribute_size, 1)\n",
    "# print(unseen_batch_mask.size())\n",
    "# #308\n",
    "# # 101\n",
    "# # 235\n",
    "# # 145\n",
    "# 151\n",
    "plt.savefig(figure_path + 'zero_shot_attr_uncertainty.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28858\n",
      "470\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f4c5435ba90>"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.hist(unseen_sigmas)\n",
    "# plt.hist(seen_sigmas)\n",
    "# plt.hist(unseen_sigmas_means)\n",
    "# plt.hist(seen_sigmas_means)\n",
    "print(len(seen_sigmas_means))\n",
    "print(len(unseen_sigmas_means))\n",
    "plt.hist(np.array(unseen_sigmas_means),\n",
    "         bins = np.arange(0.075, 0.15, 0.0025),\n",
    "         color='#AC454A',\n",
    "         density=True,\n",
    "         label='unseen',\n",
    "         weights=np.ones_like(np.array(unseen_sigmas_means)))\n",
    "\n",
    "plt.hist(np.array(seen_sigmas_means),\n",
    "         bins = np.arange(0.075, 0.15, 0.0025),\n",
    "         color='#F67941',\n",
    "         density=True,\n",
    "         label='seen',\n",
    "         alpha=0.7\n",
    "        )\n",
    "\n",
    "plt.legend()\n",
    "# plt.savefig(figure_path + 'zero_shot_attr_uncertainty_hist.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6804115720417189, 0.7182754132410755, 0.6702648232812467, 0.714998273745827, 0.6931055609298789, 0.7174276281958041, 0.6983859079039615, 0.7049175507348516, 0.6953701344521149, 0.7296628880759944, 0.722016493263452, 0.7092867312224015, 0.7558365218017412, 0.7460860590571943, 0.7157794172349183]\n",
      "\n",
      "[0.057426291227500925, 0.05609082130174483, 0.06299703259782125, 0.05952211805889683, 0.06739816001506262, 0.0625436188633083, 0.061809110545342966, 0.06241330280098864, 0.05440532888776513, 0.054207162390793526, 0.05429709133922413, 0.0504565376347752, 0.05158684070232094, 0.04933646605700575, 0.047554582677861695]\n",
      "\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print(trainer.mean_attr_accs)\n",
    "print()\n",
    "print(trainer.mean_drop_ratio)\n",
    "print()\n",
    "print(trainer.mean_sigmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".  ..  urdtc\r\n"
     ]
    }
   ],
   "source": [
    "!ls -a ../"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
