{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "As we're luckily standing on the shoulders of giants, we can do some imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import imageio\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "Let's load and convert the data, so we can use it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = ['cifar10', 'mnist', 'cub', 'awa2',\n",
    "            'imagenetfeatures', 'apyfeatures', 'zero_shot_cub']\n",
    "# dataset = 'awa2'\n",
    "# dataset = 'cub'\n",
    "dataset = 'zero_shot_cub'\n",
    "\n",
    "data_path = '/home/swezel/projects/urdtc/data/'\n",
    "figure_path = data_path + '../thesis/images/'\n",
    "\n",
    "\n",
    "# attribute name lookup (first attr_id is 0) \n",
    "with open (data_path + 'cub/attributes.txt', 'r') as f:\n",
    "    attributes=f.readlines()\n",
    "attribute_name_dict = {str(int(attr.split(' ')[0])-1): attr.split(' ')[1] for attr in attributes}\n",
    "\n",
    "def get_dataset_config(dataset, cnn_type, max_iters):\n",
    "    input_channels = None\n",
    "    if dataset == 'mnist':\n",
    "        input_channels = 1\n",
    "        if cnn_type == 'cnn':\n",
    "            cnn_output_size = 4*4*100\n",
    "        elif cnn_type == 'resnet':\n",
    "            cnn_output_size = 512\n",
    "        elif cnn_type == 'shallowcnn':\n",
    "            cnn_output_size = 4*4*64\n",
    "        out_freq = 100\n",
    "        #assert max_iters > 4\n",
    "    elif dataset == 'cifar10':\n",
    "        input_channels = 3\n",
    "        if cnn_type == 'cnn':\n",
    "            cnn_output_size = 8*8*32\n",
    "        elif cnn_type == 'resnet' or cnn_type == 'resnet18':\n",
    "            cnn_output_size = 512\n",
    "        elif cnn_type == 'shallowcnn':\n",
    "            cnn_output_size = 4*4*64\n",
    "        out_freq = 100\n",
    "        #assert max_iters > 4\n",
    "    elif dataset == 'cub':\n",
    "        input_channels = 3\n",
    "        if cnn_type == 'cnn':\n",
    "            # cnn_output_size = 32*32*32\n",
    "            cnn_output_size = 280900 # the above does not work? Maybe because of dataloader issue?\n",
    "        elif cnn_type == 'resnet' or cnn_type == 'resnet152':\n",
    "            cnn_output_size = 2048\n",
    "        out_freq = 10\n",
    "    elif dataset == 'zero_shot_cub':\n",
    "        input_channels = 3\n",
    "        if cnn_type == 'cnn':\n",
    "            # cnn_output_size = 32*32*32\n",
    "            cnn_output_size = 280900 # the above does not work? Maybe because of dataloader issue?\n",
    "        elif cnn_type == 'resnet' or cnn_type == 'resnet152':\n",
    "            cnn_output_size = 2048\n",
    "        out_freq = 10\n",
    "        #assert max_iters > 8\n",
    "    elif dataset == 'awa2':\n",
    "        input_channels = 3\n",
    "        if cnn_type == 'cnn':\n",
    "#             cnn_output_size = 32*32*32  # TODO: check\n",
    "            cnn_output_size = 2048\n",
    "        elif cnn_type == 'resnet' or cnn_type == 'resnet152':\n",
    "            cnn_output_size = 2048\n",
    "        out_freq = 10\n",
    "        #assert max_iters > 6\n",
    "    elif dataset == 'imagenetfeatures':\n",
    "        cnn_output_size = 2048\n",
    "        out_freq = 100\n",
    "        #assert max_iters > 10\n",
    "    elif dataset == 'apyfeatures':\n",
    "        cnn_output_size = 2048\n",
    "        out_freq = 10\n",
    "        #assert max_iters > 5\n",
    "\n",
    "    return input_channels, cnn_output_size, out_freq\n",
    "\n",
    "class DataLoader(object):\n",
    "    def __init__(self, dataset='mnist'):\n",
    "        assert dataset in DATASETS\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def load_data(self, batch_size=100, num_workers=4, root='./data/'):\n",
    "\n",
    "        if self.dataset == 'mnist':\n",
    "            #transform_train = transforms.ToTensor()\n",
    "            #transform_test = transforms.ToTensor()\n",
    "            class AddGaussianNoise(object):\n",
    "                def __init__(self, mean=0., std=1.):\n",
    "                    self.std = std\n",
    "                    self.mean = mean\n",
    "\n",
    "                def __call__(self, tensor):\n",
    "                    output = tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "                    return output.clamp(0., 1.)\n",
    "\n",
    "                def __repr__(self):\n",
    "                    return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
    "\n",
    "            transform_train = transforms.Compose([\n",
    "               transforms.ToTensor(),\n",
    "               #AddGaussianNoise(0., 0.2)\n",
    "               #transforms.Normalize((0.1307,), (0.3081,))\n",
    "            ])\n",
    "            transform_test = transforms.Compose([\n",
    "               transforms.ToTensor(),\n",
    "               #AddGaussianNoise(0., 0.2)\n",
    "               #transforms.Normalize((0.1307,), (0.3081,))\n",
    "            ])\n",
    "            classes = [i for i in range(10)]\n",
    "            dataset_class = dsets.MNIST\n",
    "\n",
    "        elif self.dataset == 'cifar10':\n",
    "            transform_train = transforms.Compose([\n",
    "                transforms.RandomCrop(32, padding=4),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "            ])\n",
    "            transform_test = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "            ])\n",
    "            classes = ('plane', 'car', 'bird', 'cat',\n",
    "                       'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "            dataset_class = dsets.CIFAR10\n",
    "\n",
    "        elif self.dataset == 'cub':\n",
    "\n",
    "            transform_train = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                  transforms.RandomResizedCrop(224),\n",
    "                                                  transforms.RandomHorizontalFlip(),\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                                       std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "            transform_test = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                 transforms.Resize(224),\n",
    "                                                 transforms.CenterCrop(224),\n",
    "                                                 transforms.ToTensor(),\n",
    "                                                 transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                                      std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "            dataset_class = CUB\n",
    "            classes = list(range(200))\n",
    "\n",
    "        elif self.dataset == 'zero_shot_cub':\n",
    "\n",
    "            transform_train = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                  transforms.RandomResizedCrop(224),\n",
    "                                                  transforms.RandomHorizontalFlip(),\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                                       std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "            transform_test = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                 transforms.Resize(224),\n",
    "                                                 transforms.CenterCrop(224),\n",
    "                                                 transforms.ToTensor(),\n",
    "                                                 transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                                      std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "            dataset_class = ZeroShotCUB\n",
    "            classes = list(range(200))            \n",
    "            \n",
    "            \n",
    "\n",
    "        elif self.dataset == 'awa2':\n",
    "            transform_train = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                  transforms.RandomResizedCrop(224),\n",
    "                                                  transforms.RandomHorizontalFlip(),\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                                       std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "            transform_test = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                 transforms.Resize(224),\n",
    "                                                 transforms.CenterCrop(224),\n",
    "                                                 transforms.ToTensor(),\n",
    "                                                 transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                                      std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "            dataset_class = AWA2\n",
    "            classes = list(range(50))\n",
    "\n",
    "        elif self.dataset == 'apyfeatures':\n",
    "            transform_train = transforms.ToTensor()\n",
    "            transform_test = transforms.ToTensor()\n",
    "\n",
    "            dataset_class = APYFeatures\n",
    "            classes = list(range(32))\n",
    "\n",
    "        elif self.dataset == 'imagenetfeatures':\n",
    "            transform_train = transforms.ToTensor()\n",
    "            transform_test = transforms.ToTensor()\n",
    "\n",
    "            dataset_class = ImageNetFeatures\n",
    "            classes = list(range(1000))\n",
    "\n",
    "        train_dataset = dataset_class(root=root,\n",
    "                                      train=True,\n",
    "                                      transform=transform_train,\n",
    "                                      download=True)\n",
    "\n",
    "        test_dataset = dataset_class(root=root,\n",
    "                                     train=False,\n",
    "                                     transform=transform_test)\n",
    "\n",
    "        val_size = int(len(train_dataset) * 0.1)\n",
    "        train_size = len(train_dataset) - val_size\n",
    "\n",
    "        train_dataset, val_dataset = torch.utils.data.dataset.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   shuffle=True,\n",
    "                                                   num_workers=num_workers)\n",
    "\n",
    "        val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 shuffle=False,\n",
    "                                                 num_workers=num_workers)\n",
    "\n",
    "        test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  shuffle=False,\n",
    "                                                  num_workers=num_workers)\n",
    "\n",
    "        dataloaders = {'train': train_loader,\n",
    "                       'val': val_loader,\n",
    "                       'test': test_loader}\n",
    "\n",
    "        return dataloaders, classes\n",
    "\n",
    "class CUB(Dataset):\n",
    "    \"\"\"CUB200-2011 dataset.\"\"\"\n",
    "    attribute_file = 'attributes/class_attribute_labels_continuous.txt'\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, normalize=True,\n",
    "                 download=None):\n",
    "        self.root = os.path.join(root, 'cub')\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.data_dir = os.path.join(self.root, 'images')\n",
    "\n",
    "        train_test_split = pd.read_csv(os.path.join(self.root, 'train_test_split.txt'),\n",
    "                                       sep=' ', index_col=0, header=None)\n",
    "        if train:\n",
    "            is_train_image = 1\n",
    "        else:\n",
    "            is_train_image = 0\n",
    "        self.img_ids = train_test_split[train_test_split[1] == is_train_image].index.tolist()\n",
    "        self.id_to_img = pd.read_csv(os.path.join(self.root, 'images.txt'),\n",
    "                                     sep=' ', index_col=0, header=None)\n",
    "\n",
    "        raw_mtx = np.loadtxt(os.path.join(self.root,\n",
    "                                          self.attribute_file))\n",
    "        raw_mtx[raw_mtx == -1] = 0\n",
    "        raw_mtx = raw_mtx / raw_mtx.max()\n",
    "        self.attribute_mtx = torch.tensor(raw_mtx, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_ids[idx]\n",
    "        img_name = self.id_to_img[self.id_to_img.index == img_id].values[0][0]\n",
    "        img_path = os.path.join(self.data_dir, img_name)\n",
    "\n",
    "        img = imageio.imread(img_path, pilmode='RGB')\n",
    "        label = int(img_name[:3]) - 1\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label, img_path\n",
    "\n",
    "    \n",
    "class ZeroShotCUB(Dataset):\n",
    "    \"\"\"CUB200-2011 dataset.\"\"\"\n",
    "    attribute_file = 'attributes/class_attribute_labels_continuous.txt'\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, normalize=True,\n",
    "                 download=None):\n",
    "        self.root = os.path.join(root, 'cub')\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.data_dir = os.path.join(self.root, 'images')\n",
    "\n",
    "        train_test_split = pd.read_csv(os.path.join(self.root, 'zero_shot_train_test_split.txt'),\n",
    "                                       sep=' ', index_col=0, header=None)\n",
    "        if train:\n",
    "            is_train_image = 1\n",
    "        else:\n",
    "            is_train_image = 0\n",
    "        self.img_ids = train_test_split[train_test_split[1] == is_train_image].index.tolist()\n",
    "        self.id_to_img = pd.read_csv(os.path.join(self.root, 'images.txt'),\n",
    "                                     sep=' ', index_col=0, header=None)\n",
    "\n",
    "        raw_mtx = np.loadtxt(os.path.join(self.root,\n",
    "                                          self.attribute_file))\n",
    "        raw_mtx[raw_mtx == -1] = 0\n",
    "        raw_mtx = raw_mtx / raw_mtx.max()\n",
    "        self.attribute_mtx = torch.tensor(raw_mtx, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_ids[idx]\n",
    "        img_name = self.id_to_img[self.id_to_img.index == img_id].values[0][0]\n",
    "        img_path = os.path.join(self.data_dir, img_name)\n",
    "\n",
    "        img = imageio.imread(img_path, pilmode='RGB')\n",
    "        label = int(img_name[:3]) - 1\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label, img_path\n",
    "    \n",
    "    \n",
    "class AWA2(Dataset):\n",
    "    \"\"\"Animals with Attributes 2 dataset.\"\"\"\n",
    "    split_file = 'train_test_classification_split.txt'\n",
    "    data_dir = 'awa2'\n",
    "    attribute_file = 'predicate-matrix-continuous.txt'\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, normalize=True,\n",
    "                 download=None):\n",
    "        self.root = os.path.join(root, self.data_dir)\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "\n",
    "        meta_data = pd.read_csv(os.path.join(self.root,\n",
    "                                             self.split_file),\n",
    "                                sep=' ', index_col=0, header=None)\n",
    "        if train:\n",
    "            is_train_image = 1\n",
    "        else:\n",
    "            is_train_image = 0\n",
    "        self.img_ids = meta_data[meta_data[3] == is_train_image].index.tolist()\n",
    "        self.id_to_img = meta_data\n",
    "\n",
    "        raw_mtx = np.loadtxt(os.path.join(self.root,\n",
    "                                          self.attribute_file))\n",
    "        raw_mtx[raw_mtx == -1] = 0\n",
    "        raw_mtx = raw_mtx / raw_mtx.max()\n",
    "        self.attribute_mtx = torch.tensor(raw_mtx, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_ids[idx]\n",
    "        img_meta_data = self.id_to_img[self.id_to_img.index == img_id]\n",
    "        img_name = img_meta_data.values[0][0]\n",
    "        img_path = os.path.join(self.root, img_name)\n",
    "\n",
    "        img = imageio.imread(img_path, pilmode='RGB')\n",
    "        label = img_meta_data.values[0][1] - 1\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "# device = torch.device('cpu')\n",
    "\n",
    "# create dataloader objects for train, val and test\n",
    "dl = DataLoader(dataset=dataset)\n",
    "# dataloaders, classes = dl.load_data(4, 4, data_path)# 128 insted of \n",
    "dataloaders, classes = dl.load_data(64, 4, data_path)# 128 insted of \n",
    "\n",
    "# attributes (312 column vectors with 200 rows) -> each class can be described with 312 attributes\n",
    "# percentage of time, human annotator thought, the attribute was present\n",
    "attribute_mtx = dataloaders['train'].dataset.dataset.attribute_mtx\n",
    "\n",
    "# create binary encoding for class attributes\n",
    "attribute_mtx[attribute_mtx < 0.5] = 0.0\n",
    "attribute_mtx[attribute_mtx >= 0.5] = 1.0\n",
    "attribute_mtx = attribute_mtx.to(device) # cuda\n",
    "attribute_size = attribute_mtx.size(1) # number of available attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Models\n",
    "Here, we continue by defining the various models that our uRDTC consists of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Conv2d(in_channels, 20, kernel_size=3, stride=1),\n",
    "                                 nn.ReLU(True),\n",
    "                                 nn.BatchNorm2d(20),\n",
    "                                 nn.Conv2d(20, 50, kernel_size=5, stride=2),\n",
    "                                 nn.ReLU(True),\n",
    "                                 nn.BatchNorm2d(50),\n",
    "                                 nn.Conv2d(50, 100, kernel_size=5, stride=2),\n",
    "                                 nn.ReLU(True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class DropoutCNN(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 20, kernel_size=3, stride=1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, kernel_size=5, stride=2)\n",
    "        self.conv3 = nn.Conv2d(50, 100, kernel_size=5, stride=2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.dropout2d(F.relu(self.conv1(x)), 0.2)\n",
    "        x = F.dropout2d(F.relu(self.conv2(x)), 0.2)\n",
    "        x = F.dropout2d(F.relu(self.conv3(x)), 0.2)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def get_cnn(in_channels, type='cnn', pretrained_cnn_weights=None,\n",
    "            freeze_weights=False, default_pretrained=False):\n",
    "    TYPES = ['cnn', 'dropoutcnn', 'resnet152'] # TYPES = ['cnn', 'shallowcnn', 'resnet', 'resnet152']\n",
    "    assert type in TYPES\n",
    "\n",
    "    if type == 'cnn':\n",
    "        cnn = CNN(in_channels)\n",
    "    if type == 'dropoutcnn':\n",
    "        cnn = DropoutCNN(in_channels)\n",
    "#     if type == 'resnet152':\n",
    "#         cnn = models.resnet152(pretrained=default_pretrained)\n",
    "    else:\n",
    "        cnn = Identity()\n",
    "\n",
    "    # if pretrained_cnn_weights:\n",
    "    #     if type == 'resnet152':\n",
    "    #         cnn.fc = nn.Linear(cnn.fc.in_features, pretrained_cnn_weights['fc.weight'].size(0))\n",
    "    #     cnn.load_state_dict(pretrained_cnn_weights)\n",
    "    if pretrained_cnn_weights:\n",
    "        cnn.load_state_dict(pretrained_cnn_weights)\n",
    "    \n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OC(nn.Module):\n",
    "    def __init__(self, model_type, num_classes, cnn_type, input_channels, cnn_out_size,\n",
    "                 dataset, decision_size=2, max_iters=20, attribute_size=20, attribute_mtx=None, attribute_coef=0.5, hidden_size=100,\n",
    "                 tau_initial=5, tau_target=0.5, use_pretrained=False, shallow=False, strategy='aRDTC'):\n",
    "        super(OC, self).__init__()\n",
    "        assert model_type in ['xoc'] #, 'ioc']\n",
    "        self.model_type = model_type\n",
    "        self.num_classes = num_classes\n",
    "        self.attribute_size = attribute_size\n",
    "        self.attribute_mtx = attribute_mtx\n",
    "        self.attribute_coef = attribute_coef if attribute_mtx is not None else 0.\n",
    "        self.decision_size = decision_size # change keyword default to 3?\n",
    "        self.tau_initial = tau_initial\n",
    "        self.tau_target = tau_target\n",
    "        self.max_iters = max_iters\n",
    "        self.shallow = shallow\n",
    "        self.stats = defaultdict(list)\n",
    "        self.reduced_vocab_size = 2\n",
    "        self.strategy = strategy\n",
    "\n",
    "        self.no_lstm = False\n",
    "\n",
    "        #self.init_attribute_matrix(attribute_mtx, attribute_size, attribute_coef, use_bin_attr)\n",
    "\n",
    "        self.cnn = self.init_cnn(cnn_type, input_channels, dataset, use_pretrained)\n",
    "        self.init_network(hidden_size, decision_size, num_classes, attribute_size, cnn_out_size, shallow)\n",
    "\n",
    "        self.init_losses()\n",
    "\n",
    "\n",
    "\n",
    "        self.phase = 'train'\n",
    "\n",
    "        # for stats\n",
    "        self.logits_list = []\n",
    "        self.sigmas_list = []\n",
    "#         self.labels_list\n",
    "        self.binary_features_list = []\n",
    "        self.labels_list = []\n",
    "        self.used_attributes_list = []\n",
    "        self.certain_attrs = []\n",
    "        self.attribute_accuracies = []\n",
    "        self.drop_ratios = []\n",
    "        self.mean_sigmas = []\n",
    "        self.classifications_list = []\n",
    "        \n",
    "\n",
    "    def init_network(self, hidden_size, decision_size, num_classes, attribute_size, cnn_out_size, shallow):\n",
    "        assert decision_size > 1\n",
    "\n",
    "        # LSTM initialization parameters\n",
    "        if self.no_lstm:\n",
    "            self.init_h0 = nn.Parameter(torch.zeros(attribute_size * decision_size), requires_grad=False)\n",
    "            self.init_c0 = nn.Parameter(torch.zeros(attribute_size * decision_size), requires_grad=False)\n",
    "        else:\n",
    "            self.init_h0 = nn.Parameter(torch.zeros(hidden_size).uniform_(-0.01, 0.01), requires_grad=True)\n",
    "            self.init_c0 = nn.Parameter(torch.zeros(hidden_size).uniform_(-0.01, 0.01), requires_grad=True)\n",
    "\n",
    "        if self.no_lstm:\n",
    "            self.lstm = lambda x, y: (None, (x.squeeze(), x.squeeze()))\n",
    "        else:\n",
    "            self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "\n",
    "        if self.no_lstm:\n",
    "            classifier_in = attribute_size * decision_size\n",
    "        else:\n",
    "            classifier_in = attribute_size * decision_size\n",
    "\n",
    "        self.classifier = nn.Sequential(#nn.BatchNorm1d(classifier_in) if not self.no_lstm else Identity(),\n",
    "                                        nn.Linear(classifier_in, hidden_size),\n",
    "                                        nn.ReLU(inplace=True),\n",
    "                                        nn.BatchNorm1d(hidden_size),\n",
    "                                        nn.Linear(hidden_size, num_classes))\n",
    "\n",
    "        if self.model_type == 'xoc':\n",
    "            if self.no_lstm:\n",
    "                feat_select_in_size = attribute_size * decision_size\n",
    "            else:\n",
    "                feat_select_in_size = hidden_size\n",
    "            feat_select_out_size = attribute_size\n",
    "            pre_lstm_size = attribute_size * decision_size * 2\n",
    "\n",
    "            bin_feat_type = 'shallow' if shallow else 'dropoutmlp' #'mlp'\n",
    "            feat_select_type = 'mlp_small'\n",
    "\n",
    "        elif self.model_type == 'ioc':\n",
    "            bin_feat_type = 'identity'\n",
    "            feat_select_type = 'mlp_big'\n",
    "\n",
    "            if not shallow:\n",
    "                feat_select_in_size = cnn_out_size + hidden_size\n",
    "                feat_select_out_size = decision_size\n",
    "                pre_lstm_size = feat_select_out_size\n",
    "            else:\n",
    "                feat_select_in_size = hidden_size\n",
    "                feat_select_out_size = cnn_out_size * decision_size\n",
    "                pre_lstm_size = decision_size\n",
    "\n",
    "        if feat_select_type == 'mlp_small':\n",
    "            self.feature_selection = nn.Sequential(nn.BatchNorm1d(feat_select_in_size) if not self.no_lstm else Identity(),\n",
    "                                                   nn.Linear(feat_select_in_size , hidden_size),\n",
    "                                                   nn.ReLU(inplace=True),\n",
    "                                                   nn.BatchNorm1d(hidden_size),\n",
    "                                                   nn.Linear(hidden_size, feat_select_out_size))\n",
    "        elif feat_select_type == 'mlp_big':\n",
    "            self.feature_selection = nn.Sequential(nn.BatchNorm1d(feat_select_in_size) if not self.no_lstm else Identity(),\n",
    "                                                   nn.Linear(feat_select_in_size, hidden_size),\n",
    "                                                   nn.ReLU(inplace=True),\n",
    "                                                   nn.BatchNorm1d(hidden_size),\n",
    "                                                   nn.Linear(hidden_size, hidden_size),\n",
    "                                                   nn.ReLU(inplace=True),\n",
    "                                                   nn.BatchNorm1d(hidden_size),\n",
    "                                                   nn.Linear(hidden_size, feat_select_out_size))\n",
    "\n",
    "        if bin_feat_type == 'identity':\n",
    "            self.binary_features = Identity()\n",
    "        elif bin_feat_type == 'shallow':\n",
    "            class AddZeros(nn.Module):\n",
    "                def __init__(self):\n",
    "                    super().__init__()\n",
    "\n",
    "                def forward(self, x):\n",
    "                    zeros = torch.zeros_like(x).unsqueeze(2)\n",
    "                    return torch.cat((x.unsqueeze(2), zeros), dim=2)\n",
    "\n",
    "            self.binary_features = AddZeros()\n",
    "        elif bin_feat_type == 'mlp':\n",
    "            self.binary_features = nn.Sequential(nn.BatchNorm1d(cnn_out_size), # use dropout\n",
    "                                                 nn.Linear(cnn_out_size, hidden_size),\n",
    "                                                 nn.ReLU(inplace=True),\n",
    "                                                 nn.BatchNorm1d(hidden_size), # use dropout\n",
    "                                                 nn.Linear(hidden_size, hidden_size),\n",
    "                                                 nn.ReLU(inplace=True),\n",
    "                                                 nn.BatchNorm1d(hidden_size), # use dropout\n",
    "                                                 nn.Linear(hidden_size, attribute_size * self.reduced_vocab_size))\n",
    "        elif bin_feat_type == 'dropoutmlp':\n",
    "            self.binary_features = nn.Sequential(\n",
    "                                                nn.Linear(cnn_out_size, hidden_size),\n",
    "                                                nn.ReLU(inplace=False),\n",
    "                                                nn.Dropout(0.2, inplace=False),\n",
    "                                                nn.Linear(hidden_size, hidden_size),\n",
    "                                                nn.ReLU(inplace=False),\n",
    "                                                nn.Dropout(0.2, inplace=False),\n",
    "                                                nn.Linear(hidden_size, attribute_size * self.reduced_vocab_size)\n",
    "                                                )\n",
    "\n",
    "        if self.no_lstm:\n",
    "            self.pre_lstm = Identity()\n",
    "        else:\n",
    "            self.pre_lstm = nn.Sequential(#nn.BatchNorm1d(pre_lstm_size),\n",
    "                                          nn.Linear(pre_lstm_size, hidden_size),\n",
    "                                          nn.ReLU(inplace=True),\n",
    "                                          nn.BatchNorm1d(hidden_size))\n",
    "\n",
    "\n",
    "        # Temperature parameters\n",
    "        self.binary_features.tau = nn.Parameter(torch.tensor([self.tau_initial], dtype=torch.float), requires_grad=True)\n",
    "        self.feature_selection.tau = nn.Parameter(torch.tensor([self.tau_initial], dtype=torch.float), requires_grad=True)\n",
    "        #self.init_weights()\n",
    "\n",
    "    \n",
    "    \n",
    "    def get_attribute_uncertainty(self, image_features, n=10, batch_size=64):\n",
    "        outputs = torch.zeros((n, batch_size, attribute_size * self.reduced_vocab_size), device=device)\n",
    "        \n",
    "        if self.phase == 'train':\n",
    "            for i in range(n):\n",
    "                outputs[i] = F.softmax(self.binary_features(image_features))\n",
    "#                 outputs[i] = self.binary_features(image_features)\n",
    "\n",
    "        if self.phase == 'test':\n",
    "            for layer in self.binary_features:\n",
    "                if isinstance(layer, torch.nn.modules.dropout._DropoutNd):\n",
    "                    layer.train()\n",
    "#             self.binary_features.train()\n",
    "            for i in range(n):\n",
    "                outputs[i] = F.softmax(self.binary_features(image_features))\n",
    "#                 outputs[i] = self.binary_features(image_features)\n",
    "\n",
    "            for layer in self.binary_features:\n",
    "                if isinstance(layer, torch.nn.modules.dropout._DropoutNd):\n",
    "                    layer.eval()\n",
    "#             self.binary_features.eval()\n",
    "        \n",
    "        sigmas = outputs.var(dim=0)\n",
    "#         sigmas += (0.01**2 * 0.5)/(2 * image_features.size(0) * weight_decay)\n",
    "            \n",
    "            \n",
    "        return sigmas\n",
    "    \n",
    "    def get_attribute_uncertainty_new(self, image_features, n=10, batch_size=64):\n",
    "        outputs = torch.zeros((n, batch_size, attribute_size * self.reduced_vocab_size), device=device)\n",
    "        \n",
    "        if self.phase == 'train':\n",
    "            for i in range(n):\n",
    "                outputs[i] = F.softmax(self.binary_features(image_features), dim=1)\n",
    "#                 outputs[i] = self.binary_features(image_features)\n",
    "\n",
    "        if self.phase == 'test':\n",
    "            for layer in self.binary_features:\n",
    "                if isinstance(layer, torch.nn.modules.dropout._DropoutNd):\n",
    "                    layer.train()\n",
    "#             self.binary_features.train()\n",
    "            for i in range(n):\n",
    "                outputs[i] = F.softmax(self.binary_features(image_features), dim=1)\n",
    "#                 outputs[i] = self.binary_features(image_features)\n",
    "\n",
    "            for layer in self.binary_features:\n",
    "                if isinstance(layer, torch.nn.modules.dropout._DropoutNd):\n",
    "                    layer.eval()\n",
    "#             self.binary_features.eval()\n",
    "        \n",
    "        decision_sigma = outputs.var(dim=0)\n",
    "        attribute_sigma = decision_sigma.view(batch_size, -1, 2).mean(dim=2)\n",
    "#         attribute_sigma += (0.01**2 * 0.5)/(2 * batch_size * weight_decay)\n",
    "            \n",
    "        return attribute_sigma\n",
    "  \n",
    "    def init_attribute_matrix(self, attribute_mtx, attribute_size, attribute_coef, use_bin_attr):\n",
    "        if attribute_coef > 0.:\n",
    "            if use_bin_attr:\n",
    "                attribute_mtx[attribute_mtx < 0.5] = 0.\n",
    "                attribute_mtx[attribute_mtx >= 0.5] = 1.\n",
    "            self.attribute_mtx = nn.Parameter(attribute_mtx, requires_grad=False)\n",
    "            self.attribute_size = attribute_mtx.size(1)\n",
    "        else:\n",
    "            self.attribute_mtx = None\n",
    "            self.attribute_size = attribute_size\n",
    "\n",
    "    def toggle_update_schedule(self):\n",
    "        # TODO: see a few lines below\n",
    "        #self.update_binary_features = not self.update_binary_features\n",
    "        pass\n",
    "\n",
    "    def get_param_groups(self):\n",
    "        cnn_params = []\n",
    "        tree_params = []\n",
    "        for n, p in self.named_parameters():\n",
    "            if p.requires_grad:\n",
    "                # TODO: introduce parameter that allows to switch between training alternatingly\n",
    "                # Currently commented out, so both groups contain the same parameters\n",
    "                \"\"\"\n",
    "                if n.startswith('cnn') or n.startswith('binary_features'):\n",
    "                    print('CNN', n)\n",
    "                    cnn_params.append(p)\n",
    "                else:\n",
    "                    print('OTHER', n)\n",
    "                    tree_params.append(p)\n",
    "                \"\"\"\n",
    "                cnn_params.append(p)\n",
    "                tree_params.append(p)\n",
    "        return tree_params, cnn_params\n",
    "\n",
    "    def set_optimizer(self, optimizers):\n",
    "        self.tree_optimizer = optimizers[0]\n",
    "        self.cnn_optimizer = optimizers[1]\n",
    "\n",
    "    def set_scheduler(self, schedulers):\n",
    "        self.tree_scheduler = schedulers[0]\n",
    "        self.cnn_scheduler = schedulers[1]\n",
    "\n",
    "    def get_optimizer(self):\n",
    "        if self.update_binary_features:\n",
    "            return self.cnn_optimizer\n",
    "        else:\n",
    "            return self.tree_optimizer\n",
    "\n",
    "    def get_scheduler(self):\n",
    "        if self.update_binary_features:\n",
    "            return self.cnn_scheduler\n",
    "        else:\n",
    "            return self.tree_scheduler\n",
    "\n",
    "    def init_losses(self):\n",
    "        self.cls_loss = nn.CrossEntropyLoss()\n",
    "        self.attr_loss = nn.BCEWithLogitsLoss()\n",
    "        self.update_binary_features = False\n",
    "\n",
    "    def init_cnn(self, cnn_type, input_channels, dataset, use_pretrained):\n",
    "        if cnn_type == 'None':\n",
    "            cnn = Identity()\n",
    "        else:\n",
    "            if use_pretrained:\n",
    "                # TODO add data_path and change state dict name \n",
    "                # cnn_state_dict = torch.load('pretrained/{}_{}.pth'.format(dataset, cnn_type))\n",
    "#                 cnn_state_dict = torch.load('pretrained/cub_resnet152.pkl')# .format(dataset, cnn_type)\n",
    "                cnn_state_dict = torch.load('pretrained/{}_resnet152.pkl'.format(dataset))# .format(dataset, cnn_type)\n",
    "\n",
    "                cnn = get_cnn(input_channels, cnn_type, cnn_state_dict, freeze_weights=True)\n",
    "            else:\n",
    "                cnn = get_cnn(input_channels, cnn_type)\n",
    "\n",
    "        return cnn\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight.data)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.fill_(0.1)\n",
    "\n",
    "    def set_tau(self, epoch):\n",
    "        annealing_factor = epoch / 100\n",
    "        self.tau = self.tau_initial\n",
    "        self.tau -= (self.tau_initial - self.tau_target) * annealing_factor\n",
    "        self.tau = max(self.tau, self.tau_target)\n",
    "\n",
    "    def process_images_new(self, images):\n",
    "        batch_size = images.size(0)\n",
    "        img_feats = self.cnn(images)\n",
    "        img_feats = img_feats.view(img_feats.size(0), -1)\n",
    "        image_features = self.binary_features(img_feats) \n",
    "        with torch.no_grad():\n",
    "            attribute_uncertainties = self.get_attribute_uncertainty_new(img_feats, n=5, batch_size=images.size(0))\n",
    "        \n",
    "        if self.model_type == 'xoc':\n",
    "            attribute_logits = image_features.view(-1, 2)\n",
    "\n",
    "\n",
    "            attributes_softmax = F.softmax(attribute_logits / self.binary_features.tau, dim=1)\n",
    "            attributes_hard = self.argmax(attributes_softmax, dim=1)\n",
    "            image_features = attributes_hard.view(images.size(0), -1, 2)\n",
    "\n",
    "            # TODO: generalize to different decision sizes\n",
    "            bin_attribute_logits = attribute_logits - attribute_logits[:, 1].unsqueeze(-1)\n",
    "            self.attribute_logits = bin_attribute_logits[:, 0].view(images.size(0), -1)\n",
    "\n",
    "            self.collect_hist_stats('AttributesSoft', F.softmax(attribute_logits, dim=1))\n",
    "            self.collect_hist_stats('AttributesSoftTemp', attributes_softmax)\n",
    "            self.collect_hist_stats('AttributesHard', attributes_hard.max(dim=1)[1])\n",
    "\n",
    "        return image_features, attribute_uncertainties\n",
    "\n",
    "\n",
    "    def process_images(self, images):\n",
    "        batch_size = images.size(0)\n",
    "        img_feats = self.cnn(images)\n",
    "        img_feats = img_feats.view(img_feats.size(0), -1)\n",
    "        image_features = self.binary_features(img_feats)\n",
    "        # print(image_features.size())\n",
    "        ################## remove attrs code\n",
    "#         sigmas = self.get_attribute_uncertainty_batch(img_feats,n=100, batch_size=batch_size)\n",
    "        \n",
    "        if self.strategy == 'remRDTC':\n",
    "            with torch.no_grad():\n",
    "                sigmas = self.get_attribute_uncertainty(img_feats, n=5, batch_size=images.size(0))\n",
    "            uncertain_attrs = (sigmas > 0.03925).float() # get binary uncertain attrs\n",
    "            certain_attrs = 1. - uncertain_attrs\n",
    "            mask = certain_attrs.detach()\n",
    "            inv_mask = 1-mask\n",
    "            min_value = image_features.min()\n",
    "            image_features = image_features * mask # put zeros where uncertain attts are\n",
    "            image_features = image_features - (inv_mask.detach()*min_value.detach()) #*-500\n",
    "\n",
    "#         sigmas.detach()\n",
    "#         sigmas.cuda()\n",
    "#         self.mean_sigmas.append(sigmas.mean().item())\n",
    "#         drop_ratio = (sigmas>0.005).float().sum()/(images.size(0)*attribute_size*2.)\n",
    "#         min_value = image_features.min()\n",
    "#         min_value.detach()\n",
    "#         self.drop_ratios.append(drop_ratio)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #############################################################\n",
    "#         if not self.training:\n",
    "\n",
    "#             self.sigmas_list.append(sigmas)\n",
    "            # self.logits_list.append(image_features)\n",
    "            # image_features = torch.cat((attribute_logits, sigmas),1)\n",
    "        \n",
    "        \n",
    "        ################## remove attrs\n",
    "#         uncertain_attrs = (sigmas > 0.005).float() # get binary uncertain attrs\n",
    "#         certain_attrs = 1. - uncertain_attrs\n",
    "#         mask = certain_attrs.detach()#(torch.FloatTensor(image_features.size()).uniform_() > 0.050).float().to(device)\n",
    "        if self.strategy == 'randRDTC':\n",
    "            mask = (torch.FloatTensor(image_features.size()).uniform_() > 0.050).float().to(device)\n",
    "            inv_mask = 1-mask\n",
    "#         self.drop_ratios.append((inv_mask.sum()/39936.0).item())\n",
    "#         mask.detach()\n",
    "            min_value = image_features.min()\n",
    "            image_features = image_features * mask # put zeros where uncertain attts are\n",
    "            image_features = image_features - (inv_mask.detach()*min_value.detach()) #*-500\n",
    "        ##############################################################\n",
    "\n",
    "        if self.model_type == 'xoc':\n",
    "            attribute_logits = image_features.view(-1, 2)\n",
    "\n",
    "\n",
    "            attributes_softmax = F.softmax(attribute_logits / self.binary_features.tau, dim=1)\n",
    "            attributes_hard = self.argmax(attributes_softmax, dim=1)\n",
    "            image_features = attributes_hard.view(images.size(0), -1, 2)\n",
    "\n",
    "            # TODO: generalize to different decision sizes\n",
    "            bin_attribute_logits = attribute_logits - attribute_logits[:, 1].unsqueeze(-1)\n",
    "            self.attribute_logits = bin_attribute_logits[:, 0].view(images.size(0), -1)\n",
    "\n",
    "            self.collect_hist_stats('AttributesSoft', F.softmax(attribute_logits, dim=1))\n",
    "            self.collect_hist_stats('AttributesSoftTemp', attributes_softmax)\n",
    "            self.collect_hist_stats('AttributesHard', attributes_hard.max(dim=1)[1])\n",
    "\n",
    "        return image_features\n",
    "\n",
    "    def make_decision(self, lstm_out, binary_features, iter, sigma=[], max_uncertainty=0.2):\n",
    "        if self.model_type == 'xoc':\n",
    "            # Perform categorical feature selection\n",
    "            selection_logits = self.feature_selection(lstm_out)\n",
    "################################### remRDTC      \n",
    "            if self.strategy == 'remRDTC':\n",
    "#                 mask = (torch.FloatTensor(10,5).uniform_() >= 0.975).float() #\n",
    "                uncertain_attributes = (sigma > 2e-4).float()\n",
    "#                 dummy = torch.zeros((sigma.size()), device=device)\n",
    "#                 dummy[uncertain_attributes] = -np.inf\n",
    "# #                 print(np.quantile(sigma.cpu().numpy(),0.99))\n",
    "# #                 attribute_uncertainties = torch.rand(binary_features.size(0), attribute_size, device=device, requires_grad=False)\n",
    "#                 self.mean_sigmas.append(sigma.mean().item())   \n",
    "                certain_attributes = 1. - uncertain_attributes\n",
    "                selection_logits = certain_attributes.detach() * selection_logits + uncertain_attributes.detach() * -100\n",
    "#             else:\n",
    "#                 new_selection_logits = selection_logits    \n",
    "#                 selection_probs = torch.softmax((selection_logits+dummy)/0.01, dim=1)\n",
    "    \n",
    "                if self.training:\n",
    "                    hard_selection = F.gumbel_softmax(selection_logits, tau=self.feature_selection.tau, hard=True)\n",
    "                else:\n",
    "                    hard_selection = self.argmax(selection_logits, dim=1)\n",
    "\n",
    "################################### randRDTC  \n",
    "            if self.strategy == 'randRDTC':\n",
    "                with torch.no_grad():\n",
    "                    uncertain_attributes = (torch.FloatTensor(selection_logits.size()).uniform_() >= 0.975).float().to(device) #\n",
    "                certain_attributes = 1. - uncertain_attributes\n",
    "                selection_logits = certain_attributes.detach() * selection_logits + uncertain_attributes.detach() * -100\n",
    "                if self.training:\n",
    "                    hard_selection = F.gumbel_softmax(selection_logits, tau=self.feature_selection.tau, hard=True)\n",
    "                else:\n",
    "                    hard_selection = self.argmax(selection_logits, dim=1)\n",
    "\n",
    "################################### other RDTC     \n",
    "            else: # if another strategy is used\n",
    "                if self.training:\n",
    "                    hard_selection = F.gumbel_softmax(selection_logits, tau=self.feature_selection.tau, hard=True)\n",
    "                else:\n",
    "                    hard_selection = self.argmax(selection_logits, dim=1)\n",
    "\n",
    "\n",
    "            # Get single decision\n",
    "            self.saved_attribute_selection = hard_selection.max(dim=1)[1]\n",
    "#             print(self.saved_attribute_selection.size())\n",
    "#             print(self.saved_attribute_selection)\n",
    "            \n",
    "\n",
    "            decision = (hard_selection.unsqueeze(2) * binary_features).view(-1, self.attribute_size * self.decision_size)\n",
    "#             print(decision.size())\n",
    "#             print(decision[0].size())\n",
    "#             print()\n",
    "        elif self.model_type == 'ioc':\n",
    "            if not self.shallow:\n",
    "                features = torch.cat((lstm_out, binary_features), dim=1)\n",
    "                selection_logits = self.feature_selection(features)\n",
    "            else:\n",
    "                shallow_weights = self.feature_selection(lstm_out)\n",
    "                shallow_weights = shallow_weights.view(lstm_out.size(0), -1, self.decision_size)\n",
    "                selection_logits = torch.bmm(binary_features.unsqueeze(1), shallow_weights)\n",
    "                selection_logits = selection_logits.squeeze()\n",
    "\n",
    "            soft_decision = F.softmax(selection_logits / self.tau_selection, dim=1)\n",
    "            hard_selection = self.argmax(soft_decision, dim=1)\n",
    "            decision = hard_selection\n",
    "\n",
    "        # Collect statistics\n",
    "        self.collect_hist_stats('SelectionSoft', F.softmax(selection_logits, dim=1).max(dim=1)[0], iter)\n",
    "        self.collect_hist_stats('SelectionSoftTemp', F.softmax(selection_logits / self.feature_selection.tau, dim=1).max(dim=1)[0], iter)\n",
    "        self.collect_hist_stats('SelectionHard', hard_selection.max(dim=1)[1], iter)\n",
    "\n",
    "        return decision\n",
    "\n",
    "    def get_initial_state(self, batch_size):\n",
    "        h0 = self.init_h0.view(1, 1, -1).expand(-1, batch_size, -1)\n",
    "        c0 = self.init_c0.view(1, 1, -1).expand(-1, batch_size, -1)\n",
    "        state = (h0.contiguous(), c0.contiguous())\n",
    "        return state\n",
    "\n",
    "    def argmax(self, y_soft, dim):\n",
    "        index = y_soft.max(dim, keepdim=True)[1]\n",
    "        y_hard = torch.zeros_like(y_soft).scatter_(dim, index, 1.0)\n",
    "        argmax = y_hard - y_soft.detach() + y_soft\n",
    "        return argmax\n",
    "\n",
    "    def collect_hist_stats(self, name, data, i=None):\n",
    "        # TODO: investigate performance impact of collecting these statistics,\n",
    "        # make option to disable and/or autodisable if tree is too large\n",
    "        if 'Hard' in name:\n",
    "            stat_str = 'Hist/' + name\n",
    "            data = data.detach().cpu()\n",
    "            self.stats[stat_str].append(data)\n",
    "            if i is not None:\n",
    "                stat_str += str(i)\n",
    "                self.stats[stat_str].append(data)\n",
    "\n",
    "    def get_hist_stats(self, reset=True):\n",
    "        stats = self.stats\n",
    "        if reset:\n",
    "            self.stats = defaultdict(list)\n",
    "        #return None\n",
    "        return stats\n",
    "\n",
    "    def reset_stats(self):\n",
    "        self.unique_attributes = [set() for i in range(self.max_iters)]\n",
    "        if self.attribute_coef > 0.:\n",
    "            self.attr_pred_correct = [0 for i in range(self.max_iters)]\n",
    "\n",
    "    def update_unique_attributes(self, unique_attributes, iter):\n",
    "        for attr in unique_attributes:\n",
    "            self.unique_attributes[iter].add(attr.item())\n",
    "\n",
    "    def get_unique_attributes(self):\n",
    "        uniq_per_iter = []\n",
    "        for i in range(self.max_iters):\n",
    "            iter_set = self.unique_attributes[i]\n",
    "            for j in range(i+1):\n",
    "                if j == i:\n",
    "                    continue\n",
    "                iter_set = iter_set.union(self.unique_attributes[j])\n",
    "            uniq_per_iter.append(len(iter_set))\n",
    "        return uniq_per_iter\n",
    "\n",
    "    def update_attr_preds(self, attr_correct, iter):\n",
    "        self.attr_pred_correct[iter] += attr_correct\n",
    "\n",
    "    def get_attr_acc(self, total_cnt):\n",
    "        correct_cumsum = np.cumsum(self.attr_pred_correct)\n",
    "        cnt_per_iter = (np.arange(self.max_iters) + 1) * total_cnt\n",
    "        return correct_cumsum / cnt_per_iter\n",
    "\n",
    "    def init_tree_stats(self):\n",
    "        # TODO: investigate performance impact of collecting these statistics,\n",
    "        # make option to disable and/or autodisable if tree is too large\n",
    "\n",
    "        # Would be nice if this worked with sparse tensors\n",
    "        n_possible_states = self.reduced_vocab_size** self.max_iters\n",
    "        self.label_stats = torch.zeros((n_possible_states * self.reduced_vocab_size,\n",
    "                                        self.num_classes), dtype=torch.int32)\n",
    "                                       #layout=torch.sparse_coo)\n",
    "        self.selection_stats = torch.zeros((n_possible_states,\n",
    "                                            self.attribute_size),\n",
    "                                           dtype=torch.int32)\n",
    "                                           #layout=torch.sparse_coo)\n",
    "\n",
    "    def update_tree_stats(self, attribute_selection, attribute_decisions, labels, iter):\n",
    "        # TODO: investigate performance impact of collecting these statistics,\n",
    "        # make option to disable and/or autodisable if tree is too large\n",
    "\n",
    "        if iter == 0:\n",
    "            self.batch_states = torch.zeros_like(labels)\n",
    "            for i in range(labels.size(0)):\n",
    "                self.label_stats[self.batch_states[i], labels[i]] += 1\n",
    "\n",
    "        for i in range(labels.size(0)):\n",
    "            self.selection_stats[self.batch_states[i], attribute_selection[i]] += 1\n",
    "            self.batch_states[i] += (attribute_decisions[i] + 1) * self.decision_size ** iter\n",
    "            self.label_stats[self.batch_states[i], labels[i]] += 1\n",
    "\n",
    "    def run_iteration(self, binary_features, state, decision_hist, iter, sigma=[]): # also pass sigma here\n",
    "        lstm_out = state[0].squeeze(0)\n",
    "\n",
    "        # Make binary decision\n",
    "        decision = self.make_decision(lstm_out, binary_features, iter, sigma)\n",
    "\n",
    "        if decision_hist is None:\n",
    "            decision_hist = decision\n",
    "        else:\n",
    "            decision_hist = (decision_hist + decision).clamp(0., 1.)\n",
    "\n",
    "        scaled_dh = decision_hist / decision_hist.sum(dim=1).unsqueeze(1).detach()\n",
    "        if self.no_lstm:\n",
    "            lstm_in = scaled_dh\n",
    "        else:\n",
    "            lstm_in = torch.cat((scaled_dh, decision), dim=1)\n",
    "\n",
    "        # Update LSTM state\n",
    "        lstm_in = self.pre_lstm(lstm_in).unsqueeze(1)\n",
    "        _, state = self.lstm(lstm_in, state)\n",
    "\n",
    "        # Get current classification\n",
    "        classifier_in = scaled_dh\n",
    "        #classifier_in = state[1].squeeze(0)\n",
    "        #classifier_in = torch.cat((decision_hist, self.lstm_state_bn(lstm_state)), dim=1)\n",
    "        classification = self.classifier(classifier_in)\n",
    "\n",
    "        return classification, state, decision_hist\n",
    "\n",
    "    def tree_rollout(self, images, labels, keep_tree_stats=False):\n",
    "        # Set initial state\n",
    "        state = self.get_initial_state(images.size(0))\n",
    "\n",
    "        # Get categorical features once\n",
    "#         binary_features = self.process_images(images)\n",
    "        \n",
    "        binary_features, attribute_uncertainties = self.process_images_new(images)\n",
    "\n",
    "        \n",
    "#         # collect attribute stats\n",
    "#         attr_acc = (binary_features[:,:,0] == attribute_mtx[labels]).sum().long() / float((attribute_size*labels.size(0)))    \n",
    "#         self.attribute_accuracies.append(attr_acc.item())\n",
    "#         self.mean_sigmas.append(attribute_uncertainties.mean().item())\n",
    "        uncertain_attributes = (attribute_uncertainties > 2e-4).float()\n",
    "#         self.drop_ratios.append((uncertain_attributes.sum()/19968.0).item())\n",
    "        self.sigmas_list.append(attribute_uncertainties)\n",
    "        self.labels_list.append(labels)\n",
    "\n",
    "\n",
    "        ######################### extended vocab code \n",
    "        if self.strategy == 'extRDTC':\n",
    "#             if not self.training:\n",
    "#                 self.sigmas_list.append(attribute_uncertainties)\n",
    "#                 self.labels_list.append(labels)\n",
    "#                 self.binary_features_list.append(binary_features)\n",
    "#                 self.labels_list.append(labels)\n",
    "\n",
    "\n",
    "            uncertain_attributes = (attribute_uncertainties>2e-4).float().unsqueeze(2)\n",
    "#             print(uncertain_attributes.size())\n",
    "#             print()\n",
    "            self.drop_ratios.append((uncertain_attributes.sum()/19968.0).item())\n",
    "\n",
    "            # obtain uncertainty and append to decision\n",
    "            new_attribute_decisions = torch.cat([binary_features, torch.zeros_like(uncertain_attributes, device=device)], dim=2)\n",
    "            certain_decisions = 1. - uncertain_attributes\n",
    "            uncertain_onehot = torch.tensor([[0., 0., 1.]], device=device).repeat(images.size(0), attribute_size, 1)\n",
    "            uncertain_attrs_removed = certain_decisions.detach() * new_attribute_decisions\n",
    "            shaped_uncertain_attrs = uncertain_attributes.detach() * uncertain_onehot\n",
    "            final_attribute_decisions = uncertain_attrs_removed + shaped_uncertain_attrs\n",
    "            binary_features = final_attribute_decisions\n",
    "            self.binary_features_list.append(binary_features)\n",
    "#         ######################### extended vocab code end\n",
    "        \n",
    "        \n",
    "\n",
    "        loss = 0\n",
    "        j = 0\n",
    "        # stats\n",
    "        all_classifications = []\n",
    "        all_chosen_attr = []\n",
    "        all_attribute_preds = []\n",
    "\n",
    "        decision_hist = None\n",
    "        while j < self.max_iters:\n",
    "            classification, state, decision_hist = self.run_iteration(binary_features, state, decision_hist, j+1, sigma=attribute_uncertainties)\n",
    "            loss += (1. - self.attribute_coef) * self.cls_loss(classification, labels)\n",
    "            all_classifications.append(classification)\n",
    "\n",
    "            self.update_unique_attributes(self.saved_attribute_selection.unique(), j)\n",
    "\n",
    "            if self.model_type == 'xoc' and self.attribute_coef > 0.:\n",
    "                chosen_attribtutes = self.saved_attribute_selection\n",
    "                attribute_logits = self.attribute_logits\n",
    "\n",
    "                attribute_target = self.attribute_mtx[labels, :].gather(1, chosen_attribtutes.unsqueeze(1)).squeeze()\n",
    "                attribute_pred = attribute_logits.gather(1, chosen_attribtutes.unsqueeze(1)).squeeze()\n",
    "                loss += self.attribute_coef * self.attr_loss(attribute_pred,\n",
    "                                                             attribute_target)\n",
    "                \n",
    "\n",
    "\n",
    "                attribute_pred_bin = (attribute_pred > 0.).long()\n",
    "                self.update_attr_preds((attribute_pred_bin == attribute_target).sum().item(), j)\n",
    "\n",
    "                \n",
    "            if keep_tree_stats:\n",
    "                attribute_pred = self.attribute_logits.gather(1, self.saved_attribute_selection.unsqueeze(1)).squeeze()\n",
    "                self.update_tree_stats(self.saved_attribute_selection, (attribute_pred > 0.).long(),labels, j)\n",
    "\n",
    "                # all_chosen_attr.append(self.saved_attribute_selection)\n",
    "                all_attribute_preds.append((attribute_pred > 0.).long())\n",
    "\n",
    "            j += 1\n",
    "        \n",
    "            all_chosen_attr.append(self.saved_attribute_selection)\n",
    "\n",
    "\n",
    "        self.tmp_saved_chosen_attr = torch.stack(all_chosen_attr, dim=1)\n",
    "\n",
    "        if keep_tree_stats:\n",
    "            self.tmp_saved_cls = torch.stack(all_classifications, dim=1)\n",
    "#             self.tmp_saved_chosen_attr = torch.stack(all_chosen_attr, dim=1)\n",
    "            self.tmp_saved_attr_pred = torch.stack(all_attribute_preds, dim=1)\n",
    "        # else:\n",
    "        #     self.tmp_saved_chosen_attr = None\n",
    "\n",
    "        loss = loss / self.max_iters\n",
    "                ####################################\n",
    "        self.used_attributes_list.append(self.tmp_saved_chosen_attr)\n",
    "        self.classifications_list.append(all_classifications)\n",
    "#         if binary_features.size(0)==64:\n",
    "#             chosen_attributes_binary = torch.tensor([[1 if x in [int(attr) for attr in self.tmp_saved_chosen_attr[row,:]] else 0 for x in range(312)] for row in range(64)])\n",
    "#             self.used_attributes_list.append(chosen_attributes_binary)\n",
    "\n",
    "\n",
    "        return all_classifications, loss, self.tmp_saved_chosen_attr\n",
    "\n",
    "    def forward(self, images, labels, keep_tree_stats=False):\n",
    "        classification, loss, chosen_attribtutes = self.tree_rollout(images, labels, keep_tree_stats)\n",
    "        # classification, loss, chosen_attributes = self.tree_rollout(images, labels, keep_tree_stats)\n",
    "\n",
    "        return classification, loss#, chosen_attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "After defining our models, we can continue by training it. For this, we first set some hyperparameters and then continue by defining a trainer class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake input arguments\n",
    "model_type = 'xoc'\n",
    "cnn_type = 'uncertain'\n",
    "# cnn_type = 'resnet'\n",
    "attribute_coef = 0.2\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.#0.0001\n",
    "step_size = 50\n",
    "num_epochs = 2\n",
    "max_iters = 10\n",
    "hidden_size = 1000\n",
    "cnn_out_size = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, dataloaders, num_epochs, device, log_freq, log_path): # todo remove stats dict\n",
    "\n",
    "        self.model = model\n",
    "        self.dataloaders = dataloaders\n",
    "        self.num_epochs = num_epochs\n",
    "        self.device = device\n",
    "        self.log_freq = log_freq\n",
    "        self.log_path = log_path\n",
    "        \n",
    "        self.logger = SummaryWriter(self.log_path)\n",
    "\n",
    "        #### TODO remove this workaround and use tensorboard\n",
    "#         with open('/content/drive/My Drive/rdtc/data/' + 'logs/' + 'stats_dict.json') as json_file:\n",
    "#             self.stats_dict = json.load(json_file)\n",
    "        \n",
    "        self.classifications_dict = {'correct':{'num':0, 'uncertainty':0},\n",
    "                                     'incorrect':{'num':0, 'uncertainty':0}}\n",
    "\n",
    "        self.uncertainty_stats = {'epoch_{}'.format(epoch):{'used_attributes':[],'sigmas':[], 'num_attrs_discarded':0} for epoch in range(num_epochs+2)}\n",
    "        self.mean_attr_accs = []\n",
    "        self.mean_drop_ratio = []\n",
    "        self.mean_sigmas = []\n",
    "        ############\n",
    "\n",
    "    def train(self):\n",
    "        self.model.phase = 'train'\n",
    "        self.train_model(self.dataloaders['train'])\n",
    "\n",
    "    def test(self):\n",
    "        self.model.phase = 'test'\n",
    "        self.test_model(self.dataloaders['test'], 'test', None, hard=False) # was: hard=True\n",
    "        self.model.phase = 'train'\n",
    "#         return self.model.label_stats, self.model.selection_stats\n",
    "\n",
    "    def topk_correct(self, output, target, topk=(1,)):\n",
    "        maxk = max(topk)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        target_masks = []\n",
    "        target_cnt = []\n",
    "        for i in range(self.model.num_classes):\n",
    "            target_masks.append((target == i).unsqueeze(0))\n",
    "            target_cnt.append(target_masks[i].sum().item())\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = [(correct[:k] * tm).view(-1).float().sum(0, keepdim=True).item() for tm in target_masks]\n",
    "            res.append(np.array(correct_k))\n",
    "        return res, np.array(target_cnt)\n",
    "\n",
    "    def log_stats(self, phase, epoch, epoch_stats, hist_stats,\n",
    "                  unique_attr_stats, attr_acc):\n",
    "        for k in range(len(epoch_stats[0])):\n",
    "        # for k in range(1):\n",
    "\n",
    "            self.logger.add_scalar('Top1Accuracy{}/{}'.format(k+1, phase), epoch_stats[0][k], epoch)\n",
    "            # self.logger.add_scalar('Top5Accuracy{}/{}'.format(k+1, phase), epoch_stats[1][k], epoch)\n",
    "            # self.logger.add_scalar('Top1MeanClassAccuracy{}/{}'.format(k+1, phase), epoch_stats[3][k], epoch)\n",
    "            # self.logger.add_scalar('Top5MeanClassAccuracy{}/{}'.format(k+1, phase), epoch_stats[4][k], epoch)\n",
    "            # if unique_attr_stats is not None:\n",
    "            #     self.logger.add_scalar('UniqueAttributes{}/{}'.format(k+1, phase), unique_attr_stats[k], epoch)\n",
    "            # if attr_acc is not None:\n",
    "            #     self.logger.add_scalar('AttributeAccuracy{}/{}'.format(k+1, phase), attr_acc[k], epoch)\n",
    "        self.logger.add_scalar('Loss/'+phase, epoch_stats[2], epoch)\n",
    "\n",
    "        if hist_stats is not None:\n",
    "            for name, data in hist_stats.items():\n",
    "                data = torch.cat(data, dim=0).flatten()\n",
    "                if name.startswith('SelectionHard'):\n",
    "                    bins = self.model.attribute_size\n",
    "                elif name.startswith('AttributesHard'):\n",
    "                    bins = self.model.decision_size\n",
    "                else:\n",
    "                    bins = 'tensorflow'\n",
    "                self.logger.add_histogram(name, data, epoch, bins=bins)\n",
    "\n",
    "    def test_model(self, data_loader, phase, epoch, hard=False):\n",
    "        # Test the Model\n",
    "        self.model.eval()  # Change model to 'eval' mode (BN uses moving mean/var).\n",
    "        n_stats = self.model.max_iters if hasattr(self.model, 'max_iters') else 1\n",
    "        correct_1 = np.zeros((n_stats, self.model.num_classes))\n",
    "        correct_5 = np.zeros((n_stats, self.model.num_classes))\n",
    "        total = 0\n",
    "        total_cnt = np.zeros((1, self.model.num_classes))\n",
    "        total_loss = 0\n",
    "\n",
    "        if isinstance(self.model, OC):\n",
    "            self.model.reset_stats()\n",
    "            if hard:\n",
    "                self.model.init_tree_stats()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for idx, data in enumerate(data_loader):\n",
    "                if len(data) == 2:\n",
    "                    images, labels = data\n",
    "                    attributes = None\n",
    "                else:\n",
    "                    images, labels, attributes = data\n",
    "                    #attributes = attributes.to(self.device)\n",
    "                images = images.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                \n",
    "                classification, loss = self.model(images, labels, hard)\n",
    "                #####################################\n",
    "#                 print(labels.size())\n",
    "#                 print(labels[0].item())\n",
    "                #####################################\n",
    "\n",
    "                # Collect stats\n",
    "                total_loss += loss.item()\n",
    "                total += labels.size(0)\n",
    "                for k in range(len(classification)):\n",
    "                    ######################\n",
    "                    # print(classification[k].data)\n",
    "                    # print(labels[k])\n",
    "                    # print()\n",
    "                    # print(classification[k].data.size())\n",
    "                    # print(labels.size())\n",
    "                    # print()\n",
    "                    # values, indices = torch.max(classification[k], -1)\n",
    "                    # for i in range(classification[k].size(0)):\n",
    "\n",
    "                        # print(indices[i].item(),labels[i].item())\n",
    "                        # if indices[i].item()==labels[i].item():\n",
    "                        #     self.classifications_dict['correct']+=1\n",
    "                        # if indices[i].item()!=labels[i].item():\n",
    "                        #     self.classifications_dict['incorrect']+=1              \n",
    "          \n",
    "                    ######################\n",
    "                    ctopk, target_cnt = self.topk_correct(classification[k].data, labels, (1, 5))\n",
    "                    c1, c5 = ctopk\n",
    "                    # print(target_cnt)\n",
    "                    correct_1[k] += c1\n",
    "                    correct_5[k] += c5\n",
    "                total_cnt[0] += target_cnt\n",
    "\n",
    "                \n",
    "     \n",
    "        stats = [correct_1.sum(axis=1) / total, correct_5.sum(axis=1) / total, total_loss / total, (correct_1 / total_cnt).mean(axis=1), (correct_5 / total_cnt).mean(axis=1)]\n",
    "        print('Accuracy ({}), Top1: {:.2%}, Top5: {:.2%}'.format(phase, stats[0][-1], stats[1][-1]))\n",
    "        self.model.train()  # Change model to 'train' mode\n",
    "\n",
    "        unique_attr_stats = None\n",
    "        attr_acc = None\n",
    "        if epoch is not None:\n",
    "            if isinstance(self.model, OC):\n",
    "                hist_stats = self.model.get_hist_stats()\n",
    "                unique_attr_stats = self.model.get_unique_attributes()\n",
    "                if self.model.attribute_coef > 0.:\n",
    "                    attr_acc = self.model.get_attr_acc(total)\n",
    "                else:\n",
    "                    attr_acc = None\n",
    "            else:\n",
    "                hist_stats = None\n",
    "            self.log_stats(phase, epoch, stats, hist_stats, unique_attr_stats, attr_acc)\n",
    "\n",
    "        return stats[0][-1], stats, unique_attr_stats, attr_acc\n",
    "\n",
    "    def train_model(self, data_laoder):\n",
    "        max_accuracy = 0\n",
    "        max_agg_accuracy = 0\n",
    "        max_ma_accuracy = 0\n",
    "        max_ma_agg_accuracy = 0\n",
    "\n",
    "        if isinstance(self.model, OC):\n",
    "            self.model.reset_stats()\n",
    "\n",
    "        # Train the Model       \n",
    "        for epoch in range(self.num_epochs):\n",
    "            #self.model.set_tau(epoch)\n",
    "            optimizer = self.model.get_optimizer()\n",
    "            n_stats = self.model.max_iters if hasattr(self.model, 'max_iters') else 1\n",
    "            correct_1 = np.zeros((n_stats, self.model.num_classes))\n",
    "            correct_5 = np.zeros((n_stats, self.model.num_classes))\n",
    "            total = 0\n",
    "            total_cnt = np.zeros((1, self.model.num_classes))\n",
    "            total_loss = 0\n",
    "\n",
    "            for i, data in enumerate(data_laoder):\n",
    "                \n",
    "                if len(data) == 2:\n",
    "                    images, labels = data\n",
    "                    attributes = None\n",
    "                else:\n",
    "                    images, labels, attributes = data\n",
    "                    #attributes = attributes.to(self.device)\n",
    "                images = images.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                classification, loss = self.model(images, labels)\n",
    "                \n",
    "\n",
    "                if loss.grad_fn is not None:\n",
    "                \n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # Collect stats\n",
    "                total_loss += loss.item()\n",
    "                total += labels.size(0)\n",
    "                for k in range(len(classification)):\n",
    "                    ctopk, target_cnt = self.topk_correct(classification[k].data, labels, (1, 5))\n",
    "                    c1, c5 = ctopk\n",
    "                    correct_1[k] += c1\n",
    "                    correct_5[k] += c5\n",
    "                total_cnt[0] += target_cnt\n",
    "\n",
    "                if (i+1) % self.log_freq == 0:\n",
    "                    print('Epoch [{}/{}], Iter [{}/{}] Loss: {:.4f}'\n",
    "                            .format(epoch+1, self.num_epochs, i+1, len(data_laoder)//images.size(0),\n",
    "                                    loss.item()))\n",
    "                    ##### TODO remove workaround and use tensurboard\n",
    "                    # self.stats_dict[configuration]['losses'].append(loss.item())\n",
    "            \n",
    "        # with open(data_path + '/logs/' + 'stats_dict.json', 'w') as json_file:\n",
    "        #     json.dump(self.stats_dict, json_file)\n",
    "        #     print('stats dict saved...')\n",
    "                    #############################################\n",
    "\n",
    "            self.model.get_scheduler().step()\n",
    "            # if isinstance(self.model, NeuralDecisionForest) or isinstance(self.model, OC):\n",
    "            #     self.model.toggle_update_schedule()\n",
    "\n",
    "            stats = [correct_1.sum(axis=1) / total, correct_5.sum(axis=1) / total, total_loss / total, (correct_1 / total_cnt).mean(axis=1), (correct_5 / total_cnt).mean(axis=1)]\n",
    "\n",
    "            if isinstance(self.model, OC):\n",
    "                hist_stats = self.model.get_hist_stats()\n",
    "                unique_attr_stats = self.model.get_unique_attributes()\n",
    "                if self.model.attribute_coef > 0.:\n",
    "                    attr_acc = self.model.get_attr_acc(total)\n",
    "                else:\n",
    "                    attr_acc = None\n",
    "            else:\n",
    "                hist_stats = None\n",
    "                unique_attr_stats = None\n",
    "                attr_acc = None\n",
    "            self.log_stats('train', epoch, stats, hist_stats, unique_attr_stats, attr_acc)\n",
    "            print('Accuracy (train), Top1: {:.2%}, Top5: {:.2%}'.format(stats[0][-1], stats[1][-1]))\n",
    "            self.model.phase = 'test'\n",
    "            val_accuracy, val_stats, _, _ = self.test_model(self.dataloaders['val'],\n",
    "                                                            'val', epoch+1)\n",
    "            val_agg_accuracy = val_stats[0].sum()\n",
    "            val_ma_accuracy = val_stats[3][-1]\n",
    "            val_ma_agg_accuracy = val_stats[3].sum()\n",
    "\n",
    "            # reset model stats\n",
    "            model.sigmas_list = []\n",
    "            model.labels_list = []\n",
    "            model.used_attributes_list = []\n",
    "            model.attribute_accuracies = []\n",
    "            model.drop_ratios = []\n",
    "#             self.model.phase = 'test'\n",
    "            _, test_stats, unique_attr_stats, attr_acc = self.test_model(self.dataloaders['test'], 'test', epoch+1)\n",
    "            \n",
    "#             if model.drop_ratios[0].size(0) == 64:\n",
    "            self.mean_drop_ratio.append(sum(model.drop_ratios)/(len(model.drop_ratios)+1))\n",
    "            mean_attribute_accuracy = sum(model.attribute_accuracies)/(len(model.attribute_accuracies)+1)\n",
    "            self.mean_sigmas.append(sum(model.mean_sigmas)/(len(model.mean_sigmas)+1))\n",
    "            self.mean_attr_accs.append(mean_attribute_accuracy)\n",
    "#             print(mean_attribute_accuracy)\n",
    "#             print()\n",
    "            # # collect uncertainty stats\n",
    "            # self.uncertainty_stats['epoch_{}'.format(epoch)]['used_attributes']=self.model.used_attributes_list\n",
    "            # self.model.used_attributes_list = []\n",
    "            # self.uncertainty_stats['epoch_{}'.format(epoch)]['sigmas']=self.model.sigmas_list\n",
    "            # self.model.sigmas_list = []           \n",
    "            \n",
    "            \n",
    "            \n",
    "            self.model.phase = 'train'\n",
    "            if val_accuracy > max_accuracy:\n",
    "                max_accuracy = val_accuracy\n",
    "#                 self.save_model('best', test_stats, 0, unique_attr_stats, attr_acc, epoch)\n",
    "            if val_ma_accuracy > max_ma_accuracy:\n",
    "                max_ma_accuracy = val_ma_accuracy\n",
    "#                 self.save_model('best_ma', test_stats, 3, unique_attr_stats, attr_acc, epoch)\n",
    "            if val_agg_accuracy > max_agg_accuracy and isinstance(self.model, OC):\n",
    "                max_agg_accuracy = val_agg_accuracy\n",
    "                self.save_model('best_agg', test_stats, 0, unique_attr_stats, attr_acc, epoch)\n",
    "            if val_ma_agg_accuracy > max_ma_agg_accuracy and isinstance(self.model, OC):\n",
    "                max_ma_agg_accuracy = val_ma_agg_accuracy\n",
    "#                 self.save_model('best_ma_agg', test_stats, 3, unique_attr_stats, attr_acc, epoch)\n",
    "\n",
    "            self.save_model('latest', test_stats, 0, unique_attr_stats, attr_acc, epoch)\n",
    "        # with open(data_path + '/logs/' + 'stats_dict.json', 'w') as json_file:\n",
    "        #     json.dump(self.stats_dict, json_file)\n",
    "        #     print('stats dict saved...')\n",
    "\n",
    "\n",
    "    def write_stats_file(self, stats_list, name, epoch, is_float=True):\n",
    "        fstr = '{:.2f}' if is_float else '{}'\n",
    "        with open(os.path.join(self.log_path, '{}.txt'.format(name)), 'a') as f:\n",
    "            acc_str = [fstr.format(100*c1 if is_float else c1) for c1 in stats_list]\n",
    "            f.write('{} '.format(epoch) + ' '.join(acc_str))\n",
    "            f.write('\\n')\n",
    "\n",
    "    def save_model(self, name, test_stats, stats_idx, unique_attr_stats, attr_acc, epoch):\n",
    "        torch.save(self.model.state_dict(),\n",
    "                   os.path.join(self.log_path, '{}.pth'.format(name)))\n",
    "        \n",
    "        # save state dict for vision model separately\n",
    "        torch.save(self.model.cnn.state_dict(), os.path.join(self.log_path, '{}_vision_model.pth'.format(name)))\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.write_stats_file(test_stats[stats_idx], name, epoch)\n",
    "\n",
    "        # if isinstance(self.model, NeuralDecisionForest):\n",
    "        #     _, test_stats_hard, _, _ = self.test_model(self.dataloaders['test'],\n",
    "        #                                                'test', epoch+1, hard=True)\n",
    "        #     self.write_stats_file(test_stats_hard[stats_idx], name+'_hard', epoch)\n",
    "\n",
    "        if unique_attr_stats is not None:\n",
    "            self.write_stats_file(unique_attr_stats, name+'_uniqattr', epoch,\n",
    "                                  is_float=False)\n",
    "\n",
    "        if attr_acc is not None:\n",
    "            self.write_stats_file(attr_acc, name+'_attracc', epoch)\n",
    "\n",
    "        if name != 'latest':\n",
    "            print('Saved {} model'.format(name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's instance our models..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the configuraion parameters of our dataset\n",
    "in_channels, cnn_out_size, log_freq = get_dataset_config(dataset, 'cnn', 40 )\n",
    "cnn_out_size = 2048\n",
    "\n",
    "# initiate the observer classifier model\n",
    "model = OC('xoc', len(classes), 'dropoutcnn', in_channels,\n",
    "            cnn_out_size, dataset, 2, 40, # 13 worked\n",
    "            attribute_size, attribute_mtx, attribute_coef,\n",
    "            hidden_size, tau_initial=5,\n",
    "            use_pretrained=False, shallow=False)\n",
    "\n",
    "# load pretrained resnet backbone\n",
    "model.cnn = models.resnet152(pretrained=False)\n",
    "model.cnn.fc = nn.Linear(model.cnn.fc.in_features, torch.load('/home/swezel/projects/urdtc/pretrained/cub_resnet152.pkl')['fc.weight'].size(0))\n",
    "model.cnn.load_state_dict(torch.load('/home/swezel/projects/urdtc/pretrained/cub_resnet152.pkl'))\n",
    "# model.cnn.fc = nn.Linear(model.cnn.fc.in_features, torch.load('/home/swezel/projects/urdtc/pretrained/{}_resnet152.pkl'.format(dataset))['fc.weight'].size(0))\n",
    "# model.cnn.load_state_dict(torch.load('/home/swezel/projects/urdtc/pretrained/{}_resnet152.pkl'.format(dataset)))\n",
    "\n",
    "\n",
    "model.cnn.fc = nn.Identity()\n",
    "\n",
    "# set attribute head\n",
    "model.binary_features = nn.Sequential(nn.BatchNorm1d(cnn_out_size),\n",
    "                                        nn.Linear(cnn_out_size, hidden_size),\n",
    "                                        nn.ReLU(inplace=True),\n",
    "                                        nn.BatchNorm1d(hidden_size),\n",
    "                                        nn.Dropout(0.5, inplace=False), # dropout after batchnorm\n",
    "                                        nn.Linear(hidden_size, hidden_size),\n",
    "                                        nn.ReLU(inplace=True),\n",
    "                                        nn.BatchNorm1d(hidden_size),\n",
    "                                        nn.Dropout(0.5, inplace=False),\n",
    "                                        nn.Linear(hidden_size, attribute_size * 2))\n",
    "\n",
    "model.binary_features.tau = nn.Parameter(torch.tensor([5], dtype=torch.float), requires_grad=True)\n",
    "model.to(device);\n",
    "\n",
    "# freeze resnet backbone for faster training but make all other weights trainable\n",
    "for param in model.lstm.parameters():\n",
    "    param.requires_grad=True\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad=True\n",
    "for param in model.feature_selection.parameters():\n",
    "    param.requires_grad=True\n",
    "for param in model.binary_features.parameters():\n",
    "    param.requires_grad=True\n",
    "for param in model.pre_lstm.parameters():\n",
    "    param.requires_grad=True\n",
    "    \n",
    "for param in model.cnn.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.cnn.fc.parameters():\n",
    "    param.requires_grad=True\n",
    "    \n",
    "# initiate optimizers\n",
    "tree_params, cnn_params = model.get_param_groups()\n",
    "tree_optimizer = torch.optim.Adam(tree_params, lr = learning_rate, weight_decay=weight_decay)\n",
    "cnn_optimizer = torch.optim.Adam(cnn_params, lr = learning_rate, weight_decay=weight_decay)\n",
    "optimizer = [tree_optimizer, cnn_optimizer]\n",
    "# and schedulers\n",
    "tree_scheduler = torch.optim.lr_scheduler.StepLR(tree_optimizer, step_size=step_size, gamma=0.1)\n",
    "cnn_scheduler = torch.optim.lr_scheduler.StepLR(cnn_optimizer, step_size=step_size, gamma=0.1)\n",
    "scheduler = [tree_scheduler, cnn_scheduler]\n",
    "\n",
    "model.set_optimizer(optimizer)\n",
    "# model.init_tree_stats()\n",
    "model.set_scheduler(scheduler)\n",
    "##h\n",
    "# model.strategy = 'randRDTC'\n",
    "model.strategy = 'remRDTC'\n",
    "# model.strategy = 'extRDTC'\n",
    "##hook\n",
    "# model.strategy = 'aRDTC'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and finally train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# trainer = Trainer(model, dataloaders, 1, device, log_freq, data_path + '/../log/')\n",
    "# torch.cuda.empty_cache()\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(trainer.mean_attr_accs)\n",
    "# print()\n",
    "# print(trainer.mean_drop_ratio)\n",
    "# print()\n",
    "# print(trainer.mean_sigmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect a Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (test), Top1: 39.83%, Top5: 47.35%\n"
     ]
    }
   ],
   "source": [
    "in_channels, cnn_out_size, log_freq = get_dataset_config(dataset, 'cnn', 40 )\n",
    "# cnn_out_size=2048\n",
    "model.load_state_dict(torch.load(data_path + '/../log/zero_shot_remRDTC_best_agg.pth'))#,  map_location=lambda storage, loc: storage)\n",
    "model.cnn.load_state_dict(torch.load(data_path + '/../log/zero_shot_remRDTC_best_agg_vision_model.pth'))\n",
    "# model.train()\n",
    "# model.eval()\n",
    "# print(model.n_possible_states)\n",
    "trainer = Trainer(model, dataloaders, 1, device, log_freq, data_path + '/../log/')\n",
    "# model.reset_stats()\n",
    "# model.init_tree_stats()\n",
    "trainer.test();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # choose example\n",
    "# batch_index = 11\n",
    "# within_batch_index = 0\n",
    "\n",
    "# # get last 5 attrs used of example\n",
    "# last_5 = model.used_attributes_list[batch_index][within_batch_index][-5:]\n",
    "\n",
    "\n",
    "# # get the models answer and classification for those last 5 examples\n",
    "# final_top3 = torch.topk(model.classifications_list[0][-1][within_batch_index],3)\n",
    "\n",
    "# class_probs = []\n",
    "\n",
    "# for attr_index, attr in enumerate(last_5):\n",
    "#     print(attribute_name_dict[str(attr.item())])\n",
    "#     answer = model.binary_features_list[batch_index][within_batch_index][attr.item()]\n",
    "#     print(answer.tolist())\n",
    "#     top3 = torch.topk(model.classifications_list[batch_index][-(5-(attr_index))][within_batch_index],3)\n",
    "#     classes = top3.indices.tolist()\n",
    "#     print(classes)\n",
    "#     class_logits = top3.values.tolist()\n",
    "#     class_probs.append(torch.softmax(top3.values,dim=0).tolist())\n",
    "# #     print(class_probs)\n",
    "#     print()\n",
    "    \n",
    "# print(model.labels_list[batch_index][within_batch_index])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set_style('darkgrid')\n",
    "# import matplotlib \n",
    "# matplotlib.rc('xtick', labelsize=20) \n",
    "\n",
    "# for i, class_prob in enumerate(class_probs):\n",
    "#     plt.bar(x = ['Olive_sided_Flycatcher','Western_Wood_Pewee','Sayornis'], height=np.array(class_prob), color='#EAD296')\n",
    "#     plt.xticks(rotation=45)\n",
    "#     plt.savefig(figure_path + 'class_probs_{}.svg'.format(i),bbox_inches='tight')\n",
    "\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect behaviour on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_sigmas = []\n",
    "unseen_sigmas = []\n",
    "\n",
    "for batch_index in range(len(model.labels_list)):\n",
    "    for inner_batch_index in range(model.labels_list[batch_index].size(0)):\n",
    "        class_label = model.labels_list[batch_index][inner_batch_index].item()\n",
    "        used_attrs = model.used_attributes_list[batch_index][inner_batch_index]\n",
    "#         for attr_index in range(312):\n",
    "#             if attr_index in used_attrs:\n",
    "#                 if class_label < 151:\n",
    "#                     seen_sigmas.append(model.sigmas_list[batch_index][inner_batch_index][attr_index].median().item())\n",
    "        if class_label < 151:\n",
    "            \n",
    "\n",
    "    #         if class_label not in [11,18,19,25,26,28,30,31,32,41,74,75,98,113,138,139,161,177,180,182,183,192,199,177]:\n",
    "            seen_sigmas.append(model.sigmas_list[batch_index][inner_batch_index].median().item())\n",
    "#                 else:\n",
    "#                     unseen_sigmas.append(model.sigmas_list[batch_index][inner_batch_index][attr_index].median().item())\n",
    "        else:            \n",
    "            unseen_sigmas.append(model.sigmas_list[batch_index][inner_batch_index].median().item())\n",
    "\n",
    "            \n",
    "\n",
    "# plt.savefig(figure_path + 'zero_shot_class_uncertainty.pdf',bbox_inches='tight')\n",
    "# print(np.max(unseen_sigmas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2965\n",
      "2915\n",
      "[]\n",
      "\n",
      "[]\n",
      "\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cell 3\n",
    "# plt.hist(unseen_sigmas)\n",
    "# plt.hist(seen_sigmas)\n",
    "# plt.hist(unseen_sigmas_means)\n",
    "# plt.hist(seen_sigmas_means)\n",
    "print(len(seen_sigmas))\n",
    "print(len(unseen_sigmas))\n",
    "\n",
    "new_seen_sigmas = [sigma for sigma in seen_sigmas if sigma>0.0000001]\n",
    "new_unseen_sigmas = [sigma for sigma in unseen_sigmas if sigma>0.0000001]\n",
    "# plt.hist(np.array(unseen_sigmas_means),\n",
    "#          bins = np.arange(0.0, 0.005, 0.001),\n",
    "#          color='#AC454A',\n",
    "#          density=True,\n",
    "#          label='unseen',\n",
    "#          weights=np.ones_like(np.array(unseen_sigmas_means)))\n",
    "\n",
    "# plt.hist(np.array(seen_sigmas_means),\n",
    "# #          bins = np.arange(0.075, 0.15, 0.0025),\n",
    "#          bins = np.arange(0.0, 0.005, 0.001),\n",
    "#          color='#F67941',\n",
    "#          density=True,\n",
    "#          label='seen',\n",
    "#          alpha=0.7\n",
    "#         )\n",
    "\n",
    "# sns.set(rc={'figure.figsize':(12,10)})\n",
    "\n",
    "plt.hist([np.array(new_unseen_sigmas), np.array(new_seen_sigmas)],\n",
    "#          bins = np.arange(0.001, 0.005, 0.001),\n",
    "         color=['#AC454A','#F67941'],\n",
    "#          density=[True, True],\n",
    "         label=['unseen', 'seen'],\n",
    "#          weights=[np.ones_like(np.array(unseen_sigmas_means)),np.ones_like(np.array(unseen_sigmas_means))]\n",
    "        )\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(figure_path + 'zero_shot_class_uncertainty_hist_medians.pdf',bbox_inches='tight')\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "\n",
    "print(trainer.mean_attr_accs)\n",
    "print()\n",
    "print(trainer.mean_drop_ratio)\n",
    "print()\n",
    "print(trainer.mean_sigmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seen:\n",
      "1.1984834560917151e-05\n",
      "3.203137079575941e-05\n",
      "\n",
      "unseen:\n",
      "1.4105648167035975e-05\n",
      "3.3919941245386426e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f119037bc70>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seen_sigmas = np.array(seen_sigmas)\n",
    "unseen_sigmas = np.array(unseen_sigmas)\n",
    "print('seen:')\n",
    "print(seen_sigmas.mean())\n",
    "print(seen_sigmas.std())\n",
    "print('\\nunseen:')\n",
    "print(unseen_sigmas.mean())\n",
    "print(unseen_sigmas.std())\n",
    "# for plotting\n",
    "sns.set_style('darkgrid')\n",
    "x_min = np.concatenate((seen_sigmas, unseen_sigmas)).min()\n",
    "x_max = np.concatenate((seen_sigmas, unseen_sigmas)).max()\n",
    "x = np.linspace(0.00001, x_max, 100)\n",
    "y_seen = scipy.stats.expon.pdf(x,seen_sigmas.mean(),seen_sigmas.std())\n",
    "y_unseen = scipy.stats.expon.pdf(x,unseen_sigmas.mean(), unseen_sigmas.std())\n",
    "plt.plot(x,y_unseen, color='#AC454A', label = 'unseen')\n",
    "# plt.fill_between(x, y_unseen,color='#AC454A', alpha=0.66)\n",
    "plt.plot(x,y_seen, color='#F67941', label = 'seen')\n",
    "# plt.fill_between(x, y_seen,color='#F67941', alpha=0.66)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_channels, cnn_out_size, log_freq = get_dataset_config(dataset, 'cnn', 40 )\n",
    "# # cnn_out_size=2048\n",
    "# model.load_state_dict(torch.load(data_path + '/../log/best_agg.pth'))#,  map_location=lambda storage, loc: storage)\n",
    "# model.cnn.load_state_dict(torch.load(data_path + '/../log/best_agg_vision_model.pth'))\n",
    "# # model.train()\n",
    "# # model.eval()\n",
    "# # print(model.n_possible_states)\n",
    "# trainer = Trainer(model, dataloaders, 3, device, log_freq, data_path + '/../log/')\n",
    "# # model.reset_stats()\n",
    "# # model.init_tree_stats()\n",
    "# trainer.test();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accumulated_error = torch.zeros(312, device=device)\n",
    "# accumulated_sigmas = torch.zeros(312, device=device)\n",
    "# accumulated_usage = torch.zeros(312, device=device)\n",
    "# num_batches = len(model.binary_features_list)\n",
    "# batch_size = model.binary_features_list[0].size(0)\n",
    "\n",
    "\n",
    "# for batch_index in range(num_batches):\n",
    "#     if model.binary_features_list[batch_index].size(0)==64:\n",
    "\n",
    "#         # iterate over single batch\n",
    "#         for i in range(batch_size):\n",
    "#             predicted_attributes = model.binary_features_list[batch_index][i].T[0]  \n",
    "#             class_label = model.labels_list[batch_index][i].item()\n",
    "#             ground_truth_attributes = attribute_mtx[class_label]\n",
    "\n",
    "#             diff = (ground_truth_attributes - predicted_attributes)**2\n",
    "#             accumulated_error += diff\n",
    "\n",
    "#             accumulated_sigmas += sigmas[batch_index][i]#[:312]\n",
    "#             # print(model.used_attributes_list[batch_index][i])\n",
    "#             accumulated_usage += model.used_attributes_list[batch_index][i].cuda()\n",
    "# # for i in range(len(model.used_attributes_list)):\n",
    "# #     accumulated_usage += model.used_attributes_list[i][:312]\n",
    "\n",
    "\n",
    "\n",
    "# mean_accumulated_error = accumulated_error/(batch_size * num_batches)\n",
    "# mean_accumulated_sigmas = accumulated_sigmas/(batch_size * num_batches)\n",
    "# mean_accumulated_usage = accumulated_usage/(batch_size * num_batches)# (batch_size * num_batches)\n",
    "\n",
    "\n",
    "\n",
    "# # print(accumulated_error.mean(dim=-1).size())\n",
    "# error_and_sigma = torch.stack([mean_accumulated_error, mean_accumulated_sigmas, mean_accumulated_usage], dim=0)\n",
    "# d = {'misclassification\\nrate':error_and_sigma[0].cpu().numpy(), 'uncertainty':error_and_sigma[1].cpu().numpy(), 'usage':error_and_sigma[2].cpu().numpy()}\n",
    "# df = pd.DataFrame(d)\n",
    "# # df.head()\n",
    "# df_short = df.loc[df['usage']>0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.colors as clr\n",
    "# sns.set(rc={'figure.figsize':(15,1)})\n",
    "\n",
    "# # cmap = clr.LinearSegmentedColormap.from_list('custom blue', [\"#EAD296\", \"#F67941\", \"#AC454A\", \"#5A005B\", \"#4999F2\"], N=256)\n",
    "# cmap = clr.LinearSegmentedColormap.from_list('custom blue', [\"#EAD296\", \"#F67941\", \"#AC454A\"], N=256)\n",
    "\n",
    "# sns.heatmap(df_short.to_numpy().T, #annot=True,\n",
    "#             xticklabels=df.loc[df['usage']>0].index,\n",
    "#             yticklabels=['misclassification rate', 'uncertainty', 'usage'],\n",
    "#            cmap=cmap)#sns.color_palette(\"YlOrBr\"))\n",
    "# plt.xticks(rotation=90)\n",
    "# # plt.show()\n",
    "# # plt.savefig(figure_path + 'attr_heatmap_short.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sns.set(rc={'figure.figsize':(6,5)})\n",
    "# sns.heatmap(df_short.corr(), annot=True, center = 0.5, cmap=cmap)#sns.color_palette(\"icefire\"))\n",
    "# # plt.show()\n",
    "\n",
    "# # plt.savefig(figure_path + 'corr_matrix.pdf',bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.scatterplot(x='misclassification\\nrate', y='uncertainty',\n",
    "# #                 hue='usage',\n",
    "#                 size='usage',\n",
    "#                 legend=False,\n",
    "#                 color='#AC454A',\n",
    "# #                 cmap=cmap,\n",
    "#                 linewidth=0,\n",
    "#                 data=df_short)\n",
    "\n",
    "\n",
    "# # sns.FacetGrid(df_short, row=\"error\", col=\"uncertainty\", hue=\"usage\")\n",
    "# # plt.legend()\n",
    "# # plt.show()\n",
    "\n",
    "# # plt.savefig(figure_path + 'error_sigma_corr_all.pdf',bbox_inches='tight')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
