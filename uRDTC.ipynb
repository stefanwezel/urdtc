{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "As we're luckily standing on the shoulders of giants, we can do some imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import imageio\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "Let's load and convert the data, so we can use it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = ['cifar10', 'mnist', 'cub', 'awa2',\n",
    "            'imagenetfeatures', 'apyfeatures', 'zero_shot_cub']\n",
    "# dataset = 'awa2'\n",
    "# dataset = 'cub'\n",
    "dataset = 'zero_shot_cub'\n",
    "\n",
    "data_path = '/home/swezel/projects/urdtc/data/'\n",
    "figure_path = data_path + '../thesis/images/'\n",
    "\n",
    "\n",
    "# attribute name lookup (first attr_id is 0) \n",
    "with open (data_path + 'cub/attributes.txt', 'r') as f:\n",
    "    attributes=f.readlines()\n",
    "attribute_name_dict = {str(int(attr.split(' ')[0])-1): attr.split(' ')[1] for attr in attributes}\n",
    "\n",
    "def get_dataset_config(dataset, cnn_type, max_iters):\n",
    "    input_channels = None\n",
    "    if dataset == 'mnist':\n",
    "        input_channels = 1\n",
    "        if cnn_type == 'cnn':\n",
    "            cnn_output_size = 4*4*100\n",
    "        elif cnn_type == 'resnet':\n",
    "            cnn_output_size = 512\n",
    "        elif cnn_type == 'shallowcnn':\n",
    "            cnn_output_size = 4*4*64\n",
    "        out_freq = 100\n",
    "        #assert max_iters > 4\n",
    "    elif dataset == 'cifar10':\n",
    "        input_channels = 3\n",
    "        if cnn_type == 'cnn':\n",
    "            cnn_output_size = 8*8*32\n",
    "        elif cnn_type == 'resnet' or cnn_type == 'resnet18':\n",
    "            cnn_output_size = 512\n",
    "        elif cnn_type == 'shallowcnn':\n",
    "            cnn_output_size = 4*4*64\n",
    "        out_freq = 100\n",
    "        #assert max_iters > 4\n",
    "    elif dataset == 'cub':\n",
    "        input_channels = 3\n",
    "        if cnn_type == 'cnn':\n",
    "            # cnn_output_size = 32*32*32\n",
    "            cnn_output_size = 280900 # the above does not work? Maybe because of dataloader issue?\n",
    "        elif cnn_type == 'resnet' or cnn_type == 'resnet152':\n",
    "            cnn_output_size = 2048\n",
    "        out_freq = 10\n",
    "    elif dataset == 'zero_shot_cub':\n",
    "        input_channels = 3\n",
    "        if cnn_type == 'cnn':\n",
    "            # cnn_output_size = 32*32*32\n",
    "            cnn_output_size = 280900 # the above does not work? Maybe because of dataloader issue?\n",
    "        elif cnn_type == 'resnet' or cnn_type == 'resnet152':\n",
    "            cnn_output_size = 2048\n",
    "        out_freq = 10\n",
    "        #assert max_iters > 8\n",
    "    elif dataset == 'awa2':\n",
    "        input_channels = 3\n",
    "        if cnn_type == 'cnn':\n",
    "#             cnn_output_size = 32*32*32  # TODO: check\n",
    "            cnn_output_size = 2048\n",
    "        elif cnn_type == 'resnet' or cnn_type == 'resnet152':\n",
    "            cnn_output_size = 2048\n",
    "        out_freq = 10\n",
    "        #assert max_iters > 6\n",
    "    elif dataset == 'imagenetfeatures':\n",
    "        cnn_output_size = 2048\n",
    "        out_freq = 100\n",
    "        #assert max_iters > 10\n",
    "    elif dataset == 'apyfeatures':\n",
    "        cnn_output_size = 2048\n",
    "        out_freq = 10\n",
    "        #assert max_iters > 5\n",
    "\n",
    "    return input_channels, cnn_output_size, out_freq\n",
    "\n",
    "class DataLoader(object):\n",
    "    def __init__(self, dataset='mnist'):\n",
    "        assert dataset in DATASETS\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def load_data(self, batch_size=100, num_workers=4, root='./data/'):\n",
    "\n",
    "        if self.dataset == 'mnist':\n",
    "            #transform_train = transforms.ToTensor()\n",
    "            #transform_test = transforms.ToTensor()\n",
    "            class AddGaussianNoise(object):\n",
    "                def __init__(self, mean=0., std=1.):\n",
    "                    self.std = std\n",
    "                    self.mean = mean\n",
    "\n",
    "                def __call__(self, tensor):\n",
    "                    output = tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "                    return output.clamp(0., 1.)\n",
    "\n",
    "                def __repr__(self):\n",
    "                    return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
    "\n",
    "            transform_train = transforms.Compose([\n",
    "               transforms.ToTensor(),\n",
    "               #AddGaussianNoise(0., 0.2)\n",
    "               #transforms.Normalize((0.1307,), (0.3081,))\n",
    "            ])\n",
    "            transform_test = transforms.Compose([\n",
    "               transforms.ToTensor(),\n",
    "               #AddGaussianNoise(0., 0.2)\n",
    "               #transforms.Normalize((0.1307,), (0.3081,))\n",
    "            ])\n",
    "            classes = [i for i in range(10)]\n",
    "            dataset_class = dsets.MNIST\n",
    "\n",
    "        elif self.dataset == 'cifar10':\n",
    "            transform_train = transforms.Compose([\n",
    "                transforms.RandomCrop(32, padding=4),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "            ])\n",
    "            transform_test = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "            ])\n",
    "            classes = ('plane', 'car', 'bird', 'cat',\n",
    "                       'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "            dataset_class = dsets.CIFAR10\n",
    "\n",
    "        elif self.dataset == 'cub':\n",
    "\n",
    "            transform_train = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                  transforms.RandomResizedCrop(224),\n",
    "                                                  transforms.RandomHorizontalFlip(),\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                                       std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "            transform_test = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                 transforms.Resize(224),\n",
    "                                                 transforms.CenterCrop(224),\n",
    "                                                 transforms.ToTensor(),\n",
    "                                                 transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                                      std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "            dataset_class = CUB\n",
    "            classes = list(range(200))\n",
    "\n",
    "        elif self.dataset == 'zero_shot_cub':\n",
    "\n",
    "            transform_train = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                  transforms.RandomResizedCrop(224),\n",
    "                                                  transforms.RandomHorizontalFlip(),\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                                       std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "            transform_test = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                 transforms.Resize(224),\n",
    "                                                 transforms.CenterCrop(224),\n",
    "                                                 transforms.ToTensor(),\n",
    "                                                 transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                                      std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "            dataset_class = ZeroShotCUB\n",
    "            classes = list(range(200))            \n",
    "            \n",
    "            \n",
    "\n",
    "        elif self.dataset == 'awa2':\n",
    "            transform_train = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                  transforms.RandomResizedCrop(224),\n",
    "                                                  transforms.RandomHorizontalFlip(),\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                                       std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "            transform_test = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                 transforms.Resize(224),\n",
    "                                                 transforms.CenterCrop(224),\n",
    "                                                 transforms.ToTensor(),\n",
    "                                                 transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                                      std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "            dataset_class = AWA2\n",
    "            classes = list(range(50))\n",
    "\n",
    "        elif self.dataset == 'apyfeatures':\n",
    "            transform_train = transforms.ToTensor()\n",
    "            transform_test = transforms.ToTensor()\n",
    "\n",
    "            dataset_class = APYFeatures\n",
    "            classes = list(range(32))\n",
    "\n",
    "        elif self.dataset == 'imagenetfeatures':\n",
    "            transform_train = transforms.ToTensor()\n",
    "            transform_test = transforms.ToTensor()\n",
    "\n",
    "            dataset_class = ImageNetFeatures\n",
    "            classes = list(range(1000))\n",
    "\n",
    "        train_dataset = dataset_class(root=root,\n",
    "                                      train=True,\n",
    "                                      transform=transform_train,\n",
    "                                      download=True)\n",
    "\n",
    "        test_dataset = dataset_class(root=root,\n",
    "                                     train=False,\n",
    "                                     transform=transform_test)\n",
    "\n",
    "        val_size = int(len(train_dataset) * 0.1)\n",
    "        train_size = len(train_dataset) - val_size\n",
    "\n",
    "        train_dataset, val_dataset = torch.utils.data.dataset.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   shuffle=True,\n",
    "                                                   num_workers=num_workers)\n",
    "\n",
    "        val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 shuffle=False,\n",
    "                                                 num_workers=num_workers)\n",
    "\n",
    "        test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  shuffle=False,\n",
    "                                                  num_workers=num_workers)\n",
    "\n",
    "        dataloaders = {'train': train_loader,\n",
    "                       'val': val_loader,\n",
    "                       'test': test_loader}\n",
    "\n",
    "        return dataloaders, classes\n",
    "\n",
    "class CUB(Dataset):\n",
    "    \"\"\"CUB200-2011 dataset.\"\"\"\n",
    "    attribute_file = 'attributes/class_attribute_labels_continuous.txt'\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, normalize=True,\n",
    "                 download=None):\n",
    "        self.root = os.path.join(root, 'cub')\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.data_dir = os.path.join(self.root, 'images')\n",
    "\n",
    "        train_test_split = pd.read_csv(os.path.join(self.root, 'train_test_split.txt'),\n",
    "                                       sep=' ', index_col=0, header=None)\n",
    "        if train:\n",
    "            is_train_image = 1\n",
    "        else:\n",
    "            is_train_image = 0\n",
    "        self.img_ids = train_test_split[train_test_split[1] == is_train_image].index.tolist()\n",
    "        self.id_to_img = pd.read_csv(os.path.join(self.root, 'images.txt'),\n",
    "                                     sep=' ', index_col=0, header=None)\n",
    "\n",
    "        raw_mtx = np.loadtxt(os.path.join(self.root,\n",
    "                                          self.attribute_file))\n",
    "        raw_mtx[raw_mtx == -1] = 0\n",
    "        raw_mtx = raw_mtx / raw_mtx.max()\n",
    "        self.attribute_mtx = torch.tensor(raw_mtx, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_ids[idx]\n",
    "        img_name = self.id_to_img[self.id_to_img.index == img_id].values[0][0]\n",
    "        img_path = os.path.join(self.data_dir, img_name)\n",
    "\n",
    "        img = imageio.imread(img_path, pilmode='RGB')\n",
    "        label = int(img_name[:3]) - 1\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label, img_path\n",
    "\n",
    "    \n",
    "class ZeroShotCUB(Dataset):\n",
    "    \"\"\"CUB200-2011 dataset.\"\"\"\n",
    "    attribute_file = 'attributes/class_attribute_labels_continuous.txt'\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, normalize=True,\n",
    "                 download=None):\n",
    "        self.root = os.path.join(root, 'cub')\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.data_dir = os.path.join(self.root, 'images')\n",
    "\n",
    "        train_test_split = pd.read_csv(os.path.join(self.root, 'zero_attr_train_test_split.txt'),\n",
    "                                       sep=' ', index_col=0, header=None)\n",
    "        if train:\n",
    "            is_train_image = 1\n",
    "        else:\n",
    "            is_train_image = 0\n",
    "        self.img_ids = train_test_split[train_test_split[1] == is_train_image].index.tolist()\n",
    "        self.id_to_img = pd.read_csv(os.path.join(self.root, 'images.txt'),\n",
    "                                     sep=' ', index_col=0, header=None)\n",
    "\n",
    "        raw_mtx = np.loadtxt(os.path.join(self.root,\n",
    "                                          self.attribute_file))\n",
    "        raw_mtx[raw_mtx == -1] = 0\n",
    "        raw_mtx = raw_mtx / raw_mtx.max()\n",
    "        self.attribute_mtx = torch.tensor(raw_mtx, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_ids[idx]\n",
    "        img_name = self.id_to_img[self.id_to_img.index == img_id].values[0][0]\n",
    "        img_path = os.path.join(self.data_dir, img_name)\n",
    "\n",
    "        img = imageio.imread(img_path, pilmode='RGB')\n",
    "        label = int(img_name[:3]) - 1\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label, img_path\n",
    "    \n",
    "    \n",
    "class AWA2(Dataset):\n",
    "    \"\"\"Animals with Attributes 2 dataset.\"\"\"\n",
    "    split_file = 'train_test_classification_split.txt'\n",
    "    data_dir = 'awa2'\n",
    "    attribute_file = 'predicate-matrix-continuous.txt'\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, normalize=True,\n",
    "                 download=None):\n",
    "        self.root = os.path.join(root, self.data_dir)\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "\n",
    "        meta_data = pd.read_csv(os.path.join(self.root,\n",
    "                                             self.split_file),\n",
    "                                sep=' ', index_col=0, header=None)\n",
    "        if train:\n",
    "            is_train_image = 1\n",
    "        else:\n",
    "            is_train_image = 0\n",
    "        self.img_ids = meta_data[meta_data[3] == is_train_image].index.tolist()\n",
    "        self.id_to_img = meta_data\n",
    "\n",
    "        raw_mtx = np.loadtxt(os.path.join(self.root,\n",
    "                                          self.attribute_file))\n",
    "        raw_mtx[raw_mtx == -1] = 0\n",
    "        raw_mtx = raw_mtx / raw_mtx.max()\n",
    "        self.attribute_mtx = torch.tensor(raw_mtx, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_ids[idx]\n",
    "        img_meta_data = self.id_to_img[self.id_to_img.index == img_id]\n",
    "        img_name = img_meta_data.values[0][0]\n",
    "        img_path = os.path.join(self.root, img_name)\n",
    "\n",
    "        img = imageio.imread(img_path, pilmode='RGB')\n",
    "        label = img_meta_data.values[0][1] - 1\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "# device = torch.device('cpu')\n",
    "\n",
    "# create dataloader objects for train, val and test\n",
    "dl = DataLoader(dataset=dataset)\n",
    "# dataloaders, classes = dl.load_data(4, 4, data_path)# 128 insted of \n",
    "dataloaders, classes = dl.load_data(64, 4, data_path)# 128 insted of \n",
    "\n",
    "# attributes (312 column vectors with 200 rows) -> each class can be described with 312 attributes\n",
    "# percentage of time, human annotator thought, the attribute was present\n",
    "attribute_mtx = dataloaders['train'].dataset.dataset.attribute_mtx\n",
    "\n",
    "# create binary encoding for class attributes\n",
    "attribute_mtx[attribute_mtx < 0.5] = 0.0\n",
    "attribute_mtx[attribute_mtx >= 0.5] = 1.0\n",
    "attribute_mtx = attribute_mtx.to(device) # cuda\n",
    "attribute_size = attribute_mtx.size(1) # number of available attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "18\n",
      "19\n",
      "25\n",
      "26\n",
      "41\n",
      "74\n",
      "75\n",
      "98\n",
      "113\n",
      "138\n",
      "139\n",
      "161\n",
      "180\n",
      "182\n",
      "183\n",
      "199\n",
      "\n",
      "183\n"
     ]
    }
   ],
   "source": [
    "# print(attribute_mtx[0])\n",
    "\n",
    "c = 0\n",
    "\n",
    "\n",
    "for class_id in range(attribute_mtx.size(0)):\n",
    "#     for attr_id in range(attribute_mtx.size(1)):\n",
    "#         print('...')\n",
    "#     attr_values = [attribute_mtx[class_id][x].item() for x in range(6)]\n",
    "#     if attr_values == [0.0 for x in range(6)]:\n",
    "        \n",
    "    if (attribute_mtx[class_id][308].item()==0) or (attribute_mtx[class_id][236].item()==0) or (attribute_mtx[class_id][235].item()==0.)or (attribute_mtx[class_id][145].item()==0.)or (attribute_mtx[class_id][151].item()==0.):\n",
    "\n",
    "#         print(class_id)\n",
    "        c+=1\n",
    "    else:\n",
    "        print(class_id)\n",
    "#     print(attr_values)\n",
    "#     if (attribute_mtx[class_id][3].item()==0) & (attribute_mtx[class_id][1].item()==0.) & (attribute_mtx[class_id][1].item()==0.):\n",
    "#         c += 1\n",
    "print()\n",
    "print(c)\n",
    "# print(attribute_mtx[82][40])\n",
    "\n",
    "#1\n",
    "#308\n",
    "# 101\n",
    "# 235\n",
    "# 145\n",
    "# 151"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.0\n",
      "\n",
      "1\n",
      "15.0\n",
      "\n",
      "2\n",
      "0.0\n",
      "\n",
      "3\n",
      "4.0\n",
      "\n",
      "4\n",
      "15.0\n",
      "\n",
      "5\n",
      "2.0\n",
      "\n",
      "6\n",
      "77.0\n",
      "\n",
      "7\n",
      "45.0\n",
      "\n",
      "8\n",
      "4.0\n",
      "\n",
      "9\n",
      "8.0\n",
      "\n",
      "10\n",
      "46.0\n",
      "\n",
      "11\n",
      "0.0\n",
      "\n",
      "12\n",
      "0.0\n",
      "\n",
      "13\n",
      "0.0\n",
      "\n",
      "14\n",
      "46.0\n",
      "\n",
      "15\n",
      "12.0\n",
      "\n",
      "16\n",
      "1.0\n",
      "\n",
      "17\n",
      "1.0\n",
      "\n",
      "18\n",
      "0.0\n",
      "\n",
      "19\n",
      "0.0\n",
      "\n",
      "20\n",
      "84.0\n",
      "\n",
      "21\n",
      "39.0\n",
      "\n",
      "22\n",
      "2.0\n",
      "\n",
      "23\n",
      "21.0\n",
      "\n",
      "24\n",
      "9.0\n",
      "\n",
      "25\n",
      "47.0\n",
      "\n",
      "26\n",
      "0.0\n",
      "\n",
      "27\n",
      "0.0\n",
      "\n",
      "28\n",
      "0.0\n",
      "\n",
      "29\n",
      "48.0\n",
      "\n",
      "30\n",
      "17.0\n",
      "\n",
      "31\n",
      "2.0\n",
      "\n",
      "32\n",
      "1.0\n",
      "\n",
      "33\n",
      "0.0\n",
      "\n",
      "34\n",
      "0.0\n",
      "\n",
      "35\n",
      "76.0\n",
      "\n",
      "36\n",
      "34.0\n",
      "\n",
      "37\n",
      "3.0\n",
      "\n",
      "38\n",
      "25.0\n",
      "\n",
      "39\n",
      "3.0\n",
      "\n",
      "40\n",
      "12.0\n",
      "\n",
      "41\n",
      "0.0\n",
      "\n",
      "42\n",
      "0.0\n",
      "\n",
      "43\n",
      "0.0\n",
      "\n",
      "44\n",
      "15.0\n",
      "\n",
      "45\n",
      "30.0\n",
      "\n",
      "46\n",
      "0.0\n",
      "\n",
      "47\n",
      "0.0\n",
      "\n",
      "48\n",
      "0.0\n",
      "\n",
      "49\n",
      "1.0\n",
      "\n",
      "50\n",
      "31.0\n",
      "\n",
      "51\n",
      "91.0\n",
      "\n",
      "52\n",
      "8.0\n",
      "\n",
      "53\n",
      "22.0\n",
      "\n",
      "54\n",
      "131.0\n",
      "\n",
      "55\n",
      "6.0\n",
      "\n",
      "56\n",
      "11.0\n",
      "\n",
      "57\n",
      "12.0\n",
      "\n",
      "58\n",
      "9.0\n",
      "\n",
      "59\n",
      "39.0\n",
      "\n",
      "60\n",
      "0.0\n",
      "\n",
      "61\n",
      "0.0\n",
      "\n",
      "62\n",
      "0.0\n",
      "\n",
      "63\n",
      "43.0\n",
      "\n",
      "64\n",
      "12.0\n",
      "\n",
      "65\n",
      "2.0\n",
      "\n",
      "66\n",
      "2.0\n",
      "\n",
      "67\n",
      "0.0\n",
      "\n",
      "68\n",
      "0.0\n",
      "\n",
      "69\n",
      "58.0\n",
      "\n",
      "70\n",
      "21.0\n",
      "\n",
      "71\n",
      "3.0\n",
      "\n",
      "72\n",
      "21.0\n",
      "\n",
      "73\n",
      "1.0\n",
      "\n",
      "74\n",
      "0.0\n",
      "\n",
      "75\n",
      "48.0\n",
      "\n",
      "76\n",
      "0.0\n",
      "\n",
      "77\n",
      "2.0\n",
      "\n",
      "78\n",
      "0.0\n",
      "\n",
      "79\n",
      "7.0\n",
      "\n",
      "80\n",
      "31.0\n",
      "\n",
      "81\n",
      "0.0\n",
      "\n",
      "82\n",
      "0.0\n",
      "\n",
      "83\n",
      "0.0\n",
      "\n",
      "84\n",
      "28.0\n",
      "\n",
      "85\n",
      "6.0\n",
      "\n",
      "86\n",
      "1.0\n",
      "\n",
      "87\n",
      "1.0\n",
      "\n",
      "88\n",
      "0.0\n",
      "\n",
      "89\n",
      "0.0\n",
      "\n",
      "90\n",
      "58.0\n",
      "\n",
      "91\n",
      "23.0\n",
      "\n",
      "92\n",
      "3.0\n",
      "\n",
      "93\n",
      "13.0\n",
      "\n",
      "94\n",
      "0.0\n",
      "\n",
      "95\n",
      "0.0\n",
      "\n",
      "96\n",
      "2.0\n",
      "\n",
      "97\n",
      "1.0\n",
      "\n",
      "98\n",
      "0.0\n",
      "\n",
      "99\n",
      "8.0\n",
      "\n",
      "100\n",
      "2.0\n",
      "\n",
      "101\n",
      "41.0\n",
      "\n",
      "102\n",
      "4.0\n",
      "\n",
      "103\n",
      "0.0\n",
      "\n",
      "104\n",
      "10.0\n",
      "\n",
      "105\n",
      "4.0\n",
      "\n",
      "106\n",
      "12.0\n",
      "\n",
      "107\n",
      "0.0\n",
      "\n",
      "108\n",
      "0.0\n",
      "\n",
      "109\n",
      "0.0\n",
      "\n",
      "110\n",
      "15.0\n",
      "\n",
      "111\n",
      "26.0\n",
      "\n",
      "112\n",
      "1.0\n",
      "\n",
      "113\n",
      "0.0\n",
      "\n",
      "114\n",
      "0.0\n",
      "\n",
      "115\n",
      "1.0\n",
      "\n",
      "116\n",
      "36.0\n",
      "\n",
      "117\n",
      "74.0\n",
      "\n",
      "118\n",
      "8.0\n",
      "\n",
      "119\n",
      "17.0\n",
      "\n",
      "120\n",
      "4.0\n",
      "\n",
      "121\n",
      "3.0\n",
      "\n",
      "122\n",
      "0.0\n",
      "\n",
      "123\n",
      "0.0\n",
      "\n",
      "124\n",
      "0.0\n",
      "\n",
      "125\n",
      "10.0\n",
      "\n",
      "126\n",
      "21.0\n",
      "\n",
      "127\n",
      "0.0\n",
      "\n",
      "128\n",
      "0.0\n",
      "\n",
      "129\n",
      "0.0\n",
      "\n",
      "130\n",
      "0.0\n",
      "\n",
      "131\n",
      "39.0\n",
      "\n",
      "132\n",
      "72.0\n",
      "\n",
      "133\n",
      "7.0\n",
      "\n",
      "134\n",
      "7.0\n",
      "\n",
      "135\n",
      "0.0\n",
      "\n",
      "136\n",
      "0.0\n",
      "\n",
      "137\n",
      "0.0\n",
      "\n",
      "138\n",
      "0.0\n",
      "\n",
      "139\n",
      "0.0\n",
      "\n",
      "140\n",
      "1.0\n",
      "\n",
      "141\n",
      "0.0\n",
      "\n",
      "142\n",
      "0.0\n",
      "\n",
      "143\n",
      "0.0\n",
      "\n",
      "144\n",
      "1.0\n",
      "\n",
      "145\n",
      "190.0\n",
      "\n",
      "146\n",
      "3.0\n",
      "\n",
      "147\n",
      "3.0\n",
      "\n",
      "148\n",
      "0.0\n",
      "\n",
      "149\n",
      "68.0\n",
      "\n",
      "150\n",
      "7.0\n",
      "\n",
      "151\n",
      "124.0\n",
      "\n",
      "152\n",
      "10.0\n",
      "\n",
      "153\n",
      "22.0\n",
      "\n",
      "154\n",
      "0.0\n",
      "\n",
      "155\n",
      "0.0\n",
      "\n",
      "156\n",
      "0.0\n",
      "\n",
      "157\n",
      "17.0\n",
      "\n",
      "158\n",
      "15.0\n",
      "\n",
      "159\n",
      "0.0\n",
      "\n",
      "160\n",
      "0.0\n",
      "\n",
      "161\n",
      "0.0\n",
      "\n",
      "162\n",
      "0.0\n",
      "\n",
      "163\n",
      "60.0\n",
      "\n",
      "164\n",
      "17.0\n",
      "\n",
      "165\n",
      "10.0\n",
      "\n",
      "166\n",
      "3.0\n",
      "\n",
      "167\n",
      "7.0\n",
      "\n",
      "168\n",
      "22.0\n",
      "\n",
      "169\n",
      "0.0\n",
      "\n",
      "170\n",
      "0.0\n",
      "\n",
      "171\n",
      "0.0\n",
      "\n",
      "172\n",
      "20.0\n",
      "\n",
      "173\n",
      "10.0\n",
      "\n",
      "174\n",
      "0.0\n",
      "\n",
      "175\n",
      "0.0\n",
      "\n",
      "176\n",
      "0.0\n",
      "\n",
      "177\n",
      "0.0\n",
      "\n",
      "178\n",
      "69.0\n",
      "\n",
      "179\n",
      "29.0\n",
      "\n",
      "180\n",
      "2.0\n",
      "\n",
      "181\n",
      "10.0\n",
      "\n",
      "182\n",
      "10.0\n",
      "\n",
      "183\n",
      "24.0\n",
      "\n",
      "184\n",
      "0.0\n",
      "\n",
      "185\n",
      "0.0\n",
      "\n",
      "186\n",
      "0.0\n",
      "\n",
      "187\n",
      "32.0\n",
      "\n",
      "188\n",
      "13.0\n",
      "\n",
      "189\n",
      "0.0\n",
      "\n",
      "190\n",
      "0.0\n",
      "\n",
      "191\n",
      "0.0\n",
      "\n",
      "192\n",
      "0.0\n",
      "\n",
      "193\n",
      "44.0\n",
      "\n",
      "194\n",
      "35.0\n",
      "\n",
      "195\n",
      "7.0\n",
      "\n",
      "196\n",
      "16.0\n",
      "\n",
      "197\n",
      "3.0\n",
      "\n",
      "198\n",
      "9.0\n",
      "\n",
      "199\n",
      "0.0\n",
      "\n",
      "200\n",
      "0.0\n",
      "\n",
      "201\n",
      "0.0\n",
      "\n",
      "202\n",
      "15.0\n",
      "\n",
      "203\n",
      "27.0\n",
      "\n",
      "204\n",
      "0.0\n",
      "\n",
      "205\n",
      "0.0\n",
      "\n",
      "206\n",
      "0.0\n",
      "\n",
      "207\n",
      "1.0\n",
      "\n",
      "208\n",
      "24.0\n",
      "\n",
      "209\n",
      "86.0\n",
      "\n",
      "210\n",
      "5.0\n",
      "\n",
      "211\n",
      "17.0\n",
      "\n",
      "212\n",
      "86.0\n",
      "\n",
      "213\n",
      "9.0\n",
      "\n",
      "214\n",
      "0.0\n",
      "\n",
      "215\n",
      "0.0\n",
      "\n",
      "216\n",
      "2.0\n",
      "\n",
      "217\n",
      "0.0\n",
      "\n",
      "218\n",
      "130.0\n",
      "\n",
      "219\n",
      "1.0\n",
      "\n",
      "220\n",
      "37.0\n",
      "\n",
      "221\n",
      "15.0\n",
      "\n",
      "222\n",
      "0.0\n",
      "\n",
      "223\n",
      "0.0\n",
      "\n",
      "224\n",
      "0.0\n",
      "\n",
      "225\n",
      "9.0\n",
      "\n",
      "226\n",
      "0.0\n",
      "\n",
      "227\n",
      "7.0\n",
      "\n",
      "228\n",
      "4.0\n",
      "\n",
      "229\n",
      "0.0\n",
      "\n",
      "230\n",
      "6.0\n",
      "\n",
      "231\n",
      "0.0\n",
      "\n",
      "232\n",
      "0.0\n",
      "\n",
      "233\n",
      "0.0\n",
      "\n",
      "234\n",
      "0.0\n",
      "\n",
      "235\n",
      "121.0\n",
      "\n",
      "236\n",
      "93.0\n",
      "\n",
      "237\n",
      "7.0\n",
      "\n",
      "238\n",
      "24.0\n",
      "\n",
      "239\n",
      "14.0\n",
      "\n",
      "240\n",
      "84.0\n",
      "\n",
      "241\n",
      "3.0\n",
      "\n",
      "242\n",
      "6.0\n",
      "\n",
      "243\n",
      "21.0\n",
      "\n",
      "244\n",
      "152.0\n",
      "\n",
      "245\n",
      "5.0\n",
      "\n",
      "246\n",
      "7.0\n",
      "\n",
      "247\n",
      "5.0\n",
      "\n",
      "248\n",
      "9.0\n",
      "\n",
      "249\n",
      "33.0\n",
      "\n",
      "250\n",
      "0.0\n",
      "\n",
      "251\n",
      "0.0\n",
      "\n",
      "252\n",
      "0.0\n",
      "\n",
      "253\n",
      "36.0\n",
      "\n",
      "254\n",
      "28.0\n",
      "\n",
      "255\n",
      "1.0\n",
      "\n",
      "256\n",
      "2.0\n",
      "\n",
      "257\n",
      "0.0\n",
      "\n",
      "258\n",
      "1.0\n",
      "\n",
      "259\n",
      "49.0\n",
      "\n",
      "260\n",
      "40.0\n",
      "\n",
      "261\n",
      "5.0\n",
      "\n",
      "262\n",
      "18.0\n",
      "\n",
      "263\n",
      "0.0\n",
      "\n",
      "264\n",
      "0.0\n",
      "\n",
      "265\n",
      "0.0\n",
      "\n",
      "266\n",
      "0.0\n",
      "\n",
      "267\n",
      "0.0\n",
      "\n",
      "268\n",
      "39.0\n",
      "\n",
      "269\n",
      "0.0\n",
      "\n",
      "270\n",
      "0.0\n",
      "\n",
      "271\n",
      "0.0\n",
      "\n",
      "272\n",
      "0.0\n",
      "\n",
      "273\n",
      "6.0\n",
      "\n",
      "274\n",
      "53.0\n",
      "\n",
      "275\n",
      "0.0\n",
      "\n",
      "276\n",
      "3.0\n",
      "\n",
      "277\n",
      "21.0\n",
      "\n",
      "278\n",
      "0.0\n",
      "\n",
      "279\n",
      "1.0\n",
      "\n",
      "280\n",
      "0.0\n",
      "\n",
      "281\n",
      "0.0\n",
      "\n",
      "282\n",
      "0.0\n",
      "\n",
      "283\n",
      "19.0\n",
      "\n",
      "284\n",
      "5.0\n",
      "\n",
      "285\n",
      "0.0\n",
      "\n",
      "286\n",
      "0.0\n",
      "\n",
      "287\n",
      "0.0\n",
      "\n",
      "288\n",
      "6.0\n",
      "\n",
      "289\n",
      "94.0\n",
      "\n",
      "290\n",
      "0.0\n",
      "\n",
      "291\n",
      "3.0\n",
      "\n",
      "292\n",
      "9.0\n",
      "\n",
      "293\n",
      "10.0\n",
      "\n",
      "294\n",
      "26.0\n",
      "\n",
      "295\n",
      "0.0\n",
      "\n",
      "296\n",
      "0.0\n",
      "\n",
      "297\n",
      "0.0\n",
      "\n",
      "298\n",
      "20.0\n",
      "\n",
      "299\n",
      "11.0\n",
      "\n",
      "300\n",
      "0.0\n",
      "\n",
      "301\n",
      "0.0\n",
      "\n",
      "302\n",
      "0.0\n",
      "\n",
      "303\n",
      "0.0\n",
      "\n",
      "304\n",
      "65.0\n",
      "\n",
      "305\n",
      "16.0\n",
      "\n",
      "306\n",
      "9.0\n",
      "\n",
      "307\n",
      "4.0\n",
      "\n",
      "308\n",
      "58.0\n",
      "\n",
      "309\n",
      "9.0\n",
      "\n",
      "310\n",
      "31.0\n",
      "\n",
      "311\n",
      "43.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for i in range(312):\n",
    "#     print(i)\n",
    "#     print(attribute_mtx[:,i].sum(dim=0).item())\n",
    "#     print()\n",
    "# # print(attribute_mtx.sum(dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Models\n",
    "Here, we continue by defining the various models that our uRDTC consists of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Conv2d(in_channels, 20, kernel_size=3, stride=1),\n",
    "                                 nn.ReLU(True),\n",
    "                                 nn.BatchNorm2d(20),\n",
    "                                 nn.Conv2d(20, 50, kernel_size=5, stride=2),\n",
    "                                 nn.ReLU(True),\n",
    "                                 nn.BatchNorm2d(50),\n",
    "                                 nn.Conv2d(50, 100, kernel_size=5, stride=2),\n",
    "                                 nn.ReLU(True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class DropoutCNN(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 20, kernel_size=3, stride=1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, kernel_size=5, stride=2)\n",
    "        self.conv3 = nn.Conv2d(50, 100, kernel_size=5, stride=2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.dropout2d(F.relu(self.conv1(x)), 0.2)\n",
    "        x = F.dropout2d(F.relu(self.conv2(x)), 0.2)\n",
    "        x = F.dropout2d(F.relu(self.conv3(x)), 0.2)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def get_cnn(in_channels, type='cnn', pretrained_cnn_weights=None,\n",
    "            freeze_weights=False, default_pretrained=False):\n",
    "    TYPES = ['cnn', 'dropoutcnn', 'resnet152'] # TYPES = ['cnn', 'shallowcnn', 'resnet', 'resnet152']\n",
    "    assert type in TYPES\n",
    "\n",
    "    if type == 'cnn':\n",
    "        cnn = CNN(in_channels)\n",
    "    if type == 'dropoutcnn':\n",
    "        cnn = DropoutCNN(in_channels)\n",
    "#     if type == 'resnet152':\n",
    "#         cnn = models.resnet152(pretrained=default_pretrained)\n",
    "    else:\n",
    "        cnn = Identity()\n",
    "\n",
    "    # if pretrained_cnn_weights:\n",
    "    #     if type == 'resnet152':\n",
    "    #         cnn.fc = nn.Linear(cnn.fc.in_features, pretrained_cnn_weights['fc.weight'].size(0))\n",
    "    #     cnn.load_state_dict(pretrained_cnn_weights)\n",
    "    if pretrained_cnn_weights:\n",
    "        cnn.load_state_dict(pretrained_cnn_weights)\n",
    "    \n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OC(nn.Module):\n",
    "    def __init__(self, model_type, num_classes, cnn_type, input_channels, cnn_out_size,\n",
    "                 dataset, decision_size=2, max_iters=20, attribute_size=20, attribute_mtx=None, attribute_coef=0.5, hidden_size=100,\n",
    "                 tau_initial=5, tau_target=0.5, use_pretrained=False, shallow=False, strategy='aRDTC'):\n",
    "        super(OC, self).__init__()\n",
    "        assert model_type in ['xoc'] #, 'ioc']\n",
    "        self.model_type = model_type\n",
    "        self.num_classes = num_classes\n",
    "        self.attribute_size = attribute_size\n",
    "        self.attribute_mtx = attribute_mtx\n",
    "        self.attribute_coef = attribute_coef if attribute_mtx is not None else 0.\n",
    "        self.decision_size = decision_size # change keyword default to 3?\n",
    "        self.tau_initial = tau_initial\n",
    "        self.tau_target = tau_target\n",
    "        self.max_iters = max_iters\n",
    "        self.shallow = shallow\n",
    "        self.stats = defaultdict(list)\n",
    "        self.reduced_vocab_size = 2\n",
    "        self.strategy = strategy\n",
    "\n",
    "        self.no_lstm = False\n",
    "\n",
    "        #self.init_attribute_matrix(attribute_mtx, attribute_size, attribute_coef, use_bin_attr)\n",
    "\n",
    "        self.cnn = self.init_cnn(cnn_type, input_channels, dataset, use_pretrained)\n",
    "        self.init_network(hidden_size, decision_size, num_classes, attribute_size, cnn_out_size, shallow)\n",
    "\n",
    "        self.init_losses()\n",
    "\n",
    "\n",
    "\n",
    "        self.phase = 'train'\n",
    "\n",
    "        # for stats\n",
    "        self.logits_list = []\n",
    "        self.sigmas_list = []\n",
    "#         self.labels_list\n",
    "        self.binary_features_list = []\n",
    "        self.labels_list = []\n",
    "        self.used_attributes_list = []\n",
    "        self.certain_attrs = []\n",
    "        self.attribute_accuracies = []\n",
    "        self.drop_ratios = []\n",
    "        self.mean_sigmas = []\n",
    "        \n",
    "\n",
    "    def init_network(self, hidden_size, decision_size, num_classes, attribute_size, cnn_out_size, shallow):\n",
    "        assert decision_size > 1\n",
    "\n",
    "        # LSTM initialization parameters\n",
    "        if self.no_lstm:\n",
    "            self.init_h0 = nn.Parameter(torch.zeros(attribute_size * decision_size), requires_grad=False)\n",
    "            self.init_c0 = nn.Parameter(torch.zeros(attribute_size * decision_size), requires_grad=False)\n",
    "        else:\n",
    "            self.init_h0 = nn.Parameter(torch.zeros(hidden_size).uniform_(-0.01, 0.01), requires_grad=True)\n",
    "            self.init_c0 = nn.Parameter(torch.zeros(hidden_size).uniform_(-0.01, 0.01), requires_grad=True)\n",
    "\n",
    "        if self.no_lstm:\n",
    "            self.lstm = lambda x, y: (None, (x.squeeze(), x.squeeze()))\n",
    "        else:\n",
    "            self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "\n",
    "        if self.no_lstm:\n",
    "            classifier_in = attribute_size * decision_size\n",
    "        else:\n",
    "            classifier_in = attribute_size * decision_size\n",
    "\n",
    "        self.classifier = nn.Sequential(#nn.BatchNorm1d(classifier_in) if not self.no_lstm else Identity(),\n",
    "                                        nn.Linear(classifier_in, hidden_size),\n",
    "                                        nn.ReLU(inplace=True),\n",
    "                                        nn.BatchNorm1d(hidden_size),\n",
    "                                        nn.Linear(hidden_size, num_classes))\n",
    "\n",
    "        if self.model_type == 'xoc':\n",
    "            if self.no_lstm:\n",
    "                feat_select_in_size = attribute_size * decision_size\n",
    "            else:\n",
    "                feat_select_in_size = hidden_size\n",
    "            feat_select_out_size = attribute_size\n",
    "            pre_lstm_size = attribute_size * decision_size * 2\n",
    "\n",
    "            bin_feat_type = 'shallow' if shallow else 'dropoutmlp' #'mlp'\n",
    "            feat_select_type = 'mlp_small'\n",
    "\n",
    "        elif self.model_type == 'ioc':\n",
    "            bin_feat_type = 'identity'\n",
    "            feat_select_type = 'mlp_big'\n",
    "\n",
    "            if not shallow:\n",
    "                feat_select_in_size = cnn_out_size + hidden_size\n",
    "                feat_select_out_size = decision_size\n",
    "                pre_lstm_size = feat_select_out_size\n",
    "            else:\n",
    "                feat_select_in_size = hidden_size\n",
    "                feat_select_out_size = cnn_out_size * decision_size\n",
    "                pre_lstm_size = decision_size\n",
    "\n",
    "        if feat_select_type == 'mlp_small':\n",
    "            self.feature_selection = nn.Sequential(nn.BatchNorm1d(feat_select_in_size) if not self.no_lstm else Identity(),\n",
    "                                                   nn.Linear(feat_select_in_size , hidden_size),\n",
    "                                                   nn.ReLU(inplace=True),\n",
    "                                                   nn.BatchNorm1d(hidden_size),\n",
    "                                                   nn.Linear(hidden_size, feat_select_out_size))\n",
    "        elif feat_select_type == 'mlp_big':\n",
    "            self.feature_selection = nn.Sequential(nn.BatchNorm1d(feat_select_in_size) if not self.no_lstm else Identity(),\n",
    "                                                   nn.Linear(feat_select_in_size, hidden_size),\n",
    "                                                   nn.ReLU(inplace=True),\n",
    "                                                   nn.BatchNorm1d(hidden_size),\n",
    "                                                   nn.Linear(hidden_size, hidden_size),\n",
    "                                                   nn.ReLU(inplace=True),\n",
    "                                                   nn.BatchNorm1d(hidden_size),\n",
    "                                                   nn.Linear(hidden_size, feat_select_out_size))\n",
    "\n",
    "        if bin_feat_type == 'identity':\n",
    "            self.binary_features = Identity()\n",
    "        elif bin_feat_type == 'shallow':\n",
    "            class AddZeros(nn.Module):\n",
    "                def __init__(self):\n",
    "                    super().__init__()\n",
    "\n",
    "                def forward(self, x):\n",
    "                    zeros = torch.zeros_like(x).unsqueeze(2)\n",
    "                    return torch.cat((x.unsqueeze(2), zeros), dim=2)\n",
    "\n",
    "            self.binary_features = AddZeros()\n",
    "        elif bin_feat_type == 'mlp':\n",
    "            self.binary_features = nn.Sequential(nn.BatchNorm1d(cnn_out_size), # use dropout\n",
    "                                                 nn.Linear(cnn_out_size, hidden_size),\n",
    "                                                 nn.ReLU(inplace=True),\n",
    "                                                 nn.BatchNorm1d(hidden_size), # use dropout\n",
    "                                                 nn.Linear(hidden_size, hidden_size),\n",
    "                                                 nn.ReLU(inplace=True),\n",
    "                                                 nn.BatchNorm1d(hidden_size), # use dropout\n",
    "                                                 nn.Linear(hidden_size, attribute_size * self.reduced_vocab_size))\n",
    "        elif bin_feat_type == 'dropoutmlp':\n",
    "            self.binary_features = nn.Sequential(\n",
    "                                                nn.Linear(cnn_out_size, hidden_size),\n",
    "                                                nn.ReLU(inplace=False),\n",
    "                                                nn.Dropout(0.2, inplace=False),\n",
    "                                                nn.Linear(hidden_size, hidden_size),\n",
    "                                                nn.ReLU(inplace=False),\n",
    "                                                nn.Dropout(0.2, inplace=False),\n",
    "                                                nn.Linear(hidden_size, attribute_size * self.reduced_vocab_size)\n",
    "                                                )\n",
    "\n",
    "        if self.no_lstm:\n",
    "            self.pre_lstm = Identity()\n",
    "        else:\n",
    "            self.pre_lstm = nn.Sequential(#nn.BatchNorm1d(pre_lstm_size),\n",
    "                                          nn.Linear(pre_lstm_size, hidden_size),\n",
    "                                          nn.ReLU(inplace=True),\n",
    "                                          nn.BatchNorm1d(hidden_size))\n",
    "\n",
    "\n",
    "        # Temperature parameters\n",
    "        self.binary_features.tau = nn.Parameter(torch.tensor([self.tau_initial], dtype=torch.float), requires_grad=True)\n",
    "        self.feature_selection.tau = nn.Parameter(torch.tensor([self.tau_initial], dtype=torch.float), requires_grad=True)\n",
    "        #self.init_weights()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    def get_attribute_uncertainty_batch(self, image_features, n=100, batch_size=64):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "\n",
    "            outputs = torch.zeros((n, batch_size, attribute_size * self.reduced_vocab_size), device=device) # init outputs with dummy values\n",
    "\n",
    "    #         if self.phase=='test':\n",
    "    #         print(self.binary_features.training)\n",
    "\n",
    "            if not self.binary_features.training:\n",
    "                current_phase = 'test'\n",
    "                self.binary_features.train()\n",
    "\n",
    "            else:\n",
    "                current_phase = 'train'\n",
    "    #         print(self.binary_features.training)\n",
    "    #         print()\n",
    "\n",
    "    #             for layer in self.binary_features:\n",
    "    #                 if isinstance(layer, torch.nn.modules.dropout._DropoutNd):\n",
    "    #                     layer.train()\n",
    "\n",
    "            for i in range(n):\n",
    "                outputs[i] = F.softmax(self.binary_features(image_features))\n",
    "\n",
    "            if current_phase=='test':\n",
    "    #         if self.phase=='test':\n",
    "                self.binary_features.eval()\n",
    "    #             for layer in self.binary_features:\n",
    "    #                 if isinstance(layer, torch.nn.modules.dropout._DropoutNd):\n",
    "    #                     layer.eval()\n",
    "    #                 else:\n",
    "    #                     layer.train()\n",
    "\n",
    "            sigmas = outputs.std(dim=0)\n",
    "\n",
    "            return sigmas\n",
    "    \n",
    "    \n",
    "    def get_attribute_uncertainty(self, image_features, n=10, batch_size=64):\n",
    "        outputs = torch.zeros((n, batch_size, attribute_size * self.reduced_vocab_size), device=device)\n",
    "        \n",
    "        if self.phase == 'train':\n",
    "            for i in range(n):\n",
    "                outputs[i] = F.softmax(self.binary_features(image_features))\n",
    "#                 outputs[i] = self.binary_features(image_features)\n",
    "\n",
    "        if self.phase == 'test':\n",
    "            for layer in self.binary_features:\n",
    "                if isinstance(layer, torch.nn.modules.dropout._DropoutNd):\n",
    "                    layer.train()\n",
    "#             self.binary_features.train()\n",
    "            for i in range(n):\n",
    "                outputs[i] = F.softmax(self.binary_features(image_features))\n",
    "#                 outputs[i] = self.binary_features(image_features)\n",
    "\n",
    "            for layer in self.binary_features:\n",
    "                if isinstance(layer, torch.nn.modules.dropout._DropoutNd):\n",
    "                    layer.eval()\n",
    "#             self.binary_features.eval()\n",
    "        \n",
    "        sigmas = outputs.var(dim=0)\n",
    "        sigmas += (0.01**2 * 0.5)/(2 * image_features.size(0) * weight_decay)\n",
    "#         print(sigmas.mean())\n",
    "\n",
    "        return sigmas\n",
    "  \n",
    "    def init_attribute_matrix(self, attribute_mtx, attribute_size, attribute_coef, use_bin_attr):\n",
    "        if attribute_coef > 0.:\n",
    "            if use_bin_attr:\n",
    "                attribute_mtx[attribute_mtx < 0.5] = 0.\n",
    "                attribute_mtx[attribute_mtx >= 0.5] = 1.\n",
    "            self.attribute_mtx = nn.Parameter(attribute_mtx, requires_grad=False)\n",
    "            self.attribute_size = attribute_mtx.size(1)\n",
    "        else:\n",
    "            self.attribute_mtx = None\n",
    "            self.attribute_size = attribute_size\n",
    "\n",
    "    def toggle_update_schedule(self):\n",
    "        # TODO: see a few lines below\n",
    "        #self.update_binary_features = not self.update_binary_features\n",
    "        pass\n",
    "\n",
    "    def get_param_groups(self):\n",
    "        cnn_params = []\n",
    "        tree_params = []\n",
    "        for n, p in self.named_parameters():\n",
    "            if p.requires_grad:\n",
    "                # TODO: introduce parameter that allows to switch between training alternatingly\n",
    "                # Currently commented out, so both groups contain the same parameters\n",
    "                \"\"\"\n",
    "                if n.startswith('cnn') or n.startswith('binary_features'):\n",
    "                    print('CNN', n)\n",
    "                    cnn_params.append(p)\n",
    "                else:\n",
    "                    print('OTHER', n)\n",
    "                    tree_params.append(p)\n",
    "                \"\"\"\n",
    "                cnn_params.append(p)\n",
    "                tree_params.append(p)\n",
    "        return tree_params, cnn_params\n",
    "\n",
    "    def set_optimizer(self, optimizers):\n",
    "        self.tree_optimizer = optimizers[0]\n",
    "        self.cnn_optimizer = optimizers[1]\n",
    "\n",
    "    def set_scheduler(self, schedulers):\n",
    "        self.tree_scheduler = schedulers[0]\n",
    "        self.cnn_scheduler = schedulers[1]\n",
    "\n",
    "    def get_optimizer(self):\n",
    "        if self.update_binary_features:\n",
    "            return self.cnn_optimizer\n",
    "        else:\n",
    "            return self.tree_optimizer\n",
    "\n",
    "    def get_scheduler(self):\n",
    "        if self.update_binary_features:\n",
    "            return self.cnn_scheduler\n",
    "        else:\n",
    "            return self.tree_scheduler\n",
    "\n",
    "    def init_losses(self):\n",
    "        self.cls_loss = nn.CrossEntropyLoss()\n",
    "        self.attr_loss = nn.BCEWithLogitsLoss()\n",
    "        self.update_binary_features = False\n",
    "\n",
    "    def init_cnn(self, cnn_type, input_channels, dataset, use_pretrained):\n",
    "        if cnn_type == 'None':\n",
    "            cnn = Identity()\n",
    "        else:\n",
    "            if use_pretrained:\n",
    "                # TODO add data_path and change state dict name \n",
    "                # cnn_state_dict = torch.load('pretrained/{}_{}.pth'.format(dataset, cnn_type))\n",
    "#                 cnn_state_dict = torch.load('pretrained/cub_resnet152.pkl')# .format(dataset, cnn_type)\n",
    "                cnn_state_dict = torch.load('pretrained/{}_resnet152.pkl'.format(dataset))# .format(dataset, cnn_type)\n",
    "\n",
    "                cnn = get_cnn(input_channels, cnn_type, cnn_state_dict, freeze_weights=True)\n",
    "            else:\n",
    "                cnn = get_cnn(input_channels, cnn_type)\n",
    "\n",
    "        return cnn\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight.data)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.fill_(0.1)\n",
    "\n",
    "    def set_tau(self, epoch):\n",
    "        annealing_factor = epoch / 100\n",
    "        self.tau = self.tau_initial\n",
    "        self.tau -= (self.tau_initial - self.tau_target) * annealing_factor\n",
    "        self.tau = max(self.tau, self.tau_target)\n",
    "\n",
    "    def process_images(self, images):\n",
    "        batch_size = images.size(0)\n",
    "        img_feats = self.cnn(images)\n",
    "        img_feats = img_feats.view(img_feats.size(0), -1)\n",
    "        image_features = self.binary_features(img_feats)\n",
    "        # print(image_features.size())\n",
    "        ################## remove attrs code\n",
    "#         sigmas = self.get_attribute_uncertainty_batch(img_feats,n=100, batch_size=batch_size)\n",
    "        \n",
    "        if self.strategy == 'remRDTC':\n",
    "            with torch.no_grad():\n",
    "                sigmas = self.get_attribute_uncertainty(img_feats, n=5, batch_size=images.size(0))\n",
    "            uncertain_attrs = (sigmas > 0.005).float() # get binary uncertain attrs\n",
    "            certain_attrs = 1. - uncertain_attrs\n",
    "            mask = certain_attrs.detach()\n",
    "            inv_mask = 1-mask\n",
    "            min_value = image_features.min()\n",
    "            image_features = image_features * mask # put zeros where uncertain attts are\n",
    "            image_features = image_features - (inv_mask.detach()*min_value.detach()) #*-500\n",
    "\n",
    "#         sigmas.detach()\n",
    "#         sigmas.cuda()\n",
    "#         self.mean_sigmas.append(sigmas.mean().item())\n",
    "#         drop_ratio = (sigmas>0.005).float().sum()/(images.size(0)*attribute_size*2.)\n",
    "#         min_value = image_features.min()\n",
    "#         min_value.detach()\n",
    "#         self.drop_ratios.append(drop_ratio)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #############################################################\n",
    "#         if not self.training:\n",
    "\n",
    "#             self.sigmas_list.append(sigmas)\n",
    "            # self.logits_list.append(image_features)\n",
    "            # image_features = torch.cat((attribute_logits, sigmas),1)\n",
    "        \n",
    "        \n",
    "        ################## remove attrs\n",
    "#         uncertain_attrs = (sigmas > 0.005).float() # get binary uncertain attrs\n",
    "#         certain_attrs = 1. - uncertain_attrs\n",
    "#         mask = certain_attrs.detach()#(torch.FloatTensor(image_features.size()).uniform_() > 0.050).float().to(device)\n",
    "        if self.strategy == 'randRDTC':\n",
    "            mask = (torch.FloatTensor(image_features.size()).uniform_() > 0.050).float().to(device)\n",
    "            inv_mask = 1-mask\n",
    "#         self.drop_ratios.append((inv_mask.sum()/39936.0).item())\n",
    "#         mask.detach()\n",
    "            min_value = image_features.min()\n",
    "            image_features = image_features * mask # put zeros where uncertain attts are\n",
    "            image_features = image_features - (inv_mask.detach()*min_value.detach()) #*-500\n",
    "        ##############################################################\n",
    "\n",
    "        if self.model_type == 'xoc':\n",
    "            attribute_logits = image_features.view(-1, 2)\n",
    "\n",
    "\n",
    "            attributes_softmax = F.softmax(attribute_logits / self.binary_features.tau, dim=1)\n",
    "            attributes_hard = self.argmax(attributes_softmax, dim=1)\n",
    "            image_features = attributes_hard.view(images.size(0), -1, 2)\n",
    "\n",
    "            # TODO: generalize to different decision sizes\n",
    "            bin_attribute_logits = attribute_logits - attribute_logits[:, 1].unsqueeze(-1)\n",
    "            self.attribute_logits = bin_attribute_logits[:, 0].view(images.size(0), -1)\n",
    "\n",
    "            self.collect_hist_stats('AttributesSoft', F.softmax(attribute_logits, dim=1))\n",
    "            self.collect_hist_stats('AttributesSoftTemp', attributes_softmax)\n",
    "            self.collect_hist_stats('AttributesHard', attributes_hard.max(dim=1)[1])\n",
    "\n",
    "        return image_features\n",
    "\n",
    "    def make_decision(self, lstm_out, binary_features, iter, sigma=[], max_uncertainty=0.2):\n",
    "        if self.model_type == 'xoc':\n",
    "            # Perform categorical feature selection\n",
    "            selection_logits = self.feature_selection(lstm_out)\n",
    "            # print(selection_logits[0][:10])\n",
    "            if self.training:\n",
    "                hard_selection = F.gumbel_softmax(selection_logits, tau=self.feature_selection.tau, hard=True)\n",
    "            else:\n",
    "               \n",
    "                # sigma = self.get_attribute_uncertainty(binary_features)\n",
    "                # sigma = sigma[:,:312]#.squeeze() \n",
    "                # certain_logits = torch.where(sigma>max_uncertainty,\n",
    "                #                              selection_logits,\n",
    "                #                              torch.zeros_like(selection_logits).new_full(selection_logits.size(), -10000)) # -10000\n",
    "                hard_selection = self.argmax(selection_logits, dim=1)\n",
    "                # print(hard_selection.size())\n",
    "                # print(binary_features.size())\n",
    "                # print(hard_selection.unsqueeze(2).size())\n",
    "\n",
    "\n",
    "            # Get single decision\n",
    "            self.saved_attribute_selection = hard_selection.max(dim=1)[1]\n",
    "            \n",
    "\n",
    "            decision = (hard_selection.unsqueeze(2) * binary_features).view(-1, self.attribute_size * self.decision_size)\n",
    "            # print(decision[0])\n",
    "        elif self.model_type == 'ioc':\n",
    "            if not self.shallow:\n",
    "                features = torch.cat((lstm_out, binary_features), dim=1)\n",
    "                selection_logits = self.feature_selection(features)\n",
    "            else:\n",
    "                shallow_weights = self.feature_selection(lstm_out)\n",
    "                shallow_weights = shallow_weights.view(lstm_out.size(0), -1, self.decision_size)\n",
    "                selection_logits = torch.bmm(binary_features.unsqueeze(1), shallow_weights)\n",
    "                selection_logits = selection_logits.squeeze()\n",
    "\n",
    "            soft_decision = F.softmax(selection_logits / self.tau_selection, dim=1)\n",
    "            hard_selection = self.argmax(soft_decision, dim=1)\n",
    "            decision = hard_selection\n",
    "\n",
    "        # Collect statistics\n",
    "        self.collect_hist_stats('SelectionSoft', F.softmax(selection_logits, dim=1).max(dim=1)[0], iter)\n",
    "        self.collect_hist_stats('SelectionSoftTemp', F.softmax(selection_logits / self.feature_selection.tau, dim=1).max(dim=1)[0], iter)\n",
    "        self.collect_hist_stats('SelectionHard', hard_selection.max(dim=1)[1], iter)\n",
    "\n",
    "        return decision\n",
    "\n",
    "    def get_initial_state(self, batch_size):\n",
    "        h0 = self.init_h0.view(1, 1, -1).expand(-1, batch_size, -1)\n",
    "        c0 = self.init_c0.view(1, 1, -1).expand(-1, batch_size, -1)\n",
    "        state = (h0.contiguous(), c0.contiguous())\n",
    "        return state\n",
    "\n",
    "    def argmax(self, y_soft, dim):\n",
    "        index = y_soft.max(dim, keepdim=True)[1]\n",
    "        y_hard = torch.zeros_like(y_soft).scatter_(dim, index, 1.0)\n",
    "        argmax = y_hard - y_soft.detach() + y_soft\n",
    "        return argmax\n",
    "\n",
    "    def collect_hist_stats(self, name, data, i=None):\n",
    "        # TODO: investigate performance impact of collecting these statistics,\n",
    "        # make option to disable and/or autodisable if tree is too large\n",
    "        if 'Hard' in name:\n",
    "            stat_str = 'Hist/' + name\n",
    "            data = data.detach().cpu()\n",
    "            self.stats[stat_str].append(data)\n",
    "            if i is not None:\n",
    "                stat_str += str(i)\n",
    "                self.stats[stat_str].append(data)\n",
    "\n",
    "    def get_hist_stats(self, reset=True):\n",
    "        stats = self.stats\n",
    "        if reset:\n",
    "            self.stats = defaultdict(list)\n",
    "        #return None\n",
    "        return stats\n",
    "\n",
    "    def reset_stats(self):\n",
    "        self.unique_attributes = [set() for i in range(self.max_iters)]\n",
    "        if self.attribute_coef > 0.:\n",
    "            self.attr_pred_correct = [0 for i in range(self.max_iters)]\n",
    "\n",
    "    def update_unique_attributes(self, unique_attributes, iter):\n",
    "        for attr in unique_attributes:\n",
    "            self.unique_attributes[iter].add(attr.item())\n",
    "\n",
    "    def get_unique_attributes(self):\n",
    "        uniq_per_iter = []\n",
    "        for i in range(self.max_iters):\n",
    "            iter_set = self.unique_attributes[i]\n",
    "            for j in range(i+1):\n",
    "                if j == i:\n",
    "                    continue\n",
    "                iter_set = iter_set.union(self.unique_attributes[j])\n",
    "            uniq_per_iter.append(len(iter_set))\n",
    "        return uniq_per_iter\n",
    "\n",
    "    def update_attr_preds(self, attr_correct, iter):\n",
    "        self.attr_pred_correct[iter] += attr_correct\n",
    "\n",
    "    def get_attr_acc(self, total_cnt):\n",
    "        correct_cumsum = np.cumsum(self.attr_pred_correct)\n",
    "        cnt_per_iter = (np.arange(self.max_iters) + 1) * total_cnt\n",
    "        return correct_cumsum / cnt_per_iter\n",
    "\n",
    "    def init_tree_stats(self):\n",
    "        # TODO: investigate performance impact of collecting these statistics,\n",
    "        # make option to disable and/or autodisable if tree is too large\n",
    "\n",
    "        # Would be nice if this worked with sparse tensors\n",
    "        n_possible_states = self.decision_size ** self.max_iters\n",
    "        self.label_stats = torch.zeros((n_possible_states * self.decision_size,\n",
    "                                        self.num_classes), dtype=torch.int32)\n",
    "                                       #layout=torch.sparse_coo)\n",
    "        self.selection_stats = torch.zeros((n_possible_states,\n",
    "                                            self.attribute_size),\n",
    "                                           dtype=torch.int32)\n",
    "                                           #layout=torch.sparse_coo)\n",
    "\n",
    "    def update_tree_stats(self, attribute_selection, attribute_decisions, labels, iter):\n",
    "        # TODO: investigate performance impact of collecting these statistics,\n",
    "        # make option to disable and/or autodisable if tree is too large\n",
    "\n",
    "        if iter == 0:\n",
    "            self.batch_states = torch.zeros_like(labels)\n",
    "            for i in range(labels.size(0)):\n",
    "                self.label_stats[self.batch_states[i], labels[i]] += 1\n",
    "\n",
    "        for i in range(labels.size(0)):\n",
    "            self.selection_stats[self.batch_states[i], attribute_selection[i]] += 1\n",
    "            self.batch_states[i] += (attribute_decisions[i] + 1) * self.decision_size ** iter\n",
    "            self.label_stats[self.batch_states[i], labels[i]] += 1\n",
    "\n",
    "    def run_iteration(self, binary_features, state, decision_hist, iter, sigma=[]): # also pass sigma here\n",
    "        lstm_out = state[0].squeeze(0)\n",
    "\n",
    "        # Make binary decision\n",
    "        decision = self.make_decision(lstm_out, binary_features, iter, sigma)\n",
    "\n",
    "        if decision_hist is None:\n",
    "            decision_hist = decision\n",
    "        else:\n",
    "            decision_hist = (decision_hist + decision).clamp(0., 1.)\n",
    "\n",
    "        scaled_dh = decision_hist / decision_hist.sum(dim=1).unsqueeze(1).detach()\n",
    "        if self.no_lstm:\n",
    "            lstm_in = scaled_dh\n",
    "        else:\n",
    "            lstm_in = torch.cat((scaled_dh, decision), dim=1)\n",
    "\n",
    "        # Update LSTM state\n",
    "        lstm_in = self.pre_lstm(lstm_in).unsqueeze(1)\n",
    "        _, state = self.lstm(lstm_in, state)\n",
    "\n",
    "        # Get current classification\n",
    "        classifier_in = scaled_dh\n",
    "        #classifier_in = state[1].squeeze(0)\n",
    "        #classifier_in = torch.cat((decision_hist, self.lstm_state_bn(lstm_state)), dim=1)\n",
    "        classification = self.classifier(classifier_in)\n",
    "\n",
    "        return classification, state, decision_hist\n",
    "\n",
    "    def tree_rollout(self, images, labels, keep_tree_stats=False):\n",
    "        # Set initial state\n",
    "        state = self.get_initial_state(images.size(0))\n",
    "\n",
    "        # Get categorical features once\n",
    "        binary_features = self.process_images(images)\n",
    "        # collect attribute stats\n",
    "        # self.binary_features_list.append(binary_features)\n",
    "        # self.labels_list.append(labels)\n",
    "\n",
    "#         attr_acc = (binary_features[:,:,0] == attribute_mtx[labels]).sum().long() / 19968.0 #/ (312*labels.size(0))\n",
    "        attr_acc = (binary_features[:,:,0] == attribute_mtx[labels]).sum().long() / float((attribute_size*labels.size(0)))    \n",
    "#         print(attr_acc)\n",
    "        self.attribute_accuracies.append(attr_acc.item())\n",
    "\n",
    "        ######################### extended vocab code \n",
    "        if self.strategy == 'extRDTC':\n",
    "            with torch.no_grad():\n",
    "                img_feats = self.cnn(images)\n",
    "                img_feats = img_feats.view(img_feats.size(0), -1)\n",
    "    #             image_features = self.binary_features(img_feats) # maybe do those with no grad as well\n",
    "                sigmas = self.get_attribute_uncertainty(img_feats, n=5, batch_size=images.size(0))\n",
    "            if not self.training:\n",
    "                self.sigmas_list.append(sigmas)\n",
    "                self.labels_list.append(labels)\n",
    "    #         sigmas.detach()\n",
    "        \n",
    "#         ########### remove attrs code\n",
    "#         uncertain_attrs = (sigmas > 0.005).float()\n",
    "#         certain_attrs = 1. - uncertain_attrs\n",
    "#         uncertain_attrs = uncertain_attrs.view(images.size(0), attribute_size, 2)\n",
    "#         certain_attrs = certain_attrs.view(images.size(0), attribute_size, 2)\n",
    "# #         print(certain_attrs[0])\n",
    "#         mask = torch.bernoulli(torch.empty(binary_features.size(), device=device).uniform_(1, 1))\n",
    "        \n",
    "#         binary_features = binary_features * mask#certain_attrs.detach() # clean binary_features from uncertain attrs (replace with 0)\n",
    "        \n",
    "        \n",
    "\n",
    "#         ######################################### remove attrs code end\n",
    "        \n",
    "# #         self.mean_sigmas.append(sigmas.mean().item())\n",
    "            sigmas = (sigmas > 0.005).float() # 0.004\n",
    "            sigmas_new = torch.zeros(images.size(0), attribute_size,1, device=device)\n",
    "            sigmas_new += sigmas.view(images.size(0),attribute_size,2)[:,:,0].unsqueeze(2)\n",
    "            sigmas_new += sigmas.view(images.size(0),attribute_size,2)[:,:,1].unsqueeze(2)\n",
    "            sigmas_new = (sigmas_new > 0.0).float() # <- denotes uncertain attributes\n",
    "\n",
    "            self.drop_ratios.append((sigmas_new.sum()/19968.0).item())\n",
    "\n",
    "            # obtain uncertainty and append to decision\n",
    "            new_attribute_decisions = torch.cat([binary_features, torch.zeros_like(sigmas_new, device=device)], dim=2)\n",
    "            certain_decisions = 1. - sigmas_new\n",
    "            uncertain_onehot = torch.tensor([[0., 0., 1.]], device=device).repeat(images.size(0), attribute_size, 1)\n",
    "            uncertain_attrs_removed = certain_decisions.detach() * new_attribute_decisions\n",
    "            shaped_uncertain_attrs = sigmas_new.detach() * uncertain_onehot\n",
    "            final_attribute_decisions = uncertain_attrs_removed + shaped_uncertain_attrs\n",
    "#             binary_features = final_attribute_decisions\n",
    "#         ######################### extended vocab code end\n",
    "        \n",
    "        \n",
    "\n",
    "        loss = 0\n",
    "        j = 0\n",
    "        # stats\n",
    "        all_classifications = []\n",
    "        all_chosen_attr = []\n",
    "        all_attribute_preds = []\n",
    "\n",
    "        decision_hist = None\n",
    "        while j < self.max_iters:\n",
    "            classification, state, decision_hist = self.run_iteration(binary_features, state, decision_hist, j+1)\n",
    "            loss += (1. - self.attribute_coef) * self.cls_loss(classification, labels)\n",
    "            all_classifications.append(classification)\n",
    "\n",
    "            self.update_unique_attributes(self.saved_attribute_selection.unique(), j)\n",
    "\n",
    "            if self.model_type == 'xoc' and self.attribute_coef > 0.:\n",
    "                chosen_attribtutes = self.saved_attribute_selection\n",
    "                attribute_logits = self.attribute_logits\n",
    "\n",
    "                attribute_target = self.attribute_mtx[labels, :].gather(1, chosen_attribtutes.unsqueeze(1)).squeeze()\n",
    "                attribute_pred = attribute_logits.gather(1, chosen_attribtutes.unsqueeze(1)).squeeze()\n",
    "                loss += self.attribute_coef * self.attr_loss(attribute_pred,\n",
    "                                                             attribute_target)\n",
    "                \n",
    "\n",
    "\n",
    "                attribute_pred_bin = (attribute_pred > 0.).long()\n",
    "                self.update_attr_preds((attribute_pred_bin == attribute_target).sum().item(), j)\n",
    "\n",
    "                \n",
    "            if keep_tree_stats:\n",
    "                attribute_pred = self.attribute_logits.gather(1, self.saved_attribute_selection.unsqueeze(1)).squeeze()\n",
    "                self.update_tree_stats(self.saved_attribute_selection, (attribute_pred > 0.).long(),labels, j)\n",
    "\n",
    "                # all_chosen_attr.append(self.saved_attribute_selection)\n",
    "                all_attribute_preds.append((attribute_pred > 0.).long())\n",
    "\n",
    "            j += 1\n",
    "        \n",
    "            all_chosen_attr.append(self.saved_attribute_selection)\n",
    "\n",
    "        self.tmp_saved_chosen_attr = torch.stack(all_chosen_attr, dim=1)\n",
    "\n",
    "        if keep_tree_stats:\n",
    "            self.tmp_saved_cls = torch.stack(all_classifications, dim=1)\n",
    "            # self.tmp_saved_chosen_attr = torch.stack(all_chosen_attr, dim=1)\n",
    "            self.tmp_saved_attr_pred = torch.stack(all_attribute_preds, dim=1)\n",
    "        # else:\n",
    "        #     self.tmp_saved_chosen_attr = None\n",
    "\n",
    "        loss = loss / self.max_iters\n",
    "\n",
    "\n",
    "        ####################################\n",
    "        # if binary_features.size(0)==64:\n",
    "            # self.used_attributes_list.append(self.tmp_saved_chosen_attr)\n",
    "            # self.certain_attrs.append(certain_decisions)\n",
    "            # chosen_attributes_binary = torch.tensor([1 if x in [int(attr) for attr in self.tmp_saved_chosen_attr[:,x]] else 0 for x in range(312)], device=device)\n",
    "            # self.used_attributes_list.append(chosen_attributes_binary)\n",
    "            # self.sigmas_list.append(sigmas_all)\n",
    "        ####################################\n",
    "        return all_classifications, loss, self.tmp_saved_chosen_attr\n",
    "\n",
    "    def forward(self, images, labels, keep_tree_stats=False):\n",
    "        classification, loss, chosen_attribtutes = self.tree_rollout(images, labels, keep_tree_stats)\n",
    "        # classification, loss, chosen_attributes = self.tree_rollout(images, labels, keep_tree_stats)\n",
    "\n",
    "        return classification, loss#, chosen_attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "After defining our models, we can continue by training it. For this, we first set some hyperparameters and then continue by defining a trainer class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake input arguments\n",
    "model_type = 'xoc'\n",
    "cnn_type = 'uncertain'\n",
    "# cnn_type = 'resnet'\n",
    "attribute_coef = 0.2\n",
    "# attribute_size = 85#312 #1024\n",
    "# attribute_size = 312 #1024\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.00001\n",
    "step_size = 50\n",
    "num_epochs = 2\n",
    "max_iters = 10\n",
    "hidden_size = 1000\n",
    "cnn_out_size = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, dataloaders, num_epochs, device, log_freq, log_path): # todo remove stats dict\n",
    "\n",
    "        self.model = model\n",
    "        self.dataloaders = dataloaders\n",
    "        self.num_epochs = num_epochs\n",
    "        self.device = device\n",
    "        self.log_freq = log_freq\n",
    "        self.log_path = log_path\n",
    "        \n",
    "        self.logger = SummaryWriter(self.log_path)\n",
    "\n",
    "        #### TODO remove this workaround and use tensorboard\n",
    "#         with open('/content/drive/My Drive/rdtc/data/' + 'logs/' + 'stats_dict.json') as json_file:\n",
    "#             self.stats_dict = json.load(json_file)\n",
    "        \n",
    "        self.classifications_dict = {'correct':{'num':0, 'uncertainty':0},\n",
    "                                     'incorrect':{'num':0, 'uncertainty':0}}\n",
    "\n",
    "        self.uncertainty_stats = {'epoch_{}'.format(epoch):{'used_attributes':[],'sigmas':[], 'num_attrs_discarded':0} for epoch in range(num_epochs+2)}\n",
    "        self.mean_attr_accs = []\n",
    "        self.mean_drop_ratio = []\n",
    "        self.mean_sigmas = []\n",
    "        ############\n",
    "\n",
    "    def train(self):\n",
    "        self.model.phase = 'train'\n",
    "        self.train_model(self.dataloaders['train'])\n",
    "\n",
    "    def test(self):\n",
    "        self.model.phase = 'test'\n",
    "        self.test_model(self.dataloaders['test'], 'test', None, hard=False) # was: hard=True\n",
    "        self.model.phase = 'train'\n",
    "        return self.model.label_stats, self.model.selection_stats\n",
    "\n",
    "    def topk_correct(self, output, target, topk=(1,)):\n",
    "        maxk = max(topk)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        target_masks = []\n",
    "        target_cnt = []\n",
    "        for i in range(self.model.num_classes):\n",
    "            target_masks.append((target == i).unsqueeze(0))\n",
    "            target_cnt.append(target_masks[i].sum().item())\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = [(correct[:k] * tm).view(-1).float().sum(0, keepdim=True).item() for tm in target_masks]\n",
    "            res.append(np.array(correct_k))\n",
    "        return res, np.array(target_cnt)\n",
    "\n",
    "    def log_stats(self, phase, epoch, epoch_stats, hist_stats,\n",
    "                  unique_attr_stats, attr_acc):\n",
    "        for k in range(len(epoch_stats[0])):\n",
    "        # for k in range(1):\n",
    "\n",
    "            self.logger.add_scalar('Top1Accuracy{}/{}'.format(k+1, phase), epoch_stats[0][k], epoch)\n",
    "            # self.logger.add_scalar('Top5Accuracy{}/{}'.format(k+1, phase), epoch_stats[1][k], epoch)\n",
    "            # self.logger.add_scalar('Top1MeanClassAccuracy{}/{}'.format(k+1, phase), epoch_stats[3][k], epoch)\n",
    "            # self.logger.add_scalar('Top5MeanClassAccuracy{}/{}'.format(k+1, phase), epoch_stats[4][k], epoch)\n",
    "            # if unique_attr_stats is not None:\n",
    "            #     self.logger.add_scalar('UniqueAttributes{}/{}'.format(k+1, phase), unique_attr_stats[k], epoch)\n",
    "            # if attr_acc is not None:\n",
    "            #     self.logger.add_scalar('AttributeAccuracy{}/{}'.format(k+1, phase), attr_acc[k], epoch)\n",
    "        self.logger.add_scalar('Loss/'+phase, epoch_stats[2], epoch)\n",
    "\n",
    "        if hist_stats is not None:\n",
    "            for name, data in hist_stats.items():\n",
    "                data = torch.cat(data, dim=0).flatten()\n",
    "                if name.startswith('SelectionHard'):\n",
    "                    bins = self.model.attribute_size\n",
    "                elif name.startswith('AttributesHard'):\n",
    "                    bins = self.model.decision_size\n",
    "                else:\n",
    "                    bins = 'tensorflow'\n",
    "                self.logger.add_histogram(name, data, epoch, bins=bins)\n",
    "\n",
    "    def test_model(self, data_loader, phase, epoch, hard=False):\n",
    "        # Test the Model\n",
    "        self.model.eval()  # Change model to 'eval' mode (BN uses moving mean/var).\n",
    "        n_stats = self.model.max_iters if hasattr(self.model, 'max_iters') else 1\n",
    "        correct_1 = np.zeros((n_stats, self.model.num_classes))\n",
    "        correct_5 = np.zeros((n_stats, self.model.num_classes))\n",
    "        total = 0\n",
    "        total_cnt = np.zeros((1, self.model.num_classes))\n",
    "        total_loss = 0\n",
    "\n",
    "        if isinstance(self.model, OC):\n",
    "            self.model.reset_stats()\n",
    "            if hard:\n",
    "                self.model.init_tree_stats()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for idx, data in enumerate(data_loader):\n",
    "                if len(data) == 2:\n",
    "                    images, labels = data\n",
    "                    attributes = None\n",
    "                else:\n",
    "                    images, labels, attributes = data\n",
    "                    #attributes = attributes.to(self.device)\n",
    "                images = images.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                \n",
    "                classification, loss = self.model(images, labels, hard)\n",
    "                #####################################\n",
    "#                 print(labels.size())\n",
    "#                 print(labels[0].item())\n",
    "                #####################################\n",
    "\n",
    "                # Collect stats\n",
    "                total_loss += loss.item()\n",
    "                total += labels.size(0)\n",
    "                for k in range(len(classification)):\n",
    "                    ######################\n",
    "                    # print(classification[k].data)\n",
    "                    # print(labels[k])\n",
    "                    # print()\n",
    "                    # print(classification[k].data.size())\n",
    "                    # print(labels.size())\n",
    "                    # print()\n",
    "                    # values, indices = torch.max(classification[k], -1)\n",
    "                    # for i in range(classification[k].size(0)):\n",
    "\n",
    "                        # print(indices[i].item(),labels[i].item())\n",
    "                        # if indices[i].item()==labels[i].item():\n",
    "                        #     self.classifications_dict['correct']+=1\n",
    "                        # if indices[i].item()!=labels[i].item():\n",
    "                        #     self.classifications_dict['incorrect']+=1              \n",
    "          \n",
    "                    ######################\n",
    "                    ctopk, target_cnt = self.topk_correct(classification[k].data, labels, (1, 5))\n",
    "                    c1, c5 = ctopk\n",
    "                    # print(target_cnt)\n",
    "                    correct_1[k] += c1\n",
    "                    correct_5[k] += c5\n",
    "                total_cnt[0] += target_cnt\n",
    "\n",
    "                \n",
    "                # if classification[-1].size(0)==64:\n",
    "                #     values, indices = torch.max(classification[-1], -1)\n",
    "                #     image_features_ = self.model.cnn(images)\n",
    "                #     image_features_ = image_features_.view(image_features_.size(0), -1)\n",
    "                #     # self.model.binary_features = self.model.binary_features.train()\n",
    "                #     sigmas = self.model.get_attribute_uncertainty_batch(image_features_, batch_size=64)\n",
    "                #     sigmas.cuda()\n",
    "                #     # self.model.binary_features = self.model.binary_features.eval()\n",
    "                #     _, _, attributes_used = self.model.tree_rollout(images, labels, True)\n",
    "                #     for i in range(classification[-1].size(0)): # iterate over batch\n",
    "                #         chosen_attributes_binary = torch.tensor([1 if x in [int(attr) for attr in attributes_used[i]] else 0 for x in range(624)], device=device)\n",
    "                #         self.model.used_attributes_list.append(chosen_attributes_binary)\n",
    "                #         # chosen_attributes_binary.cuda()\n",
    "                #         used_sigmas = sigmas[i] * chosen_attributes_binary\n",
    "                #         if indices[i].item()==labels[i].item():\n",
    "                #             self.classifications_dict['correct']['num'] += 1\n",
    "                #             self.classifications_dict['correct']['uncertainty'] += used_sigmas.sum().item()\n",
    "                #         if indices[i].item()!=labels[i].item():\n",
    "                #             self.classifications_dict['incorrect']['num'] += 1\n",
    "                #             self.classifications_dict['incorrect']['uncertainty'] += used_sigmas.sum().item()\n",
    "                \n",
    "        # collect uncertainty stats#############################\n",
    "        # num_batches = len(model.used_attributes_list)\n",
    "\n",
    "        # attribute_zeros = torch.zeros(num_batches,624)\n",
    "        # # attrs_discarded_zeros = torch.zeros(num_batches, 624)\n",
    "        # sigma_zeros = torch.zeros(1, 624, device=device)\n",
    "        # num_attrs_discarded = 0\n",
    "        # for i in range(num_batches):\n",
    "        #     for batch_index in range(64):\n",
    "        #         example_attrs = [int(attr) for attr in model.used_attributes_list[i][batch_index]] # \n",
    "        #         attribute_zeros[i] += torch.tensor([1 if x in example_attrs else 0 for x in range(624)]) # used attrs binary\n",
    "        #         used_attrs_binary = torch.tensor([1 if x in example_attrs else 0 for x in range(624)]) # for that example\n",
    "        #         certain_attrs = model.certain_attrs[i][batch_index]\n",
    "        #         used_certain_attrs = used_attrs_binary.detach().cpu()[:312] * certain_attrs.detach().cpu()\n",
    "        #         num_attrs_discarded += torch.abs(used_attrs_binary.sum() - used_certain_attrs.sum())\n",
    "        #     sigma_zeros += model.sigmas_list[i].mean(dim=0) # add average of batch\n",
    "        #     # num_attrs_discarded += model.num_attrs_discarded_list[i]\n",
    "\n",
    "        \n",
    "        # self.uncertainty_stats['epoch_{}'.format(epoch)]['used_attributes']= attribute_zeros.sum(dim=0)\n",
    "        # self.model.used_attributes_list = []\n",
    "        # self.uncertainty_stats['epoch_{}'.format(epoch)]['sigmas'] = sigma_zeros/num_batches\n",
    "        # self.model.sigmas_list = []\n",
    "        # self.uncertainty_stats['epoch_{}'.format(epoch)]['num_attrs_discarded'] += num_attrs_discarded\n",
    "        # model.certain_attrs = []\n",
    "        # #####################################################################################\n",
    "\n",
    "        stats = [correct_1.sum(axis=1) / total, correct_5.sum(axis=1) / total, total_loss / total, (correct_1 / total_cnt).mean(axis=1), (correct_5 / total_cnt).mean(axis=1)]\n",
    "        print('Accuracy ({}), Top1: {:.2%}, Top5: {:.2%}'.format(phase, stats[0][-1], stats[1][-1]))\n",
    "        self.model.train()  # Change model to 'train' mode\n",
    "\n",
    "        unique_attr_stats = None\n",
    "        attr_acc = None\n",
    "        if epoch is not None:\n",
    "            if isinstance(self.model, OC):\n",
    "                hist_stats = self.model.get_hist_stats()\n",
    "                unique_attr_stats = self.model.get_unique_attributes()\n",
    "                if self.model.attribute_coef > 0.:\n",
    "                    attr_acc = self.model.get_attr_acc(total)\n",
    "                else:\n",
    "                    attr_acc = None\n",
    "            else:\n",
    "                hist_stats = None\n",
    "            self.log_stats(phase, epoch, stats, hist_stats, unique_attr_stats, attr_acc)\n",
    "\n",
    "        return stats[0][-1], stats, unique_attr_stats, attr_acc\n",
    "\n",
    "    def train_model(self, data_laoder):\n",
    "        max_accuracy = 0\n",
    "        max_agg_accuracy = 0\n",
    "        max_ma_accuracy = 0\n",
    "        max_ma_agg_accuracy = 0\n",
    "\n",
    "        if isinstance(self.model, OC):\n",
    "            self.model.reset_stats()\n",
    "\n",
    "        # Train the Model\n",
    "        ############### remove this workaround\n",
    "#         configuration = self.log_path.split('logs/')[1].split('/')[0]\n",
    "        # self.stats_dict[configuration]['losses'] = []\n",
    "        ###############################################\n",
    "        \n",
    "        for epoch in range(self.num_epochs):\n",
    "            #self.model.set_tau(epoch)\n",
    "            optimizer = self.model.get_optimizer()\n",
    "            n_stats = self.model.max_iters if hasattr(self.model, 'max_iters') else 1\n",
    "            correct_1 = np.zeros((n_stats, self.model.num_classes))\n",
    "            correct_5 = np.zeros((n_stats, self.model.num_classes))\n",
    "            total = 0\n",
    "            total_cnt = np.zeros((1, self.model.num_classes))\n",
    "            total_loss = 0\n",
    "\n",
    "            for i, data in enumerate(data_laoder):\n",
    "                \n",
    "                if len(data) == 2:\n",
    "                    images, labels = data\n",
    "                    attributes = None\n",
    "                else:\n",
    "                    images, labels, attributes = data\n",
    "                    #attributes = attributes.to(self.device)\n",
    "                images = images.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                classification, loss = self.model(images, labels)\n",
    "                \n",
    "\n",
    "                if loss.grad_fn is not None:\n",
    "                \n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # Collect stats\n",
    "                total_loss += loss.item()\n",
    "                total += labels.size(0)\n",
    "                for k in range(len(classification)):\n",
    "                    ctopk, target_cnt = self.topk_correct(classification[k].data, labels, (1, 5))\n",
    "                    c1, c5 = ctopk\n",
    "                    correct_1[k] += c1\n",
    "                    correct_5[k] += c5\n",
    "                total_cnt[0] += target_cnt\n",
    "\n",
    "                if (i+1) % self.log_freq == 0:\n",
    "                    print('Epoch [{}/{}], Iter [{}/{}] Loss: {:.4f}'\n",
    "                            .format(epoch+1, self.num_epochs, i+1, len(data_laoder)//images.size(0),\n",
    "                                    loss.item()))\n",
    "                    ##### TODO remove workaround and use tensurboard\n",
    "                    # self.stats_dict[configuration]['losses'].append(loss.item())\n",
    "            \n",
    "        # with open(data_path + '/logs/' + 'stats_dict.json', 'w') as json_file:\n",
    "        #     json.dump(self.stats_dict, json_file)\n",
    "        #     print('stats dict saved...')\n",
    "                    #############################################\n",
    "\n",
    "            self.model.get_scheduler().step()\n",
    "            # if isinstance(self.model, NeuralDecisionForest) or isinstance(self.model, OC):\n",
    "            #     self.model.toggle_update_schedule()\n",
    "\n",
    "            stats = [correct_1.sum(axis=1) / total, correct_5.sum(axis=1) / total, total_loss / total, (correct_1 / total_cnt).mean(axis=1), (correct_5 / total_cnt).mean(axis=1)]\n",
    "\n",
    "            if isinstance(self.model, OC):\n",
    "                hist_stats = self.model.get_hist_stats()\n",
    "                unique_attr_stats = self.model.get_unique_attributes()\n",
    "                if self.model.attribute_coef > 0.:\n",
    "                    attr_acc = self.model.get_attr_acc(total)\n",
    "                else:\n",
    "                    attr_acc = None\n",
    "            else:\n",
    "                hist_stats = None\n",
    "                unique_attr_stats = None\n",
    "                attr_acc = None\n",
    "            self.log_stats('train', epoch, stats, hist_stats, unique_attr_stats, attr_acc)\n",
    "            print('Accuracy (train), Top1: {:.2%}, Top5: {:.2%}'.format(stats[0][-1], stats[1][-1]))\n",
    "            self.model.phase = 'test'\n",
    "            val_accuracy, val_stats, _, _ = self.test_model(self.dataloaders['val'],\n",
    "                                                            'val', epoch+1)\n",
    "            val_agg_accuracy = val_stats[0].sum()\n",
    "            val_ma_accuracy = val_stats[3][-1]\n",
    "            val_ma_agg_accuracy = val_stats[3].sum()\n",
    "\n",
    "            # reset model stats\n",
    "            model.sigmas_list = []\n",
    "            model.labels_list = []\n",
    "            model.used_attributes_list = []\n",
    "            model.attribute_accuracies = []\n",
    "            model.drop_ratios = []\n",
    "#             self.model.phase = 'test'\n",
    "            _, test_stats, unique_attr_stats, attr_acc = self.test_model(self.dataloaders['test'], 'test', epoch+1)\n",
    "            \n",
    "#             if model.drop_ratios[0].size(0) == 64:\n",
    "            self.mean_drop_ratio.append(sum(model.drop_ratios)/(len(model.drop_ratios)+1))\n",
    "            mean_attribute_accuracy = sum(model.attribute_accuracies)/len(model.attribute_accuracies)\n",
    "            self.mean_sigmas.append(sum(model.mean_sigmas)/(len(model.mean_sigmas)+1))\n",
    "            self.mean_attr_accs.append(mean_attribute_accuracy)\n",
    "#             print(mean_attribute_accuracy)\n",
    "#             print()\n",
    "            # # collect uncertainty stats\n",
    "            # self.uncertainty_stats['epoch_{}'.format(epoch)]['used_attributes']=self.model.used_attributes_list\n",
    "            # self.model.used_attributes_list = []\n",
    "            # self.uncertainty_stats['epoch_{}'.format(epoch)]['sigmas']=self.model.sigmas_list\n",
    "            # self.model.sigmas_list = []           \n",
    "            \n",
    "            \n",
    "            \n",
    "            self.model.phase = 'train'\n",
    "            if val_accuracy > max_accuracy:\n",
    "                max_accuracy = val_accuracy\n",
    "#                 self.save_model('best', test_stats, 0, unique_attr_stats, attr_acc, epoch)\n",
    "            if val_ma_accuracy > max_ma_accuracy:\n",
    "                max_ma_accuracy = val_ma_accuracy\n",
    "#                 self.save_model('best_ma', test_stats, 3, unique_attr_stats, attr_acc, epoch)\n",
    "            if val_agg_accuracy > max_agg_accuracy and isinstance(self.model, OC):\n",
    "                max_agg_accuracy = val_agg_accuracy\n",
    "                self.save_model('best_agg', test_stats, 0, unique_attr_stats, attr_acc, epoch)\n",
    "            if val_ma_agg_accuracy > max_ma_agg_accuracy and isinstance(self.model, OC):\n",
    "                max_ma_agg_accuracy = val_ma_agg_accuracy\n",
    "#                 self.save_model('best_ma_agg', test_stats, 3, unique_attr_stats, attr_acc, epoch)\n",
    "\n",
    "            self.save_model('latest', test_stats, 0, unique_attr_stats, attr_acc, epoch)\n",
    "        # with open(data_path + '/logs/' + 'stats_dict.json', 'w') as json_file:\n",
    "        #     json.dump(self.stats_dict, json_file)\n",
    "        #     print('stats dict saved...')\n",
    "\n",
    "\n",
    "    def write_stats_file(self, stats_list, name, epoch, is_float=True):\n",
    "        fstr = '{:.2f}' if is_float else '{}'\n",
    "        with open(os.path.join(self.log_path, '{}.txt'.format(name)), 'a') as f:\n",
    "            acc_str = [fstr.format(100*c1 if is_float else c1) for c1 in stats_list]\n",
    "            f.write('{} '.format(epoch) + ' '.join(acc_str))\n",
    "            f.write('\\n')\n",
    "\n",
    "    def save_model(self, name, test_stats, stats_idx, unique_attr_stats, attr_acc, epoch):\n",
    "        torch.save(self.model.state_dict(),\n",
    "                   os.path.join(self.log_path, '{}.pth'.format(name)))\n",
    "        \n",
    "        # save state dict for vision model separately\n",
    "        torch.save(self.model.cnn.state_dict(), os.path.join(self.log_path, '{}_vision_model.pth'.format(name)))\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.write_stats_file(test_stats[stats_idx], name, epoch)\n",
    "\n",
    "        # if isinstance(self.model, NeuralDecisionForest):\n",
    "        #     _, test_stats_hard, _, _ = self.test_model(self.dataloaders['test'],\n",
    "        #                                                'test', epoch+1, hard=True)\n",
    "        #     self.write_stats_file(test_stats_hard[stats_idx], name+'_hard', epoch)\n",
    "\n",
    "        if unique_attr_stats is not None:\n",
    "            self.write_stats_file(unique_attr_stats, name+'_uniqattr', epoch,\n",
    "                                  is_float=False)\n",
    "\n",
    "        if attr_acc is not None:\n",
    "            self.write_stats_file(attr_acc, name+'_attracc', epoch)\n",
    "\n",
    "        if name != 'latest':\n",
    "            print('Saved {} model'.format(name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's instance our models..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the configuraion parameters of our dataset\n",
    "in_channels, cnn_out_size, log_freq = get_dataset_config(dataset, 'cnn', 40 )\n",
    "cnn_out_size = 2048\n",
    "\n",
    "# initiate the observer classifier model\n",
    "model = OC('xoc', len(classes), 'dropoutcnn', in_channels,\n",
    "            cnn_out_size, dataset, 2, 40, # 13 worked\n",
    "            attribute_size, attribute_mtx, attribute_coef,\n",
    "            hidden_size, tau_initial=5,\n",
    "            use_pretrained=False, shallow=False)\n",
    "\n",
    "# load pretrained resnet backbone\n",
    "model.cnn = models.resnet152(pretrained=False)\n",
    "model.cnn.fc = nn.Linear(model.cnn.fc.in_features, torch.load('/home/swezel/projects/urdtc/pretrained/cub_resnet152.pkl')['fc.weight'].size(0))\n",
    "model.cnn.load_state_dict(torch.load('/home/swezel/projects/urdtc/pretrained/cub_resnet152.pkl'))\n",
    "# model.cnn.fc = nn.Linear(model.cnn.fc.in_features, torch.load('/home/swezel/projects/urdtc/pretrained/{}_resnet152.pkl'.format(dataset))['fc.weight'].size(0))\n",
    "# model.cnn.load_state_dict(torch.load('/home/swezel/projects/urdtc/pretrained/{}_resnet152.pkl'.format(dataset)))\n",
    "\n",
    "\n",
    "model.cnn.fc = nn.Identity()\n",
    "\n",
    "# set attribute head\n",
    "model.binary_features = nn.Sequential(nn.BatchNorm1d(cnn_out_size),\n",
    "                                        nn.Linear(cnn_out_size, hidden_size),\n",
    "                                        nn.ReLU(inplace=True),\n",
    "                                        nn.BatchNorm1d(hidden_size),\n",
    "                                        nn.Dropout(0.5, inplace=False), # dropout after batchnorm\n",
    "                                        nn.Linear(hidden_size, hidden_size),\n",
    "                                        nn.ReLU(inplace=True),\n",
    "                                        nn.BatchNorm1d(hidden_size),\n",
    "                                        nn.Dropout(0.5, inplace=False),\n",
    "                                        nn.Linear(hidden_size, attribute_size * 2))\n",
    "\n",
    "model.binary_features.tau = nn.Parameter(torch.tensor([5], dtype=torch.float), requires_grad=True)\n",
    "model.to(device);\n",
    "\n",
    "# freeze resnet backbone for faster training but make all other weights trainable\n",
    "for param in model.lstm.parameters():\n",
    "    param.requires_grad=True\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad=True\n",
    "for param in model.feature_selection.parameters():\n",
    "    param.requires_grad=True\n",
    "for param in model.binary_features.parameters():\n",
    "    param.requires_grad=True\n",
    "for param in model.pre_lstm.parameters():\n",
    "    param.requires_grad=True\n",
    "    \n",
    "for param in model.cnn.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.cnn.fc.parameters():\n",
    "    param.requires_grad=True\n",
    "    \n",
    "# initiate optimizers\n",
    "tree_params, cnn_params = model.get_param_groups()\n",
    "tree_optimizer = torch.optim.Adam(tree_params, lr = learning_rate, weight_decay=weight_decay)\n",
    "cnn_optimizer = torch.optim.Adam(cnn_params, lr = learning_rate, weight_decay=weight_decay)\n",
    "optimizer = [tree_optimizer, cnn_optimizer]\n",
    "# and schedulers\n",
    "tree_scheduler = torch.optim.lr_scheduler.StepLR(tree_optimizer, step_size=step_size, gamma=0.1)\n",
    "cnn_scheduler = torch.optim.lr_scheduler.StepLR(cnn_optimizer, step_size=step_size, gamma=0.1)\n",
    "scheduler = [tree_scheduler, cnn_scheduler]\n",
    "\n",
    "model.set_optimizer(optimizer)\n",
    "# model.init_tree_stats()\n",
    "model.set_scheduler(scheduler)\n",
    "##hook\n",
    "# torch.load('/home/swezel/projects/urdtc/pretrained/awa2_resnet152.pkl')\n",
    "\n",
    "# model.strategy = 'randRDTC'\n",
    "# model.strategy = 'remRDTC'\n",
    "model.strategy = 'extRDTC'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and finally train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-259-f002911457a5>:207: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs[i] = F.softmax(self.binary_features(image_features))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Iter [10/1] Loss: 4.4211\n",
      "Epoch [1/20], Iter [20/1] Loss: 4.3990\n",
      "Epoch [1/20], Iter [30/1] Loss: 4.3598\n",
      "Epoch [1/20], Iter [40/1] Loss: 4.2598\n",
      "Epoch [1/20], Iter [50/1] Loss: 4.1925\n",
      "Epoch [1/20], Iter [60/1] Loss: 4.1276\n",
      "Epoch [1/20], Iter [70/1] Loss: 3.8989\n",
      "Epoch [1/20], Iter [80/1] Loss: 4.0064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-261-070f05ede296>:280: RuntimeWarning: invalid value encountered in true_divide\n",
      "  stats = [correct_1.sum(axis=1) / total, correct_5.sum(axis=1) / total, total_loss / total, (correct_1 / total_cnt).mean(axis=1), (correct_5 / total_cnt).mean(axis=1)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (train), Top1: 2.39%, Top5: 9.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-259-f002911457a5>:216: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs[i] = F.softmax(self.binary_features(image_features))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (val), Top1: 2.08%, Top5: 11.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-261-070f05ede296>:190: RuntimeWarning: invalid value encountered in true_divide\n",
      "  stats = [correct_1.sum(axis=1) / total, correct_5.sum(axis=1) / total, total_loss / total, (correct_1 / total_cnt).mean(axis=1), (correct_5 / total_cnt).mean(axis=1)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (test), Top1: 1.48%, Top5: 10.71%\n",
      "Saved best_agg model\n",
      "Epoch [2/20], Iter [10/1] Loss: 3.6411\n",
      "Epoch [2/20], Iter [20/1] Loss: 3.8225\n",
      "Epoch [2/20], Iter [30/1] Loss: 3.5042\n",
      "Epoch [2/20], Iter [40/1] Loss: 3.5315\n",
      "Epoch [2/20], Iter [50/1] Loss: 3.2036\n",
      "Epoch [2/20], Iter [60/1] Loss: 3.3883\n",
      "Epoch [2/20], Iter [70/1] Loss: 3.2744\n",
      "Epoch [2/20], Iter [80/1] Loss: 3.5148\n",
      "Accuracy (train), Top1: 11.27%, Top5: 35.97%\n",
      "Accuracy (val), Top1: 9.90%, Top5: 34.20%\n",
      "Accuracy (test), Top1: 8.17%, Top5: 30.94%\n",
      "Saved best_agg model\n",
      "Epoch [3/20], Iter [10/1] Loss: 3.4048\n",
      "Epoch [3/20], Iter [20/1] Loss: 3.3235\n",
      "Epoch [3/20], Iter [30/1] Loss: 3.2061\n",
      "Epoch [3/20], Iter [40/1] Loss: 3.0788\n",
      "Epoch [3/20], Iter [50/1] Loss: 3.0330\n",
      "Epoch [3/20], Iter [60/1] Loss: 2.9455\n",
      "Epoch [3/20], Iter [70/1] Loss: 2.9389\n",
      "Epoch [3/20], Iter [80/1] Loss: 2.7610\n",
      "Accuracy (train), Top1: 21.43%, Top5: 57.55%\n",
      "Accuracy (val), Top1: 23.44%, Top5: 57.64%\n",
      "Accuracy (test), Top1: 21.89%, Top5: 51.56%\n",
      "Saved best_agg model\n",
      "Epoch [4/20], Iter [10/1] Loss: 2.6976\n",
      "Epoch [4/20], Iter [20/1] Loss: 2.5857\n",
      "Epoch [4/20], Iter [30/1] Loss: 2.9229\n",
      "Epoch [4/20], Iter [40/1] Loss: 2.6093\n",
      "Epoch [4/20], Iter [50/1] Loss: 2.5292\n",
      "Epoch [4/20], Iter [60/1] Loss: 2.6046\n",
      "Epoch [4/20], Iter [70/1] Loss: 2.6839\n",
      "Epoch [4/20], Iter [80/1] Loss: 2.5750\n",
      "Accuracy (train), Top1: 30.50%, Top5: 70.85%\n",
      "Accuracy (val), Top1: 31.77%, Top5: 68.75%\n",
      "Accuracy (test), Top1: 27.90%, Top5: 60.31%\n",
      "Saved best_agg model\n",
      "Epoch [5/20], Iter [10/1] Loss: 2.5732\n",
      "Epoch [5/20], Iter [20/1] Loss: 2.4178\n",
      "Epoch [5/20], Iter [30/1] Loss: 2.7310\n",
      "Epoch [5/20], Iter [40/1] Loss: 2.5900\n",
      "Epoch [5/20], Iter [50/1] Loss: 2.4474\n",
      "Epoch [5/20], Iter [60/1] Loss: 2.3931\n",
      "Epoch [5/20], Iter [70/1] Loss: 2.5033\n",
      "Epoch [5/20], Iter [80/1] Loss: 2.5452\n",
      "Accuracy (train), Top1: 37.90%, Top5: 76.05%\n",
      "Accuracy (val), Top1: 41.49%, Top5: 76.74%\n",
      "Accuracy (test), Top1: 37.94%, Top5: 67.57%\n",
      "Saved best_agg model\n",
      "Epoch [6/20], Iter [10/1] Loss: 2.6860\n",
      "Epoch [6/20], Iter [20/1] Loss: 2.4591\n",
      "Epoch [6/20], Iter [30/1] Loss: 2.3409\n",
      "Epoch [6/20], Iter [40/1] Loss: 2.2692\n",
      "Epoch [6/20], Iter [50/1] Loss: 2.3209\n",
      "Epoch [6/20], Iter [60/1] Loss: 2.5157\n",
      "Epoch [6/20], Iter [70/1] Loss: 2.3944\n",
      "Epoch [6/20], Iter [80/1] Loss: 2.2403\n",
      "Accuracy (train), Top1: 42.68%, Top5: 79.09%\n",
      "Accuracy (val), Top1: 42.88%, Top5: 82.64%\n",
      "Accuracy (test), Top1: 44.60%, Top5: 70.21%\n",
      "Saved best_agg model\n",
      "Epoch [7/20], Iter [10/1] Loss: 2.4416\n",
      "Epoch [7/20], Iter [20/1] Loss: 2.4253\n",
      "Epoch [7/20], Iter [30/1] Loss: 2.3974\n",
      "Epoch [7/20], Iter [40/1] Loss: 2.4774\n",
      "Epoch [7/20], Iter [50/1] Loss: 2.0871\n",
      "Epoch [7/20], Iter [60/1] Loss: 2.0920\n",
      "Epoch [7/20], Iter [70/1] Loss: 2.2401\n",
      "Epoch [7/20], Iter [80/1] Loss: 2.3154\n",
      "Accuracy (train), Top1: 48.11%, Top5: 80.33%\n",
      "Accuracy (val), Top1: 54.86%, Top5: 82.12%\n",
      "Accuracy (test), Top1: 46.70%, Top5: 70.47%\n",
      "Saved best_agg model\n",
      "Epoch [8/20], Iter [10/1] Loss: 2.3043\n",
      "Epoch [8/20], Iter [20/1] Loss: 2.1058\n",
      "Epoch [8/20], Iter [30/1] Loss: 1.8411\n",
      "Epoch [8/20], Iter [40/1] Loss: 2.3573\n",
      "Epoch [8/20], Iter [50/1] Loss: 2.6031\n",
      "Epoch [8/20], Iter [60/1] Loss: 2.2696\n",
      "Epoch [8/20], Iter [70/1] Loss: 2.0357\n",
      "Epoch [8/20], Iter [80/1] Loss: 2.2956\n",
      "Accuracy (train), Top1: 52.49%, Top5: 82.74%\n",
      "Accuracy (val), Top1: 54.17%, Top5: 83.33%\n",
      "Accuracy (test), Top1: 50.05%, Top5: 71.44%\n",
      "Saved best_agg model\n",
      "Epoch [9/20], Iter [10/1] Loss: 2.3262\n",
      "Epoch [9/20], Iter [20/1] Loss: 2.2395\n",
      "Epoch [9/20], Iter [30/1] Loss: 2.3595\n",
      "Epoch [9/20], Iter [40/1] Loss: 2.1784\n",
      "Epoch [9/20], Iter [50/1] Loss: 2.0220\n",
      "Epoch [9/20], Iter [60/1] Loss: 2.5063\n",
      "Epoch [9/20], Iter [70/1] Loss: 2.2493\n",
      "Epoch [9/20], Iter [80/1] Loss: 2.0422\n",
      "Accuracy (train), Top1: 53.45%, Top5: 82.89%\n",
      "Accuracy (val), Top1: 57.47%, Top5: 84.03%\n",
      "Accuracy (test), Top1: 51.30%, Top5: 71.79%\n",
      "Saved best_agg model\n",
      "Epoch [10/20], Iter [10/1] Loss: 2.2186\n",
      "Epoch [10/20], Iter [20/1] Loss: 2.1779\n",
      "Epoch [10/20], Iter [30/1] Loss: 2.3468\n",
      "Epoch [10/20], Iter [40/1] Loss: 2.3304\n",
      "Epoch [10/20], Iter [50/1] Loss: 1.8287\n",
      "Epoch [10/20], Iter [60/1] Loss: 2.1750\n",
      "Epoch [10/20], Iter [70/1] Loss: 2.0684\n",
      "Epoch [10/20], Iter [80/1] Loss: 1.9425\n",
      "Accuracy (train), Top1: 54.99%, Top5: 83.83%\n",
      "Accuracy (val), Top1: 61.46%, Top5: 88.37%\n",
      "Accuracy (test), Top1: 54.40%, Top5: 72.38%\n",
      "Saved best_agg model\n",
      "Epoch [11/20], Iter [10/1] Loss: 2.3826\n",
      "Epoch [11/20], Iter [20/1] Loss: 1.9916\n",
      "Epoch [11/20], Iter [30/1] Loss: 2.3145\n",
      "Epoch [11/20], Iter [40/1] Loss: 2.0041\n",
      "Epoch [11/20], Iter [50/1] Loss: 1.9284\n",
      "Epoch [11/20], Iter [60/1] Loss: 2.2269\n",
      "Epoch [11/20], Iter [70/1] Loss: 2.0763\n",
      "Epoch [11/20], Iter [80/1] Loss: 1.8043\n",
      "Accuracy (train), Top1: 56.45%, Top5: 84.07%\n",
      "Accuracy (val), Top1: 59.90%, Top5: 84.90%\n",
      "Accuracy (test), Top1: 51.78%, Top5: 71.77%\n",
      "Epoch [12/20], Iter [10/1] Loss: 1.9424\n",
      "Epoch [12/20], Iter [20/1] Loss: 2.1305\n",
      "Epoch [12/20], Iter [30/1] Loss: 2.0151\n",
      "Epoch [12/20], Iter [40/1] Loss: 1.9679\n",
      "Epoch [12/20], Iter [50/1] Loss: 2.0859\n",
      "Epoch [12/20], Iter [60/1] Loss: 1.9783\n",
      "Epoch [12/20], Iter [70/1] Loss: 2.0748\n",
      "Epoch [12/20], Iter [80/1] Loss: 2.1181\n",
      "Accuracy (train), Top1: 58.98%, Top5: 85.45%\n",
      "Accuracy (val), Top1: 60.59%, Top5: 86.28%\n",
      "Accuracy (test), Top1: 54.87%, Top5: 72.33%\n",
      "Epoch [13/20], Iter [10/1] Loss: 2.4541\n",
      "Epoch [13/20], Iter [20/1] Loss: 2.0513\n",
      "Epoch [13/20], Iter [30/1] Loss: 1.7727\n",
      "Epoch [13/20], Iter [40/1] Loss: 1.8080\n",
      "Epoch [13/20], Iter [50/1] Loss: 1.6705\n",
      "Epoch [13/20], Iter [60/1] Loss: 2.4579\n",
      "Epoch [13/20], Iter [70/1] Loss: 1.8192\n",
      "Epoch [13/20], Iter [80/1] Loss: 1.5577\n",
      "Accuracy (train), Top1: 59.92%, Top5: 85.32%\n",
      "Accuracy (val), Top1: 62.15%, Top5: 84.03%\n",
      "Accuracy (test), Top1: 57.14%, Top5: 72.82%\n",
      "Epoch [14/20], Iter [10/1] Loss: 2.3540\n",
      "Epoch [14/20], Iter [20/1] Loss: 2.2602\n",
      "Epoch [14/20], Iter [30/1] Loss: 2.3178\n",
      "Epoch [14/20], Iter [40/1] Loss: 1.9877\n",
      "Epoch [14/20], Iter [50/1] Loss: 1.7261\n",
      "Epoch [14/20], Iter [60/1] Loss: 2.0360\n",
      "Epoch [14/20], Iter [70/1] Loss: 2.0349\n",
      "Epoch [14/20], Iter [80/1] Loss: 2.1305\n",
      "Accuracy (train), Top1: 59.61%, Top5: 85.03%\n",
      "Accuracy (val), Top1: 66.49%, Top5: 86.98%\n",
      "Accuracy (test), Top1: 57.31%, Top5: 73.13%\n",
      "Saved best_agg model\n",
      "Epoch [15/20], Iter [10/1] Loss: 2.3610\n",
      "Epoch [15/20], Iter [20/1] Loss: 2.1476\n",
      "Epoch [15/20], Iter [30/1] Loss: 2.4343\n",
      "Epoch [15/20], Iter [40/1] Loss: 2.1920\n",
      "Epoch [15/20], Iter [50/1] Loss: 1.8920\n",
      "Epoch [15/20], Iter [60/1] Loss: 1.7977\n",
      "Epoch [15/20], Iter [70/1] Loss: 1.9122\n",
      "Epoch [15/20], Iter [80/1] Loss: 1.6818\n",
      "Accuracy (train), Top1: 61.85%, Top5: 86.18%\n",
      "Accuracy (val), Top1: 59.03%, Top5: 83.16%\n",
      "Accuracy (test), Top1: 55.68%, Top5: 72.60%\n",
      "Epoch [16/20], Iter [10/1] Loss: 1.9962\n",
      "Epoch [16/20], Iter [20/1] Loss: 2.0617\n",
      "Epoch [16/20], Iter [30/1] Loss: 2.0497\n",
      "Epoch [16/20], Iter [40/1] Loss: 1.8754\n",
      "Epoch [16/20], Iter [50/1] Loss: 1.9831\n",
      "Epoch [16/20], Iter [60/1] Loss: 1.8672\n",
      "Epoch [16/20], Iter [70/1] Loss: 1.9301\n",
      "Epoch [16/20], Iter [80/1] Loss: 1.9083\n",
      "Accuracy (train), Top1: 62.22%, Top5: 85.65%\n",
      "Accuracy (val), Top1: 65.80%, Top5: 86.11%\n",
      "Accuracy (test), Top1: 57.75%, Top5: 73.20%\n",
      "Epoch [17/20], Iter [10/1] Loss: 1.5154\n",
      "Epoch [17/20], Iter [20/1] Loss: 1.8987\n",
      "Epoch [17/20], Iter [30/1] Loss: 1.4909\n",
      "Epoch [17/20], Iter [40/1] Loss: 2.0665\n",
      "Epoch [17/20], Iter [50/1] Loss: 2.0866\n",
      "Epoch [17/20], Iter [60/1] Loss: 1.9139\n",
      "Epoch [17/20], Iter [70/1] Loss: 1.6599\n",
      "Epoch [17/20], Iter [80/1] Loss: 1.8799\n",
      "Accuracy (train), Top1: 62.91%, Top5: 85.95%\n",
      "Accuracy (val), Top1: 63.37%, Top5: 84.55%\n",
      "Accuracy (test), Top1: 58.29%, Top5: 73.33%\n",
      "Epoch [18/20], Iter [10/1] Loss: 1.7320\n",
      "Epoch [18/20], Iter [20/1] Loss: 1.7385\n",
      "Epoch [18/20], Iter [30/1] Loss: 1.7339\n",
      "Epoch [18/20], Iter [40/1] Loss: 2.0191\n",
      "Epoch [18/20], Iter [50/1] Loss: 1.9532\n",
      "Epoch [18/20], Iter [60/1] Loss: 1.6197\n",
      "Epoch [18/20], Iter [70/1] Loss: 1.9544\n",
      "Epoch [18/20], Iter [80/1] Loss: 1.8325\n",
      "Accuracy (train), Top1: 63.45%, Top5: 85.82%\n",
      "Accuracy (val), Top1: 66.49%, Top5: 87.85%\n",
      "Accuracy (test), Top1: 58.02%, Top5: 72.85%\n",
      "Saved best_agg model\n",
      "Epoch [19/20], Iter [10/1] Loss: 1.5447\n",
      "Epoch [19/20], Iter [20/1] Loss: 2.1368\n",
      "Epoch [19/20], Iter [30/1] Loss: 1.7269\n",
      "Epoch [19/20], Iter [40/1] Loss: 2.3784\n",
      "Epoch [19/20], Iter [50/1] Loss: 1.5692\n",
      "Epoch [19/20], Iter [60/1] Loss: 2.2441\n",
      "Epoch [19/20], Iter [70/1] Loss: 1.6184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Iter [80/1] Loss: 1.8021\n",
      "Accuracy (train), Top1: 64.99%, Top5: 86.86%\n",
      "Accuracy (val), Top1: 66.67%, Top5: 87.67%\n",
      "Accuracy (test), Top1: 58.59%, Top5: 73.12%\n",
      "Saved best_agg model\n",
      "Epoch [20/20], Iter [10/1] Loss: 2.0159\n",
      "Epoch [20/20], Iter [20/1] Loss: 1.9775\n",
      "Epoch [20/20], Iter [30/1] Loss: 1.6295\n",
      "Epoch [20/20], Iter [40/1] Loss: 1.8501\n",
      "Epoch [20/20], Iter [50/1] Loss: 1.7039\n",
      "Epoch [20/20], Iter [60/1] Loss: 1.6786\n",
      "Epoch [20/20], Iter [70/1] Loss: 1.6042\n",
      "Epoch [20/20], Iter [80/1] Loss: 1.9402\n",
      "Accuracy (train), Top1: 64.57%, Top5: 86.67%\n",
      "Accuracy (val), Top1: 68.23%, Top5: 87.85%\n",
      "Accuracy (test), Top1: 59.70%, Top5: 73.02%\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model, dataloaders, 20, device, log_freq, data_path + '/../log/')\n",
    "torch.cuda.empty_cache()\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seen:\n",
      "0.039380110512494036\n",
      "0.00021236080341905416\n",
      "\n",
      "unseen:\n",
      "0.04217024260453315\n",
      "0.03223300108340782\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAA6dklEQVR4nO3de3xU9Z3/8deZM7lO7pdJQgiRKN64+lippWqosIgQkCxKu/7W/a1Ua4uuFmltQVsqaAVta0XbWija2lb9bWsttKSuSBTwjlotoKLcIkkgE8h9ZpJMZub7+yOZgUBCZiZzzXyej0d3ycm5vGdiPvnO93zP96sppRRCCCHigiHSAYQQQoSPFH0hhIgjUvSFECKOSNEXQog4IkVfCCHiiDHSAYbidrtxuQIbYKTrWsDHhpLk8o/k8o/k8s9IzZWQoA+4PeqLvsulaG21B3RsVlZqwMeGkuTyj+Tyj+Tyz0jNlZ+fPuB26d4RQog4IkVfCCHiiBR9IYSII1Hfpy+EiG8ul5OWluM4nY6QnN9i0YjG2Wh8zWU0JpKdnY+u+1bOpegLIaJaS8txkpNTMZkK0TQt6OfXdQMulzvo5x0uX3IppbDZ2mlpOU5eXpFP55XuHSFEVHM6HZhMGSEp+LFO0zRMpgy/PgVJ0RdCRD0p+IPz972Roi9GLEPDfgz1H0c6hhBRRYq+GJmUIvmlR0ne9otIJxEiqsiNXDEiGZqOYGiuQ2kGcPaAMSHSkYSIClL0xYhk/OwNADTlxtBSjzv/nMgGEjGrs7OTlSuX09jYiNvt4qabbqG4uISf//xn2O12srKyuOee+8jLy6O+vo6f/vQhWltbSE5O5nvf+z6lpefwox/dh8lkYt++T2hqauK22+7gqqv+NSKvR4q+GHmUwrj/DdxpuRisTRiajkjRHyGMH79CwkfVQT2na+IsXBd+edDvv/POm+Tl5fPjH68DwGq18p3v3MmaNT8lOzub6uqtbNjwC+6554c8/PCP+M53VlBSMoaPPtrLT3+6lsce+xUAJ06c4Je/3Mjnn9ewfPkyKfpCBIuh6XMMzXV0T7+FxJ1PYWg6EulIIoaVlZ3HL36xjl/+8jEuv/xK0tPTOXToIHfddTsAbreL3Nw87HY7e/bs5gc/WO49tqfn5FDK8vIvYzAYGDu2jObm5rC/Dg8p+mLEMX72Bkoz4LzgShL2/K8U/RHEefEMnBfPCOo5dd0AZ3kIasyYUp588ve89dYb/OpXP2fq1MsYO7aM9et/028/m81Kenoav/3tswOeJyHh1PtKkXsCWEbviJFFKYyfvYFr9HiUKQt3TgmGptpIpxIx7MSJ4yQlJTN79lxuuOE/+fjjvbS2trB3724AnE4nhw4dxGRKo6iomFde2Qb0Pi27f/9nkYw+IGnpixHF0PQ5hpZ6HJfMB8CdOwb9wNvg7AZjUoTTiVh08OABfvnLdWiaAaPRyHe+sxxd13n00Z9gtVpxuVx85Ss3UFZ2LitX3s9PfrKWp59+EpfLycyZVzNu3PmRfgn9SNEXI4qna8c1bhrQW/Q1FIbmetzmsginE7Hossumcdll087Y/otf/PqMbaNGFfPII4+fsf3ee+/r9/XLL78WtHz+ku4dMaLon3+Ie9SFqNQsoLfoA9KvL0SfIVv6K1asYPv27eTm5rJlyxYAli5dyuHDhwHo6OggPT2dzZs3U1dXx9y5cxk7diwAkydPZvXq1QDs3buXFStW0NXVxfTp07n33ntlPg0RdJq1CdeYyd6v3dlFKIMuRV+IPkMW/YULF3LjjTfyve99z7vt0Ucf9f577dq1pKWleb8eM2YMmzdvPuM89913H6tXr2bKlCl8/etfZ+fOnUyfPn2Y8YU4hVJo9jaUKfvkNj0Bd9YoKfpC9Bmye2fq1KlkZmYO+D2lFC+++CLz5s076zkaGxuxWq1ccsklaJpGZWUl1dXBfcBCCLqtaG4nKjW732Z37hgZwSNEn2HdyH3vvffIzc3lnHPO8W6rq6ujsrKStLQ0li5dyqWXXorFYqGwsNC7T2FhIRaLxadr6LpGVlZqQPl03RDwsaEkufzjay7VeBwXkGIuwHTK/u7ic3EfeJPMVANaYnLYc4XbSMtlsWi9Y+lDKNTnD5SvuTTN9zo5rKK/ZcuWfq18s9nMq6++SnZ2Nnv37uX222+nqqpqwCW/fO3Pd7kUra32gPJlZaUGfGwoSS7/+JpLbzhGCmAlFfcp++umQlKUouPwZ7gLzgt7rnAbabmUUiFd2SqWV87yUOrMOpmfnz7gvgH/eXM6nbz88svMnTvXuy0xMZHs7N6P1hMmTGDMmDEcPnyYwsJCGhoavPs1NDRgNpsDvbQQA9LsLQDekTseMoJHiJMCLvpvvvkmZWVl/bptmpubcblcANTW1lJTU0NJSQlmsxmTycSHH36IUopNmzYxc+bM4acX4hSarRU4s+irrCKUwSj9+kLgQ/fOsmXL2LVrFy0tLZSXl3PHHXewaNEi/v73v1NRUdFv33fffZfHHnsMXdfRdZ1Vq1aRlZUF9I7e8QzZLC8vp7y8PCQvSMQvzdaC0hMgydT/G7oRd3axtPRFwI4dO8p3v7uU3//+jwA8++zv6ey088EH73PxxRP44IP36OiwsmLFD5g8+RIOHTrImjWr6OlxopSbBx54mJKSMbz00t95/vn/R0+Pk4svHs+3v937dO+uXW/z5JPr6elxMGrUaO6554ekp6dx/fXzmTNnHm+8sROn08n99z9Eaek5w3otQxb9Rx55ZMDta9euPWPb7NmzmT179oD7T5w40TvOX4hQ0OwtvcM1B7hf5M4djW45GIFUIpgsr+2kYcerQT3nqKtmkH/5lQEf73K5+PWvf8dbb73OU0/9mnXrfsnmzX9m0aIbuPrqOfT09OB2u6ipOUx19cs88cRTGI1GfvKTtWzd+iLTpl3B008/yaOP/pKUlBT+8Iff8j//8wy33PINADIzM3nqqWd44YU/8dxzv2f58h8M6/XKNAxixNBsrWd07XgoUw5a5z/CG0jEhenTrwLgggsuoqHhKADjx0/id797isZGC9Onz6CkZAzvv7+LTz/9hFtu+b8AdHd3kZ2dzUcf7aGm5hBLltwMgNPZw/jxE085/wzv+XcE4Q+eFH0xYmj2VlRmwYDfUykZaI5OWToxxhVcWU7BlcHtGvZllIyu6/1GIToc3d5/JyYmAmAw6N57mldffQ3jx0/gzTdfZ9myO1i+/PsopZgzZx7f/OZ/9zv366/v5NJLL2PVqgcHvHZCQuIpOZ3+v8DTROfgVCECoNlbBm/pp2T07tPVHsZEYqTIycmlpaWZtrZWHA4Hb775+ln3r6+vY9SoYhYt+neuuKKcgwf38y//8gW2b6+mpaV3AZX29jYaGo4xfvxE9uz5J3V1vQMNurq6OHLk85C9Fmnpi5HB7UKztw9d9DvbUWm5YQwmRgKj0chNN32dW2+9iaKiUUPeTH3llZd56aUXMRqN5OTksnjxLWRkZPL1ry/hrrv+G6Xc6LqRZcu+x4QJE7n33vu47757vSttff3rS7xzmAWbpgZ6ciqK9PS45OGsMInlXJq1GdOvF9M145s4J8854/uGur2k/uleOheuwlU6JWy5ImGk5Wpo+JzCwtIQJOo1Eh7OGug9CvrDWUJEE83eCoAyZQ34feneEaKXFH0xImg2z9O42QPv4O3e6QhXJCGikhR9MSJ4p2AwDVz0VXI6Cg3N3hbOWCJIorwXOqL8fW+k6IsRYbApGLwMOiSngXTvxByjMRGbrV0K/wCUUths7RiNiT4fI6N3xIig2VtRiamQMPji5yolHc0uRT/WZGfn09JyHKu1NSTn1zQtKv+g+JrLaEwkOzvf5/NK0RcjgmYbfIy+h0rJlBu5MUjXjeTlFYXs/CNttNNQpHtHjAgGe+ugI3c8VEoGWqcUfRHfpOiLEUGzteAebOROH5WSId07Iu5J0RcjguZrS7+rHaKw/1aIcJGiL2Kfsxut2zbocE0PlZKJ5nZBty1MwYSIPlL0Rcw7OVxzqKLf+1i61iUPaIn4JUVfxLyhpmDwOHXSNSHilRR9EfO8RX/Iln5m3/7yVK6IX0MW/RUrVjBt2jTmzZvn3fb4449z5ZVXsmDBAhYsWMCOHTu831u/fj2zZs1i9uzZvPbaa97te/fuZf78+cyaNYsHHnggKh+GELHJO++Ory19Gasv4tiQRX/hwoVs3LjxjO033XQTmzdvZvPmzUyfPh2AAwcOUFVVRVVVFRs3bmTVqlXelWTuu+8+Vq9ezdatW6mpqWHnzp1BfikiXnn79Pta8oOR7h0hfCj6U6dOJTPz7L9MHtXV1VRUVJCYmEhJSQmlpaXs3r2bxsZGrFYrl1xyCZqmUVlZSXV19bDDCwFgsLf0FnR9iAfME5JReoKM1RdxLeBpGJ555hk2bdrEhAkTWL58OZmZmVgsFiZPnuzdp6CgAIvFgtFopLCw0Lu9sLAQi8Xi03V0XSMrKzWgjLpuCPjYUJJc/hkql8vRgUrP8Sm705RJkttOahBeZ6y+X5EiufwTqlwBFf0bbriB2267DU3TWLduHWvXrmXNmjUD9tMPNmmQpmk+XcvlUrJyVpjEaq6UthOo5EysPmRPSUpHtTbTEYTXGavvV6RILv8MN1dQV87Ky8tD13UMBgOLFi1iz549QG8LvqGhwbufxWLBbDafsb2hoQGz2RzIpYU4g2ZrRaX61gXpfSpXiDgVUNFvbGz0/nvbtm2MGzcOgBkzZlBVVYXD4aC2tpaamhomTZqE2WzGZDLx4YcfopRi06ZNzJw5MzivQMQ9rduKSh64VXM6lZIpN3JFXBuye2fZsmXs2rWLlpYWysvLueOOO9i1axf79u0DoLi4mNWrVwMwbtw45syZw9y5c9F1nZUrV6LrOtA7emfFihV0dXVRXl5OeXl5CF+WiBtuF1q3DXwu+ulS9EVcG7LoP/LII2dsW7Ro0aD7L1myhCVLlpyxfeLEiWzZssXPeEIMoW8eHZWc5tPuKiWj94+Eyzn0aB8hRiB5IlfENK3LCoBK8rXo9z2VK619Eaek6IuYpnX3FX2fu3fkqVwR36Toi5jmben72L2DPJUr4pwUfRHTPNMk+9OnD8hTuSJuSdEXMc3T0sfPoo9074g4JUVfxDZ/b+T29f1LS1/EKyn6IqZpXR2ohGTfh1/qRlSSSW7kirglRV/ENK3b5vPIHQ95KlfEMyn6IqZpXR2+j9zpo1LSZfUsEbek6IuYpnVZAyj6GbI4uohbUvRFTNO6OsDHm7geKiVTWvoibknRF7GtK4A+/eR0aemLuCVFX8QupdC6A+jTT05Dc/WAsztEwYSIXlL0RexydqO5nAEVfTjlwS4h4ogUfRGzTs6741/3jucegBR9EY+k6IuY5fdka328+0vRF3FIir6IWd6bsf6O3vF073RL0RfxZ8hn11esWMH27dvJzc31rnz10EMP8eqrr5KQkMCYMWNYs2YNGRkZ1NXVMXfuXMaOHQvA5MmTvUsp7t2717tc4vTp07n33nvRNC2EL02MeN2BtvT75t+Rlr6IQ0O29BcuXMjGjRv7bbv88svZsmULf/vb3zjnnHNYv36993tjxoxh8+bNbN682VvwoXeN3NWrV7N161ZqamrYuXNnEF+GiEeB9umrJFO/44WIJ0MW/alTp5KZmdlv2xVXXIHR2PshYcqUKTQ0NJz1HI2NjVitVi655BI0TaOyspLq6uphxBbi1Ln0Tf4dmJSK0gzSvSPi0rBXhv7zn//MnDlzvF/X1dVRWVlJWloaS5cu5dJLL8VisVBYWOjdp7CwEIvF4tP5dV0jKys1oGy6bgj42FCSXP4ZLJeLbpRBJzM/1++uQmeyiSR3J6nDeL2x9n5FmuTyT6hyDavoP/HEE+i6zrXXXguA2Wzm1VdfJTs7m71793L77bdTVVWFUuqMY339JXW5FK2t9oDyZWWlBnxsKEku/wyWK6m1BT05DWtbp9/nTE004Wpvo3sYrzfW3q9IOz2Xo72dfb94nPSyMgrKp5NaNCoqckWL4ebKzx+42zPgov+Xv/yF7du389vf/tZbwBMTE0lMTARgwoQJjBkzhsOHD1NYWNivC6ihoQGz2RzopYXo1WX1e+SOh0pOl+6dCDv60ou07t1D60d7qf3rZjLOv4ALb7ud5HypDaEU0JDNnTt38utf/5onnniClJQU7/bm5mZcLhcAtbW11NTUUFJSgtlsxmQy8eGHH6KUYtOmTcycOTM4r0DELa3b/xk2PVSySebfiSBXVxdHt71M7qVTuezxXzL23/8P1sOHqKvaEuloI96QLf1ly5axa9cuWlpaKC8v54477mDDhg04HA4WL14MnBya+e677/LYY4+h6zq6rrNq1SqysrKA3tE7niGb5eXllJeXh/SFiZFP67KiTNkBHauS0zG0NQY5kfCV5bWdOK1WRs+dR1J2NiXzr6Xj8CGOv/MO5/7nf6HpeqQjjlhDFv1HHnnkjG2LFi0acN/Zs2cze/bsAb83ceJE7zh/IYJB6+rAnVMS2MFJadLSjxDldlP3YhXp555Hxvnne7ebp32JE++8TesnH5M9YWIEE45s8kSuiFm9SyUG2r2TBt02UO4gpxJDaXr/PbosFkZXzOs3oCN78hT05BSOv/VmBNONfFL0RWxyuwJaH9dDJaehKTc4/B/5I4anrmoLyflm8qZ+od92PTGR3Esv5cSuXbidzgilG/mk6IvY1G3r/f/+PpjVR8lMmxFhrTlM+/7PKL5mDprhzPJjnvYlnHYbLbv/GYF08UGKvohJAU+r3OfkpGu2oGUSQ2v9+GMA8r84bcDvZ02YiDEtjUbp4gkZKfoiJp2cgmEYffqnnEeER/tnn5JsNpPYN6rvdAajkbwvXEbT++/h6paVzUJBir6IScNt6SNz6oedUor2/Z+RMe78s+5n/uKXcHd30/zhB2FKFl+k6IuY5Hma1jNjpr+kTz/8OhsbcbS2Dln0My+6CD05hbZPPg5TsvgiRV/EpOH36ffNqS9TMYRN8yf7AIYs+prBQNrYsXQcOhSOWHFHir6ITZ6++AD79DEmonSjtPTDqPmTT9CTkzGVDP1AXXpZGdYjn8vQzRCQoi9iktZlRSWmgCHAx/U1DZWUJkU/jFo+2Uf6uef5NMVC2tgyVE8P9rq6MCSLL1L0RUzSuqyB38T1SE6T7p0wcXV10Xa4pt+0C2eTXlYGQMehg6GMFZek6IuY1Fv0A+za6aOS0mT0Tpi0HzwAbveQ/fkeyeYCjKkmOg5Lv36wSdEXMUnr6vCOwAmUzKkfPu2ffQZAxnnjfNpf0zTSysqwys3coJOiL2KS1m0N/CZun9459aXoh0P7/s9ILx2D0eT7ENv0sWXYao/gdjhCmCz+SNEXsanLGpyWvhT9kFNuNx3795Nz4YV+HZdWVoZyubDV1oYoWXySoi9ij1K9ffopw7uRq5LS0Bx2cLuCFEwMxH70KE67jeyLLvLruPSxfTdzD8vN3GCSoi9iT08nmts57Bu53hk6ZdK1kPKMwMm+wLebuB5JeXkkpKfLQ1pBNmTRX7FiBdOmTWPevHneba2trSxevJirr76axYsX09bW5v3e+vXrmTVrFrNnz+a1117zbt+7dy/z589n1qxZPPDAAyilgvxSRLw4+TRuxrDO430qV7p4QspeV4uWkICpeJRfx2maRtrYMqwygieohiz6CxcuZOPGjf22bdiwgWnTprF161amTZvGhg0bADhw4ABVVVVUVVWxceNGVq1a5V0o/b777mP16tVs3bqVmpoadu7cGYKXI+KB1jm8GTY9Ts6/IzNthpKttpbUUcUYAlj3Nr2sDFtdncy4GURDFv2pU6eSmZnZb1t1dTWVlZUAVFZWsm3bNu/2iooKEhMTKSkpobS0lN27d9PY2IjVauWSSy5B0zQqKyuprq4O/qsRceHktMrD7NOXOfXDwl5fh2n06ICOTRt7Lrjd2I58HuRU8WvIhdEH0tTUhNlsBsBsNtPc3AyAxWJh8uTJ3v0KCgqwWCwYjUYKCwu92wsLC7FYLD5dS9c1srJSA4mJrhsCPjaUJJd/Ts/lrnPgBtLN+WjDyKt68nABJoMDQwDniZX3K5J6bDa6m5rIPa8soFxJU8bzMeA8VkvW1CkhyRhN79epQpUroKI/mIH66TVNG3S7L1wuRWurPaA8WVmpAR8bSpLLP6fnMjY1kQy09ySghpFX6zFiAjqbm+gJ4Dyx8n5FUlvfQ1mGvAJcLrffuZSeTEJGBsf37SenPDSvKZrer1MNN1d+/sCfhAMavZObm0tjYyMAjY2N5OTkAL0t+IaGBu9+FosFs9l8xvaGhgbvJwUh/DXcVbM8vOP8pXsnZDwTpqWOHnpmzYFomkZq8Wg6j9YHM1ZcC6joz5gxg02bNgGwadMmZs6c6d1eVVWFw+GgtraWmpoaJk2ahNlsxmQy8eGHH6KU6neMEP7SOttRCcmgJwzvRLoRlZAsN3JDyFZXiyEpieS8vIDPkVo8Glt9vYz4C5Ihu3eWLVvGrl27aGlpoby8nDvuuINbb72VpUuX8vzzz1NUVMS6desAGDduHHPmzGHu3Lnous7KlSvR++7Y33fffaxYsYKuri7Ky8spLy8P7SsTI1bvg1nDG67poZJleuVQstfVYho9Gs0Q+CNBpuJiXHY7jtYWkrJzgpguPg1Z9B955JEBtz/99NMDbl+yZAlLliw5Y/vEiRPZsmWLn/GEOJPW1TH8B7P6yJz6oWWrqyNnyiXDOkdqce/IH3t9vRT9IJAnckXM6S36w5xLv4+SOfVDxtHeTk9bG6YA+/M9UkcXA8iCKkEiRV/EnGC29EmWOfVDxV7XO1FaaoBj9D0SMjIxpqVhr5ebucEgRV/EHK3LCsOcgsFDundCx9ZX9H1ZE/dsekfwFGOrl5Z+MEjRF7FFuXunVQ5Wn75074SMva4OY6qJxKzsYZ8rtXg09vo6GcETBFL0RWzptqMp97CnVfZQyeloTgc4ZW6XYLPV1ZJaMtrnBzHPxlRcjNNqpae9PQjJ4psUfRFTvA9mJQWp6PcN/fRM4iaCQymFvbZu2DdxPU6O4JEunuGSoi9iirfoB6ul33cerVNakMHkaG3BabcN+yauR+qovhE8cjN32KToi5hyci79YPXpe1r6UvSDybPEYbBa+ok5OejJKdhlOoZhk6IvYoqnOAdtnL6ne6dLin4weVrkgc65czrPCB7p3hk+Kfoippxs6UuffjTrPHoUY1o6iRnBGVoLveP9pXtn+KToi5jinRwtiA9nKTTp3gky+7F6Ukf5tzziUFKLi3G0ttJjlSG2wyFFX8SWrg5UkgkM/i+9NyCD3vsHRIp+UNmPHiWlqCio5zSdMgePCJwUfRFTgjnvjodKSZeWfhD12Kz0tLV5R9wES2qxZwSP9OsPhxR9EVO0Lmvwi35yhhT9IOo8egwg6N07Sbl5GJKSpOgPkxR9EVO0ziBOttZHpWTIQipB5BlWGeyirxkMpBaNwn70aFDPG2+k6IuYonV1BO3BLA+VIi39YOo8dhRN10nOD/6SqCmjRmE/JkV/OKToi5gSmj79vqIvk3kFhf3oUVIKi9D0IN1sP0XqqFF0nziBq1vmSgqUFH0RO9wutG4bhOJGrqsHerqCet54ZT96NOhdOx6po4pBKTobGkJy/ngw5HKJgzl06BB33XWX9+va2lruvPNOOjo6+OMf/0hOTu+yZsuWLWP69OkArF+/nueffx6DwcD3v/99rrzyymHGF3Gl2wYEbwoGj5MPaLWjElOCeu5443Y66Wq0kPeFL4Tk/KlFvX9M7EfrSSstDck1RrqAi35ZWRmbN28GwOVyUV5ezqxZs3jhhRe46aabuPnmm/vtf+DAAaqqqqiqqsJisbB48WJeeukl78LpQgwl2FMweJw6/47KLAjqueNNV6MF5XJ5i3OwpRQWgqbRKTdzAxaU7p233nqLkpISiosHH5dbXV1NRUUFiYmJlJSUUFpayu7du4NxeREngj0Fg8fJ+XdkBM9weUbWBHuMvochMZHkvHy5mTsMAbf0T1VVVcW8efO8Xz/zzDNs2rSJCRMmsHz5cjIzM7FYLEyePNm7T0FBARaLZchz67pGVlZqQLl03RDwsaEkufzjyeW2OHADafn5aEHMqVxmXIBJ68Lgx3mj/f2KhOPNxwEovOhcElL7ZwhWrozSErosx4L2GuPt5zjsou9wOHjllVf49re/DcANN9zAbbfdhqZprFu3jrVr17JmzZoBlznzZUUdl0vR2moPKFtWVmrAx4aS5PKPJ5ex6QTJQLszARXMnD2JpAGdTSfo8eO80f5+RULzoRoSs7OxOQBH/wzBypWQX8CJ3XtoabaiGYbfWTFSf475+QN/Ih72O7Zz507Gjx9PXl4eAHl5eei6jsFgYNGiRezZsweAwsJCGk65426xWDCbgz+OV4xc3gVUgty9Q1IqSjPIWP0gCOXIHY/UUaNwOxx0NzWF9Doj1bCLflVVFRUVFd6vGxsbvf/etm0b48aNA2DGjBlUVVXhcDiora2lpqaGSZMmDffyIo5oXVaUZoCkIH/k1Qy9a+VK0R8WpRT2Y0dJCdFNXI+Uor45eKRfPyDD6t7p7OzkzTffZPXq1d5tP/7xj9m3bx8AxcXF3u+NGzeOOXPmMHfuXHRdZ+XKlTJyR/hF6+yAJBNoIXi8RCZdG7aetjZcdnvIRu54eD5JdB6th0mTh9hbnG5YRT8lJYV33nmn37Yf//jHg+6/ZMkSlixZMpxLingWgikYPFRKBsjonWHxzLmTEuLunYSMDIwmE/Zjx0J6nZFKnsgVMSMUUzB49E7FIEV/OEI9XNND0zRSR8nEa4GSoi9iRkiLvkyvPGz2o/UYkpJI6nsaP5RSRhXLA1oBkqIvYkbvXPrBnYLBo3d6ZZl0bTjs9fWkjioOyjDKoaQWjcLR2oLTHn1DLaOdFH0RM7TO9tB277hdZ4wtF76z19d7V7cKNc/NXBnB4z8p+iI2OHvQerq8UyYEm+cGsXTxBMZpt+NoaSa1bx3bUPMMC5UuHv9J0RcxQbO3AKBSs0Jy/lNn2hT+O7laVnha+slmM5que68rfCdFX8QEzdZX9E2huUl4sujLCJ5A2Ot7i69pdHiKvsFoJLmgQEbwBECKvogJJ4t+dkjOf+r0ysJ/9vp6tISEkCyROBhT8WhZJD0AUvRFTDhZ9LNCcv6T0ytL0Q+Evb6O1BAtkTiY1NGj6WxowO1whO2aI4EUfRETDLZmFFrI+vRJTEEZjNLSD1A4R+54pBaPBqXkyVw/SdEXMUGztaJSM8EQopakpvWulStF32+u7m66ThwP201cD9PoEgDsdbVhvW6sk6IvYoJmawlZf75H71QMUvT91XnsKChF6ujwDNf0SCnq7U6ySb++X6Toi5ig2ZrDVPRl9I6/PCN3wt29YzAaSSkoxF4nRd8fUvRFTNDsraEv+skZciM3ALb6ejAYSCksCvu1U0ePxiZF3y9S9EXUU253b9FPDW3RR7p3AmKvryOloBCDMShLbvsldfRouhotuGQEj8+k6Ivo19mO5naFoXsnHbqs4HaF9Dojjf1o+EfueJhGl4BSvQuqCJ9I0RfRr6MZAHc4+vSVG7ptIb3OSOJ2OulsaIhY0ffM9SNdPL4b1uexGTNmYDKZMBgM6LrOCy+8QGtrK3fddRf19fUUFxfz6KOPkpmZCcD69et5/vnnMRgMfP/73+fKK68MyosQI5uy9i6AHeqWvrtvigeDtRl3iCZ2G2k6GxrA7Q7bRGunSyks7J2DR4q+z4bd0n/66afZvHkzL7zwAgAbNmxg2rRpbN26lWnTprFhwwYADhw4QFVVFVVVVWzcuJFVq1bhcsnHaOEDa2inYPBQ6XkAaB0nQnqdkcQzDYIpQi19g9FISlGRDNv0Q9C7d6qrq6msrASgsrKSbdu2ebdXVFSQmJhISUkJpaWl7N69O9iXFyNRX/dO2Iq+VYq+r+z19aBp3qmOI8FUPFoe0PLDsG+333zzzWiaxle/+lW++tWv0tTUhNncO+mS2Wymubn3F9ZisTB58smV6wsKCrBYLEOeX9c1srJSA8qm64aAjw0lyeUfZWuGpFSy8kO7DJ/KSMJlMJDS04buw/sQre9XOHPtb6gntbCA3IKh/yCHKlfOeWUc3/UOack6xuQkv4+Pt5/jsIr+c889R0FBAU1NTSxevJiysrJB91UDLEOnadqQ13C5FK2tga1mlJWVGvCxoSS5/JPe3ow7NSss2VJNObhONNDtw7Wi9f0KZ66WAwdJKz3Hp+uFKpchrwCU4tgn+0kfO3gNCneu4Rpurvz8gVeZG1b3TkFBAQC5ubnMmjWL3bt3k5ubS2NjIwCNjY3k9C2SXFhYSENDg/dYi8Xi/UQgxNkoa3PI5tE/41ppudKn7yOn3U6XxUJa6TkRzWHqm/5Bbub6JuCib7fbsVqt3n+/8cYbjBs3jhkzZrBp0yYANm3axMyZM4HekT5VVVU4HA5qa2upqalh0qRJw38FYuTraMIdqtk1T+NOz8Mgffo+sdUeAcBUWhrRHCkFhWhGIzbp1/dJwN07TU1N3H777QC4XC7mzZtHeXk5EydOZOnSpTz//PMUFRWxbt06AMaNG8ecOXOYO3cuuq6zcuVK9DDOvS1imLUFVRrip3H7qLQ8tEPvglLgQ/djPLPW1ACQds45Ec2h6TqpRaOkpe+jgIt+SUkJf/3rX8/Ynp2dzdNPPz3gMUuWLGHJkiWBXlLEI0cnODrD172TnofmdEC3FZIH7hMVvayf15CQkUFiVnj+IJ+NacwYWj/+KNIxYoI8kSuiWqhXzDqdOy0XAIP06w/J9vnnmMaU+jQgI9TSxpbhaGnB0doa6ShRT4q+iGqhXhD9dCcf0GoKy/VildvpxFZXG/GbuB7pY8cC0HH4UISTRD8p+iKqGUK8IPrpThb942G5XqyyH61HOZ0R78/3SDtnLGga1sOHIx0l6knRF1HN09IP9WRrHio1C6UZMFilpX82ts8/B4ialr6enExKUZG09H0gRV9ENc3eAroxfDdVDToqLUfG6g/B+nkNhsREUorCv3DKYNLHlmGVoj8kKfoiqmm2FkjLDuvwSZWWhyYt/bOy1tRgKilBM0RPCZGbub6Jnp+YEAPQbM2QFp6buB7u9FwZvXMWSqnekTtR0rXjITdzfSNFX0Q1zdaKFuai39vSP9H7gJY4Q/eJEzjttqjpz/fw3sw9JEX/bKToi6im2VogPcxF3/OAVldHWK8bK6xRdhPXw3szt0ZG8JyNFH0RvVzO3oXKw92943lAS/r1B2T9/DBoGqaSkkhHOYPczB2aFH0RtTRrExoKrW/sfLjIClpnZz10iNSiUejJyZGOcgbPzdzulpZIR4laUvRF1DK01AOg5Ye3RSlFf3DK7abt031kXHhhpKMMyHMzV1r7g5OiL6KWobm36JMX5qLvfUBLiv7pbEeO4OrsJPOC6Cz68mTu0KToi6hlaKlDJadDamaYL+x5QEv69E/X9uk+gKgt+nIzd2hS9EXU0prrcGcXR2QWR++wTdFP275PSMrNJTk/P9JRBpVedi4dB/aj3O5IR4lKUvRF1DI01+POGR2Ra/c+oCUt/VMppWj7dB+ZF14U6ShnlXXxeHra22UlrUFI0RfRqcuKwd6CO6c4IpdX6fm9N3LlAS2vLksDPW1tZERp145H1vgJALR+JIuqDCTgon/s2DH+8z//kzlz5lBRUeFdLevxxx/nyiuvZMGCBSxYsIAdO3Z4j1m/fj2zZs1i9uzZvPbaa8NPL0Ysz8gdd3ZkWvoqLRfNJQ9onap13ydA9PbneyTn5ZFcUEjrR3sjHSUqBbxcoq7rLF++nPHjx2O1Wrnuuuu4/PLLAbjpppu4+eab++1/4MABqqqqqKqqwmKxsHjxYl566SVZJ1cMyDNyJ2LdOxnm3hxtDbhTMiKSIdq079tHQno6qcWR+fTlj+zxE2h88w2Uy4UmNaafgFv6ZrOZ8ePHA5CWlkZZWRkWi2XQ/aurq6moqCAxMZGSkhJKS0vZvXt3oJcXI5yhpQ5lMKIyCyJyfXd+73hvQ6OM9/Zo+3QfGRdcGBXLIw4la8IEXF2ddMg8PGcISp9+XV0dn3zyCZMnTwbgmWeeYf78+axYsYK2tjYALBYLhYWF3mMKCgrO+kdCxDdDcx3urCIwRKaVpjLMqCQTuhR9ALqbm+lqbIz6rh2PzIsuBpAungEE3L3jYbPZuPPOO7nnnntIS0vjhhtu4LbbbkPTNNatW8fatWtZs2YNaoAbYr60GHRdIysrNaBsum4I+NhQklxDc7YdRSsoJSsrNWK5XEXnkdD8OSmDXDua3q9ThSJX/T/fA2D01Cmx8fuYlUrG2LFYP/2YrKz/iJ5cfghVrmEV/Z6eHu68807mz5/P1VdfDUBe3sl5UhYtWsQ3v/lNAAoLC2loaPB+z2KxYDabh7yGy6VobbUHlC8rKzXgY0NJcg3B5cTUfBTH2MtwtNojlisxp5SEf/4vrc0dA37iiJr36zShyHX0H7vRk5NROYUx8/uYfuHFHN22labGVvTExKjJ5avh5srPH3i1uYC7d5RS3HvvvZSVlbF48WLv9sbGRu+/t23bxrhx4wCYMWMGVVVVOBwOamtrqampYdKkSYFeXoxgWlsDmtsVseGaHu78MjSX4+R0EHFKKUXzh/8g88KLYuqmaPaECaieHto/+zTSUaJKwC39999/n82bN3P++eezYMECAJYtW8aWLVvYt6/3Ue3i4mJWr14NwLhx45gzZw5z585F13VWrlwpI3fEgLzDNSM0csfDbS4DwHD8EO68MRHNEkkdhw7SfeIEpQuvj3QUv2RccCGartP60V6yJ0yMdJyoEXDRv/TSS/n00zP/gk6fPn3QY5YsWcKSJUsCvaSIE4bmOgDc2RFu6eeMRumJGBoPwkVfjmiWSDrxzjtouk7upZdGOopfjCkppJedKzdzTyNP5IqoY2iuw23KhiRThIPouPNL43rYplKK47veJmv8BBJMaZGO47fsyVPoOHiQruPHIx0lakjRF1HH0BK5OXdO584vQz9+OG6nY7AePkT38ePkX/bFSEcJiPnyKwBofOP1CCeJHlL0RXRRCkNzHSpC0y+czmUuQ+u2obU3Dr3zCHT8nbf7unamRjpKQFLMZjIvvAjL6zsHHDYej6Toi6ii2VvRum0RH7nj4b2ZG4ddPEopTux6p7drJy32unY8zFdeSeexY3QcPBDpKFFBir6IKnrdHgBcBeMinKSXO68UpRnQj8df0bfW1NDV2EjeZZdFOsqw5H/hixgSErC8tjPSUaKCFH0RVfSD7+JOycRdGB1FH2MS7pzRvSN44syJd94Gg4G8f4nNrh0PY2oquZdO5fhbb+Lu6Yl0nIiToi+ih8uJseZ9XGWXRmzOnYG4zWVx173jdjiwvL6T7AkTSUgf+MnOWFJQPh2nzUbzhx9EOkrESdEXUUM/+jFatw1nWXS1LN3mMgy2FjRba6SjhM2x7a/gaGlh9Lz5kY4SFNnjJ5CYlY1l546hdx7hpOiLqKEfehelJ+AaMyXSUfpxFZwPgH7kw8gGCRN3Tw+1f/0rGRdcQNbF4yMdJyg0Xcd8xRU0ffgB9qPxPa2GFH0RHZTCeHAXrpJJkJgS6TT9uEddgDuzkIS9L0c6Slg07HgVR0szpQuvj4m58301eu489MQkDj33bKSjRJQUfREVtOY6DG0NUde1A4BmoGfCLPS6vWgtI7uV2NvK30zGuPO9a82OFImZmYyprKT5H+/TsndPpONEjBR9ERWMh94FwBWNRR9wXjwDpRlI2DOyW/sNO3fQ3dTEmIXXjahWvkfx7Dkk5edz6Jnfo9zuSMeJCCn6IioYD+3CZT4XlZ439M4RoNJycJVNxfjxK+AamcP+ultaOPLC86Sfex7ZE0fmtOeGxETK/v3/YDtyhIYd2yMdJyKk6IuI0+ytGI59GrWtfI+eiVdj6GxDP7gr0lGCzu108sm6n+Hs7OT8W24dka18j7zLvkjGuPOp+eP/0N3cHOk4YSdFX0Rc4o7fANBz/hURTnJ2rtJLcKfnkbBna6SjBN3Bp39L+/7PuOAbSzCNGdlrB2iaxnlfuxm3o5s9ax/E0d4e6UhhJUVfRJTx09dJ2Lcdxxe/isotiXScszPoOMf/K8YjH6L1zfk/Ehx7ZRvHXtlGyfxrY3Y2TX+ljSll/LK76Wy08PYPV+Pq6op0pLCRoi8iRrM2kVT9BK7CcfR8YVGk4/ikZ+LVqCQTKZvuR7WfiHScYXE7nRx69g/sf3Ij2ZMmc85X/j3SkcIqa/x4Lvrvb9F24AAfPfJjejrio8UvRV9EhlIkbX0MXD10XXNXVE27cDYqLZfOf/shmr0V1+++B/a2SEcKSGfDMT68byV1VVsomvmvXLx0GZoh/spB3qWXMuWub9G2bx/vfmcZx159ZcSP6gl4ucRA7dy5kx/96Ee43W4WLVrErbfeGu4IIsIMdR+R9PrT6Mc+pWvGN1ERXhbRX+6iC+is/AGpf1lFygs/pKvi7ph4DcrtpmX3P2nY/ipN/3gfPSWFi5cuI2/qFyIdLaJKZlyFIX8U+3/zJPs3bqDh1WqKZvwruf/yLySkZ0Q6XtBpKowrC7hcLmbPns1vfvMbCgoKuP7663nkkUc477zzBj2mp8dFa6s9oOtlZaUGfGwoxVUupaDbhqGpFkPT5xgP7cJ4+H3cphwc027AOWEWDDFSJFrfr4wTH+F69odorh5cRRfQc9GXcReMQ6XnoVIzQQt/y1kpRXqKzvEjDfS0tdHd0oztyBGsNYfpOHiQnvY2EtLTMV9Rzui5FSTl5IQtW7T+HD25lFI0vv4aNX/+E93Hj4OmkXnBhaSNHUvqqFGkFI0iMTOLhPQ0jKkmND20n06H+37l5w88UV5Yi/4HH3zAz3/+c5588kkA1q9fD8A3vvGNQY8JtOjXPbaKxo8+i8pV7jQtOlff8zXX4CX6lIOV6juZu99mDAZUcgYqOc3noqjrGi5X9L1huq7h6ulB67ZDtw3t1PH7mtb3x0w77Y+aT+/eoN9Uff/X83NSCtzu3q/dLoVrkJ4Jk0knI8OI2ZyIOT8RgyH8QzJ13YBrsIARdHoupRQdHS4sjd2cOO7AanMxUI+PwQAGg4bB0DsiyPMj9/y4NbSz/biHlGnO4rwHfhHw8YMV/bB271gsFgoLC71fFxQUsHv37rMeo+saWVmpfl+rvaSYzoaGs/8iRYjGEL/gETL8XJ7/yPv+yzfoYNDRdCMkpfYudJ6Q5P9ZNS0ql7o7I1e3HRyd0NONcjrA7QK3G5QbUH1v7tlfx1lrxGnFpLfAaGgGDYNBQ9cN6EYDulEnMdlIUrKRpJQE0jKT0Y2Rv2eiaRpalP4cT8+VUwQ5vfPsoZSi0+bA1t6Fo8uJo9tJT7cTl0vhdrl7/6dAuVXvfw/q5HG+GGyvtKKCgGrfUMJa9Ad6E4Z6CMTlUgG19DP+7RbGLL4zqj9ORhvJ5Z9YyRUtCWPl/RpMct//wiVU3Tth7XQsLCykoaHB+7XFYsFsNoczghBCxLWwFv2JEydSU1NDbW0tDoeDqqoqZsyYEc4IQggR18LavWM0Glm5ciW33HILLpeL6667jnHjomQtVCGEiANhH6c/ffp0pk+fHu7LCiGEQJ7IFUKIuCJFXwgh4ogUfSGEiCNS9IUQIo6EdRoGIYQQkSUtfSGEiCNS9IUQIo5I0RdCiDgiRV8IIeKIFH0hhIgjUvSFECKOSNEXQog4EjNFf+fOncyePZtZs2axYcOGM76vlOKBBx5g1qxZzJ8/n48++giA7u5urr/+eq699loqKip47LHH+h33+9//ntmzZ1NRUcHDDz8cFbmWLl3KggULWLBgATNmzGDBggVRkeuTTz7hK1/5CgsWLGDhwoVDrnoWrlz79u3jq1/9KvPnz+eb3/wmVqs1bLk8XC4XlZWV/Zb+bG1tZfHixVx99dUsXryYtra2qMj14osvUlFRwYUXXsiePXv8zhSqXA899BDXXHMN8+fP5/bbb6e9vT0qcj366KPMnz+fBQsW8LWvfQ2LxeJ3rlBl83jyySe54IILaG5uHjqIigFOp1PNnDlTHTlyRHV3d6v58+er/fv399tn+/bt6uabb1Zut1t98MEH6vrrr1dKKeV2u5XValVKKeVwONT111+vPvjgA6WUUm+99Zb6r//6L9Xd3a2UUurEiRNRketUa9asUY8//nhU5Fq8eLHavn279/gbb7wxKnItXLhQvfPOO0oppf70pz+pn/3sZ2HL5fHUU0+pZcuWqVtvvdW77aGHHlLr169XSim1fv169fDDD0dFrgMHDqiDBw+qG2+8Ue3evduvTKHM9dprr6menh6llFIPP/xw1LxfHR0d3n8//fTT6gc/+IFfuUKZTSmljh49qr72ta+pL3/5y6qpqWnILDHR0t+9ezelpaWUlJSQmJhIRUUF1dXV/faprq6msrISTdOYMmUK7e3tNDY2omkaJpMJAKfTidPp9C7R+Nxzz3HrrbeSmJgIQG5ublTk8lBK8eKLLzJv3ryoyKVpGjabDYCOjg6/Vz0LVa7Dhw8zdepUAC6//HK2bt0atlwADQ0NbN++neuvv37AYwAqKyvZtm1bVOQ699xzKSsr8ytLOHJdccUVGI29s71PmTKl3yp7kcyVlpbm/XdnZ+eQS7yGMxvAmjVruPvuu33OFRNFf6AF1U//iHX6PoWFhd59XC4XCxYs4Etf+hJf+tKXmDx5MgA1NTW89957LFq0iBtvvNHv7opQ5fJ47733yM3N5ZxzzomKXPfccw8PP/ww06dP56GHHmLZsmVRkev888/3/gL97//+L8eOHQtrrgcffJC7774bg6H/r1NTU5P3D6PZbPbto3cYcg1XOHL9+c9/pry8PGpy/exnP2P69On87W9/41vf+pZfuUKZrbq6GrPZzIUXXuhzlpgo+sqHBdXPto+u62zevJkdO3awe/duPvvsM6C3iLS3t/PHP/6R7373uyxdutTnFexDmctjy5YtfrfyQ5nrueeeY8WKFezYsYMVK1Zw7733RkWuH/3oRzz77LMsXLgQm83m/eQWjlyvvvoqOTk5TJgwwa9rSq7Bcz3xxBPous61114bNbnuuusuduzYwfz58/nDH/7gV65QZevs7ORXv/qV33+EYqLo+7Kg+un7NDQ0nLFPRkYGl112Ga+99hrQ+9d21qxZaJrGpEmTMBgMtLS0RDwX9HZhvPzyy8ydO9fnPKHO9Ze//IWrr74agDlz5vj9yShUuc4991yeeuopXnjhBSoqKigpKQlbrn/84x+88sorzJgxg2XLlvH222/zne98B+jtLvR8PG9sbCQnJycqcg1XKHP95S9/Yfv27fzkJz/xuxslHO/XvHnz/O4+DFW2I0eOUFdX5x3w0dDQwMKFCzl+/PjZw/h3OyIyenp61IwZM/rdBPnss8/67fPqq6/2uwly3XXXKaWUampqUm1tbUoppTo7O9UNN9ygXnnlFaWUUs8++6x69NFHlVJKHTp0SJWXlyu32x3xXEoptWPHDvUf//Ef/rxNIc91zTXXqLffflsppdSbb76p/u3f/i0qcnluwLtcLnX33XerP/3pT2HLdaq333673022tWvX9ruR+9BDD0VFLo9Ab+SGKteOHTvUnDlzfLoZGc5chw8f9v77d7/7nbrjjjuiJtuprrrqKp/eu7CvkRuIwRZUf+655wC44YYbmD59Ojt27GDWrFmkpKTw4IMPAr0trOXLl+NyuVBKcc0113DVVVcBcN1113HPPfcwb948EhISWLt2rV+ti1DlAvj73/9ORUVFVL1f999/Pw8++CBOp5OkpCRWr14dFbm2bNnCs88+C8CsWbO47rrrwpbrbG699VaWLl3K888/T1FREevWrYuKXC+//DL3338/zc3NfOMb3+Ciiy7iySefjHiu+++/H4fDweLFiwGYPHmyX/+NhSrXT3/6Uw4fPoymaRQXF7Nq1SqfM4U6WyBkPn0hhIgjMdGnL4QQIjik6AshRByRoi+EEHFEir4QQsQRKfpCCBFHpOgLIUQckaIvhBBx5P8DLzbViOFSsT4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seen_sigmas = []\n",
    "unseen_sigmas = []\n",
    "\n",
    "for batch_index in range(len(model.labels_list)):\n",
    "    for inner_batch_index in range(model.labels_list[batch_index].size(0)):\n",
    "        class_label = model.labels_list[batch_index][inner_batch_index].item()\n",
    "#         if class_label <= 151:\n",
    "        if class_label not in [11,18,19,25,26,28,30,31,32,41,74,75,98,113,138,139,161,177,180,182,183,192,199,177]:\n",
    "            seen_sigmas.append(model.sigmas_list[batch_index][inner_batch_index].mean().item())\n",
    "        else:\n",
    "            unseen_sigmas.append(model.sigmas_list[batch_index][inner_batch_index].mean().item())\n",
    "            \n",
    "seen_sigmas = np.array(seen_sigmas)\n",
    "unseen_sigmas = np.array(unseen_sigmas)\n",
    "print('seen:')\n",
    "print(seen_sigmas.mean())\n",
    "print(seen_sigmas.std())\n",
    "print('\\nunseen:')\n",
    "print(unseen_sigmas.mean())\n",
    "print(unseen_sigmas.std())\n",
    "# for plotting\n",
    "sns.set_style('darkgrid')\n",
    "x_min = 0.036#np.concatenate((seen_sigmas, unseen_sigmas)).min()\n",
    "x_max = 0.044#np.concatenate((seen_sigmas, unseen_sigmas)).max()\n",
    "x = np.linspace(x_min, x_max, 100)\n",
    "y_seen = scipy.stats.norm.pdf(x,seen_sigmas.mean(),seen_sigmas.std())\n",
    "y_unseen = scipy.stats.norm.pdf(x,unseen_sigmas.mean(), unseen_sigmas.std()/100)\n",
    "\n",
    "\n",
    "plt.plot(x,y_seen, color='#F67941', label = 'seen')\n",
    "plt.plot(x,y_unseen, color='#AC454A', label = 'unseen')\n",
    "plt.legend()\n",
    "plt.savefig(figure_path + 'zero_shot_uncertainty.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08514898966284508\n",
      "0.07866149883665921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f4c55de0df0>"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(model.sigmas_list[0])\n",
    "\n",
    "# unseen_attrs = [101-1, 145-1, 151-1, 235 -1,308-1, 312+101-1, 312+145-1, 312+151-1, 312+235 -1,312+308-1]\n",
    "unseen_attrs = [101, 145, 151, 235 ,308]#, 312+101, 312+145, 312+151, 312+235 ,312+308]\n",
    "# unseen_attrs = [101+1, 145+1, 151+1, 235 +1,308+1, 312+101+1, 312+145+1, 312+151+1, 312+235 +1,312+308+1]\n",
    "# unseen_attrs = [101, 101+1, 145, 145+1, 151, 151+1, 235,235 +1,308,308+1]\n",
    "seen_attrs = [i for i in range(312)if i not in unseen_attrs]\n",
    "unseen_mask = torch.tensor([1 if x in unseen_attrs else 0 for x in range(312)], device=device).repeat(model.sigmas_list[0].size(0),1)\n",
    "# print(unseen_mask.size())\n",
    "\n",
    "seen_mask = 1. - unseen_mask\n",
    "# print(seen_mask.size())\n",
    "unseen_sigmas_means = []\n",
    "\n",
    "seen_sigmas_means = []\n",
    "\n",
    "\n",
    "for batch_index in range(len(model.sigmas_list)):\n",
    "# for batch_index in range(2):\n",
    "    if model.sigmas_list[batch_index].size(0)==64:\n",
    "        sigmas = model.sigmas_list[batch_index]\n",
    "        sigmas_new = torch.zeros(64, 312, 1,device=device)\n",
    "        sigmas_new += sigmas.view(64,-1,2)[:,:,0].unsqueeze(2)\n",
    "        sigmas_new += sigmas.view(64,-1,2)[:,:,1].unsqueeze(2)\n",
    "        sigmas = sigmas_new[:,:,0]\n",
    "#         print(sigmas.size())\n",
    "        unseen_sigmas = sigmas * unseen_mask\n",
    "        unseen_sigmas_means += unseen_sigmas.mean(dim=0)[[unseen_attrs]].tolist()\n",
    "        seen_sigmas = sigmas * seen_mask\n",
    "        seen_sigmas_means += seen_sigmas.mean(dim=0)[[seen_attrs]].tolist()\n",
    "#         print(seen_sigmas.mean())\n",
    "\n",
    "\n",
    "print(np.mean(unseen_sigmas_means))\n",
    "print(np.mean(seen_sigmas_means))\n",
    "\n",
    "\n",
    "x_min = 0.03#min(np.array(unseen_sigmas_means).min(), np.array(seen_sigmas_means).min())\n",
    "x_max = 0.13\n",
    "#min(np.array(unseen_sigmas_means).max(), np.array(seen_sigmas_means).max())\n",
    "\n",
    "\n",
    "# x_min = np.concatenate((unseen_sigmas_means, unseen_sigmas)).min()\n",
    "# x_max = np.concatenate((seen_sigmas, unseen_sigmas)).max()\n",
    "x = np.linspace(x_min, x_max, 100)\n",
    "y_unseen = scipy.stats.expon.pdf(x,np.mean(unseen_sigmas_means),np.std(unseen_sigmas_means))\n",
    "y_seen = scipy.stats.expon.pdf(x,np.mean(seen_sigmas_means),np.std(seen_sigmas_means))\n",
    "plt.plot(x,y_unseen, color='#AC454A', label = 'unseen')\n",
    "plt.plot(x,y_seen, color='#F67941', label = 'seen')\n",
    "plt.legend()\n",
    "\n",
    "# uncertain_onehot = torch.tensor([[0., 0., 1.]], device=device).repeat(images.size(0), attribute_size, 1)\n",
    "# print(unseen_batch_mask.size())\n",
    "# #308\n",
    "# # 101\n",
    "# # 235\n",
    "# # 145\n",
    "# 151\n",
    "# plt.savefig(figure_path + 'zero_shot_attr_uncertainty.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28858\n",
      "470\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f4c55611670>"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.hist(unseen_sigmas)\n",
    "# plt.hist(seen_sigmas)\n",
    "# plt.hist(unseen_sigmas_means)\n",
    "# plt.hist(seen_sigmas_means)\n",
    "print(len(seen_sigmas_means))\n",
    "print(len(unseen_sigmas_means))\n",
    "plt.hist(np.array(unseen_sigmas_means),\n",
    "         bins = np.arange(0.075, 0.15, 0.0025),\n",
    "         color='#AC454A',\n",
    "         den\n",
    "         weights=np.ones_like(np.array(unseen_sigmas_means)))\n",
    "\n",
    "plt.hist(np.array(seen_sigmas_means),\n",
    "         bins = np.arange(0.075, 0.15, 0.0025),\n",
    "         color='#F67941',\n",
    "         density=True,\n",
    "         label='seen'\n",
    "        )\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6804115720417189, 0.7182754132410755, 0.6702648232812467, 0.714998273745827, 0.6931055609298789, 0.7174276281958041, 0.6983859079039615, 0.7049175507348516, 0.6953701344521149, 0.7296628880759944, 0.722016493263452, 0.7092867312224015, 0.7558365218017412, 0.7460860590571943, 0.7157794172349183]\n",
      "\n",
      "[0.057426291227500925, 0.05609082130174483, 0.06299703259782125, 0.05952211805889683, 0.06739816001506262, 0.0625436188633083, 0.061809110545342966, 0.06241330280098864, 0.05440532888776513, 0.054207162390793526, 0.05429709133922413, 0.0504565376347752, 0.05158684070232094, 0.04933646605700575, 0.047554582677861695]\n",
      "\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print(trainer.mean_attr_accs)\n",
    "print()\n",
    "print(trainer.mean_drop_ratio)\n",
    "print()\n",
    "print(trainer.mean_sigmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".  ..  urdtc\r\n"
     ]
    }
   ],
   "source": [
    "!ls -a ../"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
