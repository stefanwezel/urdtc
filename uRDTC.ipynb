{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "As we're luckily standing on the shoulders of giants, we can do some imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import imageio\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "Let's load and convert the data, so we can use it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = ['cifar10', 'mnist', 'cub', 'awa2',\n",
    "            'imagenetfeatures', 'apyfeatures', 'zero_shot_cub']\n",
    "# dataset = 'awa2'\n",
    "dataset = 'cub'\n",
    "# dataset = 'zero_shot_cub'\n",
    "\n",
    "data_path = '/home/swezel/projects/urdtc/data/'\n",
    "figure_path = data_path + '../thesis/images/'\n",
    "\n",
    "\n",
    "# attribute name lookup (first attr_id is 0) \n",
    "with open (data_path + 'cub/attributes.txt', 'r') as f:\n",
    "    attributes=f.readlines()\n",
    "attribute_name_dict = {str(int(attr.split(' ')[0])-1): attr.split(' ')[1] for attr in attributes}\n",
    "\n",
    "def get_dataset_config(dataset, cnn_type, max_iters):\n",
    "    input_channels = None\n",
    "    if dataset == 'mnist':\n",
    "        input_channels = 1\n",
    "        if cnn_type == 'cnn':\n",
    "            cnn_output_size = 4*4*100\n",
    "        elif cnn_type == 'resnet':\n",
    "            cnn_output_size = 512\n",
    "        elif cnn_type == 'shallowcnn':\n",
    "            cnn_output_size = 4*4*64\n",
    "        out_freq = 100\n",
    "        #assert max_iters > 4\n",
    "    elif dataset == 'cifar10':\n",
    "        input_channels = 3\n",
    "        if cnn_type == 'cnn':\n",
    "            cnn_output_size = 8*8*32\n",
    "        elif cnn_type == 'resnet' or cnn_type == 'resnet18':\n",
    "            cnn_output_size = 512\n",
    "        elif cnn_type == 'shallowcnn':\n",
    "            cnn_output_size = 4*4*64\n",
    "        out_freq = 100\n",
    "        #assert max_iters > 4\n",
    "    elif dataset == 'cub':\n",
    "        input_channels = 3\n",
    "        if cnn_type == 'cnn':\n",
    "            # cnn_output_size = 32*32*32\n",
    "            cnn_output_size = 280900 # the above does not work? Maybe because of dataloader issue?\n",
    "        elif cnn_type == 'resnet' or cnn_type == 'resnet152':\n",
    "            cnn_output_size = 2048\n",
    "        out_freq = 10\n",
    "    elif dataset == 'zero_shot_cub':\n",
    "        input_channels = 3\n",
    "        if cnn_type == 'cnn':\n",
    "            # cnn_output_size = 32*32*32\n",
    "            cnn_output_size = 280900 # the above does not work? Maybe because of dataloader issue?\n",
    "        elif cnn_type == 'resnet' or cnn_type == 'resnet152':\n",
    "            cnn_output_size = 2048\n",
    "        out_freq = 10\n",
    "        #assert max_iters > 8\n",
    "    elif dataset == 'awa2':\n",
    "        input_channels = 3\n",
    "        if cnn_type == 'cnn':\n",
    "#             cnn_output_size = 32*32*32  # TODO: check\n",
    "            cnn_output_size = 2048\n",
    "        elif cnn_type == 'resnet' or cnn_type == 'resnet152':\n",
    "            cnn_output_size = 2048\n",
    "        out_freq = 10\n",
    "        #assert max_iters > 6\n",
    "    elif dataset == 'imagenetfeatures':\n",
    "        cnn_output_size = 2048\n",
    "        out_freq = 100\n",
    "        #assert max_iters > 10\n",
    "    elif dataset == 'apyfeatures':\n",
    "        cnn_output_size = 2048\n",
    "        out_freq = 10\n",
    "        #assert max_iters > 5\n",
    "\n",
    "    return input_channels, cnn_output_size, out_freq\n",
    "\n",
    "class DataLoader(object):\n",
    "    def __init__(self, dataset='mnist'):\n",
    "        assert dataset in DATASETS\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def load_data(self, batch_size=100, num_workers=4, root='./data/'):\n",
    "\n",
    "        if self.dataset == 'mnist':\n",
    "            #transform_train = transforms.ToTensor()\n",
    "            #transform_test = transforms.ToTensor()\n",
    "            class AddGaussianNoise(object):\n",
    "                def __init__(self, mean=0., std=1.):\n",
    "                    self.std = std\n",
    "                    self.mean = mean\n",
    "\n",
    "                def __call__(self, tensor):\n",
    "                    output = tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "                    return output.clamp(0., 1.)\n",
    "\n",
    "                def __repr__(self):\n",
    "                    return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
    "\n",
    "            transform_train = transforms.Compose([\n",
    "               transforms.ToTensor(),\n",
    "               #AddGaussianNoise(0., 0.2)\n",
    "               #transforms.Normalize((0.1307,), (0.3081,))\n",
    "            ])\n",
    "            transform_test = transforms.Compose([\n",
    "               transforms.ToTensor(),\n",
    "               #AddGaussianNoise(0., 0.2)\n",
    "               #transforms.Normalize((0.1307,), (0.3081,))\n",
    "            ])\n",
    "            classes = [i for i in range(10)]\n",
    "            dataset_class = dsets.MNIST\n",
    "\n",
    "        elif self.dataset == 'cifar10':\n",
    "            transform_train = transforms.Compose([\n",
    "                transforms.RandomCrop(32, padding=4),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "            ])\n",
    "            transform_test = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "            ])\n",
    "            classes = ('plane', 'car', 'bird', 'cat',\n",
    "                       'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "            dataset_class = dsets.CIFAR10\n",
    "\n",
    "        elif self.dataset == 'cub':\n",
    "\n",
    "            transform_train = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                  transforms.RandomResizedCrop(224),\n",
    "                                                  transforms.RandomHorizontalFlip(),\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                                       std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "            transform_test = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                 transforms.Resize(224),\n",
    "                                                 transforms.CenterCrop(224),\n",
    "                                                 transforms.ToTensor(),\n",
    "                                                 transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                                      std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "            dataset_class = CUB\n",
    "            classes = list(range(200))\n",
    "\n",
    "        elif self.dataset == 'zero_shot_cub':\n",
    "\n",
    "            transform_train = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                  transforms.RandomResizedCrop(224),\n",
    "                                                  transforms.RandomHorizontalFlip(),\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                                       std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "            transform_test = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                 transforms.Resize(224),\n",
    "                                                 transforms.CenterCrop(224),\n",
    "                                                 transforms.ToTensor(),\n",
    "                                                 transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                                      std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "            dataset_class = ZeroShotCUB\n",
    "            classes = list(range(200))            \n",
    "            \n",
    "            \n",
    "\n",
    "        elif self.dataset == 'awa2':\n",
    "            transform_train = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                  transforms.RandomResizedCrop(224),\n",
    "                                                  transforms.RandomHorizontalFlip(),\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                                       std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "            transform_test = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                 transforms.Resize(224),\n",
    "                                                 transforms.CenterCrop(224),\n",
    "                                                 transforms.ToTensor(),\n",
    "                                                 transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                                      std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "            dataset_class = AWA2\n",
    "            classes = list(range(50))\n",
    "\n",
    "        elif self.dataset == 'apyfeatures':\n",
    "            transform_train = transforms.ToTensor()\n",
    "            transform_test = transforms.ToTensor()\n",
    "\n",
    "            dataset_class = APYFeatures\n",
    "            classes = list(range(32))\n",
    "\n",
    "        elif self.dataset == 'imagenetfeatures':\n",
    "            transform_train = transforms.ToTensor()\n",
    "            transform_test = transforms.ToTensor()\n",
    "\n",
    "            dataset_class = ImageNetFeatures\n",
    "            classes = list(range(1000))\n",
    "\n",
    "        train_dataset = dataset_class(root=root,\n",
    "                                      train=True,\n",
    "                                      transform=transform_train,\n",
    "                                      download=True)\n",
    "\n",
    "        test_dataset = dataset_class(root=root,\n",
    "                                     train=False,\n",
    "                                     transform=transform_test)\n",
    "\n",
    "        val_size = int(len(train_dataset) * 0.1)\n",
    "        train_size = len(train_dataset) - val_size\n",
    "\n",
    "        train_dataset, val_dataset = torch.utils.data.dataset.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   shuffle=True,\n",
    "                                                   num_workers=num_workers)\n",
    "\n",
    "        val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 shuffle=False,\n",
    "                                                 num_workers=num_workers)\n",
    "\n",
    "        test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  shuffle=False,\n",
    "                                                  num_workers=num_workers)\n",
    "\n",
    "        dataloaders = {'train': train_loader,\n",
    "                       'val': val_loader,\n",
    "                       'test': test_loader}\n",
    "\n",
    "        return dataloaders, classes\n",
    "\n",
    "class CUB(Dataset):\n",
    "    \"\"\"CUB200-2011 dataset.\"\"\"\n",
    "    attribute_file = 'attributes/class_attribute_labels_continuous.txt'\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, normalize=True,\n",
    "                 download=None):\n",
    "        self.root = os.path.join(root, 'cub')\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.data_dir = os.path.join(self.root, 'images')\n",
    "\n",
    "        train_test_split = pd.read_csv(os.path.join(self.root, 'train_test_split.txt'),\n",
    "                                       sep=' ', index_col=0, header=None)\n",
    "        if train:\n",
    "            is_train_image = 1\n",
    "        else:\n",
    "            is_train_image = 0\n",
    "        self.img_ids = train_test_split[train_test_split[1] == is_train_image].index.tolist()\n",
    "        self.id_to_img = pd.read_csv(os.path.join(self.root, 'images.txt'),\n",
    "                                     sep=' ', index_col=0, header=None)\n",
    "\n",
    "        raw_mtx = np.loadtxt(os.path.join(self.root,\n",
    "                                          self.attribute_file))\n",
    "        raw_mtx[raw_mtx == -1] = 0\n",
    "        raw_mtx = raw_mtx / raw_mtx.max()\n",
    "        self.attribute_mtx = torch.tensor(raw_mtx, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_ids[idx]\n",
    "        img_name = self.id_to_img[self.id_to_img.index == img_id].values[0][0]\n",
    "        img_path = os.path.join(self.data_dir, img_name)\n",
    "\n",
    "        img = imageio.imread(img_path, pilmode='RGB')\n",
    "        label = int(img_name[:3]) - 1\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label, img_path\n",
    "\n",
    "    \n",
    "class ZeroShotCUB(Dataset):\n",
    "    \"\"\"CUB200-2011 dataset.\"\"\"\n",
    "    attribute_file = 'attributes/class_attribute_labels_continuous.txt'\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, normalize=True,\n",
    "                 download=None):\n",
    "        self.root = os.path.join(root, 'cub')\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.data_dir = os.path.join(self.root, 'images')\n",
    "\n",
    "        train_test_split = pd.read_csv(os.path.join(self.root, 'zero_attr_train_test_split.txt'),\n",
    "                                       sep=' ', index_col=0, header=None)\n",
    "        if train:\n",
    "            is_train_image = 1\n",
    "        else:\n",
    "            is_train_image = 0\n",
    "        self.img_ids = train_test_split[train_test_split[1] == is_train_image].index.tolist()\n",
    "        self.id_to_img = pd.read_csv(os.path.join(self.root, 'images.txt'),\n",
    "                                     sep=' ', index_col=0, header=None)\n",
    "\n",
    "        raw_mtx = np.loadtxt(os.path.join(self.root,\n",
    "                                          self.attribute_file))\n",
    "        raw_mtx[raw_mtx == -1] = 0\n",
    "        raw_mtx = raw_mtx / raw_mtx.max()\n",
    "        self.attribute_mtx = torch.tensor(raw_mtx, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_ids[idx]\n",
    "        img_name = self.id_to_img[self.id_to_img.index == img_id].values[0][0]\n",
    "        img_path = os.path.join(self.data_dir, img_name)\n",
    "\n",
    "        img = imageio.imread(img_path, pilmode='RGB')\n",
    "        label = int(img_name[:3]) - 1\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label, img_path\n",
    "    \n",
    "    \n",
    "class AWA2(Dataset):\n",
    "    \"\"\"Animals with Attributes 2 dataset.\"\"\"\n",
    "    split_file = 'train_test_classification_split.txt'\n",
    "    data_dir = 'awa2'\n",
    "    attribute_file = 'predicate-matrix-continuous.txt'\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, normalize=True,\n",
    "                 download=None):\n",
    "        self.root = os.path.join(root, self.data_dir)\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "\n",
    "        meta_data = pd.read_csv(os.path.join(self.root,\n",
    "                                             self.split_file),\n",
    "                                sep=' ', index_col=0, header=None)\n",
    "        if train:\n",
    "            is_train_image = 1\n",
    "        else:\n",
    "            is_train_image = 0\n",
    "        self.img_ids = meta_data[meta_data[3] == is_train_image].index.tolist()\n",
    "        self.id_to_img = meta_data\n",
    "\n",
    "        raw_mtx = np.loadtxt(os.path.join(self.root,\n",
    "                                          self.attribute_file))\n",
    "        raw_mtx[raw_mtx == -1] = 0\n",
    "        raw_mtx = raw_mtx / raw_mtx.max()\n",
    "        self.attribute_mtx = torch.tensor(raw_mtx, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_ids[idx]\n",
    "        img_meta_data = self.id_to_img[self.id_to_img.index == img_id]\n",
    "        img_name = img_meta_data.values[0][0]\n",
    "        img_path = os.path.join(self.root, img_name)\n",
    "\n",
    "        img = imageio.imread(img_path, pilmode='RGB')\n",
    "        label = img_meta_data.values[0][1] - 1\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "# device = torch.device('cpu')\n",
    "\n",
    "# create dataloader objects for train, val and test\n",
    "dl = DataLoader(dataset=dataset)\n",
    "# dataloaders, classes = dl.load_data(4, 4, data_path)# 128 insted of \n",
    "dataloaders, classes = dl.load_data(64, 4, data_path)# 128 insted of \n",
    "\n",
    "# attributes (312 column vectors with 200 rows) -> each class can be described with 312 attributes\n",
    "# percentage of time, human annotator thought, the attribute was present\n",
    "attribute_mtx = dataloaders['train'].dataset.dataset.attribute_mtx\n",
    "\n",
    "# create binary encoding for class attributes\n",
    "attribute_mtx[attribute_mtx < 0.5] = 0.0\n",
    "attribute_mtx[attribute_mtx >= 0.5] = 1.0\n",
    "attribute_mtx = attribute_mtx.to(device) # cuda\n",
    "attribute_size = attribute_mtx.size(1) # number of available attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Models\n",
    "Here, we continue by defining the various models that our uRDTC consists of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Conv2d(in_channels, 20, kernel_size=3, stride=1),\n",
    "                                 nn.ReLU(True),\n",
    "                                 nn.BatchNorm2d(20),\n",
    "                                 nn.Conv2d(20, 50, kernel_size=5, stride=2),\n",
    "                                 nn.ReLU(True),\n",
    "                                 nn.BatchNorm2d(50),\n",
    "                                 nn.Conv2d(50, 100, kernel_size=5, stride=2),\n",
    "                                 nn.ReLU(True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class DropoutCNN(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 20, kernel_size=3, stride=1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, kernel_size=5, stride=2)\n",
    "        self.conv3 = nn.Conv2d(50, 100, kernel_size=5, stride=2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.dropout2d(F.relu(self.conv1(x)), 0.2)\n",
    "        x = F.dropout2d(F.relu(self.conv2(x)), 0.2)\n",
    "        x = F.dropout2d(F.relu(self.conv3(x)), 0.2)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def get_cnn(in_channels, type='cnn', pretrained_cnn_weights=None,\n",
    "            freeze_weights=False, default_pretrained=False):\n",
    "    TYPES = ['cnn', 'dropoutcnn', 'resnet152'] # TYPES = ['cnn', 'shallowcnn', 'resnet', 'resnet152']\n",
    "    assert type in TYPES\n",
    "\n",
    "    if type == 'cnn':\n",
    "        cnn = CNN(in_channels)\n",
    "    if type == 'dropoutcnn':\n",
    "        cnn = DropoutCNN(in_channels)\n",
    "#     if type == 'resnet152':\n",
    "#         cnn = models.resnet152(pretrained=default_pretrained)\n",
    "    else:\n",
    "        cnn = Identity()\n",
    "\n",
    "    # if pretrained_cnn_weights:\n",
    "    #     if type == 'resnet152':\n",
    "    #         cnn.fc = nn.Linear(cnn.fc.in_features, pretrained_cnn_weights['fc.weight'].size(0))\n",
    "    #     cnn.load_state_dict(pretrained_cnn_weights)\n",
    "    if pretrained_cnn_weights:\n",
    "        cnn.load_state_dict(pretrained_cnn_weights)\n",
    "    \n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OC(nn.Module):\n",
    "    def __init__(self, model_type, num_classes, cnn_type, input_channels, cnn_out_size,\n",
    "                 dataset, decision_size=2, max_iters=20, attribute_size=20, attribute_mtx=None, attribute_coef=0.5, hidden_size=100,\n",
    "                 tau_initial=5, tau_target=0.5, use_pretrained=False, shallow=False, strategy='aRDTC'):\n",
    "        super(OC, self).__init__()\n",
    "        assert model_type in ['xoc'] #, 'ioc']\n",
    "        self.model_type = model_type\n",
    "        self.num_classes = num_classes\n",
    "        self.attribute_size = attribute_size\n",
    "        self.attribute_mtx = attribute_mtx\n",
    "        self.attribute_coef = attribute_coef if attribute_mtx is not None else 0.\n",
    "        self.decision_size = decision_size # change keyword default to 3?\n",
    "        self.tau_initial = tau_initial\n",
    "        self.tau_target = tau_target\n",
    "        self.max_iters = max_iters\n",
    "        self.shallow = shallow\n",
    "        self.stats = defaultdict(list)\n",
    "        self.reduced_vocab_size = 2\n",
    "        self.strategy = strategy\n",
    "\n",
    "        self.no_lstm = False\n",
    "\n",
    "        #self.init_attribute_matrix(attribute_mtx, attribute_size, attribute_coef, use_bin_attr)\n",
    "\n",
    "        self.cnn = self.init_cnn(cnn_type, input_channels, dataset, use_pretrained)\n",
    "        self.init_network(hidden_size, decision_size, num_classes, attribute_size, cnn_out_size, shallow)\n",
    "\n",
    "        self.init_losses()\n",
    "\n",
    "\n",
    "\n",
    "        self.phase = 'train'\n",
    "\n",
    "        # for stats\n",
    "        self.logits_list = []\n",
    "        self.sigmas_list = []\n",
    "#         self.labels_list\n",
    "        self.binary_features_list = []\n",
    "        self.labels_list = []\n",
    "        self.used_attributes_list = []\n",
    "        self.certain_attrs = []\n",
    "        self.attribute_accuracies = []\n",
    "        self.drop_ratios = []\n",
    "        self.mean_sigmas = []\n",
    "        \n",
    "\n",
    "    def init_network(self, hidden_size, decision_size, num_classes, attribute_size, cnn_out_size, shallow):\n",
    "        assert decision_size > 1\n",
    "\n",
    "        # LSTM initialization parameters\n",
    "        if self.no_lstm:\n",
    "            self.init_h0 = nn.Parameter(torch.zeros(attribute_size * decision_size), requires_grad=False)\n",
    "            self.init_c0 = nn.Parameter(torch.zeros(attribute_size * decision_size), requires_grad=False)\n",
    "        else:\n",
    "            self.init_h0 = nn.Parameter(torch.zeros(hidden_size).uniform_(-0.01, 0.01), requires_grad=True)\n",
    "            self.init_c0 = nn.Parameter(torch.zeros(hidden_size).uniform_(-0.01, 0.01), requires_grad=True)\n",
    "\n",
    "        if self.no_lstm:\n",
    "            self.lstm = lambda x, y: (None, (x.squeeze(), x.squeeze()))\n",
    "        else:\n",
    "            self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "\n",
    "        if self.no_lstm:\n",
    "            classifier_in = attribute_size * decision_size\n",
    "        else:\n",
    "            classifier_in = attribute_size * decision_size\n",
    "\n",
    "        self.classifier = nn.Sequential(#nn.BatchNorm1d(classifier_in) if not self.no_lstm else Identity(),\n",
    "                                        nn.Linear(classifier_in, hidden_size),\n",
    "                                        nn.ReLU(inplace=True),\n",
    "                                        nn.BatchNorm1d(hidden_size),\n",
    "                                        nn.Linear(hidden_size, num_classes))\n",
    "\n",
    "        if self.model_type == 'xoc':\n",
    "            if self.no_lstm:\n",
    "                feat_select_in_size = attribute_size * decision_size\n",
    "            else:\n",
    "                feat_select_in_size = hidden_size\n",
    "            feat_select_out_size = attribute_size\n",
    "            pre_lstm_size = attribute_size * decision_size * 2\n",
    "\n",
    "            bin_feat_type = 'shallow' if shallow else 'dropoutmlp' #'mlp'\n",
    "            feat_select_type = 'mlp_small'\n",
    "\n",
    "        elif self.model_type == 'ioc':\n",
    "            bin_feat_type = 'identity'\n",
    "            feat_select_type = 'mlp_big'\n",
    "\n",
    "            if not shallow:\n",
    "                feat_select_in_size = cnn_out_size + hidden_size\n",
    "                feat_select_out_size = decision_size\n",
    "                pre_lstm_size = feat_select_out_size\n",
    "            else:\n",
    "                feat_select_in_size = hidden_size\n",
    "                feat_select_out_size = cnn_out_size * decision_size\n",
    "                pre_lstm_size = decision_size\n",
    "\n",
    "        if feat_select_type == 'mlp_small':\n",
    "            self.feature_selection = nn.Sequential(nn.BatchNorm1d(feat_select_in_size) if not self.no_lstm else Identity(),\n",
    "                                                   nn.Linear(feat_select_in_size , hidden_size),\n",
    "                                                   nn.ReLU(inplace=True),\n",
    "                                                   nn.BatchNorm1d(hidden_size),\n",
    "                                                   nn.Linear(hidden_size, feat_select_out_size))\n",
    "        elif feat_select_type == 'mlp_big':\n",
    "            self.feature_selection = nn.Sequential(nn.BatchNorm1d(feat_select_in_size) if not self.no_lstm else Identity(),\n",
    "                                                   nn.Linear(feat_select_in_size, hidden_size),\n",
    "                                                   nn.ReLU(inplace=True),\n",
    "                                                   nn.BatchNorm1d(hidden_size),\n",
    "                                                   nn.Linear(hidden_size, hidden_size),\n",
    "                                                   nn.ReLU(inplace=True),\n",
    "                                                   nn.BatchNorm1d(hidden_size),\n",
    "                                                   nn.Linear(hidden_size, feat_select_out_size))\n",
    "\n",
    "        if bin_feat_type == 'identity':\n",
    "            self.binary_features = Identity()\n",
    "        elif bin_feat_type == 'shallow':\n",
    "            class AddZeros(nn.Module):\n",
    "                def __init__(self):\n",
    "                    super().__init__()\n",
    "\n",
    "                def forward(self, x):\n",
    "                    zeros = torch.zeros_like(x).unsqueeze(2)\n",
    "                    return torch.cat((x.unsqueeze(2), zeros), dim=2)\n",
    "\n",
    "            self.binary_features = AddZeros()\n",
    "        elif bin_feat_type == 'mlp':\n",
    "            self.binary_features = nn.Sequential(nn.BatchNorm1d(cnn_out_size), # use dropout\n",
    "                                                 nn.Linear(cnn_out_size, hidden_size),\n",
    "                                                 nn.ReLU(inplace=True),\n",
    "                                                 nn.BatchNorm1d(hidden_size), # use dropout\n",
    "                                                 nn.Linear(hidden_size, hidden_size),\n",
    "                                                 nn.ReLU(inplace=True),\n",
    "                                                 nn.BatchNorm1d(hidden_size), # use dropout\n",
    "                                                 nn.Linear(hidden_size, attribute_size * self.reduced_vocab_size))\n",
    "        elif bin_feat_type == 'dropoutmlp':\n",
    "            self.binary_features = nn.Sequential(\n",
    "                                                nn.Linear(cnn_out_size, hidden_size),\n",
    "                                                nn.ReLU(inplace=False),\n",
    "                                                nn.Dropout(0.2, inplace=False),\n",
    "                                                nn.Linear(hidden_size, hidden_size),\n",
    "                                                nn.ReLU(inplace=False),\n",
    "                                                nn.Dropout(0.2, inplace=False),\n",
    "                                                nn.Linear(hidden_size, attribute_size * self.reduced_vocab_size)\n",
    "                                                )\n",
    "\n",
    "        if self.no_lstm:\n",
    "            self.pre_lstm = Identity()\n",
    "        else:\n",
    "            self.pre_lstm = nn.Sequential(#nn.BatchNorm1d(pre_lstm_size),\n",
    "                                          nn.Linear(pre_lstm_size, hidden_size),\n",
    "                                          nn.ReLU(inplace=True),\n",
    "                                          nn.BatchNorm1d(hidden_size))\n",
    "\n",
    "\n",
    "        # Temperature parameters\n",
    "        self.binary_features.tau = nn.Parameter(torch.tensor([self.tau_initial], dtype=torch.float), requires_grad=True)\n",
    "        self.feature_selection.tau = nn.Parameter(torch.tensor([self.tau_initial], dtype=torch.float), requires_grad=True)\n",
    "        #self.init_weights()\n",
    "\n",
    "    \n",
    "    \n",
    "    def get_attribute_uncertainty(self, image_features, n=10, batch_size=64):\n",
    "        outputs = torch.zeros((n, batch_size, attribute_size * self.reduced_vocab_size), device=device)\n",
    "        \n",
    "        if self.phase == 'train':\n",
    "            for i in range(n):\n",
    "                outputs[i] = F.softmax(self.binary_features(image_features))\n",
    "#                 outputs[i] = self.binary_features(image_features)\n",
    "\n",
    "        if self.phase == 'test':\n",
    "            for layer in self.binary_features:\n",
    "                if isinstance(layer, torch.nn.modules.dropout._DropoutNd):\n",
    "                    layer.train()\n",
    "#             self.binary_features.train()\n",
    "            for i in range(n):\n",
    "                outputs[i] = F.softmax(self.binary_features(image_features))\n",
    "#                 outputs[i] = self.binary_features(image_features)\n",
    "\n",
    "            for layer in self.binary_features:\n",
    "                if isinstance(layer, torch.nn.modules.dropout._DropoutNd):\n",
    "                    layer.eval()\n",
    "#             self.binary_features.eval()\n",
    "        \n",
    "        sigmas = outputs.var(dim=0)\n",
    "#         sigmas += (0.01**2 * 0.5)/(2 * image_features.size(0) * weight_decay)\n",
    "            \n",
    "            \n",
    "        return sigmas\n",
    "    \n",
    "    def get_attribute_uncertainty_new(self, image_features, n=10, batch_size=64):\n",
    "        outputs = torch.zeros((n, batch_size, attribute_size * self.reduced_vocab_size), device=device)\n",
    "        \n",
    "        if self.phase == 'train':\n",
    "            for i in range(n):\n",
    "                outputs[i] = F.softmax(self.binary_features(image_features), dim=1)\n",
    "#                 outputs[i] = self.binary_features(image_features)\n",
    "\n",
    "        if self.phase == 'test':\n",
    "            for layer in self.binary_features:\n",
    "                if isinstance(layer, torch.nn.modules.dropout._DropoutNd):\n",
    "                    layer.train()\n",
    "#             self.binary_features.train()\n",
    "            for i in range(n):\n",
    "                outputs[i] = F.softmax(self.binary_features(image_features), dim=1)\n",
    "#                 outputs[i] = self.binary_features(image_features)\n",
    "\n",
    "            for layer in self.binary_features:\n",
    "                if isinstance(layer, torch.nn.modules.dropout._DropoutNd):\n",
    "                    layer.eval()\n",
    "#             self.binary_features.eval()\n",
    "        \n",
    "        decision_sigma = outputs.var(dim=0)\n",
    "        attribute_sigma = decision_sigma.view(batch_size, -1, 2).mean(dim=2)\n",
    "#         attribute_sigma += (0.01**2 * 0.5)/(2 * batch_size * weight_decay)\n",
    "            \n",
    "        return attribute_sigma\n",
    "  \n",
    "    def init_attribute_matrix(self, attribute_mtx, attribute_size, attribute_coef, use_bin_attr):\n",
    "        if attribute_coef > 0.:\n",
    "            if use_bin_attr:\n",
    "                attribute_mtx[attribute_mtx < 0.5] = 0.\n",
    "                attribute_mtx[attribute_mtx >= 0.5] = 1.\n",
    "            self.attribute_mtx = nn.Parameter(attribute_mtx, requires_grad=False)\n",
    "            self.attribute_size = attribute_mtx.size(1)\n",
    "        else:\n",
    "            self.attribute_mtx = None\n",
    "            self.attribute_size = attribute_size\n",
    "\n",
    "    def toggle_update_schedule(self):\n",
    "        # TODO: see a few lines below\n",
    "        #self.update_binary_features = not self.update_binary_features\n",
    "        pass\n",
    "\n",
    "    def get_param_groups(self):\n",
    "        cnn_params = []\n",
    "        tree_params = []\n",
    "        for n, p in self.named_parameters():\n",
    "            if p.requires_grad:\n",
    "                # TODO: introduce parameter that allows to switch between training alternatingly\n",
    "                # Currently commented out, so both groups contain the same parameters\n",
    "                \"\"\"\n",
    "                if n.startswith('cnn') or n.startswith('binary_features'):\n",
    "                    print('CNN', n)\n",
    "                    cnn_params.append(p)\n",
    "                else:\n",
    "                    print('OTHER', n)\n",
    "                    tree_params.append(p)\n",
    "                \"\"\"\n",
    "                cnn_params.append(p)\n",
    "                tree_params.append(p)\n",
    "        return tree_params, cnn_params\n",
    "\n",
    "    def set_optimizer(self, optimizers):\n",
    "        self.tree_optimizer = optimizers[0]\n",
    "        self.cnn_optimizer = optimizers[1]\n",
    "\n",
    "    def set_scheduler(self, schedulers):\n",
    "        self.tree_scheduler = schedulers[0]\n",
    "        self.cnn_scheduler = schedulers[1]\n",
    "\n",
    "    def get_optimizer(self):\n",
    "        if self.update_binary_features:\n",
    "            return self.cnn_optimizer\n",
    "        else:\n",
    "            return self.tree_optimizer\n",
    "\n",
    "    def get_scheduler(self):\n",
    "        if self.update_binary_features:\n",
    "            return self.cnn_scheduler\n",
    "        else:\n",
    "            return self.tree_scheduler\n",
    "\n",
    "    def init_losses(self):\n",
    "        self.cls_loss = nn.CrossEntropyLoss()\n",
    "        self.attr_loss = nn.BCEWithLogitsLoss()\n",
    "        self.update_binary_features = False\n",
    "\n",
    "    def init_cnn(self, cnn_type, input_channels, dataset, use_pretrained):\n",
    "        if cnn_type == 'None':\n",
    "            cnn = Identity()\n",
    "        else:\n",
    "            if use_pretrained:\n",
    "                # TODO add data_path and change state dict name \n",
    "                # cnn_state_dict = torch.load('pretrained/{}_{}.pth'.format(dataset, cnn_type))\n",
    "#                 cnn_state_dict = torch.load('pretrained/cub_resnet152.pkl')# .format(dataset, cnn_type)\n",
    "                cnn_state_dict = torch.load('pretrained/{}_resnet152.pkl'.format(dataset))# .format(dataset, cnn_type)\n",
    "\n",
    "                cnn = get_cnn(input_channels, cnn_type, cnn_state_dict, freeze_weights=True)\n",
    "            else:\n",
    "                cnn = get_cnn(input_channels, cnn_type)\n",
    "\n",
    "        return cnn\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight.data)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.fill_(0.1)\n",
    "\n",
    "    def set_tau(self, epoch):\n",
    "        annealing_factor = epoch / 100\n",
    "        self.tau = self.tau_initial\n",
    "        self.tau -= (self.tau_initial - self.tau_target) * annealing_factor\n",
    "        self.tau = max(self.tau, self.tau_target)\n",
    "\n",
    "    def process_images_new(self, images):\n",
    "        batch_size = images.size(0)\n",
    "        img_feats = self.cnn(images)\n",
    "        img_feats = img_feats.view(img_feats.size(0), -1)\n",
    "        image_features = self.binary_features(img_feats) \n",
    "        with torch.no_grad():\n",
    "            attribute_uncertainties = self.get_attribute_uncertainty_new(img_feats, n=5, batch_size=images.size(0))\n",
    "        \n",
    "        if self.model_type == 'xoc':\n",
    "            attribute_logits = image_features.view(-1, 2)\n",
    "\n",
    "\n",
    "            attributes_softmax = F.softmax(attribute_logits / self.binary_features.tau, dim=1)\n",
    "            attributes_hard = self.argmax(attributes_softmax, dim=1)\n",
    "            image_features = attributes_hard.view(images.size(0), -1, 2)\n",
    "\n",
    "            # TODO: generalize to different decision sizes\n",
    "            bin_attribute_logits = attribute_logits - attribute_logits[:, 1].unsqueeze(-1)\n",
    "            self.attribute_logits = bin_attribute_logits[:, 0].view(images.size(0), -1)\n",
    "\n",
    "            self.collect_hist_stats('AttributesSoft', F.softmax(attribute_logits, dim=1))\n",
    "            self.collect_hist_stats('AttributesSoftTemp', attributes_softmax)\n",
    "            self.collect_hist_stats('AttributesHard', attributes_hard.max(dim=1)[1])\n",
    "\n",
    "        return image_features, attribute_uncertainties\n",
    "\n",
    "\n",
    "    def process_images(self, images):\n",
    "        batch_size = images.size(0)\n",
    "        img_feats = self.cnn(images)\n",
    "        img_feats = img_feats.view(img_feats.size(0), -1)\n",
    "        image_features = self.binary_features(img_feats)\n",
    "        # print(image_features.size())\n",
    "        ################## remove attrs code\n",
    "#         sigmas = self.get_attribute_uncertainty_batch(img_feats,n=100, batch_size=batch_size)\n",
    "        \n",
    "        if self.strategy == 'remRDTC':\n",
    "            with torch.no_grad():\n",
    "                sigmas = self.get_attribute_uncertainty(img_feats, n=5, batch_size=images.size(0))\n",
    "            uncertain_attrs = (sigmas > 0.03925).float() # get binary uncertain attrs\n",
    "            certain_attrs = 1. - uncertain_attrs\n",
    "            mask = certain_attrs.detach()\n",
    "            inv_mask = 1-mask\n",
    "            min_value = image_features.min()\n",
    "            image_features = image_features * mask # put zeros where uncertain attts are\n",
    "            image_features = image_features - (inv_mask.detach()*min_value.detach()) #*-500\n",
    "\n",
    "#         sigmas.detach()\n",
    "#         sigmas.cuda()\n",
    "#         self.mean_sigmas.append(sigmas.mean().item())\n",
    "#         drop_ratio = (sigmas>0.005).float().sum()/(images.size(0)*attribute_size*2.)\n",
    "#         min_value = image_features.min()\n",
    "#         min_value.detach()\n",
    "#         self.drop_ratios.append(drop_ratio)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #############################################################\n",
    "#         if not self.training:\n",
    "\n",
    "#             self.sigmas_list.append(sigmas)\n",
    "            # self.logits_list.append(image_features)\n",
    "            # image_features = torch.cat((attribute_logits, sigmas),1)\n",
    "        \n",
    "        \n",
    "        ################## remove attrs\n",
    "#         uncertain_attrs = (sigmas > 0.005).float() # get binary uncertain attrs\n",
    "#         certain_attrs = 1. - uncertain_attrs\n",
    "#         mask = certain_attrs.detach()#(torch.FloatTensor(image_features.size()).uniform_() > 0.050).float().to(device)\n",
    "        if self.strategy == 'randRDTC':\n",
    "            mask = (torch.FloatTensor(image_features.size()).uniform_() > 0.050).float().to(device)\n",
    "            inv_mask = 1-mask\n",
    "#         self.drop_ratios.append((inv_mask.sum()/39936.0).item())\n",
    "#         mask.detach()\n",
    "            min_value = image_features.min()\n",
    "            image_features = image_features * mask # put zeros where uncertain attts are\n",
    "            image_features = image_features - (inv_mask.detach()*min_value.detach()) #*-500\n",
    "        ##############################################################\n",
    "\n",
    "        if self.model_type == 'xoc':\n",
    "            attribute_logits = image_features.view(-1, 2)\n",
    "\n",
    "\n",
    "            attributes_softmax = F.softmax(attribute_logits / self.binary_features.tau, dim=1)\n",
    "            attributes_hard = self.argmax(attributes_softmax, dim=1)\n",
    "            image_features = attributes_hard.view(images.size(0), -1, 2)\n",
    "\n",
    "            # TODO: generalize to different decision sizes\n",
    "            bin_attribute_logits = attribute_logits - attribute_logits[:, 1].unsqueeze(-1)\n",
    "            self.attribute_logits = bin_attribute_logits[:, 0].view(images.size(0), -1)\n",
    "\n",
    "            self.collect_hist_stats('AttributesSoft', F.softmax(attribute_logits, dim=1))\n",
    "            self.collect_hist_stats('AttributesSoftTemp', attributes_softmax)\n",
    "            self.collect_hist_stats('AttributesHard', attributes_hard.max(dim=1)[1])\n",
    "\n",
    "        return image_features\n",
    "\n",
    "    def make_decision(self, lstm_out, binary_features, iter, sigma=[], max_uncertainty=0.2):\n",
    "        if self.model_type == 'xoc':\n",
    "            # Perform categorical feature selection\n",
    "            selection_logits = self.feature_selection(lstm_out)\n",
    "            \n",
    "            if self.strategy == 'remRDTC':\n",
    "                \n",
    "                uncertain_attributes = (sigma > 2e-4).float()\n",
    "#                 dummy = torch.zeros((sigma.size()), device=device)\n",
    "#                 dummy[uncertain_attributes] = -np.inf\n",
    "# #                 print(np.quantile(sigma.cpu().numpy(),0.99))\n",
    "# #                 attribute_uncertainties = torch.rand(binary_features.size(0), attribute_size, device=device, requires_grad=False)\n",
    "#                 self.mean_sigmas.append(sigma.mean().item())\n",
    "\n",
    "                \n",
    "                certain_attributes = 1. - uncertain_attributes\n",
    "                selection_logits = certain_attributes.detach() * selection_logits + uncertain_attributes.detach() * -100\n",
    "#             else:\n",
    "#                 new_selection_logits = selection_logits    \n",
    "#                 selection_probs = torch.softmax((selection_logits+dummy)/0.01, dim=1)\n",
    "    \n",
    "                if self.training:\n",
    "                    hard_selection = F.gumbel_softmax(selection_logits, tau=self.feature_selection.tau, hard=True)\n",
    "                else:\n",
    "#                     print(sigma.mean())\n",
    "                    hard_selection = self.argmax(selection_logits, dim=1)\n",
    "#                     print(hard_selection)\n",
    "\n",
    "            \n",
    "            else: # if another strategy is used\n",
    "                if self.training:\n",
    "                    hard_selection = F.gumbel_softmax(selection_logits, tau=self.feature_selection.tau, hard=True)\n",
    "                else:\n",
    "                    hard_selection = self.argmax(selection_logits, dim=1)\n",
    "\n",
    "\n",
    "            # Get single decision\n",
    "            self.saved_attribute_selection = hard_selection.max(dim=1)[1]\n",
    "            \n",
    "\n",
    "            decision = (hard_selection.unsqueeze(2) * binary_features).view(-1, self.attribute_size * self.decision_size)\n",
    "            # print(decision[0])\n",
    "        elif self.model_type == 'ioc':\n",
    "            if not self.shallow:\n",
    "                features = torch.cat((lstm_out, binary_features), dim=1)\n",
    "                selection_logits = self.feature_selection(features)\n",
    "            else:\n",
    "                shallow_weights = self.feature_selection(lstm_out)\n",
    "                shallow_weights = shallow_weights.view(lstm_out.size(0), -1, self.decision_size)\n",
    "                selection_logits = torch.bmm(binary_features.unsqueeze(1), shallow_weights)\n",
    "                selection_logits = selection_logits.squeeze()\n",
    "\n",
    "            soft_decision = F.softmax(selection_logits / self.tau_selection, dim=1)\n",
    "            hard_selection = self.argmax(soft_decision, dim=1)\n",
    "            decision = hard_selection\n",
    "\n",
    "        # Collect statistics\n",
    "        self.collect_hist_stats('SelectionSoft', F.softmax(selection_logits, dim=1).max(dim=1)[0], iter)\n",
    "        self.collect_hist_stats('SelectionSoftTemp', F.softmax(selection_logits / self.feature_selection.tau, dim=1).max(dim=1)[0], iter)\n",
    "        self.collect_hist_stats('SelectionHard', hard_selection.max(dim=1)[1], iter)\n",
    "\n",
    "        return decision\n",
    "\n",
    "    def get_initial_state(self, batch_size):\n",
    "        h0 = self.init_h0.view(1, 1, -1).expand(-1, batch_size, -1)\n",
    "        c0 = self.init_c0.view(1, 1, -1).expand(-1, batch_size, -1)\n",
    "        state = (h0.contiguous(), c0.contiguous())\n",
    "        return state\n",
    "\n",
    "    def argmax(self, y_soft, dim):\n",
    "        index = y_soft.max(dim, keepdim=True)[1]\n",
    "        y_hard = torch.zeros_like(y_soft).scatter_(dim, index, 1.0)\n",
    "        argmax = y_hard - y_soft.detach() + y_soft\n",
    "        return argmax\n",
    "\n",
    "    def collect_hist_stats(self, name, data, i=None):\n",
    "        # TODO: investigate performance impact of collecting these statistics,\n",
    "        # make option to disable and/or autodisable if tree is too large\n",
    "        if 'Hard' in name:\n",
    "            stat_str = 'Hist/' + name\n",
    "            data = data.detach().cpu()\n",
    "            self.stats[stat_str].append(data)\n",
    "            if i is not None:\n",
    "                stat_str += str(i)\n",
    "                self.stats[stat_str].append(data)\n",
    "\n",
    "    def get_hist_stats(self, reset=True):\n",
    "        stats = self.stats\n",
    "        if reset:\n",
    "            self.stats = defaultdict(list)\n",
    "        #return None\n",
    "        return stats\n",
    "\n",
    "    def reset_stats(self):\n",
    "        self.unique_attributes = [set() for i in range(self.max_iters)]\n",
    "        if self.attribute_coef > 0.:\n",
    "            self.attr_pred_correct = [0 for i in range(self.max_iters)]\n",
    "\n",
    "    def update_unique_attributes(self, unique_attributes, iter):\n",
    "        for attr in unique_attributes:\n",
    "            self.unique_attributes[iter].add(attr.item())\n",
    "\n",
    "    def get_unique_attributes(self):\n",
    "        uniq_per_iter = []\n",
    "        for i in range(self.max_iters):\n",
    "            iter_set = self.unique_attributes[i]\n",
    "            for j in range(i+1):\n",
    "                if j == i:\n",
    "                    continue\n",
    "                iter_set = iter_set.union(self.unique_attributes[j])\n",
    "            uniq_per_iter.append(len(iter_set))\n",
    "        return uniq_per_iter\n",
    "\n",
    "    def update_attr_preds(self, attr_correct, iter):\n",
    "        self.attr_pred_correct[iter] += attr_correct\n",
    "\n",
    "    def get_attr_acc(self, total_cnt):\n",
    "        correct_cumsum = np.cumsum(self.attr_pred_correct)\n",
    "        cnt_per_iter = (np.arange(self.max_iters) + 1) * total_cnt\n",
    "        return correct_cumsum / cnt_per_iter\n",
    "\n",
    "    def init_tree_stats(self):\n",
    "        # TODO: investigate performance impact of collecting these statistics,\n",
    "        # make option to disable and/or autodisable if tree is too large\n",
    "\n",
    "        # Would be nice if this worked with sparse tensors\n",
    "        n_possible_states = self.reduced_vocab_size** self.max_iters\n",
    "        self.label_stats = torch.zeros((n_possible_states * self.reduced_vocab_size,\n",
    "                                        self.num_classes), dtype=torch.int32)\n",
    "                                       #layout=torch.sparse_coo)\n",
    "        self.selection_stats = torch.zeros((n_possible_states,\n",
    "                                            self.attribute_size),\n",
    "                                           dtype=torch.int32)\n",
    "                                           #layout=torch.sparse_coo)\n",
    "\n",
    "    def update_tree_stats(self, attribute_selection, attribute_decisions, labels, iter):\n",
    "        # TODO: investigate performance impact of collecting these statistics,\n",
    "        # make option to disable and/or autodisable if tree is too large\n",
    "\n",
    "        if iter == 0:\n",
    "            self.batch_states = torch.zeros_like(labels)\n",
    "            for i in range(labels.size(0)):\n",
    "                self.label_stats[self.batch_states[i], labels[i]] += 1\n",
    "\n",
    "        for i in range(labels.size(0)):\n",
    "            self.selection_stats[self.batch_states[i], attribute_selection[i]] += 1\n",
    "            self.batch_states[i] += (attribute_decisions[i] + 1) * self.decision_size ** iter\n",
    "            self.label_stats[self.batch_states[i], labels[i]] += 1\n",
    "\n",
    "    def run_iteration(self, binary_features, state, decision_hist, iter, sigma=[]): # also pass sigma here\n",
    "        lstm_out = state[0].squeeze(0)\n",
    "\n",
    "        # Make binary decision\n",
    "        decision = self.make_decision(lstm_out, binary_features, iter, sigma)\n",
    "\n",
    "        if decision_hist is None:\n",
    "            decision_hist = decision\n",
    "        else:\n",
    "            decision_hist = (decision_hist + decision).clamp(0., 1.)\n",
    "\n",
    "        scaled_dh = decision_hist / decision_hist.sum(dim=1).unsqueeze(1).detach()\n",
    "        if self.no_lstm:\n",
    "            lstm_in = scaled_dh\n",
    "        else:\n",
    "            lstm_in = torch.cat((scaled_dh, decision), dim=1)\n",
    "\n",
    "        # Update LSTM state\n",
    "        lstm_in = self.pre_lstm(lstm_in).unsqueeze(1)\n",
    "        _, state = self.lstm(lstm_in, state)\n",
    "\n",
    "        # Get current classification\n",
    "        classifier_in = scaled_dh\n",
    "        #classifier_in = state[1].squeeze(0)\n",
    "        #classifier_in = torch.cat((decision_hist, self.lstm_state_bn(lstm_state)), dim=1)\n",
    "        classification = self.classifier(classifier_in)\n",
    "\n",
    "        return classification, state, decision_hist\n",
    "\n",
    "    def tree_rollout(self, images, labels, keep_tree_stats=False):\n",
    "        # Set initial state\n",
    "        state = self.get_initial_state(images.size(0))\n",
    "\n",
    "        # Get categorical features once\n",
    "#         binary_features = self.process_images(images)\n",
    "        \n",
    "        binary_features, attribute_uncertainties = self.process_images_new(images)\n",
    "#         print(alt_binary_features.size())\n",
    "#         print(attribute_uncertainties.size())\n",
    "        # collect attribute stats\n",
    "\n",
    "#         attr_acc = (binary_features[:,:,0] == attribute_mtx[labels]).sum().long() / 19968.0 #/ (312*labels.size(0))\n",
    "#         attr_acc = (binary_features[:,:,0] == attribute_mtx[labels]).sum().long() / float((attribute_size*labels.size(0)))    \n",
    "#         print(attr_acc)\n",
    "#         self.attribute_accuracies.append(attr_acc.item())\n",
    "#         self.mean_sigmas.append(attribute_uncertainties.mean().item())\n",
    "#         uncertain_attributes = (attribute_uncertainties > 2e-4).float()\n",
    "#         self.drop_ratios.append((uncertain_attributes.sum()/19968.0).item())\n",
    "\n",
    "\n",
    "        ######################### extended vocab code \n",
    "        if self.strategy == 'extRDTC':\n",
    "#             with torch.no_grad():\n",
    "#                 img_feats = self.cnn(images)\n",
    "#                 img_feats = img_feats.view(img_feats.size(0), -1)\n",
    "#                 sigmas = self.get_attribute_uncertainty(img_feats, n=5, batch_size=images.size(0))\n",
    "#                 attribute_sigma = self.get_attribute_uncertainty_new(img_feats, n=5, batch_size=images.size(0))\n",
    "#                 print(attribute_sigma.size())\n",
    "            if not self.training:\n",
    "                self.sigmas_list.append(attribute_uncertainties)\n",
    "#                 self.labels_list.append(labels)\n",
    "                self.binary_features_list.append(binary_features)\n",
    "                self.labels_list.append(labels)\n",
    "\n",
    "\n",
    "        \n",
    "#             self.mean_sigmas.append(attribute_uncertainties.mean().item())\n",
    "#             sigmas = (sigmas > 0.0002).float() # 0.03925,0.06\n",
    "# #             sigmas = (sigmas > 0.05).float() # 0.005\n",
    "#             sigmas_new = torch.zeros(images.size(0), attribute_size,1, device=device)\n",
    "#             sigmas_new += sigmas.view(images.size(0),-1,2)[:,:,0].unsqueeze(2)\n",
    "#             sigmas_new += sigmas.view(images.size(0),-1,2)[:,:,1].unsqueeze(2)\n",
    "#             sigmas_new = (sigmas_new > 0.0).float() # <- denotes uncertain attributes\n",
    "#             print(sigmas_new.size())\n",
    "            uncertain_attributes = (attribute_uncertainties>2e-5).float().unsqueeze(2)\n",
    "#             print(uncertain_attributes.size())\n",
    "#             print()\n",
    "#             self.drop_ratios.append((uncertain_attributes.sum()/19968.0).item())\n",
    "\n",
    "            # obtain uncertainty and append to decision\n",
    "            new_attribute_decisions = torch.cat([binary_features, torch.zeros_like(uncertain_attributes, device=device)], dim=2)\n",
    "            certain_decisions = 1. - uncertain_attributes\n",
    "            uncertain_onehot = torch.tensor([[0., 0., 1.]], device=device).repeat(images.size(0), attribute_size, 1)\n",
    "            uncertain_attrs_removed = certain_decisions.detach() * new_attribute_decisions\n",
    "            shaped_uncertain_attrs = uncertain_attributes.detach() * uncertain_onehot\n",
    "            final_attribute_decisions = uncertain_attrs_removed + shaped_uncertain_attrs\n",
    "            binary_features = final_attribute_decisions\n",
    "#         ######################### extended vocab code end\n",
    "        \n",
    "        \n",
    "\n",
    "        loss = 0\n",
    "        j = 0\n",
    "        # stats\n",
    "        all_classifications = []\n",
    "        all_chosen_attr = []\n",
    "        all_attribute_preds = []\n",
    "\n",
    "        decision_hist = None\n",
    "        while j < self.max_iters:\n",
    "            classification, state, decision_hist = self.run_iteration(binary_features, state, decision_hist, j+1, sigma=attribute_uncertainties)\n",
    "            loss += (1. - self.attribute_coef) * self.cls_loss(classification, labels)\n",
    "            all_classifications.append(classification)\n",
    "\n",
    "            self.update_unique_attributes(self.saved_attribute_selection.unique(), j)\n",
    "\n",
    "            if self.model_type == 'xoc' and self.attribute_coef > 0.:\n",
    "                chosen_attribtutes = self.saved_attribute_selection\n",
    "                attribute_logits = self.attribute_logits\n",
    "\n",
    "                attribute_target = self.attribute_mtx[labels, :].gather(1, chosen_attribtutes.unsqueeze(1)).squeeze()\n",
    "                attribute_pred = attribute_logits.gather(1, chosen_attribtutes.unsqueeze(1)).squeeze()\n",
    "                loss += self.attribute_coef * self.attr_loss(attribute_pred,\n",
    "                                                             attribute_target)\n",
    "                \n",
    "\n",
    "\n",
    "                attribute_pred_bin = (attribute_pred > 0.).long()\n",
    "                self.update_attr_preds((attribute_pred_bin == attribute_target).sum().item(), j)\n",
    "\n",
    "                \n",
    "            if keep_tree_stats:\n",
    "                attribute_pred = self.attribute_logits.gather(1, self.saved_attribute_selection.unsqueeze(1)).squeeze()\n",
    "                self.update_tree_stats(self.saved_attribute_selection, (attribute_pred > 0.).long(),labels, j)\n",
    "\n",
    "                # all_chosen_attr.append(self.saved_attribute_selection)\n",
    "                all_attribute_preds.append((attribute_pred > 0.).long())\n",
    "\n",
    "            j += 1\n",
    "        \n",
    "            all_chosen_attr.append(self.saved_attribute_selection)\n",
    "\n",
    "\n",
    "        self.tmp_saved_chosen_attr = torch.stack(all_chosen_attr, dim=1)\n",
    "\n",
    "        if keep_tree_stats:\n",
    "            self.tmp_saved_cls = torch.stack(all_classifications, dim=1)\n",
    "#             self.tmp_saved_chosen_attr = torch.stack(all_chosen_attr, dim=1)\n",
    "            self.tmp_saved_attr_pred = torch.stack(all_attribute_preds, dim=1)\n",
    "        # else:\n",
    "        #     self.tmp_saved_chosen_attr = None\n",
    "\n",
    "        loss = loss / self.max_iters\n",
    "                ####################################\n",
    "        if binary_features.size(0)==64:\n",
    "            # self.used_attributes_list.append(self.tmp_saved_chosen_attr)\n",
    "            # self.certain_attrs.append(certain_decisions)\n",
    "#             print(self.tmp_saved_chosen_attr.size())\n",
    "            chosen_attributes_binary = torch.tensor([[1 if x in [int(attr) for attr in self.tmp_saved_chosen_attr[row,:]] else 0 for x in range(312)] for row in range(64)])\n",
    "#             ###chosen_attributes_binary = torch.tensor([1 if x in [int(attr) for attr in self.tmp_saved_chosen_attr[:,x]] else 0 for x in range(312)], device=device)\n",
    "            self.used_attributes_list.append(chosen_attributes_binary)\n",
    "#             print(chosen_attributes_binary.size())\n",
    "        \n",
    "\n",
    "        return all_classifications, loss, self.tmp_saved_chosen_attr\n",
    "\n",
    "    def forward(self, images, labels, keep_tree_stats=False):\n",
    "        classification, loss, chosen_attribtutes = self.tree_rollout(images, labels, keep_tree_stats)\n",
    "        # classification, loss, chosen_attributes = self.tree_rollout(images, labels, keep_tree_stats)\n",
    "\n",
    "        return classification, loss#, chosen_attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "After defining our models, we can continue by training it. For this, we first set some hyperparameters and then continue by defining a trainer class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake input arguments\n",
    "model_type = 'xoc'\n",
    "cnn_type = 'uncertain'\n",
    "# cnn_type = 'resnet'\n",
    "attribute_coef = 0.2\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.#0.0001\n",
    "step_size = 50\n",
    "num_epochs = 2\n",
    "max_iters = 10\n",
    "hidden_size = 1000\n",
    "cnn_out_size = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, dataloaders, num_epochs, device, log_freq, log_path): # todo remove stats dict\n",
    "\n",
    "        self.model = model\n",
    "        self.dataloaders = dataloaders\n",
    "        self.num_epochs = num_epochs\n",
    "        self.device = device\n",
    "        self.log_freq = log_freq\n",
    "        self.log_path = log_path\n",
    "        \n",
    "        self.logger = SummaryWriter(self.log_path)\n",
    "\n",
    "        #### TODO remove this workaround and use tensorboard\n",
    "#         with open('/content/drive/My Drive/rdtc/data/' + 'logs/' + 'stats_dict.json') as json_file:\n",
    "#             self.stats_dict = json.load(json_file)\n",
    "        \n",
    "        self.classifications_dict = {'correct':{'num':0, 'uncertainty':0},\n",
    "                                     'incorrect':{'num':0, 'uncertainty':0}}\n",
    "\n",
    "        self.uncertainty_stats = {'epoch_{}'.format(epoch):{'used_attributes':[],'sigmas':[], 'num_attrs_discarded':0} for epoch in range(num_epochs+2)}\n",
    "        self.mean_attr_accs = []\n",
    "        self.mean_drop_ratio = []\n",
    "        self.mean_sigmas = []\n",
    "        ############\n",
    "\n",
    "    def train(self):\n",
    "        self.model.phase = 'train'\n",
    "        self.train_model(self.dataloaders['train'])\n",
    "\n",
    "    def test(self):\n",
    "        self.model.phase = 'test'\n",
    "        self.test_model(self.dataloaders['test'], 'test', None, hard=False) # was: hard=True\n",
    "        self.model.phase = 'train'\n",
    "#         return self.model.label_stats, self.model.selection_stats\n",
    "\n",
    "    def topk_correct(self, output, target, topk=(1,)):\n",
    "        maxk = max(topk)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        target_masks = []\n",
    "        target_cnt = []\n",
    "        for i in range(self.model.num_classes):\n",
    "            target_masks.append((target == i).unsqueeze(0))\n",
    "            target_cnt.append(target_masks[i].sum().item())\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = [(correct[:k] * tm).view(-1).float().sum(0, keepdim=True).item() for tm in target_masks]\n",
    "            res.append(np.array(correct_k))\n",
    "        return res, np.array(target_cnt)\n",
    "\n",
    "    def log_stats(self, phase, epoch, epoch_stats, hist_stats,\n",
    "                  unique_attr_stats, attr_acc):\n",
    "        for k in range(len(epoch_stats[0])):\n",
    "        # for k in range(1):\n",
    "\n",
    "            self.logger.add_scalar('Top1Accuracy{}/{}'.format(k+1, phase), epoch_stats[0][k], epoch)\n",
    "            # self.logger.add_scalar('Top5Accuracy{}/{}'.format(k+1, phase), epoch_stats[1][k], epoch)\n",
    "            # self.logger.add_scalar('Top1MeanClassAccuracy{}/{}'.format(k+1, phase), epoch_stats[3][k], epoch)\n",
    "            # self.logger.add_scalar('Top5MeanClassAccuracy{}/{}'.format(k+1, phase), epoch_stats[4][k], epoch)\n",
    "            # if unique_attr_stats is not None:\n",
    "            #     self.logger.add_scalar('UniqueAttributes{}/{}'.format(k+1, phase), unique_attr_stats[k], epoch)\n",
    "            # if attr_acc is not None:\n",
    "            #     self.logger.add_scalar('AttributeAccuracy{}/{}'.format(k+1, phase), attr_acc[k], epoch)\n",
    "        self.logger.add_scalar('Loss/'+phase, epoch_stats[2], epoch)\n",
    "\n",
    "        if hist_stats is not None:\n",
    "            for name, data in hist_stats.items():\n",
    "                data = torch.cat(data, dim=0).flatten()\n",
    "                if name.startswith('SelectionHard'):\n",
    "                    bins = self.model.attribute_size\n",
    "                elif name.startswith('AttributesHard'):\n",
    "                    bins = self.model.decision_size\n",
    "                else:\n",
    "                    bins = 'tensorflow'\n",
    "                self.logger.add_histogram(name, data, epoch, bins=bins)\n",
    "\n",
    "    def test_model(self, data_loader, phase, epoch, hard=False):\n",
    "        # Test the Model\n",
    "        self.model.eval()  # Change model to 'eval' mode (BN uses moving mean/var).\n",
    "        n_stats = self.model.max_iters if hasattr(self.model, 'max_iters') else 1\n",
    "        correct_1 = np.zeros((n_stats, self.model.num_classes))\n",
    "        correct_5 = np.zeros((n_stats, self.model.num_classes))\n",
    "        total = 0\n",
    "        total_cnt = np.zeros((1, self.model.num_classes))\n",
    "        total_loss = 0\n",
    "\n",
    "        if isinstance(self.model, OC):\n",
    "            self.model.reset_stats()\n",
    "            if hard:\n",
    "                self.model.init_tree_stats()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for idx, data in enumerate(data_loader):\n",
    "                if len(data) == 2:\n",
    "                    images, labels = data\n",
    "                    attributes = None\n",
    "                else:\n",
    "                    images, labels, attributes = data\n",
    "                    #attributes = attributes.to(self.device)\n",
    "                images = images.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                \n",
    "                classification, loss = self.model(images, labels, hard)\n",
    "                #####################################\n",
    "#                 print(labels.size())\n",
    "#                 print(labels[0].item())\n",
    "                #####################################\n",
    "\n",
    "                # Collect stats\n",
    "                total_loss += loss.item()\n",
    "                total += labels.size(0)\n",
    "                for k in range(len(classification)):\n",
    "                    ######################\n",
    "                    # print(classification[k].data)\n",
    "                    # print(labels[k])\n",
    "                    # print()\n",
    "                    # print(classification[k].data.size())\n",
    "                    # print(labels.size())\n",
    "                    # print()\n",
    "                    # values, indices = torch.max(classification[k], -1)\n",
    "                    # for i in range(classification[k].size(0)):\n",
    "\n",
    "                        # print(indices[i].item(),labels[i].item())\n",
    "                        # if indices[i].item()==labels[i].item():\n",
    "                        #     self.classifications_dict['correct']+=1\n",
    "                        # if indices[i].item()!=labels[i].item():\n",
    "                        #     self.classifications_dict['incorrect']+=1              \n",
    "          \n",
    "                    ######################\n",
    "                    ctopk, target_cnt = self.topk_correct(classification[k].data, labels, (1, 5))\n",
    "                    c1, c5 = ctopk\n",
    "                    # print(target_cnt)\n",
    "                    correct_1[k] += c1\n",
    "                    correct_5[k] += c5\n",
    "                total_cnt[0] += target_cnt\n",
    "\n",
    "                \n",
    "     \n",
    "        stats = [correct_1.sum(axis=1) / total, correct_5.sum(axis=1) / total, total_loss / total, (correct_1 / total_cnt).mean(axis=1), (correct_5 / total_cnt).mean(axis=1)]\n",
    "        print('Accuracy ({}), Top1: {:.2%}, Top5: {:.2%}'.format(phase, stats[0][-1], stats[1][-1]))\n",
    "        self.model.train()  # Change model to 'train' mode\n",
    "\n",
    "        unique_attr_stats = None\n",
    "        attr_acc = None\n",
    "        if epoch is not None:\n",
    "            if isinstance(self.model, OC):\n",
    "                hist_stats = self.model.get_hist_stats()\n",
    "                unique_attr_stats = self.model.get_unique_attributes()\n",
    "                if self.model.attribute_coef > 0.:\n",
    "                    attr_acc = self.model.get_attr_acc(total)\n",
    "                else:\n",
    "                    attr_acc = None\n",
    "            else:\n",
    "                hist_stats = None\n",
    "            self.log_stats(phase, epoch, stats, hist_stats, unique_attr_stats, attr_acc)\n",
    "\n",
    "        return stats[0][-1], stats, unique_attr_stats, attr_acc\n",
    "\n",
    "    def train_model(self, data_laoder):\n",
    "        max_accuracy = 0\n",
    "        max_agg_accuracy = 0\n",
    "        max_ma_accuracy = 0\n",
    "        max_ma_agg_accuracy = 0\n",
    "\n",
    "        if isinstance(self.model, OC):\n",
    "            self.model.reset_stats()\n",
    "\n",
    "        # Train the Model       \n",
    "        for epoch in range(self.num_epochs):\n",
    "            #self.model.set_tau(epoch)\n",
    "            optimizer = self.model.get_optimizer()\n",
    "            n_stats = self.model.max_iters if hasattr(self.model, 'max_iters') else 1\n",
    "            correct_1 = np.zeros((n_stats, self.model.num_classes))\n",
    "            correct_5 = np.zeros((n_stats, self.model.num_classes))\n",
    "            total = 0\n",
    "            total_cnt = np.zeros((1, self.model.num_classes))\n",
    "            total_loss = 0\n",
    "\n",
    "            for i, data in enumerate(data_laoder):\n",
    "                \n",
    "                if len(data) == 2:\n",
    "                    images, labels = data\n",
    "                    attributes = None\n",
    "                else:\n",
    "                    images, labels, attributes = data\n",
    "                    #attributes = attributes.to(self.device)\n",
    "                images = images.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                classification, loss = self.model(images, labels)\n",
    "                \n",
    "\n",
    "                if loss.grad_fn is not None:\n",
    "                \n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # Collect stats\n",
    "                total_loss += loss.item()\n",
    "                total += labels.size(0)\n",
    "                for k in range(len(classification)):\n",
    "                    ctopk, target_cnt = self.topk_correct(classification[k].data, labels, (1, 5))\n",
    "                    c1, c5 = ctopk\n",
    "                    correct_1[k] += c1\n",
    "                    correct_5[k] += c5\n",
    "                total_cnt[0] += target_cnt\n",
    "\n",
    "                if (i+1) % self.log_freq == 0:\n",
    "                    print('Epoch [{}/{}], Iter [{}/{}] Loss: {:.4f}'\n",
    "                            .format(epoch+1, self.num_epochs, i+1, len(data_laoder)//images.size(0),\n",
    "                                    loss.item()))\n",
    "                    ##### TODO remove workaround and use tensurboard\n",
    "                    # self.stats_dict[configuration]['losses'].append(loss.item())\n",
    "            \n",
    "        # with open(data_path + '/logs/' + 'stats_dict.json', 'w') as json_file:\n",
    "        #     json.dump(self.stats_dict, json_file)\n",
    "        #     print('stats dict saved...')\n",
    "                    #############################################\n",
    "\n",
    "            self.model.get_scheduler().step()\n",
    "            # if isinstance(self.model, NeuralDecisionForest) or isinstance(self.model, OC):\n",
    "            #     self.model.toggle_update_schedule()\n",
    "\n",
    "            stats = [correct_1.sum(axis=1) / total, correct_5.sum(axis=1) / total, total_loss / total, (correct_1 / total_cnt).mean(axis=1), (correct_5 / total_cnt).mean(axis=1)]\n",
    "\n",
    "            if isinstance(self.model, OC):\n",
    "                hist_stats = self.model.get_hist_stats()\n",
    "                unique_attr_stats = self.model.get_unique_attributes()\n",
    "                if self.model.attribute_coef > 0.:\n",
    "                    attr_acc = self.model.get_attr_acc(total)\n",
    "                else:\n",
    "                    attr_acc = None\n",
    "            else:\n",
    "                hist_stats = None\n",
    "                unique_attr_stats = None\n",
    "                attr_acc = None\n",
    "            self.log_stats('train', epoch, stats, hist_stats, unique_attr_stats, attr_acc)\n",
    "            print('Accuracy (train), Top1: {:.2%}, Top5: {:.2%}'.format(stats[0][-1], stats[1][-1]))\n",
    "            self.model.phase = 'test'\n",
    "            val_accuracy, val_stats, _, _ = self.test_model(self.dataloaders['val'],\n",
    "                                                            'val', epoch+1)\n",
    "            val_agg_accuracy = val_stats[0].sum()\n",
    "            val_ma_accuracy = val_stats[3][-1]\n",
    "            val_ma_agg_accuracy = val_stats[3].sum()\n",
    "\n",
    "            # reset model stats\n",
    "            model.sigmas_list = []\n",
    "            model.labels_list = []\n",
    "            model.used_attributes_list = []\n",
    "            model.attribute_accuracies = []\n",
    "            model.drop_ratios = []\n",
    "#             self.model.phase = 'test'\n",
    "            _, test_stats, unique_attr_stats, attr_acc = self.test_model(self.dataloaders['test'], 'test', epoch+1)\n",
    "            \n",
    "#             if model.drop_ratios[0].size(0) == 64:\n",
    "            self.mean_drop_ratio.append(sum(model.drop_ratios)/(len(model.drop_ratios)+1))\n",
    "            mean_attribute_accuracy = sum(model.attribute_accuracies)/(len(model.attribute_accuracies)+1)\n",
    "            self.mean_sigmas.append(sum(model.mean_sigmas)/(len(model.mean_sigmas)+1))\n",
    "            self.mean_attr_accs.append(mean_attribute_accuracy)\n",
    "#             print(mean_attribute_accuracy)\n",
    "#             print()\n",
    "            # # collect uncertainty stats\n",
    "            # self.uncertainty_stats['epoch_{}'.format(epoch)]['used_attributes']=self.model.used_attributes_list\n",
    "            # self.model.used_attributes_list = []\n",
    "            # self.uncertainty_stats['epoch_{}'.format(epoch)]['sigmas']=self.model.sigmas_list\n",
    "            # self.model.sigmas_list = []           \n",
    "            \n",
    "            \n",
    "            \n",
    "            self.model.phase = 'train'\n",
    "            if val_accuracy > max_accuracy:\n",
    "                max_accuracy = val_accuracy\n",
    "#                 self.save_model('best', test_stats, 0, unique_attr_stats, attr_acc, epoch)\n",
    "            if val_ma_accuracy > max_ma_accuracy:\n",
    "                max_ma_accuracy = val_ma_accuracy\n",
    "#                 self.save_model('best_ma', test_stats, 3, unique_attr_stats, attr_acc, epoch)\n",
    "            if val_agg_accuracy > max_agg_accuracy and isinstance(self.model, OC):\n",
    "                max_agg_accuracy = val_agg_accuracy\n",
    "                self.save_model('best_agg', test_stats, 0, unique_attr_stats, attr_acc, epoch)\n",
    "            if val_ma_agg_accuracy > max_ma_agg_accuracy and isinstance(self.model, OC):\n",
    "                max_ma_agg_accuracy = val_ma_agg_accuracy\n",
    "#                 self.save_model('best_ma_agg', test_stats, 3, unique_attr_stats, attr_acc, epoch)\n",
    "\n",
    "            self.save_model('latest', test_stats, 0, unique_attr_stats, attr_acc, epoch)\n",
    "        # with open(data_path + '/logs/' + 'stats_dict.json', 'w') as json_file:\n",
    "        #     json.dump(self.stats_dict, json_file)\n",
    "        #     print('stats dict saved...')\n",
    "\n",
    "\n",
    "    def write_stats_file(self, stats_list, name, epoch, is_float=True):\n",
    "        fstr = '{:.2f}' if is_float else '{}'\n",
    "        with open(os.path.join(self.log_path, '{}.txt'.format(name)), 'a') as f:\n",
    "            acc_str = [fstr.format(100*c1 if is_float else c1) for c1 in stats_list]\n",
    "            f.write('{} '.format(epoch) + ' '.join(acc_str))\n",
    "            f.write('\\n')\n",
    "\n",
    "    def save_model(self, name, test_stats, stats_idx, unique_attr_stats, attr_acc, epoch):\n",
    "        torch.save(self.model.state_dict(),\n",
    "                   os.path.join(self.log_path, '{}.pth'.format(name)))\n",
    "        \n",
    "        # save state dict for vision model separately\n",
    "        torch.save(self.model.cnn.state_dict(), os.path.join(self.log_path, '{}_vision_model.pth'.format(name)))\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.write_stats_file(test_stats[stats_idx], name, epoch)\n",
    "\n",
    "        # if isinstance(self.model, NeuralDecisionForest):\n",
    "        #     _, test_stats_hard, _, _ = self.test_model(self.dataloaders['test'],\n",
    "        #                                                'test', epoch+1, hard=True)\n",
    "        #     self.write_stats_file(test_stats_hard[stats_idx], name+'_hard', epoch)\n",
    "\n",
    "        if unique_attr_stats is not None:\n",
    "            self.write_stats_file(unique_attr_stats, name+'_uniqattr', epoch,\n",
    "                                  is_float=False)\n",
    "\n",
    "        if attr_acc is not None:\n",
    "            self.write_stats_file(attr_acc, name+'_attracc', epoch)\n",
    "\n",
    "        if name != 'latest':\n",
    "            print('Saved {} model'.format(name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's instance our models..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the configuraion parameters of our dataset\n",
    "in_channels, cnn_out_size, log_freq = get_dataset_config(dataset, 'cnn', 40 )\n",
    "cnn_out_size = 2048\n",
    "\n",
    "# initiate the observer classifier model\n",
    "model = OC('xoc', len(classes), 'dropoutcnn', in_channels,\n",
    "            cnn_out_size, dataset, 3, 10, # 13 worked\n",
    "            attribute_size, attribute_mtx, attribute_coef,\n",
    "            hidden_size, tau_initial=5,\n",
    "            use_pretrained=False, shallow=False)\n",
    "\n",
    "# load pretrained resnet backbone\n",
    "model.cnn = models.resnet152(pretrained=False)\n",
    "# model.cnn.fc = nn.Linear(model.cnn.fc.in_features, torch.load('/home/swezel/projects/urdtc/pretrained/cub_resnet152.pkl')['fc.weight'].size(0))\n",
    "# model.cnn.load_state_dict(torch.load('/home/swezel/projects/urdtc/pretrained/cub_resnet152.pkl'))\n",
    "model.cnn.fc = nn.Linear(model.cnn.fc.in_features, torch.load('/home/swezel/projects/urdtc/pretrained/{}_resnet152.pkl'.format(dataset))['fc.weight'].size(0))\n",
    "model.cnn.load_state_dict(torch.load('/home/swezel/projects/urdtc/pretrained/{}_resnet152.pkl'.format(dataset)))\n",
    "\n",
    "\n",
    "model.cnn.fc = nn.Identity()\n",
    "\n",
    "# set attribute head\n",
    "model.binary_features = nn.Sequential(nn.BatchNorm1d(cnn_out_size),\n",
    "                                        nn.Linear(cnn_out_size, hidden_size),\n",
    "                                        nn.ReLU(inplace=True),\n",
    "                                        nn.BatchNorm1d(hidden_size),\n",
    "                                        nn.Dropout(0.5, inplace=False), # dropout after batchnorm\n",
    "                                        nn.Linear(hidden_size, hidden_size),\n",
    "                                        nn.ReLU(inplace=True),\n",
    "                                        nn.BatchNorm1d(hidden_size),\n",
    "                                        nn.Dropout(0.5, inplace=False),\n",
    "                                        nn.Linear(hidden_size, attribute_size * 2))\n",
    "\n",
    "model.binary_features.tau = nn.Parameter(torch.tensor([5], dtype=torch.float), requires_grad=True)\n",
    "model.to(device);\n",
    "\n",
    "# freeze resnet backbone for faster training but make all other weights trainable\n",
    "for param in model.lstm.parameters():\n",
    "    param.requires_grad=True\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad=True\n",
    "for param in model.feature_selection.parameters():\n",
    "    param.requires_grad=True\n",
    "for param in model.binary_features.parameters():\n",
    "    param.requires_grad=True\n",
    "for param in model.pre_lstm.parameters():\n",
    "    param.requires_grad=True\n",
    "    \n",
    "for param in model.cnn.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.cnn.fc.parameters():\n",
    "    param.requires_grad=True\n",
    "    \n",
    "# initiate optimizers\n",
    "tree_params, cnn_params = model.get_param_groups()\n",
    "tree_optimizer = torch.optim.Adam(tree_params, lr = learning_rate, weight_decay=weight_decay)\n",
    "cnn_optimizer = torch.optim.Adam(cnn_params, lr = learning_rate, weight_decay=weight_decay)\n",
    "optimizer = [tree_optimizer, cnn_optimizer]\n",
    "# and schedulers\n",
    "tree_scheduler = torch.optim.lr_scheduler.StepLR(tree_optimizer, step_size=step_size, gamma=0.1)\n",
    "cnn_scheduler = torch.optim.lr_scheduler.StepLR(cnn_optimizer, step_size=step_size, gamma=0.1)\n",
    "scheduler = [tree_scheduler, cnn_scheduler]\n",
    "\n",
    "model.set_optimizer(optimizer)\n",
    "# model.init_tree_stats()\n",
    "model.set_scheduler(scheduler)\n",
    "##h\n",
    "# model.strategy = 'randRDTC'\n",
    "# model.strategy = 'remRDTC'\n",
    "model.strategy = 'extRDTC'\n",
    "##hook\n",
    "# model.strategy = 'aRDTC'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and finally train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Iter [10/1] Loss: 4.4890\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-175-ba9870471734>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/../log/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-28e3bb35b834>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-28e3bb35b834>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, data_laoder)\u001b[0m\n\u001b[1;32m    192\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m                 \u001b[0mclassification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/uoc/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-171-ba16290fb377>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, labels, keep_tree_stats)\u001b[0m\n\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_tree_stats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m         \u001b[0mclassification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchosen_attribtutes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_rollout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_tree_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    713\u001b[0m         \u001b[0;31m# classification, loss, chosen_attributes = self.tree_rollout(images, labels, keep_tree_stats)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-171-ba16290fb377>\u001b[0m in \u001b[0;36mtree_rollout\u001b[0;34m(self, images, labels, keep_tree_stats)\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# self.certain_attrs.append(certain_decisions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[0;31m#             print(self.tmp_saved_chosen_attr.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             \u001b[0mchosen_attributes_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtmp_saved_chosen_attr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m312\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;31m#             ###chosen_attributes_binary = torch.tensor([1 if x in [int(attr) for attr in self.tmp_saved_chosen_attr[:,x]] else 0 for x in range(312)], device=device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mused_attributes_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchosen_attributes_binary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-171-ba16290fb377>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# self.certain_attrs.append(certain_decisions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[0;31m#             print(self.tmp_saved_chosen_attr.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             \u001b[0mchosen_attributes_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtmp_saved_chosen_attr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m312\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;31m#             ###chosen_attributes_binary = torch.tensor([1 if x in [int(attr) for attr in self.tmp_saved_chosen_attr[:,x]] else 0 for x in range(312)], device=device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mused_attributes_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchosen_attributes_binary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-171-ba16290fb377>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# self.certain_attrs.append(certain_decisions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[0;31m#             print(self.tmp_saved_chosen_attr.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             \u001b[0mchosen_attributes_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtmp_saved_chosen_attr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m312\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;31m#             ###chosen_attributes_binary = torch.tensor([1 if x in [int(attr) for attr in self.tmp_saved_chosen_attr[:,x]] else 0 for x in range(312)], device=device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mused_attributes_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchosen_attributes_binary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-171-ba16290fb377>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# self.certain_attrs.append(certain_decisions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[0;31m#             print(self.tmp_saved_chosen_attr.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             \u001b[0mchosen_attributes_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtmp_saved_chosen_attr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m312\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;31m#             ###chosen_attributes_binary = torch.tensor([1 if x in [int(attr) for attr in self.tmp_saved_chosen_attr[:,x]] else 0 for x in range(312)], device=device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mused_attributes_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchosen_attributes_binary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model, dataloaders, 10, device, log_freq, data_path + '/../log/')\n",
    "torch.cuda.empty_cache()\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "[0.008769466024165487, 0.01692436178943709, 0.019500222350673183, 0.020969420833432156, 0.02276958377383973, 0.02337871055604647, 0.02356651112558725, 0.0230303270863774, 0.022462570806965232, 0.022027091447101986]\n",
      "\n",
      "[1.4856674289163531e-05, 4.453562348558458e-05, 6.280758732873519e-05, 7.567543573304952e-05, 8.675725339989109e-05, 9.542724129258997e-05, 0.00010176273999800186, 0.00010816451014353676, 0.00011275476479622468, 0.00011742354715490427]\n"
     ]
    }
   ],
   "source": [
    "print(trainer.mean_attr_accs)\n",
    "print()\n",
    "print(trainer.mean_drop_ratio)\n",
    "print()\n",
    "print(trainer.mean_sigmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (test), Top1: 47.57%, Top5: 77.77%\n"
     ]
    }
   ],
   "source": [
    "in_channels, cnn_out_size, log_freq = get_dataset_config(dataset, 'cnn', 40 )\n",
    "# cnn_out_size=2048\n",
    "model.load_state_dict(torch.load(data_path + '/../log/extRDTC_best_agg.pth'))#,  map_location=lambda storage, loc: storage)\n",
    "model.cnn.load_state_dict(torch.load(data_path + '/../log/extRDTC_best_agg_vision_model.pth'))\n",
    "# model.train()\n",
    "# model.eval()\n",
    "# print(model.n_possible_states)\n",
    "trainer = Trainer(model, dataloaders, 3, device, log_freq, data_path + '/../log/')\n",
    "# model.reset_stats()\n",
    "# model.init_tree_stats()\n",
    "trainer.test();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulated_error = torch.zeros(312, device=device)\n",
    "accumulated_sigmas = torch.zeros(312, device=device)\n",
    "accumulated_usage = torch.zeros(312, device=device)\n",
    "num_batches = len(model.binary_features_list)\n",
    "batch_size = model.binary_features_list[0].size(0)\n",
    "\n",
    "\n",
    "for batch_index in range(num_batches):\n",
    "    if model.binary_features_list[batch_index].size(0)==64:\n",
    "\n",
    "        # iterate over single batch\n",
    "        for i in range(batch_size):\n",
    "            predicted_attributes = model.binary_features_list[batch_index][i].T[0]  \n",
    "            class_label = model.labels_list[batch_index][i].item()\n",
    "            ground_truth_attributes = attribute_mtx[class_label]\n",
    "\n",
    "            diff = (ground_truth_attributes - predicted_attributes)**2\n",
    "            accumulated_error += diff\n",
    "\n",
    "            accumulated_sigmas += sigmas[batch_index][i][:312]\n",
    "            # print(model.used_attributes_list[batch_index][i])\n",
    "            accumulated_usage += model.used_attributes_list[batch_index][i].cuda()\n",
    "# for i in range(len(model.used_attributes_list)):\n",
    "#     accumulated_usage += model.used_attributes_list[i][:312]\n",
    "\n",
    "\n",
    "\n",
    "mean_accumulated_error = accumulated_error/(batch_size * num_batches)\n",
    "mean_accumulated_sigmas = accumulated_sigmas/(batch_size * num_batches)\n",
    "mean_accumulated_usage = accumulated_usage/(batch_size * num_batches)# (batch_size * num_batches)\n",
    "\n",
    "\n",
    "\n",
    "# print(accumulated_error.mean(dim=-1).size())\n",
    "error_and_sigma = torch.stack([mean_accumulated_error, mean_accumulated_sigmas, mean_accumulated_usage], dim=0)\n",
    "d = {'misclassification\\nrate':error_and_sigma[0].cpu().numpy(), 'uncertainty':error_and_sigma[1].cpu().numpy(), 'usage':error_and_sigma[2].cpu().numpy()}\n",
    "df = pd.DataFrame(d)\n",
    "# df.head()\n",
    "df_short = df.loc[df['usage']>0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x72 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.colors as clr\n",
    "sns.set(rc={'figure.figsize':(15,1)})\n",
    "\n",
    "# cmap = clr.LinearSegmentedColormap.from_list('custom blue', [\"#EAD296\", \"#F67941\", \"#AC454A\", \"#5A005B\", \"#4999F2\"], N=256)\n",
    "cmap = clr.LinearSegmentedColormap.from_list('custom blue', [\"#EAD296\", \"#F67941\", \"#AC454A\"], N=256)\n",
    "\n",
    "sns.heatmap(df_short.to_numpy().T, #annot=True,\n",
    "            xticklabels=df.loc[df['usage']>0].index,\n",
    "            yticklabels=['misclassification rate', 'uncertainty', 'usage'],\n",
    "           cmap=sns.color_palette(\"YlOrBr\"))\n",
    "plt.xticks(rotation=90)\n",
    "# plt.show()\n",
    "plt.savefig(figure_path + 'attr_heatmap_short.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc={'figure.figsize':(6,5)})\n",
    "sns.heatmap(df_short.corr(), annot=True, center = 0.5, cmap=cmap)#sns.color_palette(\"icefire\"))\n",
    "# plt.show()\n",
    "\n",
    "plt.savefig(figure_path + 'corr_matrix.pdf',bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x='misclassification\\nrate', y='uncertainty',\n",
    "#                 hue='usage',\n",
    "                size='usage',\n",
    "                legend=False,\n",
    "                color='#AC454A',\n",
    "#                 cmap=cmap,\n",
    "                linewidth=0,\n",
    "                data=df_short)\n",
    "# sns.FacetGrid(df_short, row=\"error\", col=\"uncertainty\", hue=\"usage\")\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "plt.savefig(figure_path + 'error_sigma_corr_all.pdf',bbox_inches='tight')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
