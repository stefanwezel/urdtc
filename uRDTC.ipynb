{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "As we're luckily standing on the shoulders of giants, we can do some imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import imageio\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "Let's load and convert the data, so we can use it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = ['cifar10', 'mnist', 'cub', 'awa2',\n",
    "            'imagenetfeatures', 'apyfeatures', 'zero_shot_cub']\n",
    "# dataset = 'awa2'\n",
    "# dataset = 'cub'\n",
    "dataset = 'zero_shot_cub'\n",
    "\n",
    "data_path = '/home/swezel/projects/urdtc/data/'\n",
    "figure_path = data_path + '../thesis/images/'\n",
    "\n",
    "\n",
    "# attribute name lookup (first attr_id is 0) \n",
    "with open (data_path + 'cub/attributes.txt', 'r') as f:\n",
    "    attributes=f.readlines()\n",
    "attribute_name_dict = {str(int(attr.split(' ')[0])-1): attr.split(' ')[1] for attr in attributes}\n",
    "\n",
    "def get_dataset_config(dataset, cnn_type, max_iters):\n",
    "    input_channels = None\n",
    "    if dataset == 'mnist':\n",
    "        input_channels = 1\n",
    "        if cnn_type == 'cnn':\n",
    "            cnn_output_size = 4*4*100\n",
    "        elif cnn_type == 'resnet':\n",
    "            cnn_output_size = 512\n",
    "        elif cnn_type == 'shallowcnn':\n",
    "            cnn_output_size = 4*4*64\n",
    "        out_freq = 100\n",
    "        #assert max_iters > 4\n",
    "    elif dataset == 'cifar10':\n",
    "        input_channels = 3\n",
    "        if cnn_type == 'cnn':\n",
    "            cnn_output_size = 8*8*32\n",
    "        elif cnn_type == 'resnet' or cnn_type == 'resnet18':\n",
    "            cnn_output_size = 512\n",
    "        elif cnn_type == 'shallowcnn':\n",
    "            cnn_output_size = 4*4*64\n",
    "        out_freq = 100\n",
    "        #assert max_iters > 4\n",
    "    elif dataset == 'cub':\n",
    "        input_channels = 3\n",
    "        if cnn_type == 'cnn':\n",
    "            # cnn_output_size = 32*32*32\n",
    "            cnn_output_size = 280900 # the above does not work? Maybe because of dataloader issue?\n",
    "        elif cnn_type == 'resnet' or cnn_type == 'resnet152':\n",
    "            cnn_output_size = 2048\n",
    "        out_freq = 10\n",
    "    elif dataset == 'zero_shot_cub':\n",
    "        input_channels = 3\n",
    "        if cnn_type == 'cnn':\n",
    "            # cnn_output_size = 32*32*32\n",
    "            cnn_output_size = 280900 # the above does not work? Maybe because of dataloader issue?\n",
    "        elif cnn_type == 'resnet' or cnn_type == 'resnet152':\n",
    "            cnn_output_size = 2048\n",
    "        out_freq = 10\n",
    "        #assert max_iters > 8\n",
    "    elif dataset == 'awa2':\n",
    "        input_channels = 3\n",
    "        if cnn_type == 'cnn':\n",
    "#             cnn_output_size = 32*32*32  # TODO: check\n",
    "            cnn_output_size = 2048\n",
    "        elif cnn_type == 'resnet' or cnn_type == 'resnet152':\n",
    "            cnn_output_size = 2048\n",
    "        out_freq = 10\n",
    "        #assert max_iters > 6\n",
    "    elif dataset == 'imagenetfeatures':\n",
    "        cnn_output_size = 2048\n",
    "        out_freq = 100\n",
    "        #assert max_iters > 10\n",
    "    elif dataset == 'apyfeatures':\n",
    "        cnn_output_size = 2048\n",
    "        out_freq = 10\n",
    "        #assert max_iters > 5\n",
    "\n",
    "    return input_channels, cnn_output_size, out_freq\n",
    "\n",
    "class DataLoader(object):\n",
    "    def __init__(self, dataset='mnist'):\n",
    "        assert dataset in DATASETS\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def load_data(self, batch_size=100, num_workers=4, root='./data/'):\n",
    "\n",
    "        if self.dataset == 'mnist':\n",
    "            #transform_train = transforms.ToTensor()\n",
    "            #transform_test = transforms.ToTensor()\n",
    "            class AddGaussianNoise(object):\n",
    "                def __init__(self, mean=0., std=1.):\n",
    "                    self.std = std\n",
    "                    self.mean = mean\n",
    "\n",
    "                def __call__(self, tensor):\n",
    "                    output = tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "                    return output.clamp(0., 1.)\n",
    "\n",
    "                def __repr__(self):\n",
    "                    return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
    "\n",
    "            transform_train = transforms.Compose([\n",
    "               transforms.ToTensor(),\n",
    "               #AddGaussianNoise(0., 0.2)\n",
    "               #transforms.Normalize((0.1307,), (0.3081,))\n",
    "            ])\n",
    "            transform_test = transforms.Compose([\n",
    "               transforms.ToTensor(),\n",
    "               #AddGaussianNoise(0., 0.2)\n",
    "               #transforms.Normalize((0.1307,), (0.3081,))\n",
    "            ])\n",
    "            classes = [i for i in range(10)]\n",
    "            dataset_class = dsets.MNIST\n",
    "\n",
    "        elif self.dataset == 'cifar10':\n",
    "            transform_train = transforms.Compose([\n",
    "                transforms.RandomCrop(32, padding=4),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "            ])\n",
    "            transform_test = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "            ])\n",
    "            classes = ('plane', 'car', 'bird', 'cat',\n",
    "                       'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "            dataset_class = dsets.CIFAR10\n",
    "\n",
    "        elif self.dataset == 'cub':\n",
    "\n",
    "            transform_train = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                  transforms.RandomResizedCrop(224),\n",
    "                                                  transforms.RandomHorizontalFlip(),\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                                       std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "            transform_test = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                 transforms.Resize(224),\n",
    "                                                 transforms.CenterCrop(224),\n",
    "                                                 transforms.ToTensor(),\n",
    "                                                 transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                                      std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "            dataset_class = CUB\n",
    "            classes = list(range(200))\n",
    "\n",
    "        elif self.dataset == 'zero_shot_cub':\n",
    "\n",
    "            transform_train = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                  transforms.RandomResizedCrop(224),\n",
    "                                                  transforms.RandomHorizontalFlip(),\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                                       std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "            transform_test = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                 transforms.Resize(224),\n",
    "                                                 transforms.CenterCrop(224),\n",
    "                                                 transforms.ToTensor(),\n",
    "                                                 transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                                      std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "            dataset_class = ZeroShotCUB\n",
    "            classes = list(range(200))            \n",
    "            \n",
    "            \n",
    "\n",
    "        elif self.dataset == 'awa2':\n",
    "            transform_train = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                  transforms.RandomResizedCrop(224),\n",
    "                                                  transforms.RandomHorizontalFlip(),\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                                       std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "            transform_test = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                 transforms.Resize(224),\n",
    "                                                 transforms.CenterCrop(224),\n",
    "                                                 transforms.ToTensor(),\n",
    "                                                 transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                                      std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "            dataset_class = AWA2\n",
    "            classes = list(range(50))\n",
    "\n",
    "        elif self.dataset == 'apyfeatures':\n",
    "            transform_train = transforms.ToTensor()\n",
    "            transform_test = transforms.ToTensor()\n",
    "\n",
    "            dataset_class = APYFeatures\n",
    "            classes = list(range(32))\n",
    "\n",
    "        elif self.dataset == 'imagenetfeatures':\n",
    "            transform_train = transforms.ToTensor()\n",
    "            transform_test = transforms.ToTensor()\n",
    "\n",
    "            dataset_class = ImageNetFeatures\n",
    "            classes = list(range(1000))\n",
    "\n",
    "        train_dataset = dataset_class(root=root,\n",
    "                                      train=True,\n",
    "                                      transform=transform_train,\n",
    "                                      download=True)\n",
    "\n",
    "        test_dataset = dataset_class(root=root,\n",
    "                                     train=False,\n",
    "                                     transform=transform_test)\n",
    "\n",
    "        val_size = int(len(train_dataset) * 0.1)\n",
    "        train_size = len(train_dataset) - val_size\n",
    "\n",
    "        train_dataset, val_dataset = torch.utils.data.dataset.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   shuffle=True,\n",
    "                                                   num_workers=num_workers)\n",
    "\n",
    "        val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 shuffle=False,\n",
    "                                                 num_workers=num_workers)\n",
    "\n",
    "        test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  shuffle=False,\n",
    "                                                  num_workers=num_workers)\n",
    "\n",
    "        dataloaders = {'train': train_loader,\n",
    "                       'val': val_loader,\n",
    "                       'test': test_loader}\n",
    "\n",
    "        return dataloaders, classes\n",
    "\n",
    "class CUB(Dataset):\n",
    "    \"\"\"CUB200-2011 dataset.\"\"\"\n",
    "    attribute_file = 'attributes/class_attribute_labels_continuous.txt'\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, normalize=True,\n",
    "                 download=None):\n",
    "        self.root = os.path.join(root, 'cub')\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.data_dir = os.path.join(self.root, 'images')\n",
    "\n",
    "        train_test_split = pd.read_csv(os.path.join(self.root, 'train_test_split.txt'),\n",
    "                                       sep=' ', index_col=0, header=None)\n",
    "        if train:\n",
    "            is_train_image = 1\n",
    "        else:\n",
    "            is_train_image = 0\n",
    "        self.img_ids = train_test_split[train_test_split[1] == is_train_image].index.tolist()\n",
    "        self.id_to_img = pd.read_csv(os.path.join(self.root, 'images.txt'),\n",
    "                                     sep=' ', index_col=0, header=None)\n",
    "\n",
    "        raw_mtx = np.loadtxt(os.path.join(self.root,\n",
    "                                          self.attribute_file))\n",
    "        raw_mtx[raw_mtx == -1] = 0\n",
    "        raw_mtx = raw_mtx / raw_mtx.max()\n",
    "        self.attribute_mtx = torch.tensor(raw_mtx, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_ids[idx]\n",
    "        img_name = self.id_to_img[self.id_to_img.index == img_id].values[0][0]\n",
    "        img_path = os.path.join(self.data_dir, img_name)\n",
    "\n",
    "        img = imageio.imread(img_path, pilmode='RGB')\n",
    "        label = int(img_name[:3]) - 1\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label, img_path\n",
    "\n",
    "    \n",
    "class ZeroShotCUB(Dataset):\n",
    "    \"\"\"CUB200-2011 dataset.\"\"\"\n",
    "    attribute_file = 'attributes/class_attribute_labels_continuous.txt'\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, normalize=True,\n",
    "                 download=None):\n",
    "        self.root = os.path.join(root, 'cub')\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.data_dir = os.path.join(self.root, 'images')\n",
    "\n",
    "        train_test_split = pd.read_csv(os.path.join(self.root, 'zero_attr_train_test_split.txt'),\n",
    "                                       sep=' ', index_col=0, header=None)\n",
    "        if train:\n",
    "            is_train_image = 1\n",
    "        else:\n",
    "            is_train_image = 0\n",
    "        self.img_ids = train_test_split[train_test_split[1] == is_train_image].index.tolist()\n",
    "        self.id_to_img = pd.read_csv(os.path.join(self.root, 'images.txt'),\n",
    "                                     sep=' ', index_col=0, header=None)\n",
    "\n",
    "        raw_mtx = np.loadtxt(os.path.join(self.root,\n",
    "                                          self.attribute_file))\n",
    "        raw_mtx[raw_mtx == -1] = 0\n",
    "        raw_mtx = raw_mtx / raw_mtx.max()\n",
    "        self.attribute_mtx = torch.tensor(raw_mtx, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_ids[idx]\n",
    "        img_name = self.id_to_img[self.id_to_img.index == img_id].values[0][0]\n",
    "        img_path = os.path.join(self.data_dir, img_name)\n",
    "\n",
    "        img = imageio.imread(img_path, pilmode='RGB')\n",
    "        label = int(img_name[:3]) - 1\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label, img_path\n",
    "    \n",
    "    \n",
    "class AWA2(Dataset):\n",
    "    \"\"\"Animals with Attributes 2 dataset.\"\"\"\n",
    "    split_file = 'train_test_classification_split.txt'\n",
    "    data_dir = 'awa2'\n",
    "    attribute_file = 'predicate-matrix-continuous.txt'\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, normalize=True,\n",
    "                 download=None):\n",
    "        self.root = os.path.join(root, self.data_dir)\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "\n",
    "        meta_data = pd.read_csv(os.path.join(self.root,\n",
    "                                             self.split_file),\n",
    "                                sep=' ', index_col=0, header=None)\n",
    "        if train:\n",
    "            is_train_image = 1\n",
    "        else:\n",
    "            is_train_image = 0\n",
    "        self.img_ids = meta_data[meta_data[3] == is_train_image].index.tolist()\n",
    "        self.id_to_img = meta_data\n",
    "\n",
    "        raw_mtx = np.loadtxt(os.path.join(self.root,\n",
    "                                          self.attribute_file))\n",
    "        raw_mtx[raw_mtx == -1] = 0\n",
    "        raw_mtx = raw_mtx / raw_mtx.max()\n",
    "        self.attribute_mtx = torch.tensor(raw_mtx, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_ids[idx]\n",
    "        img_meta_data = self.id_to_img[self.id_to_img.index == img_id]\n",
    "        img_name = img_meta_data.values[0][0]\n",
    "        img_path = os.path.join(self.root, img_name)\n",
    "\n",
    "        img = imageio.imread(img_path, pilmode='RGB')\n",
    "        label = img_meta_data.values[0][1] - 1\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "# device = torch.device('cpu')\n",
    "\n",
    "# create dataloader objects for train, val and test\n",
    "dl = DataLoader(dataset=dataset)\n",
    "# dataloaders, classes = dl.load_data(4, 4, data_path)# 128 insted of \n",
    "dataloaders, classes = dl.load_data(64, 4, data_path)# 128 insted of \n",
    "\n",
    "# attributes (312 column vectors with 200 rows) -> each class can be described with 312 attributes\n",
    "# percentage of time, human annotator thought, the attribute was present\n",
    "attribute_mtx = dataloaders['train'].dataset.dataset.attribute_mtx\n",
    "\n",
    "# create binary encoding for class attributes\n",
    "attribute_mtx[attribute_mtx < 0.5] = 0.0\n",
    "attribute_mtx[attribute_mtx >= 0.5] = 1.0\n",
    "attribute_mtx = attribute_mtx.to(device) # cuda\n",
    "attribute_size = attribute_mtx.size(1) # number of available attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "18\n",
      "19\n",
      "25\n",
      "26\n",
      "41\n",
      "74\n",
      "75\n",
      "98\n",
      "113\n",
      "138\n",
      "139\n",
      "161\n",
      "180\n",
      "182\n",
      "183\n",
      "199\n",
      "\n",
      "183\n"
     ]
    }
   ],
   "source": [
    "# print(attribute_mtx[0])\n",
    "\n",
    "c = 0\n",
    "\n",
    "\n",
    "for class_id in range(attribute_mtx.size(0)):\n",
    "#     for attr_id in range(attribute_mtx.size(1)):\n",
    "#         print('...')\n",
    "#     attr_values = [attribute_mtx[class_id][x].item() for x in range(6)]\n",
    "#     if attr_values == [0.0 for x in range(6)]:\n",
    "        \n",
    "    if (attribute_mtx[class_id][308].item()==0) or (attribute_mtx[class_id][236].item()==0) or (attribute_mtx[class_id][235].item()==0.)or (attribute_mtx[class_id][145].item()==0.)or (attribute_mtx[class_id][151].item()==0.):\n",
    "\n",
    "#         print(class_id)\n",
    "        c+=1\n",
    "    else:\n",
    "        print(class_id)\n",
    "#     print(attr_values)\n",
    "#     if (attribute_mtx[class_id][3].item()==0) & (attribute_mtx[class_id][1].item()==0.) & (attribute_mtx[class_id][1].item()==0.):\n",
    "#         c += 1\n",
    "print()\n",
    "print(c)\n",
    "# print(attribute_mtx[82][40])\n",
    "\n",
    "#1\n",
    "#308\n",
    "# 101\n",
    "# 235\n",
    "# 145\n",
    "# 151"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.0\n",
      "\n",
      "1\n",
      "15.0\n",
      "\n",
      "2\n",
      "0.0\n",
      "\n",
      "3\n",
      "4.0\n",
      "\n",
      "4\n",
      "15.0\n",
      "\n",
      "5\n",
      "2.0\n",
      "\n",
      "6\n",
      "77.0\n",
      "\n",
      "7\n",
      "45.0\n",
      "\n",
      "8\n",
      "4.0\n",
      "\n",
      "9\n",
      "8.0\n",
      "\n",
      "10\n",
      "46.0\n",
      "\n",
      "11\n",
      "0.0\n",
      "\n",
      "12\n",
      "0.0\n",
      "\n",
      "13\n",
      "0.0\n",
      "\n",
      "14\n",
      "46.0\n",
      "\n",
      "15\n",
      "12.0\n",
      "\n",
      "16\n",
      "1.0\n",
      "\n",
      "17\n",
      "1.0\n",
      "\n",
      "18\n",
      "0.0\n",
      "\n",
      "19\n",
      "0.0\n",
      "\n",
      "20\n",
      "84.0\n",
      "\n",
      "21\n",
      "39.0\n",
      "\n",
      "22\n",
      "2.0\n",
      "\n",
      "23\n",
      "21.0\n",
      "\n",
      "24\n",
      "9.0\n",
      "\n",
      "25\n",
      "47.0\n",
      "\n",
      "26\n",
      "0.0\n",
      "\n",
      "27\n",
      "0.0\n",
      "\n",
      "28\n",
      "0.0\n",
      "\n",
      "29\n",
      "48.0\n",
      "\n",
      "30\n",
      "17.0\n",
      "\n",
      "31\n",
      "2.0\n",
      "\n",
      "32\n",
      "1.0\n",
      "\n",
      "33\n",
      "0.0\n",
      "\n",
      "34\n",
      "0.0\n",
      "\n",
      "35\n",
      "76.0\n",
      "\n",
      "36\n",
      "34.0\n",
      "\n",
      "37\n",
      "3.0\n",
      "\n",
      "38\n",
      "25.0\n",
      "\n",
      "39\n",
      "3.0\n",
      "\n",
      "40\n",
      "12.0\n",
      "\n",
      "41\n",
      "0.0\n",
      "\n",
      "42\n",
      "0.0\n",
      "\n",
      "43\n",
      "0.0\n",
      "\n",
      "44\n",
      "15.0\n",
      "\n",
      "45\n",
      "30.0\n",
      "\n",
      "46\n",
      "0.0\n",
      "\n",
      "47\n",
      "0.0\n",
      "\n",
      "48\n",
      "0.0\n",
      "\n",
      "49\n",
      "1.0\n",
      "\n",
      "50\n",
      "31.0\n",
      "\n",
      "51\n",
      "91.0\n",
      "\n",
      "52\n",
      "8.0\n",
      "\n",
      "53\n",
      "22.0\n",
      "\n",
      "54\n",
      "131.0\n",
      "\n",
      "55\n",
      "6.0\n",
      "\n",
      "56\n",
      "11.0\n",
      "\n",
      "57\n",
      "12.0\n",
      "\n",
      "58\n",
      "9.0\n",
      "\n",
      "59\n",
      "39.0\n",
      "\n",
      "60\n",
      "0.0\n",
      "\n",
      "61\n",
      "0.0\n",
      "\n",
      "62\n",
      "0.0\n",
      "\n",
      "63\n",
      "43.0\n",
      "\n",
      "64\n",
      "12.0\n",
      "\n",
      "65\n",
      "2.0\n",
      "\n",
      "66\n",
      "2.0\n",
      "\n",
      "67\n",
      "0.0\n",
      "\n",
      "68\n",
      "0.0\n",
      "\n",
      "69\n",
      "58.0\n",
      "\n",
      "70\n",
      "21.0\n",
      "\n",
      "71\n",
      "3.0\n",
      "\n",
      "72\n",
      "21.0\n",
      "\n",
      "73\n",
      "1.0\n",
      "\n",
      "74\n",
      "0.0\n",
      "\n",
      "75\n",
      "48.0\n",
      "\n",
      "76\n",
      "0.0\n",
      "\n",
      "77\n",
      "2.0\n",
      "\n",
      "78\n",
      "0.0\n",
      "\n",
      "79\n",
      "7.0\n",
      "\n",
      "80\n",
      "31.0\n",
      "\n",
      "81\n",
      "0.0\n",
      "\n",
      "82\n",
      "0.0\n",
      "\n",
      "83\n",
      "0.0\n",
      "\n",
      "84\n",
      "28.0\n",
      "\n",
      "85\n",
      "6.0\n",
      "\n",
      "86\n",
      "1.0\n",
      "\n",
      "87\n",
      "1.0\n",
      "\n",
      "88\n",
      "0.0\n",
      "\n",
      "89\n",
      "0.0\n",
      "\n",
      "90\n",
      "58.0\n",
      "\n",
      "91\n",
      "23.0\n",
      "\n",
      "92\n",
      "3.0\n",
      "\n",
      "93\n",
      "13.0\n",
      "\n",
      "94\n",
      "0.0\n",
      "\n",
      "95\n",
      "0.0\n",
      "\n",
      "96\n",
      "2.0\n",
      "\n",
      "97\n",
      "1.0\n",
      "\n",
      "98\n",
      "0.0\n",
      "\n",
      "99\n",
      "8.0\n",
      "\n",
      "100\n",
      "2.0\n",
      "\n",
      "101\n",
      "41.0\n",
      "\n",
      "102\n",
      "4.0\n",
      "\n",
      "103\n",
      "0.0\n",
      "\n",
      "104\n",
      "10.0\n",
      "\n",
      "105\n",
      "4.0\n",
      "\n",
      "106\n",
      "12.0\n",
      "\n",
      "107\n",
      "0.0\n",
      "\n",
      "108\n",
      "0.0\n",
      "\n",
      "109\n",
      "0.0\n",
      "\n",
      "110\n",
      "15.0\n",
      "\n",
      "111\n",
      "26.0\n",
      "\n",
      "112\n",
      "1.0\n",
      "\n",
      "113\n",
      "0.0\n",
      "\n",
      "114\n",
      "0.0\n",
      "\n",
      "115\n",
      "1.0\n",
      "\n",
      "116\n",
      "36.0\n",
      "\n",
      "117\n",
      "74.0\n",
      "\n",
      "118\n",
      "8.0\n",
      "\n",
      "119\n",
      "17.0\n",
      "\n",
      "120\n",
      "4.0\n",
      "\n",
      "121\n",
      "3.0\n",
      "\n",
      "122\n",
      "0.0\n",
      "\n",
      "123\n",
      "0.0\n",
      "\n",
      "124\n",
      "0.0\n",
      "\n",
      "125\n",
      "10.0\n",
      "\n",
      "126\n",
      "21.0\n",
      "\n",
      "127\n",
      "0.0\n",
      "\n",
      "128\n",
      "0.0\n",
      "\n",
      "129\n",
      "0.0\n",
      "\n",
      "130\n",
      "0.0\n",
      "\n",
      "131\n",
      "39.0\n",
      "\n",
      "132\n",
      "72.0\n",
      "\n",
      "133\n",
      "7.0\n",
      "\n",
      "134\n",
      "7.0\n",
      "\n",
      "135\n",
      "0.0\n",
      "\n",
      "136\n",
      "0.0\n",
      "\n",
      "137\n",
      "0.0\n",
      "\n",
      "138\n",
      "0.0\n",
      "\n",
      "139\n",
      "0.0\n",
      "\n",
      "140\n",
      "1.0\n",
      "\n",
      "141\n",
      "0.0\n",
      "\n",
      "142\n",
      "0.0\n",
      "\n",
      "143\n",
      "0.0\n",
      "\n",
      "144\n",
      "1.0\n",
      "\n",
      "145\n",
      "190.0\n",
      "\n",
      "146\n",
      "3.0\n",
      "\n",
      "147\n",
      "3.0\n",
      "\n",
      "148\n",
      "0.0\n",
      "\n",
      "149\n",
      "68.0\n",
      "\n",
      "150\n",
      "7.0\n",
      "\n",
      "151\n",
      "124.0\n",
      "\n",
      "152\n",
      "10.0\n",
      "\n",
      "153\n",
      "22.0\n",
      "\n",
      "154\n",
      "0.0\n",
      "\n",
      "155\n",
      "0.0\n",
      "\n",
      "156\n",
      "0.0\n",
      "\n",
      "157\n",
      "17.0\n",
      "\n",
      "158\n",
      "15.0\n",
      "\n",
      "159\n",
      "0.0\n",
      "\n",
      "160\n",
      "0.0\n",
      "\n",
      "161\n",
      "0.0\n",
      "\n",
      "162\n",
      "0.0\n",
      "\n",
      "163\n",
      "60.0\n",
      "\n",
      "164\n",
      "17.0\n",
      "\n",
      "165\n",
      "10.0\n",
      "\n",
      "166\n",
      "3.0\n",
      "\n",
      "167\n",
      "7.0\n",
      "\n",
      "168\n",
      "22.0\n",
      "\n",
      "169\n",
      "0.0\n",
      "\n",
      "170\n",
      "0.0\n",
      "\n",
      "171\n",
      "0.0\n",
      "\n",
      "172\n",
      "20.0\n",
      "\n",
      "173\n",
      "10.0\n",
      "\n",
      "174\n",
      "0.0\n",
      "\n",
      "175\n",
      "0.0\n",
      "\n",
      "176\n",
      "0.0\n",
      "\n",
      "177\n",
      "0.0\n",
      "\n",
      "178\n",
      "69.0\n",
      "\n",
      "179\n",
      "29.0\n",
      "\n",
      "180\n",
      "2.0\n",
      "\n",
      "181\n",
      "10.0\n",
      "\n",
      "182\n",
      "10.0\n",
      "\n",
      "183\n",
      "24.0\n",
      "\n",
      "184\n",
      "0.0\n",
      "\n",
      "185\n",
      "0.0\n",
      "\n",
      "186\n",
      "0.0\n",
      "\n",
      "187\n",
      "32.0\n",
      "\n",
      "188\n",
      "13.0\n",
      "\n",
      "189\n",
      "0.0\n",
      "\n",
      "190\n",
      "0.0\n",
      "\n",
      "191\n",
      "0.0\n",
      "\n",
      "192\n",
      "0.0\n",
      "\n",
      "193\n",
      "44.0\n",
      "\n",
      "194\n",
      "35.0\n",
      "\n",
      "195\n",
      "7.0\n",
      "\n",
      "196\n",
      "16.0\n",
      "\n",
      "197\n",
      "3.0\n",
      "\n",
      "198\n",
      "9.0\n",
      "\n",
      "199\n",
      "0.0\n",
      "\n",
      "200\n",
      "0.0\n",
      "\n",
      "201\n",
      "0.0\n",
      "\n",
      "202\n",
      "15.0\n",
      "\n",
      "203\n",
      "27.0\n",
      "\n",
      "204\n",
      "0.0\n",
      "\n",
      "205\n",
      "0.0\n",
      "\n",
      "206\n",
      "0.0\n",
      "\n",
      "207\n",
      "1.0\n",
      "\n",
      "208\n",
      "24.0\n",
      "\n",
      "209\n",
      "86.0\n",
      "\n",
      "210\n",
      "5.0\n",
      "\n",
      "211\n",
      "17.0\n",
      "\n",
      "212\n",
      "86.0\n",
      "\n",
      "213\n",
      "9.0\n",
      "\n",
      "214\n",
      "0.0\n",
      "\n",
      "215\n",
      "0.0\n",
      "\n",
      "216\n",
      "2.0\n",
      "\n",
      "217\n",
      "0.0\n",
      "\n",
      "218\n",
      "130.0\n",
      "\n",
      "219\n",
      "1.0\n",
      "\n",
      "220\n",
      "37.0\n",
      "\n",
      "221\n",
      "15.0\n",
      "\n",
      "222\n",
      "0.0\n",
      "\n",
      "223\n",
      "0.0\n",
      "\n",
      "224\n",
      "0.0\n",
      "\n",
      "225\n",
      "9.0\n",
      "\n",
      "226\n",
      "0.0\n",
      "\n",
      "227\n",
      "7.0\n",
      "\n",
      "228\n",
      "4.0\n",
      "\n",
      "229\n",
      "0.0\n",
      "\n",
      "230\n",
      "6.0\n",
      "\n",
      "231\n",
      "0.0\n",
      "\n",
      "232\n",
      "0.0\n",
      "\n",
      "233\n",
      "0.0\n",
      "\n",
      "234\n",
      "0.0\n",
      "\n",
      "235\n",
      "121.0\n",
      "\n",
      "236\n",
      "93.0\n",
      "\n",
      "237\n",
      "7.0\n",
      "\n",
      "238\n",
      "24.0\n",
      "\n",
      "239\n",
      "14.0\n",
      "\n",
      "240\n",
      "84.0\n",
      "\n",
      "241\n",
      "3.0\n",
      "\n",
      "242\n",
      "6.0\n",
      "\n",
      "243\n",
      "21.0\n",
      "\n",
      "244\n",
      "152.0\n",
      "\n",
      "245\n",
      "5.0\n",
      "\n",
      "246\n",
      "7.0\n",
      "\n",
      "247\n",
      "5.0\n",
      "\n",
      "248\n",
      "9.0\n",
      "\n",
      "249\n",
      "33.0\n",
      "\n",
      "250\n",
      "0.0\n",
      "\n",
      "251\n",
      "0.0\n",
      "\n",
      "252\n",
      "0.0\n",
      "\n",
      "253\n",
      "36.0\n",
      "\n",
      "254\n",
      "28.0\n",
      "\n",
      "255\n",
      "1.0\n",
      "\n",
      "256\n",
      "2.0\n",
      "\n",
      "257\n",
      "0.0\n",
      "\n",
      "258\n",
      "1.0\n",
      "\n",
      "259\n",
      "49.0\n",
      "\n",
      "260\n",
      "40.0\n",
      "\n",
      "261\n",
      "5.0\n",
      "\n",
      "262\n",
      "18.0\n",
      "\n",
      "263\n",
      "0.0\n",
      "\n",
      "264\n",
      "0.0\n",
      "\n",
      "265\n",
      "0.0\n",
      "\n",
      "266\n",
      "0.0\n",
      "\n",
      "267\n",
      "0.0\n",
      "\n",
      "268\n",
      "39.0\n",
      "\n",
      "269\n",
      "0.0\n",
      "\n",
      "270\n",
      "0.0\n",
      "\n",
      "271\n",
      "0.0\n",
      "\n",
      "272\n",
      "0.0\n",
      "\n",
      "273\n",
      "6.0\n",
      "\n",
      "274\n",
      "53.0\n",
      "\n",
      "275\n",
      "0.0\n",
      "\n",
      "276\n",
      "3.0\n",
      "\n",
      "277\n",
      "21.0\n",
      "\n",
      "278\n",
      "0.0\n",
      "\n",
      "279\n",
      "1.0\n",
      "\n",
      "280\n",
      "0.0\n",
      "\n",
      "281\n",
      "0.0\n",
      "\n",
      "282\n",
      "0.0\n",
      "\n",
      "283\n",
      "19.0\n",
      "\n",
      "284\n",
      "5.0\n",
      "\n",
      "285\n",
      "0.0\n",
      "\n",
      "286\n",
      "0.0\n",
      "\n",
      "287\n",
      "0.0\n",
      "\n",
      "288\n",
      "6.0\n",
      "\n",
      "289\n",
      "94.0\n",
      "\n",
      "290\n",
      "0.0\n",
      "\n",
      "291\n",
      "3.0\n",
      "\n",
      "292\n",
      "9.0\n",
      "\n",
      "293\n",
      "10.0\n",
      "\n",
      "294\n",
      "26.0\n",
      "\n",
      "295\n",
      "0.0\n",
      "\n",
      "296\n",
      "0.0\n",
      "\n",
      "297\n",
      "0.0\n",
      "\n",
      "298\n",
      "20.0\n",
      "\n",
      "299\n",
      "11.0\n",
      "\n",
      "300\n",
      "0.0\n",
      "\n",
      "301\n",
      "0.0\n",
      "\n",
      "302\n",
      "0.0\n",
      "\n",
      "303\n",
      "0.0\n",
      "\n",
      "304\n",
      "65.0\n",
      "\n",
      "305\n",
      "16.0\n",
      "\n",
      "306\n",
      "9.0\n",
      "\n",
      "307\n",
      "4.0\n",
      "\n",
      "308\n",
      "58.0\n",
      "\n",
      "309\n",
      "9.0\n",
      "\n",
      "310\n",
      "31.0\n",
      "\n",
      "311\n",
      "43.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for i in range(312):\n",
    "#     print(i)\n",
    "#     print(attribute_mtx[:,i].sum(dim=0).item())\n",
    "#     print()\n",
    "# # print(attribute_mtx.sum(dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Models\n",
    "Here, we continue by defining the various models that our uRDTC consists of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Conv2d(in_channels, 20, kernel_size=3, stride=1),\n",
    "                                 nn.ReLU(True),\n",
    "                                 nn.BatchNorm2d(20),\n",
    "                                 nn.Conv2d(20, 50, kernel_size=5, stride=2),\n",
    "                                 nn.ReLU(True),\n",
    "                                 nn.BatchNorm2d(50),\n",
    "                                 nn.Conv2d(50, 100, kernel_size=5, stride=2),\n",
    "                                 nn.ReLU(True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class DropoutCNN(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 20, kernel_size=3, stride=1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, kernel_size=5, stride=2)\n",
    "        self.conv3 = nn.Conv2d(50, 100, kernel_size=5, stride=2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.dropout2d(F.relu(self.conv1(x)), 0.2)\n",
    "        x = F.dropout2d(F.relu(self.conv2(x)), 0.2)\n",
    "        x = F.dropout2d(F.relu(self.conv3(x)), 0.2)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def get_cnn(in_channels, type='cnn', pretrained_cnn_weights=None,\n",
    "            freeze_weights=False, default_pretrained=False):\n",
    "    TYPES = ['cnn', 'dropoutcnn', 'resnet152'] # TYPES = ['cnn', 'shallowcnn', 'resnet', 'resnet152']\n",
    "    assert type in TYPES\n",
    "\n",
    "    if type == 'cnn':\n",
    "        cnn = CNN(in_channels)\n",
    "    if type == 'dropoutcnn':\n",
    "        cnn = DropoutCNN(in_channels)\n",
    "#     if type == 'resnet152':\n",
    "#         cnn = models.resnet152(pretrained=default_pretrained)\n",
    "    else:\n",
    "        cnn = Identity()\n",
    "\n",
    "    # if pretrained_cnn_weights:\n",
    "    #     if type == 'resnet152':\n",
    "    #         cnn.fc = nn.Linear(cnn.fc.in_features, pretrained_cnn_weights['fc.weight'].size(0))\n",
    "    #     cnn.load_state_dict(pretrained_cnn_weights)\n",
    "    if pretrained_cnn_weights:\n",
    "        cnn.load_state_dict(pretrained_cnn_weights)\n",
    "    \n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OC(nn.Module):\n",
    "    def __init__(self, model_type, num_classes, cnn_type, input_channels, cnn_out_size,\n",
    "                 dataset, decision_size=2, max_iters=20, attribute_size=20, attribute_mtx=None, attribute_coef=0.5, hidden_size=100,\n",
    "                 tau_initial=5, tau_target=0.5, use_pretrained=False, shallow=False, strategy='aRDTC'):\n",
    "        super(OC, self).__init__()\n",
    "        assert model_type in ['xoc'] #, 'ioc']\n",
    "        self.model_type = model_type\n",
    "        self.num_classes = num_classes\n",
    "        self.attribute_size = attribute_size\n",
    "        self.attribute_mtx = attribute_mtx\n",
    "        self.attribute_coef = attribute_coef if attribute_mtx is not None else 0.\n",
    "        self.decision_size = decision_size # change keyword default to 3?\n",
    "        self.tau_initial = tau_initial\n",
    "        self.tau_target = tau_target\n",
    "        self.max_iters = max_iters\n",
    "        self.shallow = shallow\n",
    "        self.stats = defaultdict(list)\n",
    "        self.reduced_vocab_size = 2\n",
    "        self.strategy = strategy\n",
    "\n",
    "        self.no_lstm = False\n",
    "\n",
    "        #self.init_attribute_matrix(attribute_mtx, attribute_size, attribute_coef, use_bin_attr)\n",
    "\n",
    "        self.cnn = self.init_cnn(cnn_type, input_channels, dataset, use_pretrained)\n",
    "        self.init_network(hidden_size, decision_size, num_classes, attribute_size, cnn_out_size, shallow)\n",
    "\n",
    "        self.init_losses()\n",
    "\n",
    "\n",
    "\n",
    "        self.phase = 'train'\n",
    "\n",
    "        # for stats\n",
    "        self.logits_list = []\n",
    "        self.sigmas_list = []\n",
    "#         self.labels_list\n",
    "        self.binary_features_list = []\n",
    "        self.labels_list = []\n",
    "        self.used_attributes_list = []\n",
    "        self.certain_attrs = []\n",
    "        self.attribute_accuracies = []\n",
    "        self.drop_ratios = []\n",
    "        self.mean_sigmas = []\n",
    "        \n",
    "\n",
    "    def init_network(self, hidden_size, decision_size, num_classes, attribute_size, cnn_out_size, shallow):\n",
    "        assert decision_size > 1\n",
    "\n",
    "        # LSTM initialization parameters\n",
    "        if self.no_lstm:\n",
    "            self.init_h0 = nn.Parameter(torch.zeros(attribute_size * decision_size), requires_grad=False)\n",
    "            self.init_c0 = nn.Parameter(torch.zeros(attribute_size * decision_size), requires_grad=False)\n",
    "        else:\n",
    "            self.init_h0 = nn.Parameter(torch.zeros(hidden_size).uniform_(-0.01, 0.01), requires_grad=True)\n",
    "            self.init_c0 = nn.Parameter(torch.zeros(hidden_size).uniform_(-0.01, 0.01), requires_grad=True)\n",
    "\n",
    "        if self.no_lstm:\n",
    "            self.lstm = lambda x, y: (None, (x.squeeze(), x.squeeze()))\n",
    "        else:\n",
    "            self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "\n",
    "        if self.no_lstm:\n",
    "            classifier_in = attribute_size * decision_size\n",
    "        else:\n",
    "            classifier_in = attribute_size * decision_size\n",
    "\n",
    "        self.classifier = nn.Sequential(#nn.BatchNorm1d(classifier_in) if not self.no_lstm else Identity(),\n",
    "                                        nn.Linear(classifier_in, hidden_size),\n",
    "                                        nn.ReLU(inplace=True),\n",
    "                                        nn.BatchNorm1d(hidden_size),\n",
    "                                        nn.Linear(hidden_size, num_classes))\n",
    "\n",
    "        if self.model_type == 'xoc':\n",
    "            if self.no_lstm:\n",
    "                feat_select_in_size = attribute_size * decision_size\n",
    "            else:\n",
    "                feat_select_in_size = hidden_size\n",
    "            feat_select_out_size = attribute_size\n",
    "            pre_lstm_size = attribute_size * decision_size * 2\n",
    "\n",
    "            bin_feat_type = 'shallow' if shallow else 'dropoutmlp' #'mlp'\n",
    "            feat_select_type = 'mlp_small'\n",
    "\n",
    "        elif self.model_type == 'ioc':\n",
    "            bin_feat_type = 'identity'\n",
    "            feat_select_type = 'mlp_big'\n",
    "\n",
    "            if not shallow:\n",
    "                feat_select_in_size = cnn_out_size + hidden_size\n",
    "                feat_select_out_size = decision_size\n",
    "                pre_lstm_size = feat_select_out_size\n",
    "            else:\n",
    "                feat_select_in_size = hidden_size\n",
    "                feat_select_out_size = cnn_out_size * decision_size\n",
    "                pre_lstm_size = decision_size\n",
    "\n",
    "        if feat_select_type == 'mlp_small':\n",
    "            self.feature_selection = nn.Sequential(nn.BatchNorm1d(feat_select_in_size) if not self.no_lstm else Identity(),\n",
    "                                                   nn.Linear(feat_select_in_size , hidden_size),\n",
    "                                                   nn.ReLU(inplace=True),\n",
    "                                                   nn.BatchNorm1d(hidden_size),\n",
    "                                                   nn.Linear(hidden_size, feat_select_out_size))\n",
    "        elif feat_select_type == 'mlp_big':\n",
    "            self.feature_selection = nn.Sequential(nn.BatchNorm1d(feat_select_in_size) if not self.no_lstm else Identity(),\n",
    "                                                   nn.Linear(feat_select_in_size, hidden_size),\n",
    "                                                   nn.ReLU(inplace=True),\n",
    "                                                   nn.BatchNorm1d(hidden_size),\n",
    "                                                   nn.Linear(hidden_size, hidden_size),\n",
    "                                                   nn.ReLU(inplace=True),\n",
    "                                                   nn.BatchNorm1d(hidden_size),\n",
    "                                                   nn.Linear(hidden_size, feat_select_out_size))\n",
    "\n",
    "        if bin_feat_type == 'identity':\n",
    "            self.binary_features = Identity()\n",
    "        elif bin_feat_type == 'shallow':\n",
    "            class AddZeros(nn.Module):\n",
    "                def __init__(self):\n",
    "                    super().__init__()\n",
    "\n",
    "                def forward(self, x):\n",
    "                    zeros = torch.zeros_like(x).unsqueeze(2)\n",
    "                    return torch.cat((x.unsqueeze(2), zeros), dim=2)\n",
    "\n",
    "            self.binary_features = AddZeros()\n",
    "        elif bin_feat_type == 'mlp':\n",
    "            self.binary_features = nn.Sequential(nn.BatchNorm1d(cnn_out_size), # use dropout\n",
    "                                                 nn.Linear(cnn_out_size, hidden_size),\n",
    "                                                 nn.ReLU(inplace=True),\n",
    "                                                 nn.BatchNorm1d(hidden_size), # use dropout\n",
    "                                                 nn.Linear(hidden_size, hidden_size),\n",
    "                                                 nn.ReLU(inplace=True),\n",
    "                                                 nn.BatchNorm1d(hidden_size), # use dropout\n",
    "                                                 nn.Linear(hidden_size, attribute_size * self.reduced_vocab_size))\n",
    "        elif bin_feat_type == 'dropoutmlp':\n",
    "            self.binary_features = nn.Sequential(\n",
    "                                                nn.Linear(cnn_out_size, hidden_size),\n",
    "                                                nn.ReLU(inplace=False),\n",
    "                                                nn.Dropout(0.2, inplace=False),\n",
    "                                                nn.Linear(hidden_size, hidden_size),\n",
    "                                                nn.ReLU(inplace=False),\n",
    "                                                nn.Dropout(0.2, inplace=False),\n",
    "                                                nn.Linear(hidden_size, attribute_size * self.reduced_vocab_size)\n",
    "                                                )\n",
    "\n",
    "        if self.no_lstm:\n",
    "            self.pre_lstm = Identity()\n",
    "        else:\n",
    "            self.pre_lstm = nn.Sequential(#nn.BatchNorm1d(pre_lstm_size),\n",
    "                                          nn.Linear(pre_lstm_size, hidden_size),\n",
    "                                          nn.ReLU(inplace=True),\n",
    "                                          nn.BatchNorm1d(hidden_size))\n",
    "\n",
    "\n",
    "        # Temperature parameters\n",
    "        self.binary_features.tau = nn.Parameter(torch.tensor([self.tau_initial], dtype=torch.float), requires_grad=True)\n",
    "        self.feature_selection.tau = nn.Parameter(torch.tensor([self.tau_initial], dtype=torch.float), requires_grad=True)\n",
    "        #self.init_weights()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    def get_attribute_uncertainty_batch(self, image_features, n=100, batch_size=64):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "\n",
    "            outputs = torch.zeros((n, batch_size, attribute_size * self.reduced_vocab_size), device=device) # init outputs with dummy values\n",
    "\n",
    "    #         if self.phase=='test':\n",
    "    #         print(self.binary_features.training)\n",
    "\n",
    "            if not self.binary_features.training:\n",
    "                current_phase = 'test'\n",
    "                self.binary_features.train()\n",
    "\n",
    "            else:\n",
    "                current_phase = 'train'\n",
    "    #         print(self.binary_features.training)\n",
    "    #         print()\n",
    "\n",
    "    #             for layer in self.binary_features:\n",
    "    #                 if isinstance(layer, torch.nn.modules.dropout._DropoutNd):\n",
    "    #                     layer.train()\n",
    "\n",
    "            for i in range(n):\n",
    "                outputs[i] = F.softmax(self.binary_features(image_features))\n",
    "\n",
    "            if current_phase=='test':\n",
    "    #         if self.phase=='test':\n",
    "                self.binary_features.eval()\n",
    "    #             for layer in self.binary_features:\n",
    "    #                 if isinstance(layer, torch.nn.modules.dropout._DropoutNd):\n",
    "    #                     layer.eval()\n",
    "    #                 else:\n",
    "    #                     layer.train()\n",
    "\n",
    "            sigmas = outputs.std(dim=0)\n",
    "\n",
    "            return sigmas\n",
    "    \n",
    "    \n",
    "    def get_attribute_uncertainty(self, image_features, n=10, batch_size=64):\n",
    "        outputs = torch.zeros((n, batch_size, attribute_size * self.reduced_vocab_size), device=device)\n",
    "        \n",
    "        if self.phase == 'train':\n",
    "            for i in range(n):\n",
    "                outputs[i] = F.softmax(self.binary_features(image_features))\n",
    "#                 outputs[i] = self.binary_features(image_features)\n",
    "\n",
    "        if self.phase == 'test':\n",
    "            for layer in self.binary_features:\n",
    "                if isinstance(layer, torch.nn.modules.dropout._DropoutNd):\n",
    "                    layer.train()\n",
    "#             self.binary_features.train()\n",
    "            for i in range(n):\n",
    "                outputs[i] = F.softmax(self.binary_features(image_features))\n",
    "#                 outputs[i] = self.binary_features(image_features)\n",
    "\n",
    "            for layer in self.binary_features:\n",
    "                if isinstance(layer, torch.nn.modules.dropout._DropoutNd):\n",
    "                    layer.eval()\n",
    "#             self.binary_features.eval()\n",
    "        \n",
    "        sigmas = outputs.var(dim=0)\n",
    "        sigmas += (0.01**2 * 0.5)/(2 * image_features.size(0) * weight_decay)\n",
    "#         print(sigmas.mean())\n",
    "\n",
    "        return sigmas\n",
    "  \n",
    "    def init_attribute_matrix(self, attribute_mtx, attribute_size, attribute_coef, use_bin_attr):\n",
    "        if attribute_coef > 0.:\n",
    "            if use_bin_attr:\n",
    "                attribute_mtx[attribute_mtx < 0.5] = 0.\n",
    "                attribute_mtx[attribute_mtx >= 0.5] = 1.\n",
    "            self.attribute_mtx = nn.Parameter(attribute_mtx, requires_grad=False)\n",
    "            self.attribute_size = attribute_mtx.size(1)\n",
    "        else:\n",
    "            self.attribute_mtx = None\n",
    "            self.attribute_size = attribute_size\n",
    "\n",
    "    def toggle_update_schedule(self):\n",
    "        # TODO: see a few lines below\n",
    "        #self.update_binary_features = not self.update_binary_features\n",
    "        pass\n",
    "\n",
    "    def get_param_groups(self):\n",
    "        cnn_params = []\n",
    "        tree_params = []\n",
    "        for n, p in self.named_parameters():\n",
    "            if p.requires_grad:\n",
    "                # TODO: introduce parameter that allows to switch between training alternatingly\n",
    "                # Currently commented out, so both groups contain the same parameters\n",
    "                \"\"\"\n",
    "                if n.startswith('cnn') or n.startswith('binary_features'):\n",
    "                    print('CNN', n)\n",
    "                    cnn_params.append(p)\n",
    "                else:\n",
    "                    print('OTHER', n)\n",
    "                    tree_params.append(p)\n",
    "                \"\"\"\n",
    "                cnn_params.append(p)\n",
    "                tree_params.append(p)\n",
    "        return tree_params, cnn_params\n",
    "\n",
    "    def set_optimizer(self, optimizers):\n",
    "        self.tree_optimizer = optimizers[0]\n",
    "        self.cnn_optimizer = optimizers[1]\n",
    "\n",
    "    def set_scheduler(self, schedulers):\n",
    "        self.tree_scheduler = schedulers[0]\n",
    "        self.cnn_scheduler = schedulers[1]\n",
    "\n",
    "    def get_optimizer(self):\n",
    "        if self.update_binary_features:\n",
    "            return self.cnn_optimizer\n",
    "        else:\n",
    "            return self.tree_optimizer\n",
    "\n",
    "    def get_scheduler(self):\n",
    "        if self.update_binary_features:\n",
    "            return self.cnn_scheduler\n",
    "        else:\n",
    "            return self.tree_scheduler\n",
    "\n",
    "    def init_losses(self):\n",
    "        self.cls_loss = nn.CrossEntropyLoss()\n",
    "        self.attr_loss = nn.BCEWithLogitsLoss()\n",
    "        self.update_binary_features = False\n",
    "\n",
    "    def init_cnn(self, cnn_type, input_channels, dataset, use_pretrained):\n",
    "        if cnn_type == 'None':\n",
    "            cnn = Identity()\n",
    "        else:\n",
    "            if use_pretrained:\n",
    "                # TODO add data_path and change state dict name \n",
    "                # cnn_state_dict = torch.load('pretrained/{}_{}.pth'.format(dataset, cnn_type))\n",
    "#                 cnn_state_dict = torch.load('pretrained/cub_resnet152.pkl')# .format(dataset, cnn_type)\n",
    "                cnn_state_dict = torch.load('pretrained/{}_resnet152.pkl'.format(dataset))# .format(dataset, cnn_type)\n",
    "\n",
    "                cnn = get_cnn(input_channels, cnn_type, cnn_state_dict, freeze_weights=True)\n",
    "            else:\n",
    "                cnn = get_cnn(input_channels, cnn_type)\n",
    "\n",
    "        return cnn\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight.data)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.fill_(0.1)\n",
    "\n",
    "    def set_tau(self, epoch):\n",
    "        annealing_factor = epoch / 100\n",
    "        self.tau = self.tau_initial\n",
    "        self.tau -= (self.tau_initial - self.tau_target) * annealing_factor\n",
    "        self.tau = max(self.tau, self.tau_target)\n",
    "\n",
    "    def process_images(self, images):\n",
    "        batch_size = images.size(0)\n",
    "        img_feats = self.cnn(images)\n",
    "        img_feats = img_feats.view(img_feats.size(0), -1)\n",
    "        image_features = self.binary_features(img_feats)\n",
    "        # print(image_features.size())\n",
    "        ################## remove attrs code\n",
    "#         sigmas = self.get_attribute_uncertainty_batch(img_feats,n=100, batch_size=batch_size)\n",
    "        \n",
    "        if self.strategy == 'remRDTC':\n",
    "            with torch.no_grad():\n",
    "                sigmas = self.get_attribute_uncertainty(img_feats, n=5, batch_size=images.size(0))\n",
    "            uncertain_attrs = (sigmas > 0.005).float() # get binary uncertain attrs\n",
    "            certain_attrs = 1. - uncertain_attrs\n",
    "            mask = certain_attrs.detach()\n",
    "            inv_mask = 1-mask\n",
    "            min_value = image_features.min()\n",
    "            image_features = image_features * mask # put zeros where uncertain attts are\n",
    "            image_features = image_features - (inv_mask.detach()*min_value.detach()) #*-500\n",
    "\n",
    "#         sigmas.detach()\n",
    "#         sigmas.cuda()\n",
    "#         self.mean_sigmas.append(sigmas.mean().item())\n",
    "#         drop_ratio = (sigmas>0.005).float().sum()/(images.size(0)*attribute_size*2.)\n",
    "#         min_value = image_features.min()\n",
    "#         min_value.detach()\n",
    "#         self.drop_ratios.append(drop_ratio)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #############################################################\n",
    "#         if not self.training:\n",
    "\n",
    "#             self.sigmas_list.append(sigmas)\n",
    "            # self.logits_list.append(image_features)\n",
    "            # image_features = torch.cat((attribute_logits, sigmas),1)\n",
    "        \n",
    "        \n",
    "        ################## remove attrs\n",
    "#         uncertain_attrs = (sigmas > 0.005).float() # get binary uncertain attrs\n",
    "#         certain_attrs = 1. - uncertain_attrs\n",
    "#         mask = certain_attrs.detach()#(torch.FloatTensor(image_features.size()).uniform_() > 0.050).float().to(device)\n",
    "        if self.strategy == 'randRDTC':\n",
    "            mask = (torch.FloatTensor(image_features.size()).uniform_() > 0.050).float().to(device)\n",
    "            inv_mask = 1-mask\n",
    "#         self.drop_ratios.append((inv_mask.sum()/39936.0).item())\n",
    "#         mask.detach()\n",
    "            min_value = image_features.min()\n",
    "            image_features = image_features * mask # put zeros where uncertain attts are\n",
    "            image_features = image_features - (inv_mask.detach()*min_value.detach()) #*-500\n",
    "        ##############################################################\n",
    "\n",
    "        if self.model_type == 'xoc':\n",
    "            attribute_logits = image_features.view(-1, 2)\n",
    "\n",
    "\n",
    "            attributes_softmax = F.softmax(attribute_logits / self.binary_features.tau, dim=1)\n",
    "            attributes_hard = self.argmax(attributes_softmax, dim=1)\n",
    "            image_features = attributes_hard.view(images.size(0), -1, 2)\n",
    "\n",
    "            # TODO: generalize to different decision sizes\n",
    "            bin_attribute_logits = attribute_logits - attribute_logits[:, 1].unsqueeze(-1)\n",
    "            self.attribute_logits = bin_attribute_logits[:, 0].view(images.size(0), -1)\n",
    "\n",
    "            self.collect_hist_stats('AttributesSoft', F.softmax(attribute_logits, dim=1))\n",
    "            self.collect_hist_stats('AttributesSoftTemp', attributes_softmax)\n",
    "            self.collect_hist_stats('AttributesHard', attributes_hard.max(dim=1)[1])\n",
    "\n",
    "        return image_features\n",
    "\n",
    "    def make_decision(self, lstm_out, binary_features, iter, sigma=[], max_uncertainty=0.2):\n",
    "        if self.model_type == 'xoc':\n",
    "            # Perform categorical feature selection\n",
    "            selection_logits = self.feature_selection(lstm_out)\n",
    "            # print(selection_logits[0][:10])\n",
    "            if self.training:\n",
    "                hard_selection = F.gumbel_softmax(selection_logits, tau=self.feature_selection.tau, hard=True)\n",
    "            else:\n",
    "               \n",
    "                # sigma = self.get_attribute_uncertainty(binary_features)\n",
    "                # sigma = sigma[:,:312]#.squeeze() \n",
    "                # certain_logits = torch.where(sigma>max_uncertainty,\n",
    "                #                              selection_logits,\n",
    "                #                              torch.zeros_like(selection_logits).new_full(selection_logits.size(), -10000)) # -10000\n",
    "                hard_selection = self.argmax(selection_logits, dim=1)\n",
    "                # print(hard_selection.size())\n",
    "                # print(binary_features.size())\n",
    "                # print(hard_selection.unsqueeze(2).size())\n",
    "\n",
    "\n",
    "            # Get single decision\n",
    "            self.saved_attribute_selection = hard_selection.max(dim=1)[1]\n",
    "            \n",
    "\n",
    "            decision = (hard_selection.unsqueeze(2) * binary_features).view(-1, self.attribute_size * self.decision_size)\n",
    "            # print(decision[0])\n",
    "        elif self.model_type == 'ioc':\n",
    "            if not self.shallow:\n",
    "                features = torch.cat((lstm_out, binary_features), dim=1)\n",
    "                selection_logits = self.feature_selection(features)\n",
    "            else:\n",
    "                shallow_weights = self.feature_selection(lstm_out)\n",
    "                shallow_weights = shallow_weights.view(lstm_out.size(0), -1, self.decision_size)\n",
    "                selection_logits = torch.bmm(binary_features.unsqueeze(1), shallow_weights)\n",
    "                selection_logits = selection_logits.squeeze()\n",
    "\n",
    "            soft_decision = F.softmax(selection_logits / self.tau_selection, dim=1)\n",
    "            hard_selection = self.argmax(soft_decision, dim=1)\n",
    "            decision = hard_selection\n",
    "\n",
    "        # Collect statistics\n",
    "        self.collect_hist_stats('SelectionSoft', F.softmax(selection_logits, dim=1).max(dim=1)[0], iter)\n",
    "        self.collect_hist_stats('SelectionSoftTemp', F.softmax(selection_logits / self.feature_selection.tau, dim=1).max(dim=1)[0], iter)\n",
    "        self.collect_hist_stats('SelectionHard', hard_selection.max(dim=1)[1], iter)\n",
    "\n",
    "        return decision\n",
    "\n",
    "    def get_initial_state(self, batch_size):\n",
    "        h0 = self.init_h0.view(1, 1, -1).expand(-1, batch_size, -1)\n",
    "        c0 = self.init_c0.view(1, 1, -1).expand(-1, batch_size, -1)\n",
    "        state = (h0.contiguous(), c0.contiguous())\n",
    "        return state\n",
    "\n",
    "    def argmax(self, y_soft, dim):\n",
    "        index = y_soft.max(dim, keepdim=True)[1]\n",
    "        y_hard = torch.zeros_like(y_soft).scatter_(dim, index, 1.0)\n",
    "        argmax = y_hard - y_soft.detach() + y_soft\n",
    "        return argmax\n",
    "\n",
    "    def collect_hist_stats(self, name, data, i=None):\n",
    "        # TODO: investigate performance impact of collecting these statistics,\n",
    "        # make option to disable and/or autodisable if tree is too large\n",
    "        if 'Hard' in name:\n",
    "            stat_str = 'Hist/' + name\n",
    "            data = data.detach().cpu()\n",
    "            self.stats[stat_str].append(data)\n",
    "            if i is not None:\n",
    "                stat_str += str(i)\n",
    "                self.stats[stat_str].append(data)\n",
    "\n",
    "    def get_hist_stats(self, reset=True):\n",
    "        stats = self.stats\n",
    "        if reset:\n",
    "            self.stats = defaultdict(list)\n",
    "        #return None\n",
    "        return stats\n",
    "\n",
    "    def reset_stats(self):\n",
    "        self.unique_attributes = [set() for i in range(self.max_iters)]\n",
    "        if self.attribute_coef > 0.:\n",
    "            self.attr_pred_correct = [0 for i in range(self.max_iters)]\n",
    "\n",
    "    def update_unique_attributes(self, unique_attributes, iter):\n",
    "        for attr in unique_attributes:\n",
    "            self.unique_attributes[iter].add(attr.item())\n",
    "\n",
    "    def get_unique_attributes(self):\n",
    "        uniq_per_iter = []\n",
    "        for i in range(self.max_iters):\n",
    "            iter_set = self.unique_attributes[i]\n",
    "            for j in range(i+1):\n",
    "                if j == i:\n",
    "                    continue\n",
    "                iter_set = iter_set.union(self.unique_attributes[j])\n",
    "            uniq_per_iter.append(len(iter_set))\n",
    "        return uniq_per_iter\n",
    "\n",
    "    def update_attr_preds(self, attr_correct, iter):\n",
    "        self.attr_pred_correct[iter] += attr_correct\n",
    "\n",
    "    def get_attr_acc(self, total_cnt):\n",
    "        correct_cumsum = np.cumsum(self.attr_pred_correct)\n",
    "        cnt_per_iter = (np.arange(self.max_iters) + 1) * total_cnt\n",
    "        return correct_cumsum / cnt_per_iter\n",
    "\n",
    "    def init_tree_stats(self):\n",
    "        # TODO: investigate performance impact of collecting these statistics,\n",
    "        # make option to disable and/or autodisable if tree is too large\n",
    "\n",
    "        # Would be nice if this worked with sparse tensors\n",
    "        n_possible_states = self.decision_size ** self.max_iters\n",
    "        self.label_stats = torch.zeros((n_possible_states * self.decision_size,\n",
    "                                        self.num_classes), dtype=torch.int32)\n",
    "                                       #layout=torch.sparse_coo)\n",
    "        self.selection_stats = torch.zeros((n_possible_states,\n",
    "                                            self.attribute_size),\n",
    "                                           dtype=torch.int32)\n",
    "                                           #layout=torch.sparse_coo)\n",
    "\n",
    "    def update_tree_stats(self, attribute_selection, attribute_decisions, labels, iter):\n",
    "        # TODO: investigate performance impact of collecting these statistics,\n",
    "        # make option to disable and/or autodisable if tree is too large\n",
    "\n",
    "        if iter == 0:\n",
    "            self.batch_states = torch.zeros_like(labels)\n",
    "            for i in range(labels.size(0)):\n",
    "                self.label_stats[self.batch_states[i], labels[i]] += 1\n",
    "\n",
    "        for i in range(labels.size(0)):\n",
    "            self.selection_stats[self.batch_states[i], attribute_selection[i]] += 1\n",
    "            self.batch_states[i] += (attribute_decisions[i] + 1) * self.decision_size ** iter\n",
    "            self.label_stats[self.batch_states[i], labels[i]] += 1\n",
    "\n",
    "    def run_iteration(self, binary_features, state, decision_hist, iter, sigma=[]): # also pass sigma here\n",
    "        lstm_out = state[0].squeeze(0)\n",
    "\n",
    "        # Make binary decision\n",
    "        decision = self.make_decision(lstm_out, binary_features, iter, sigma)\n",
    "\n",
    "        if decision_hist is None:\n",
    "            decision_hist = decision\n",
    "        else:\n",
    "            decision_hist = (decision_hist + decision).clamp(0., 1.)\n",
    "\n",
    "        scaled_dh = decision_hist / decision_hist.sum(dim=1).unsqueeze(1).detach()\n",
    "        if self.no_lstm:\n",
    "            lstm_in = scaled_dh\n",
    "        else:\n",
    "            lstm_in = torch.cat((scaled_dh, decision), dim=1)\n",
    "\n",
    "        # Update LSTM state\n",
    "        lstm_in = self.pre_lstm(lstm_in).unsqueeze(1)\n",
    "        _, state = self.lstm(lstm_in, state)\n",
    "\n",
    "        # Get current classification\n",
    "        classifier_in = scaled_dh\n",
    "        #classifier_in = state[1].squeeze(0)\n",
    "        #classifier_in = torch.cat((decision_hist, self.lstm_state_bn(lstm_state)), dim=1)\n",
    "        classification = self.classifier(classifier_in)\n",
    "\n",
    "        return classification, state, decision_hist\n",
    "\n",
    "    def tree_rollout(self, images, labels, keep_tree_stats=False):\n",
    "        # Set initial state\n",
    "        state = self.get_initial_state(images.size(0))\n",
    "\n",
    "        # Get categorical features once\n",
    "        binary_features = self.process_images(images)\n",
    "        # collect attribute stats\n",
    "        # self.binary_features_list.append(binary_features)\n",
    "        # self.labels_list.append(labels)\n",
    "\n",
    "#         attr_acc = (binary_features[:,:,0] == attribute_mtx[labels]).sum().long() / 19968.0 #/ (312*labels.size(0))\n",
    "        attr_acc = (binary_features[:,:,0] == attribute_mtx[labels]).sum().long() / float((attribute_size*labels.size(0)))    \n",
    "#         print(attr_acc)\n",
    "        self.attribute_accuracies.append(attr_acc.item())\n",
    "\n",
    "        ######################### extended vocab code \n",
    "        if self.strategy == 'extRDTC':\n",
    "            with torch.no_grad():\n",
    "                img_feats = self.cnn(images)\n",
    "                img_feats = img_feats.view(img_feats.size(0), -1)\n",
    "    #             image_features = self.binary_features(img_feats) # maybe do those with no grad as well\n",
    "                sigmas = self.get_attribute_uncertainty(img_feats, n=5, batch_size=images.size(0))\n",
    "            if not self.training:\n",
    "                self.sigmas_list.append(sigmas)\n",
    "                self.labels_list.append(labels)\n",
    "    #         sigmas.detach()\n",
    "        \n",
    "#         ########### remove attrs code\n",
    "#         uncertain_attrs = (sigmas > 0.005).float()\n",
    "#         certain_attrs = 1. - uncertain_attrs\n",
    "#         uncertain_attrs = uncertain_attrs.view(images.size(0), attribute_size, 2)\n",
    "#         certain_attrs = certain_attrs.view(images.size(0), attribute_size, 2)\n",
    "# #         print(certain_attrs[0])\n",
    "#         mask = torch.bernoulli(torch.empty(binary_features.size(), device=device).uniform_(1, 1))\n",
    "        \n",
    "#         binary_features = binary_features * mask#certain_attrs.detach() # clean binary_features from uncertain attrs (replace with 0)\n",
    "        \n",
    "        \n",
    "\n",
    "#         ######################################### remove attrs code end\n",
    "        \n",
    "# #         self.mean_sigmas.append(sigmas.mean().item())\n",
    "            sigmas = (sigmas > 0.005).float() # 0.004\n",
    "            sigmas_new = torch.zeros(images.size(0), attribute_size,1, device=device)\n",
    "            sigmas_new += sigmas.view(images.size(0),attribute_size,2)[:,:,0].unsqueeze(2)\n",
    "            sigmas_new += sigmas.view(images.size(0),attribute_size,2)[:,:,1].unsqueeze(2)\n",
    "            sigmas_new = (sigmas_new > 0.0).float() # <- denotes uncertain attributes\n",
    "\n",
    "            self.drop_ratios.append((sigmas_new.sum()/19968.0).item())\n",
    "\n",
    "            # obtain uncertainty and append to decision\n",
    "            new_attribute_decisions = torch.cat([binary_features, torch.zeros_like(sigmas_new, device=device)], dim=2)\n",
    "            certain_decisions = 1. - sigmas_new\n",
    "            uncertain_onehot = torch.tensor([[0., 0., 1.]], device=device).repeat(images.size(0), attribute_size, 1)\n",
    "            uncertain_attrs_removed = certain_decisions.detach() * new_attribute_decisions\n",
    "            shaped_uncertain_attrs = sigmas_new.detach() * uncertain_onehot\n",
    "            final_attribute_decisions = uncertain_attrs_removed + shaped_uncertain_attrs\n",
    "#             binary_features = final_attribute_decisions\n",
    "#         ######################### extended vocab code end\n",
    "        \n",
    "        \n",
    "\n",
    "        loss = 0\n",
    "        j = 0\n",
    "        # stats\n",
    "        all_classifications = []\n",
    "        all_chosen_attr = []\n",
    "        all_attribute_preds = []\n",
    "\n",
    "        decision_hist = None\n",
    "        while j < self.max_iters:\n",
    "            classification, state, decision_hist = self.run_iteration(binary_features, state, decision_hist, j+1)\n",
    "            loss += (1. - self.attribute_coef) * self.cls_loss(classification, labels)\n",
    "            all_classifications.append(classification)\n",
    "\n",
    "            self.update_unique_attributes(self.saved_attribute_selection.unique(), j)\n",
    "\n",
    "            if self.model_type == 'xoc' and self.attribute_coef > 0.:\n",
    "                chosen_attribtutes = self.saved_attribute_selection\n",
    "                attribute_logits = self.attribute_logits\n",
    "\n",
    "                attribute_target = self.attribute_mtx[labels, :].gather(1, chosen_attribtutes.unsqueeze(1)).squeeze()\n",
    "                attribute_pred = attribute_logits.gather(1, chosen_attribtutes.unsqueeze(1)).squeeze()\n",
    "                loss += self.attribute_coef * self.attr_loss(attribute_pred,\n",
    "                                                             attribute_target)\n",
    "                \n",
    "\n",
    "\n",
    "                attribute_pred_bin = (attribute_pred > 0.).long()\n",
    "                self.update_attr_preds((attribute_pred_bin == attribute_target).sum().item(), j)\n",
    "\n",
    "                \n",
    "            if keep_tree_stats:\n",
    "                attribute_pred = self.attribute_logits.gather(1, self.saved_attribute_selection.unsqueeze(1)).squeeze()\n",
    "                self.update_tree_stats(self.saved_attribute_selection, (attribute_pred > 0.).long(),labels, j)\n",
    "\n",
    "                # all_chosen_attr.append(self.saved_attribute_selection)\n",
    "                all_attribute_preds.append((attribute_pred > 0.).long())\n",
    "\n",
    "            j += 1\n",
    "        \n",
    "            all_chosen_attr.append(self.saved_attribute_selection)\n",
    "\n",
    "        self.tmp_saved_chosen_attr = torch.stack(all_chosen_attr, dim=1)\n",
    "\n",
    "        if keep_tree_stats:\n",
    "            self.tmp_saved_cls = torch.stack(all_classifications, dim=1)\n",
    "            # self.tmp_saved_chosen_attr = torch.stack(all_chosen_attr, dim=1)\n",
    "            self.tmp_saved_attr_pred = torch.stack(all_attribute_preds, dim=1)\n",
    "        # else:\n",
    "        #     self.tmp_saved_chosen_attr = None\n",
    "\n",
    "        loss = loss / self.max_iters\n",
    "\n",
    "\n",
    "        ####################################\n",
    "        # if binary_features.size(0)==64:\n",
    "            # self.used_attributes_list.append(self.tmp_saved_chosen_attr)\n",
    "            # self.certain_attrs.append(certain_decisions)\n",
    "            # chosen_attributes_binary = torch.tensor([1 if x in [int(attr) for attr in self.tmp_saved_chosen_attr[:,x]] else 0 for x in range(312)], device=device)\n",
    "            # self.used_attributes_list.append(chosen_attributes_binary)\n",
    "            # self.sigmas_list.append(sigmas_all)\n",
    "        ####################################\n",
    "        return all_classifications, loss, self.tmp_saved_chosen_attr\n",
    "\n",
    "    def forward(self, images, labels, keep_tree_stats=False):\n",
    "        classification, loss, chosen_attribtutes = self.tree_rollout(images, labels, keep_tree_stats)\n",
    "        # classification, loss, chosen_attributes = self.tree_rollout(images, labels, keep_tree_stats)\n",
    "\n",
    "        return classification, loss#, chosen_attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "After defining our models, we can continue by training it. For this, we first set some hyperparameters and then continue by defining a trainer class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake input arguments\n",
    "model_type = 'xoc'\n",
    "cnn_type = 'uncertain'\n",
    "# cnn_type = 'resnet'\n",
    "attribute_coef = 0.2\n",
    "# attribute_size = 85#312 #1024\n",
    "# attribute_size = 312 #1024\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.00001\n",
    "step_size = 50\n",
    "num_epochs = 2\n",
    "max_iters = 10\n",
    "hidden_size = 1000\n",
    "cnn_out_size = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, dataloaders, num_epochs, device, log_freq, log_path): # todo remove stats dict\n",
    "\n",
    "        self.model = model\n",
    "        self.dataloaders = dataloaders\n",
    "        self.num_epochs = num_epochs\n",
    "        self.device = device\n",
    "        self.log_freq = log_freq\n",
    "        self.log_path = log_path\n",
    "        \n",
    "        self.logger = SummaryWriter(self.log_path)\n",
    "\n",
    "        #### TODO remove this workaround and use tensorboard\n",
    "#         with open('/content/drive/My Drive/rdtc/data/' + 'logs/' + 'stats_dict.json') as json_file:\n",
    "#             self.stats_dict = json.load(json_file)\n",
    "        \n",
    "        self.classifications_dict = {'correct':{'num':0, 'uncertainty':0},\n",
    "                                     'incorrect':{'num':0, 'uncertainty':0}}\n",
    "\n",
    "        self.uncertainty_stats = {'epoch_{}'.format(epoch):{'used_attributes':[],'sigmas':[], 'num_attrs_discarded':0} for epoch in range(num_epochs+2)}\n",
    "        self.mean_attr_accs = []\n",
    "        self.mean_drop_ratio = []\n",
    "        self.mean_sigmas = []\n",
    "        ############\n",
    "\n",
    "    def train(self):\n",
    "        self.model.phase = 'train'\n",
    "        self.train_model(self.dataloaders['train'])\n",
    "\n",
    "    def test(self):\n",
    "        self.model.phase = 'test'\n",
    "        self.test_model(self.dataloaders['test'], 'test', None, hard=False) # was: hard=True\n",
    "        self.model.phase = 'train'\n",
    "        return self.model.label_stats, self.model.selection_stats\n",
    "\n",
    "    def topk_correct(self, output, target, topk=(1,)):\n",
    "        maxk = max(topk)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        target_masks = []\n",
    "        target_cnt = []\n",
    "        for i in range(self.model.num_classes):\n",
    "            target_masks.append((target == i).unsqueeze(0))\n",
    "            target_cnt.append(target_masks[i].sum().item())\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = [(correct[:k] * tm).view(-1).float().sum(0, keepdim=True).item() for tm in target_masks]\n",
    "            res.append(np.array(correct_k))\n",
    "        return res, np.array(target_cnt)\n",
    "\n",
    "    def log_stats(self, phase, epoch, epoch_stats, hist_stats,\n",
    "                  unique_attr_stats, attr_acc):\n",
    "        for k in range(len(epoch_stats[0])):\n",
    "        # for k in range(1):\n",
    "\n",
    "            self.logger.add_scalar('Top1Accuracy{}/{}'.format(k+1, phase), epoch_stats[0][k], epoch)\n",
    "            # self.logger.add_scalar('Top5Accuracy{}/{}'.format(k+1, phase), epoch_stats[1][k], epoch)\n",
    "            # self.logger.add_scalar('Top1MeanClassAccuracy{}/{}'.format(k+1, phase), epoch_stats[3][k], epoch)\n",
    "            # self.logger.add_scalar('Top5MeanClassAccuracy{}/{}'.format(k+1, phase), epoch_stats[4][k], epoch)\n",
    "            # if unique_attr_stats is not None:\n",
    "            #     self.logger.add_scalar('UniqueAttributes{}/{}'.format(k+1, phase), unique_attr_stats[k], epoch)\n",
    "            # if attr_acc is not None:\n",
    "            #     self.logger.add_scalar('AttributeAccuracy{}/{}'.format(k+1, phase), attr_acc[k], epoch)\n",
    "        self.logger.add_scalar('Loss/'+phase, epoch_stats[2], epoch)\n",
    "\n",
    "        if hist_stats is not None:\n",
    "            for name, data in hist_stats.items():\n",
    "                data = torch.cat(data, dim=0).flatten()\n",
    "                if name.startswith('SelectionHard'):\n",
    "                    bins = self.model.attribute_size\n",
    "                elif name.startswith('AttributesHard'):\n",
    "                    bins = self.model.decision_size\n",
    "                else:\n",
    "                    bins = 'tensorflow'\n",
    "                self.logger.add_histogram(name, data, epoch, bins=bins)\n",
    "\n",
    "    def test_model(self, data_loader, phase, epoch, hard=False):\n",
    "        # Test the Model\n",
    "        self.model.eval()  # Change model to 'eval' mode (BN uses moving mean/var).\n",
    "        n_stats = self.model.max_iters if hasattr(self.model, 'max_iters') else 1\n",
    "        correct_1 = np.zeros((n_stats, self.model.num_classes))\n",
    "        correct_5 = np.zeros((n_stats, self.model.num_classes))\n",
    "        total = 0\n",
    "        total_cnt = np.zeros((1, self.model.num_classes))\n",
    "        total_loss = 0\n",
    "\n",
    "        if isinstance(self.model, OC):\n",
    "            self.model.reset_stats()\n",
    "            if hard:\n",
    "                self.model.init_tree_stats()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for idx, data in enumerate(data_loader):\n",
    "                if len(data) == 2:\n",
    "                    images, labels = data\n",
    "                    attributes = None\n",
    "                else:\n",
    "                    images, labels, attributes = data\n",
    "                    #attributes = attributes.to(self.device)\n",
    "                images = images.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                \n",
    "                classification, loss = self.model(images, labels, hard)\n",
    "                #####################################\n",
    "#                 print(labels.size())\n",
    "#                 print(labels[0].item())\n",
    "                #####################################\n",
    "\n",
    "                # Collect stats\n",
    "                total_loss += loss.item()\n",
    "                total += labels.size(0)\n",
    "                for k in range(len(classification)):\n",
    "                    ######################\n",
    "                    # print(classification[k].data)\n",
    "                    # print(labels[k])\n",
    "                    # print()\n",
    "                    # print(classification[k].data.size())\n",
    "                    # print(labels.size())\n",
    "                    # print()\n",
    "                    # values, indices = torch.max(classification[k], -1)\n",
    "                    # for i in range(classification[k].size(0)):\n",
    "\n",
    "                        # print(indices[i].item(),labels[i].item())\n",
    "                        # if indices[i].item()==labels[i].item():\n",
    "                        #     self.classifications_dict['correct']+=1\n",
    "                        # if indices[i].item()!=labels[i].item():\n",
    "                        #     self.classifications_dict['incorrect']+=1              \n",
    "          \n",
    "                    ######################\n",
    "                    ctopk, target_cnt = self.topk_correct(classification[k].data, labels, (1, 5))\n",
    "                    c1, c5 = ctopk\n",
    "                    # print(target_cnt)\n",
    "                    correct_1[k] += c1\n",
    "                    correct_5[k] += c5\n",
    "                total_cnt[0] += target_cnt\n",
    "\n",
    "                \n",
    "                # if classification[-1].size(0)==64:\n",
    "                #     values, indices = torch.max(classification[-1], -1)\n",
    "                #     image_features_ = self.model.cnn(images)\n",
    "                #     image_features_ = image_features_.view(image_features_.size(0), -1)\n",
    "                #     # self.model.binary_features = self.model.binary_features.train()\n",
    "                #     sigmas = self.model.get_attribute_uncertainty_batch(image_features_, batch_size=64)\n",
    "                #     sigmas.cuda()\n",
    "                #     # self.model.binary_features = self.model.binary_features.eval()\n",
    "                #     _, _, attributes_used = self.model.tree_rollout(images, labels, True)\n",
    "                #     for i in range(classification[-1].size(0)): # iterate over batch\n",
    "                #         chosen_attributes_binary = torch.tensor([1 if x in [int(attr) for attr in attributes_used[i]] else 0 for x in range(624)], device=device)\n",
    "                #         self.model.used_attributes_list.append(chosen_attributes_binary)\n",
    "                #         # chosen_attributes_binary.cuda()\n",
    "                #         used_sigmas = sigmas[i] * chosen_attributes_binary\n",
    "                #         if indices[i].item()==labels[i].item():\n",
    "                #             self.classifications_dict['correct']['num'] += 1\n",
    "                #             self.classifications_dict['correct']['uncertainty'] += used_sigmas.sum().item()\n",
    "                #         if indices[i].item()!=labels[i].item():\n",
    "                #             self.classifications_dict['incorrect']['num'] += 1\n",
    "                #             self.classifications_dict['incorrect']['uncertainty'] += used_sigmas.sum().item()\n",
    "                \n",
    "        # collect uncertainty stats#############################\n",
    "        # num_batches = len(model.used_attributes_list)\n",
    "\n",
    "        # attribute_zeros = torch.zeros(num_batches,624)\n",
    "        # # attrs_discarded_zeros = torch.zeros(num_batches, 624)\n",
    "        # sigma_zeros = torch.zeros(1, 624, device=device)\n",
    "        # num_attrs_discarded = 0\n",
    "        # for i in range(num_batches):\n",
    "        #     for batch_index in range(64):\n",
    "        #         example_attrs = [int(attr) for attr in model.used_attributes_list[i][batch_index]] # \n",
    "        #         attribute_zeros[i] += torch.tensor([1 if x in example_attrs else 0 for x in range(624)]) # used attrs binary\n",
    "        #         used_attrs_binary = torch.tensor([1 if x in example_attrs else 0 for x in range(624)]) # for that example\n",
    "        #         certain_attrs = model.certain_attrs[i][batch_index]\n",
    "        #         used_certain_attrs = used_attrs_binary.detach().cpu()[:312] * certain_attrs.detach().cpu()\n",
    "        #         num_attrs_discarded += torch.abs(used_attrs_binary.sum() - used_certain_attrs.sum())\n",
    "        #     sigma_zeros += model.sigmas_list[i].mean(dim=0) # add average of batch\n",
    "        #     # num_attrs_discarded += model.num_attrs_discarded_list[i]\n",
    "\n",
    "        \n",
    "        # self.uncertainty_stats['epoch_{}'.format(epoch)]['used_attributes']= attribute_zeros.sum(dim=0)\n",
    "        # self.model.used_attributes_list = []\n",
    "        # self.uncertainty_stats['epoch_{}'.format(epoch)]['sigmas'] = sigma_zeros/num_batches\n",
    "        # self.model.sigmas_list = []\n",
    "        # self.uncertainty_stats['epoch_{}'.format(epoch)]['num_attrs_discarded'] += num_attrs_discarded\n",
    "        # model.certain_attrs = []\n",
    "        # #####################################################################################\n",
    "\n",
    "        stats = [correct_1.sum(axis=1) / total, correct_5.sum(axis=1) / total, total_loss / total, (correct_1 / total_cnt).mean(axis=1), (correct_5 / total_cnt).mean(axis=1)]\n",
    "        print('Accuracy ({}), Top1: {:.2%}, Top5: {:.2%}'.format(phase, stats[0][-1], stats[1][-1]))\n",
    "        self.model.train()  # Change model to 'train' mode\n",
    "\n",
    "        unique_attr_stats = None\n",
    "        attr_acc = None\n",
    "        if epoch is not None:\n",
    "            if isinstance(self.model, OC):\n",
    "                hist_stats = self.model.get_hist_stats()\n",
    "                unique_attr_stats = self.model.get_unique_attributes()\n",
    "                if self.model.attribute_coef > 0.:\n",
    "                    attr_acc = self.model.get_attr_acc(total)\n",
    "                else:\n",
    "                    attr_acc = None\n",
    "            else:\n",
    "                hist_stats = None\n",
    "            self.log_stats(phase, epoch, stats, hist_stats, unique_attr_stats, attr_acc)\n",
    "\n",
    "        return stats[0][-1], stats, unique_attr_stats, attr_acc\n",
    "\n",
    "    def train_model(self, data_laoder):\n",
    "        max_accuracy = 0\n",
    "        max_agg_accuracy = 0\n",
    "        max_ma_accuracy = 0\n",
    "        max_ma_agg_accuracy = 0\n",
    "\n",
    "        if isinstance(self.model, OC):\n",
    "            self.model.reset_stats()\n",
    "\n",
    "        # Train the Model\n",
    "        ############### remove this workaround\n",
    "#         configuration = self.log_path.split('logs/')[1].split('/')[0]\n",
    "        # self.stats_dict[configuration]['losses'] = []\n",
    "        ###############################################\n",
    "        \n",
    "        for epoch in range(self.num_epochs):\n",
    "            #self.model.set_tau(epoch)\n",
    "            optimizer = self.model.get_optimizer()\n",
    "            n_stats = self.model.max_iters if hasattr(self.model, 'max_iters') else 1\n",
    "            correct_1 = np.zeros((n_stats, self.model.num_classes))\n",
    "            correct_5 = np.zeros((n_stats, self.model.num_classes))\n",
    "            total = 0\n",
    "            total_cnt = np.zeros((1, self.model.num_classes))\n",
    "            total_loss = 0\n",
    "\n",
    "            for i, data in enumerate(data_laoder):\n",
    "                \n",
    "                if len(data) == 2:\n",
    "                    images, labels = data\n",
    "                    attributes = None\n",
    "                else:\n",
    "                    images, labels, attributes = data\n",
    "                    #attributes = attributes.to(self.device)\n",
    "                images = images.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                classification, loss = self.model(images, labels)\n",
    "                \n",
    "\n",
    "                if loss.grad_fn is not None:\n",
    "                \n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # Collect stats\n",
    "                total_loss += loss.item()\n",
    "                total += labels.size(0)\n",
    "                for k in range(len(classification)):\n",
    "                    ctopk, target_cnt = self.topk_correct(classification[k].data, labels, (1, 5))\n",
    "                    c1, c5 = ctopk\n",
    "                    correct_1[k] += c1\n",
    "                    correct_5[k] += c5\n",
    "                total_cnt[0] += target_cnt\n",
    "\n",
    "                if (i+1) % self.log_freq == 0:\n",
    "                    print('Epoch [{}/{}], Iter [{}/{}] Loss: {:.4f}'\n",
    "                            .format(epoch+1, self.num_epochs, i+1, len(data_laoder)//images.size(0),\n",
    "                                    loss.item()))\n",
    "                    ##### TODO remove workaround and use tensurboard\n",
    "                    # self.stats_dict[configuration]['losses'].append(loss.item())\n",
    "            \n",
    "        # with open(data_path + '/logs/' + 'stats_dict.json', 'w') as json_file:\n",
    "        #     json.dump(self.stats_dict, json_file)\n",
    "        #     print('stats dict saved...')\n",
    "                    #############################################\n",
    "\n",
    "            self.model.get_scheduler().step()\n",
    "            # if isinstance(self.model, NeuralDecisionForest) or isinstance(self.model, OC):\n",
    "            #     self.model.toggle_update_schedule()\n",
    "\n",
    "            stats = [correct_1.sum(axis=1) / total, correct_5.sum(axis=1) / total, total_loss / total, (correct_1 / total_cnt).mean(axis=1), (correct_5 / total_cnt).mean(axis=1)]\n",
    "\n",
    "            if isinstance(self.model, OC):\n",
    "                hist_stats = self.model.get_hist_stats()\n",
    "                unique_attr_stats = self.model.get_unique_attributes()\n",
    "                if self.model.attribute_coef > 0.:\n",
    "                    attr_acc = self.model.get_attr_acc(total)\n",
    "                else:\n",
    "                    attr_acc = None\n",
    "            else:\n",
    "                hist_stats = None\n",
    "                unique_attr_stats = None\n",
    "                attr_acc = None\n",
    "            self.log_stats('train', epoch, stats, hist_stats, unique_attr_stats, attr_acc)\n",
    "            print('Accuracy (train), Top1: {:.2%}, Top5: {:.2%}'.format(stats[0][-1], stats[1][-1]))\n",
    "            self.model.phase = 'test'\n",
    "            val_accuracy, val_stats, _, _ = self.test_model(self.dataloaders['val'],\n",
    "                                                            'val', epoch+1)\n",
    "            val_agg_accuracy = val_stats[0].sum()\n",
    "            val_ma_accuracy = val_stats[3][-1]\n",
    "            val_ma_agg_accuracy = val_stats[3].sum()\n",
    "\n",
    "            # reset model stats\n",
    "            model.sigmas_list = []\n",
    "            model.labels_list = []\n",
    "            model.used_attributes_list = []\n",
    "            model.attribute_accuracies = []\n",
    "            model.drop_ratios = []\n",
    "#             self.model.phase = 'test'\n",
    "            _, test_stats, unique_attr_stats, attr_acc = self.test_model(self.dataloaders['test'], 'test', epoch+1)\n",
    "            \n",
    "#             if model.drop_ratios[0].size(0) == 64:\n",
    "            self.mean_drop_ratio.append(sum(model.drop_ratios)/(len(model.drop_ratios)+1))\n",
    "            mean_attribute_accuracy = sum(model.attribute_accuracies)/len(model.attribute_accuracies)\n",
    "            self.mean_sigmas.append(sum(model.mean_sigmas)/(len(model.mean_sigmas)+1))\n",
    "            self.mean_attr_accs.append(mean_attribute_accuracy)\n",
    "#             print(mean_attribute_accuracy)\n",
    "#             print()\n",
    "            # # collect uncertainty stats\n",
    "            # self.uncertainty_stats['epoch_{}'.format(epoch)]['used_attributes']=self.model.used_attributes_list\n",
    "            # self.model.used_attributes_list = []\n",
    "            # self.uncertainty_stats['epoch_{}'.format(epoch)]['sigmas']=self.model.sigmas_list\n",
    "            # self.model.sigmas_list = []           \n",
    "            \n",
    "            \n",
    "            \n",
    "            self.model.phase = 'train'\n",
    "            if val_accuracy > max_accuracy:\n",
    "                max_accuracy = val_accuracy\n",
    "#                 self.save_model('best', test_stats, 0, unique_attr_stats, attr_acc, epoch)\n",
    "            if val_ma_accuracy > max_ma_accuracy:\n",
    "                max_ma_accuracy = val_ma_accuracy\n",
    "#                 self.save_model('best_ma', test_stats, 3, unique_attr_stats, attr_acc, epoch)\n",
    "            if val_agg_accuracy > max_agg_accuracy and isinstance(self.model, OC):\n",
    "                max_agg_accuracy = val_agg_accuracy\n",
    "                self.save_model('best_agg', test_stats, 0, unique_attr_stats, attr_acc, epoch)\n",
    "            if val_ma_agg_accuracy > max_ma_agg_accuracy and isinstance(self.model, OC):\n",
    "                max_ma_agg_accuracy = val_ma_agg_accuracy\n",
    "#                 self.save_model('best_ma_agg', test_stats, 3, unique_attr_stats, attr_acc, epoch)\n",
    "\n",
    "            self.save_model('latest', test_stats, 0, unique_attr_stats, attr_acc, epoch)\n",
    "        # with open(data_path + '/logs/' + 'stats_dict.json', 'w') as json_file:\n",
    "        #     json.dump(self.stats_dict, json_file)\n",
    "        #     print('stats dict saved...')\n",
    "\n",
    "\n",
    "    def write_stats_file(self, stats_list, name, epoch, is_float=True):\n",
    "        fstr = '{:.2f}' if is_float else '{}'\n",
    "        with open(os.path.join(self.log_path, '{}.txt'.format(name)), 'a') as f:\n",
    "            acc_str = [fstr.format(100*c1 if is_float else c1) for c1 in stats_list]\n",
    "            f.write('{} '.format(epoch) + ' '.join(acc_str))\n",
    "            f.write('\\n')\n",
    "\n",
    "    def save_model(self, name, test_stats, stats_idx, unique_attr_stats, attr_acc, epoch):\n",
    "        torch.save(self.model.state_dict(),\n",
    "                   os.path.join(self.log_path, '{}.pth'.format(name)))\n",
    "        \n",
    "        # save state dict for vision model separately\n",
    "        torch.save(self.model.cnn.state_dict(), os.path.join(self.log_path, '{}_vision_model.pth'.format(name)))\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.write_stats_file(test_stats[stats_idx], name, epoch)\n",
    "\n",
    "        # if isinstance(self.model, NeuralDecisionForest):\n",
    "        #     _, test_stats_hard, _, _ = self.test_model(self.dataloaders['test'],\n",
    "        #                                                'test', epoch+1, hard=True)\n",
    "        #     self.write_stats_file(test_stats_hard[stats_idx], name+'_hard', epoch)\n",
    "\n",
    "        if unique_attr_stats is not None:\n",
    "            self.write_stats_file(unique_attr_stats, name+'_uniqattr', epoch,\n",
    "                                  is_float=False)\n",
    "\n",
    "        if attr_acc is not None:\n",
    "            self.write_stats_file(attr_acc, name+'_attracc', epoch)\n",
    "\n",
    "        if name != 'latest':\n",
    "            print('Saved {} model'.format(name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's instance our models..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the configuraion parameters of our dataset\n",
    "in_channels, cnn_out_size, log_freq = get_dataset_config(dataset, 'cnn', 40 )\n",
    "cnn_out_size = 2048\n",
    "\n",
    "# initiate the observer classifier model\n",
    "model = OC('xoc', len(classes), 'dropoutcnn', in_channels,\n",
    "            cnn_out_size, dataset, 2, 40, # 13 worked\n",
    "            attribute_size, attribute_mtx, attribute_coef,\n",
    "            hidden_size, tau_initial=5,\n",
    "            use_pretrained=False, shallow=False)\n",
    "\n",
    "# load pretrained resnet backbone\n",
    "model.cnn = models.resnet152(pretrained=False)\n",
    "model.cnn.fc = nn.Linear(model.cnn.fc.in_features, torch.load('/home/swezel/projects/urdtc/pretrained/cub_resnet152.pkl')['fc.weight'].size(0))\n",
    "model.cnn.load_state_dict(torch.load('/home/swezel/projects/urdtc/pretrained/cub_resnet152.pkl'))\n",
    "# model.cnn.fc = nn.Linear(model.cnn.fc.in_features, torch.load('/home/swezel/projects/urdtc/pretrained/{}_resnet152.pkl'.format(dataset))['fc.weight'].size(0))\n",
    "# model.cnn.load_state_dict(torch.load('/home/swezel/projects/urdtc/pretrained/{}_resnet152.pkl'.format(dataset)))\n",
    "\n",
    "\n",
    "model.cnn.fc = nn.Identity()\n",
    "\n",
    "# set attribute head\n",
    "model.binary_features = nn.Sequential(nn.BatchNorm1d(cnn_out_size),\n",
    "                                        nn.Linear(cnn_out_size, hidden_size),\n",
    "                                        nn.ReLU(inplace=True),\n",
    "                                        nn.BatchNorm1d(hidden_size),\n",
    "                                        nn.Dropout(0.5, inplace=False), # dropout after batchnorm\n",
    "                                        nn.Linear(hidden_size, hidden_size),\n",
    "                                        nn.ReLU(inplace=True),\n",
    "                                        nn.BatchNorm1d(hidden_size),\n",
    "                                        nn.Dropout(0.5, inplace=False),\n",
    "                                        nn.Linear(hidden_size, attribute_size * 2))\n",
    "\n",
    "model.binary_features.tau = nn.Parameter(torch.tensor([5], dtype=torch.float), requires_grad=True)\n",
    "model.to(device);\n",
    "\n",
    "# freeze resnet backbone for faster training but make all other weights trainable\n",
    "for param in model.lstm.parameters():\n",
    "    param.requires_grad=True\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad=True\n",
    "for param in model.feature_selection.parameters():\n",
    "    param.requires_grad=True\n",
    "for param in model.binary_features.parameters():\n",
    "    param.requires_grad=True\n",
    "for param in model.pre_lstm.parameters():\n",
    "    param.requires_grad=True\n",
    "    \n",
    "for param in model.cnn.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.cnn.fc.parameters():\n",
    "    param.requires_grad=True\n",
    "    \n",
    "# initiate optimizers\n",
    "tree_params, cnn_params = model.get_param_groups()\n",
    "tree_optimizer = torch.optim.Adam(tree_params, lr = learning_rate, weight_decay=weight_decay)\n",
    "cnn_optimizer = torch.optim.Adam(cnn_params, lr = learning_rate, weight_decay=weight_decay)\n",
    "optimizer = [tree_optimizer, cnn_optimizer]\n",
    "# and schedulers\n",
    "tree_scheduler = torch.optim.lr_scheduler.StepLR(tree_optimizer, step_size=step_size, gamma=0.1)\n",
    "cnn_scheduler = torch.optim.lr_scheduler.StepLR(cnn_optimizer, step_size=step_size, gamma=0.1)\n",
    "scheduler = [tree_scheduler, cnn_scheduler]\n",
    "\n",
    "model.set_optimizer(optimizer)\n",
    "# model.init_tree_stats()\n",
    "model.set_scheduler(scheduler)\n",
    "##hook\n",
    "# torch.load('/home/swezel/projects/urdtc/pretrained/awa2_resnet152.pkl')\n",
    "\n",
    "# model.strategy = 'randRDTC'\n",
    "# model.strategy = 'remRDTC'\n",
    "model.strategy = 'extRDTC'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and finally train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-259-f002911457a5>:207: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs[i] = F.softmax(self.binary_features(image_features))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Iter [10/1] Loss: 4.4211\n",
      "Epoch [1/20], Iter [20/1] Loss: 4.3990\n",
      "Epoch [1/20], Iter [30/1] Loss: 4.3598\n",
      "Epoch [1/20], Iter [40/1] Loss: 4.2598\n",
      "Epoch [1/20], Iter [50/1] Loss: 4.1925\n",
      "Epoch [1/20], Iter [60/1] Loss: 4.1276\n",
      "Epoch [1/20], Iter [70/1] Loss: 3.8989\n",
      "Epoch [1/20], Iter [80/1] Loss: 4.0064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-261-070f05ede296>:280: RuntimeWarning: invalid value encountered in true_divide\n",
      "  stats = [correct_1.sum(axis=1) / total, correct_5.sum(axis=1) / total, total_loss / total, (correct_1 / total_cnt).mean(axis=1), (correct_5 / total_cnt).mean(axis=1)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (train), Top1: 2.39%, Top5: 9.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-259-f002911457a5>:216: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs[i] = F.softmax(self.binary_features(image_features))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (val), Top1: 2.08%, Top5: 11.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-261-070f05ede296>:190: RuntimeWarning: invalid value encountered in true_divide\n",
      "  stats = [correct_1.sum(axis=1) / total, correct_5.sum(axis=1) / total, total_loss / total, (correct_1 / total_cnt).mean(axis=1), (correct_5 / total_cnt).mean(axis=1)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (test), Top1: 1.48%, Top5: 10.71%\n",
      "Saved best_agg model\n",
      "Epoch [2/20], Iter [10/1] Loss: 3.6411\n",
      "Epoch [2/20], Iter [20/1] Loss: 3.8225\n",
      "Epoch [2/20], Iter [30/1] Loss: 3.5042\n",
      "Epoch [2/20], Iter [40/1] Loss: 3.5315\n",
      "Epoch [2/20], Iter [50/1] Loss: 3.2036\n",
      "Epoch [2/20], Iter [60/1] Loss: 3.3883\n",
      "Epoch [2/20], Iter [70/1] Loss: 3.2744\n",
      "Epoch [2/20], Iter [80/1] Loss: 3.5148\n",
      "Accuracy (train), Top1: 11.27%, Top5: 35.97%\n",
      "Accuracy (val), Top1: 9.90%, Top5: 34.20%\n",
      "Accuracy (test), Top1: 8.17%, Top5: 30.94%\n",
      "Saved best_agg model\n",
      "Epoch [3/20], Iter [10/1] Loss: 3.4048\n",
      "Epoch [3/20], Iter [20/1] Loss: 3.3235\n",
      "Epoch [3/20], Iter [30/1] Loss: 3.2061\n",
      "Epoch [3/20], Iter [40/1] Loss: 3.0788\n",
      "Epoch [3/20], Iter [50/1] Loss: 3.0330\n",
      "Epoch [3/20], Iter [60/1] Loss: 2.9455\n",
      "Epoch [3/20], Iter [70/1] Loss: 2.9389\n",
      "Epoch [3/20], Iter [80/1] Loss: 2.7610\n",
      "Accuracy (train), Top1: 21.43%, Top5: 57.55%\n",
      "Accuracy (val), Top1: 23.44%, Top5: 57.64%\n",
      "Accuracy (test), Top1: 21.89%, Top5: 51.56%\n",
      "Saved best_agg model\n",
      "Epoch [4/20], Iter [10/1] Loss: 2.6976\n",
      "Epoch [4/20], Iter [20/1] Loss: 2.5857\n",
      "Epoch [4/20], Iter [30/1] Loss: 2.9229\n",
      "Epoch [4/20], Iter [40/1] Loss: 2.6093\n",
      "Epoch [4/20], Iter [50/1] Loss: 2.5292\n",
      "Epoch [4/20], Iter [60/1] Loss: 2.6046\n",
      "Epoch [4/20], Iter [70/1] Loss: 2.6839\n",
      "Epoch [4/20], Iter [80/1] Loss: 2.5750\n",
      "Accuracy (train), Top1: 30.50%, Top5: 70.85%\n",
      "Accuracy (val), Top1: 31.77%, Top5: 68.75%\n",
      "Accuracy (test), Top1: 27.90%, Top5: 60.31%\n",
      "Saved best_agg model\n",
      "Epoch [5/20], Iter [10/1] Loss: 2.5732\n",
      "Epoch [5/20], Iter [20/1] Loss: 2.4178\n",
      "Epoch [5/20], Iter [30/1] Loss: 2.7310\n",
      "Epoch [5/20], Iter [40/1] Loss: 2.5900\n",
      "Epoch [5/20], Iter [50/1] Loss: 2.4474\n",
      "Epoch [5/20], Iter [60/1] Loss: 2.3931\n",
      "Epoch [5/20], Iter [70/1] Loss: 2.5033\n",
      "Epoch [5/20], Iter [80/1] Loss: 2.5452\n",
      "Accuracy (train), Top1: 37.90%, Top5: 76.05%\n",
      "Accuracy (val), Top1: 41.49%, Top5: 76.74%\n",
      "Accuracy (test), Top1: 37.94%, Top5: 67.57%\n",
      "Saved best_agg model\n",
      "Epoch [6/20], Iter [10/1] Loss: 2.6860\n",
      "Epoch [6/20], Iter [20/1] Loss: 2.4591\n",
      "Epoch [6/20], Iter [30/1] Loss: 2.3409\n",
      "Epoch [6/20], Iter [40/1] Loss: 2.2692\n",
      "Epoch [6/20], Iter [50/1] Loss: 2.3209\n",
      "Epoch [6/20], Iter [60/1] Loss: 2.5157\n",
      "Epoch [6/20], Iter [70/1] Loss: 2.3944\n",
      "Epoch [6/20], Iter [80/1] Loss: 2.2403\n",
      "Accuracy (train), Top1: 42.68%, Top5: 79.09%\n",
      "Accuracy (val), Top1: 42.88%, Top5: 82.64%\n",
      "Accuracy (test), Top1: 44.60%, Top5: 70.21%\n",
      "Saved best_agg model\n",
      "Epoch [7/20], Iter [10/1] Loss: 2.4416\n",
      "Epoch [7/20], Iter [20/1] Loss: 2.4253\n",
      "Epoch [7/20], Iter [30/1] Loss: 2.3974\n",
      "Epoch [7/20], Iter [40/1] Loss: 2.4774\n",
      "Epoch [7/20], Iter [50/1] Loss: 2.0871\n",
      "Epoch [7/20], Iter [60/1] Loss: 2.0920\n",
      "Epoch [7/20], Iter [70/1] Loss: 2.2401\n",
      "Epoch [7/20], Iter [80/1] Loss: 2.3154\n",
      "Accuracy (train), Top1: 48.11%, Top5: 80.33%\n",
      "Accuracy (val), Top1: 54.86%, Top5: 82.12%\n",
      "Accuracy (test), Top1: 46.70%, Top5: 70.47%\n",
      "Saved best_agg model\n",
      "Epoch [8/20], Iter [10/1] Loss: 2.3043\n",
      "Epoch [8/20], Iter [20/1] Loss: 2.1058\n",
      "Epoch [8/20], Iter [30/1] Loss: 1.8411\n",
      "Epoch [8/20], Iter [40/1] Loss: 2.3573\n",
      "Epoch [8/20], Iter [50/1] Loss: 2.6031\n",
      "Epoch [8/20], Iter [60/1] Loss: 2.2696\n",
      "Epoch [8/20], Iter [70/1] Loss: 2.0357\n",
      "Epoch [8/20], Iter [80/1] Loss: 2.2956\n",
      "Accuracy (train), Top1: 52.49%, Top5: 82.74%\n",
      "Accuracy (val), Top1: 54.17%, Top5: 83.33%\n",
      "Accuracy (test), Top1: 50.05%, Top5: 71.44%\n",
      "Saved best_agg model\n",
      "Epoch [9/20], Iter [10/1] Loss: 2.3262\n",
      "Epoch [9/20], Iter [20/1] Loss: 2.2395\n",
      "Epoch [9/20], Iter [30/1] Loss: 2.3595\n",
      "Epoch [9/20], Iter [40/1] Loss: 2.1784\n",
      "Epoch [9/20], Iter [50/1] Loss: 2.0220\n",
      "Epoch [9/20], Iter [60/1] Loss: 2.5063\n",
      "Epoch [9/20], Iter [70/1] Loss: 2.2493\n",
      "Epoch [9/20], Iter [80/1] Loss: 2.0422\n",
      "Accuracy (train), Top1: 53.45%, Top5: 82.89%\n",
      "Accuracy (val), Top1: 57.47%, Top5: 84.03%\n",
      "Accuracy (test), Top1: 51.30%, Top5: 71.79%\n",
      "Saved best_agg model\n",
      "Epoch [10/20], Iter [10/1] Loss: 2.2186\n",
      "Epoch [10/20], Iter [20/1] Loss: 2.1779\n",
      "Epoch [10/20], Iter [30/1] Loss: 2.3468\n",
      "Epoch [10/20], Iter [40/1] Loss: 2.3304\n",
      "Epoch [10/20], Iter [50/1] Loss: 1.8287\n",
      "Epoch [10/20], Iter [60/1] Loss: 2.1750\n",
      "Epoch [10/20], Iter [70/1] Loss: 2.0684\n",
      "Epoch [10/20], Iter [80/1] Loss: 1.9425\n",
      "Accuracy (train), Top1: 54.99%, Top5: 83.83%\n",
      "Accuracy (val), Top1: 61.46%, Top5: 88.37%\n",
      "Accuracy (test), Top1: 54.40%, Top5: 72.38%\n",
      "Saved best_agg model\n",
      "Epoch [11/20], Iter [10/1] Loss: 2.3826\n",
      "Epoch [11/20], Iter [20/1] Loss: 1.9916\n",
      "Epoch [11/20], Iter [30/1] Loss: 2.3145\n",
      "Epoch [11/20], Iter [40/1] Loss: 2.0041\n",
      "Epoch [11/20], Iter [50/1] Loss: 1.9284\n",
      "Epoch [11/20], Iter [60/1] Loss: 2.2269\n",
      "Epoch [11/20], Iter [70/1] Loss: 2.0763\n",
      "Epoch [11/20], Iter [80/1] Loss: 1.8043\n",
      "Accuracy (train), Top1: 56.45%, Top5: 84.07%\n",
      "Accuracy (val), Top1: 59.90%, Top5: 84.90%\n",
      "Accuracy (test), Top1: 51.78%, Top5: 71.77%\n",
      "Epoch [12/20], Iter [10/1] Loss: 1.9424\n",
      "Epoch [12/20], Iter [20/1] Loss: 2.1305\n",
      "Epoch [12/20], Iter [30/1] Loss: 2.0151\n",
      "Epoch [12/20], Iter [40/1] Loss: 1.9679\n",
      "Epoch [12/20], Iter [50/1] Loss: 2.0859\n",
      "Epoch [12/20], Iter [60/1] Loss: 1.9783\n",
      "Epoch [12/20], Iter [70/1] Loss: 2.0748\n",
      "Epoch [12/20], Iter [80/1] Loss: 2.1181\n",
      "Accuracy (train), Top1: 58.98%, Top5: 85.45%\n",
      "Accuracy (val), Top1: 60.59%, Top5: 86.28%\n",
      "Accuracy (test), Top1: 54.87%, Top5: 72.33%\n",
      "Epoch [13/20], Iter [10/1] Loss: 2.4541\n",
      "Epoch [13/20], Iter [20/1] Loss: 2.0513\n",
      "Epoch [13/20], Iter [30/1] Loss: 1.7727\n",
      "Epoch [13/20], Iter [40/1] Loss: 1.8080\n",
      "Epoch [13/20], Iter [50/1] Loss: 1.6705\n",
      "Epoch [13/20], Iter [60/1] Loss: 2.4579\n",
      "Epoch [13/20], Iter [70/1] Loss: 1.8192\n",
      "Epoch [13/20], Iter [80/1] Loss: 1.5577\n",
      "Accuracy (train), Top1: 59.92%, Top5: 85.32%\n",
      "Accuracy (val), Top1: 62.15%, Top5: 84.03%\n",
      "Accuracy (test), Top1: 57.14%, Top5: 72.82%\n",
      "Epoch [14/20], Iter [10/1] Loss: 2.3540\n",
      "Epoch [14/20], Iter [20/1] Loss: 2.2602\n",
      "Epoch [14/20], Iter [30/1] Loss: 2.3178\n",
      "Epoch [14/20], Iter [40/1] Loss: 1.9877\n",
      "Epoch [14/20], Iter [50/1] Loss: 1.7261\n",
      "Epoch [14/20], Iter [60/1] Loss: 2.0360\n",
      "Epoch [14/20], Iter [70/1] Loss: 2.0349\n",
      "Epoch [14/20], Iter [80/1] Loss: 2.1305\n",
      "Accuracy (train), Top1: 59.61%, Top5: 85.03%\n",
      "Accuracy (val), Top1: 66.49%, Top5: 86.98%\n",
      "Accuracy (test), Top1: 57.31%, Top5: 73.13%\n",
      "Saved best_agg model\n",
      "Epoch [15/20], Iter [10/1] Loss: 2.3610\n",
      "Epoch [15/20], Iter [20/1] Loss: 2.1476\n",
      "Epoch [15/20], Iter [30/1] Loss: 2.4343\n",
      "Epoch [15/20], Iter [40/1] Loss: 2.1920\n",
      "Epoch [15/20], Iter [50/1] Loss: 1.8920\n",
      "Epoch [15/20], Iter [60/1] Loss: 1.7977\n",
      "Epoch [15/20], Iter [70/1] Loss: 1.9122\n",
      "Epoch [15/20], Iter [80/1] Loss: 1.6818\n",
      "Accuracy (train), Top1: 61.85%, Top5: 86.18%\n",
      "Accuracy (val), Top1: 59.03%, Top5: 83.16%\n",
      "Accuracy (test), Top1: 55.68%, Top5: 72.60%\n",
      "Epoch [16/20], Iter [10/1] Loss: 1.9962\n",
      "Epoch [16/20], Iter [20/1] Loss: 2.0617\n",
      "Epoch [16/20], Iter [30/1] Loss: 2.0497\n",
      "Epoch [16/20], Iter [40/1] Loss: 1.8754\n",
      "Epoch [16/20], Iter [50/1] Loss: 1.9831\n",
      "Epoch [16/20], Iter [60/1] Loss: 1.8672\n",
      "Epoch [16/20], Iter [70/1] Loss: 1.9301\n",
      "Epoch [16/20], Iter [80/1] Loss: 1.9083\n",
      "Accuracy (train), Top1: 62.22%, Top5: 85.65%\n",
      "Accuracy (val), Top1: 65.80%, Top5: 86.11%\n",
      "Accuracy (test), Top1: 57.75%, Top5: 73.20%\n",
      "Epoch [17/20], Iter [10/1] Loss: 1.5154\n",
      "Epoch [17/20], Iter [20/1] Loss: 1.8987\n",
      "Epoch [17/20], Iter [30/1] Loss: 1.4909\n",
      "Epoch [17/20], Iter [40/1] Loss: 2.0665\n",
      "Epoch [17/20], Iter [50/1] Loss: 2.0866\n",
      "Epoch [17/20], Iter [60/1] Loss: 1.9139\n",
      "Epoch [17/20], Iter [70/1] Loss: 1.6599\n",
      "Epoch [17/20], Iter [80/1] Loss: 1.8799\n",
      "Accuracy (train), Top1: 62.91%, Top5: 85.95%\n",
      "Accuracy (val), Top1: 63.37%, Top5: 84.55%\n",
      "Accuracy (test), Top1: 58.29%, Top5: 73.33%\n",
      "Epoch [18/20], Iter [10/1] Loss: 1.7320\n",
      "Epoch [18/20], Iter [20/1] Loss: 1.7385\n",
      "Epoch [18/20], Iter [30/1] Loss: 1.7339\n",
      "Epoch [18/20], Iter [40/1] Loss: 2.0191\n",
      "Epoch [18/20], Iter [50/1] Loss: 1.9532\n",
      "Epoch [18/20], Iter [60/1] Loss: 1.6197\n",
      "Epoch [18/20], Iter [70/1] Loss: 1.9544\n",
      "Epoch [18/20], Iter [80/1] Loss: 1.8325\n",
      "Accuracy (train), Top1: 63.45%, Top5: 85.82%\n",
      "Accuracy (val), Top1: 66.49%, Top5: 87.85%\n",
      "Accuracy (test), Top1: 58.02%, Top5: 72.85%\n",
      "Saved best_agg model\n",
      "Epoch [19/20], Iter [10/1] Loss: 1.5447\n",
      "Epoch [19/20], Iter [20/1] Loss: 2.1368\n",
      "Epoch [19/20], Iter [30/1] Loss: 1.7269\n",
      "Epoch [19/20], Iter [40/1] Loss: 2.3784\n",
      "Epoch [19/20], Iter [50/1] Loss: 1.5692\n",
      "Epoch [19/20], Iter [60/1] Loss: 2.2441\n",
      "Epoch [19/20], Iter [70/1] Loss: 1.6184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Iter [80/1] Loss: 1.8021\n",
      "Accuracy (train), Top1: 64.99%, Top5: 86.86%\n",
      "Accuracy (val), Top1: 66.67%, Top5: 87.67%\n",
      "Accuracy (test), Top1: 58.59%, Top5: 73.12%\n",
      "Saved best_agg model\n",
      "Epoch [20/20], Iter [10/1] Loss: 2.0159\n",
      "Epoch [20/20], Iter [20/1] Loss: 1.9775\n",
      "Epoch [20/20], Iter [30/1] Loss: 1.6295\n",
      "Epoch [20/20], Iter [40/1] Loss: 1.8501\n",
      "Epoch [20/20], Iter [50/1] Loss: 1.7039\n",
      "Epoch [20/20], Iter [60/1] Loss: 1.6786\n",
      "Epoch [20/20], Iter [70/1] Loss: 1.6042\n",
      "Epoch [20/20], Iter [80/1] Loss: 1.9402\n",
      "Accuracy (train), Top1: 64.57%, Top5: 86.67%\n",
      "Accuracy (val), Top1: 68.23%, Top5: 87.85%\n",
      "Accuracy (test), Top1: 59.70%, Top5: 73.02%\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model, dataloaders, 20, device, log_freq, data_path + '/../log/')\n",
    "torch.cuda.empty_cache()\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seen:\n",
      "0.039380110512494036\n",
      "0.00021236080341905416\n",
      "\n",
      "unseen:\n",
      "0.04217024260453315\n",
      "0.03223300108340782\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seen_sigmas = []\n",
    "unseen_sigmas = []\n",
    "\n",
    "for batch_index in range(len(model.labels_list)):\n",
    "    for inner_batch_index in range(model.labels_list[batch_index].size(0)):\n",
    "        class_label = model.labels_list[batch_index][inner_batch_index].item()\n",
    "#         if class_label <= 151:\n",
    "        if class_label not in [11,18,19,25,26,28,30,31,32,41,74,75,98,113,138,139,161,177,180,182,183,192,199,177]:\n",
    "            seen_sigmas.append(model.sigmas_list[batch_index][inner_batch_index].mean().item())\n",
    "        else:\n",
    "            unseen_sigmas.append(model.sigmas_list[batch_index][inner_batch_index].mean().item())\n",
    "            \n",
    "seen_sigmas = np.array(seen_sigmas)\n",
    "unseen_sigmas = np.array(unseen_sigmas)\n",
    "print('seen:')\n",
    "print(seen_sigmas.mean())\n",
    "print(seen_sigmas.std())\n",
    "print('\\nunseen:')\n",
    "print(unseen_sigmas.mean())\n",
    "print(unseen_sigmas.std())\n",
    "# for plotting\n",
    "sns.set_style('darkgrid')\n",
    "x_min = 0.036#np.concatenate((seen_sigmas, unseen_sigmas)).min()\n",
    "x_max = 0.044#np.concatenate((seen_sigmas, unseen_sigmas)).max()\n",
    "x = np.linspace(x_min, x_max, 100)\n",
    "y_seen = scipy.stats.norm.pdf(x,seen_sigmas.mean(),seen_sigmas.std())\n",
    "y_unseen = scipy.stats.norm.pdf(x,unseen_sigmas.mean(), unseen_sigmas.std()/100)\n",
    "\n",
    "\n",
    "plt.plot(x,y_seen, color='coral', label = 'seen')\n",
    "plt.plot(x,y_unseen, color='xkcd:plum', label = 'unseen')\n",
    "plt.legend()\n",
    "plt.savefig(figure_path + 'zero_shot_uncertainty.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08514898966284508\n",
      "0.07866149883665921\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(model.sigmas_list[0])\n",
    "\n",
    "# unseen_attrs = [101-1, 145-1, 151-1, 235 -1,308-1, 312+101-1, 312+145-1, 312+151-1, 312+235 -1,312+308-1]\n",
    "unseen_attrs = [101, 145, 151, 235 ,308]#, 312+101, 312+145, 312+151, 312+235 ,312+308]\n",
    "# unseen_attrs = [101+1, 145+1, 151+1, 235 +1,308+1, 312+101+1, 312+145+1, 312+151+1, 312+235 +1,312+308+1]\n",
    "# unseen_attrs = [101, 101+1, 145, 145+1, 151, 151+1, 235,235 +1,308,308+1]\n",
    "seen_attrs = [i for i in range(312)if i not in unseen_attrs]\n",
    "unseen_mask = torch.tensor([1 if x in unseen_attrs else 0 for x in range(312)], device=device).repeat(model.sigmas_list[0].size(0),1)\n",
    "# print(unseen_mask.size())\n",
    "\n",
    "seen_mask = 1. - unseen_mask\n",
    "# print(seen_mask.size())\n",
    "unseen_sigmas_means = []\n",
    "\n",
    "seen_sigmas_means = []\n",
    "\n",
    "\n",
    "for batch_index in range(len(model.sigmas_list)):\n",
    "# for batch_index in range(2):\n",
    "    if model.sigmas_list[batch_index].size(0)==64:\n",
    "        sigmas = model.sigmas_list[batch_index]\n",
    "        sigmas_new = torch.zeros(64, 312, 1,device=device)\n",
    "        sigmas_new += sigmas.view(64,-1,2)[:,:,0].unsqueeze(2)\n",
    "        sigmas_new += sigmas.view(64,-1,2)[:,:,1].unsqueeze(2)\n",
    "        sigmas = sigmas_new[:,:,0]\n",
    "#         print(sigmas.size())\n",
    "        unseen_sigmas = sigmas * unseen_mask\n",
    "        unseen_sigmas_means += unseen_sigmas.mean(dim=0)[[unseen_attrs]].tolist()\n",
    "        seen_sigmas = sigmas * seen_mask\n",
    "        seen_sigmas_means += seen_sigmas.mean(dim=0)[[seen_attrs]].tolist()\n",
    "#         print(seen_sigmas.mean())\n",
    "\n",
    "\n",
    "print(np.mean(unseen_sigmas_means))\n",
    "print(np.mean(seen_sigmas_means))\n",
    "\n",
    "\n",
    "x_min = 0.03#min(np.array(unseen_sigmas_means).min(), np.array(seen_sigmas_means).min())\n",
    "x_max = 0.13\n",
    "#min(np.array(unseen_sigmas_means).max(), np.array(seen_sigmas_means).max())\n",
    "\n",
    "\n",
    "# x_min = np.concatenate((unseen_sigmas_means, unseen_sigmas)).min()\n",
    "# x_max = np.concatenate((seen_sigmas, unseen_sigmas)).max()\n",
    "x = np.linspace(x_min, x_max, 100)\n",
    "y_unseen = scipy.stats.norm.pdf(x,np.mean(unseen_sigmas_means),np.std(unseen_sigmas_means))\n",
    "y_seen = scipy.stats.norm.pdf(x,np.mean(seen_sigmas_means),np.std(seen_sigmas_means))\n",
    "plt.plot(x,y_unseen, color='#AC454A', label = 'unseen')\n",
    "plt.plot(x,y_seen, color='#F67941', label = 'seen')\n",
    "plt.legend()\n",
    "\n",
    "# uncertain_onehot = torch.tensor([[0., 0., 1.]], device=device).repeat(images.size(0), attribute_size, 1)\n",
    "# print(unseen_batch_mask.size())\n",
    "# #308\n",
    "# # 101\n",
    "# # 235\n",
    "# # 145\n",
    "# 151\n",
    "plt.savefig(figure_path + 'zero_shot_attr_uncertainty.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1080., 1006., 1017.,  931.,  624.,  326.,  147.,   56.,   15.,\n",
       "           2.]),\n",
       " array([0.0390625 , 0.03918218, 0.03930186, 0.03942155, 0.03954123,\n",
       "        0.03966091, 0.03978059, 0.03990028, 0.04001996, 0.04013964,\n",
       "        0.04025932]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(unseen_sigmas)\n",
    "plt.hist(seen_sigmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6804115720417189, 0.7182754132410755, 0.6702648232812467, 0.714998273745827, 0.6931055609298789, 0.7174276281958041, 0.6983859079039615, 0.7049175507348516, 0.6953701344521149, 0.7296628880759944, 0.722016493263452, 0.7092867312224015, 0.7558365218017412, 0.7460860590571943, 0.7157794172349183]\n",
      "\n",
      "[0.057426291227500925, 0.05609082130174483, 0.06299703259782125, 0.05952211805889683, 0.06739816001506262, 0.0625436188633083, 0.061809110545342966, 0.06241330280098864, 0.05440532888776513, 0.054207162390793526, 0.05429709133922413, 0.0504565376347752, 0.05158684070232094, 0.04933646605700575, 0.047554582677861695]\n",
      "\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print(trainer.mean_attr_accs)\n",
    "print()\n",
    "print(trainer.mean_drop_ratio)\n",
    "print()\n",
    "print(trainer.mean_sigmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".  ..  urdtc\r\n"
     ]
    }
   ],
   "source": [
    "!ls -a ../"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
