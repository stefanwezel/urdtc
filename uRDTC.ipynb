{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "As we're luckily standing on the shoulders of giants, we can do some imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import imageio\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "Let's load and convert the data, so we can use it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = ['cifar10', 'mnist', 'cub', 'awa2',\n",
    "            'imagenetfeatures', 'apyfeatures', 'zero_shot_cub']\n",
    "# dataset = 'awa2'\n",
    "dataset = 'cub'\n",
    "# dataset = 'zero_shot_cub'\n",
    "\n",
    "data_path = '/home/swezel/projects/urdtc/data/'\n",
    "figure_path = data_path + '../thesis/images/'\n",
    "\n",
    "\n",
    "# attribute name lookup (first attr_id is 0) \n",
    "with open (data_path + 'cub/attributes.txt', 'r') as f:\n",
    "    attributes=f.readlines()\n",
    "attribute_name_dict = {str(int(attr.split(' ')[0])-1): attr.split(' ')[1] for attr in attributes}\n",
    "\n",
    "def get_dataset_config(dataset, cnn_type, max_iters):\n",
    "    input_channels = None\n",
    "    if dataset == 'mnist':\n",
    "        input_channels = 1\n",
    "        if cnn_type == 'cnn':\n",
    "            cnn_output_size = 4*4*100\n",
    "        elif cnn_type == 'resnet':\n",
    "            cnn_output_size = 512\n",
    "        elif cnn_type == 'shallowcnn':\n",
    "            cnn_output_size = 4*4*64\n",
    "        out_freq = 100\n",
    "        #assert max_iters > 4\n",
    "    elif dataset == 'cifar10':\n",
    "        input_channels = 3\n",
    "        if cnn_type == 'cnn':\n",
    "            cnn_output_size = 8*8*32\n",
    "        elif cnn_type == 'resnet' or cnn_type == 'resnet18':\n",
    "            cnn_output_size = 512\n",
    "        elif cnn_type == 'shallowcnn':\n",
    "            cnn_output_size = 4*4*64\n",
    "        out_freq = 100\n",
    "        #assert max_iters > 4\n",
    "    elif dataset == 'cub':\n",
    "        input_channels = 3\n",
    "        if cnn_type == 'cnn':\n",
    "            # cnn_output_size = 32*32*32\n",
    "            cnn_output_size = 280900 # the above does not work? Maybe because of dataloader issue?\n",
    "        elif cnn_type == 'resnet' or cnn_type == 'resnet152':\n",
    "            cnn_output_size = 2048\n",
    "        out_freq = 10\n",
    "    elif dataset == 'zero_shot_cub':\n",
    "        input_channels = 3\n",
    "        if cnn_type == 'cnn':\n",
    "            # cnn_output_size = 32*32*32\n",
    "            cnn_output_size = 280900 # the above does not work? Maybe because of dataloader issue?\n",
    "        elif cnn_type == 'resnet' or cnn_type == 'resnet152':\n",
    "            cnn_output_size = 2048\n",
    "        out_freq = 10\n",
    "        #assert max_iters > 8\n",
    "    elif dataset == 'awa2':\n",
    "        input_channels = 3\n",
    "        if cnn_type == 'cnn':\n",
    "#             cnn_output_size = 32*32*32  # TODO: check\n",
    "            cnn_output_size = 2048\n",
    "        elif cnn_type == 'resnet' or cnn_type == 'resnet152':\n",
    "            cnn_output_size = 2048\n",
    "        out_freq = 10\n",
    "        #assert max_iters > 6\n",
    "    elif dataset == 'imagenetfeatures':\n",
    "        cnn_output_size = 2048\n",
    "        out_freq = 100\n",
    "        #assert max_iters > 10\n",
    "    elif dataset == 'apyfeatures':\n",
    "        cnn_output_size = 2048\n",
    "        out_freq = 10\n",
    "        #assert max_iters > 5\n",
    "\n",
    "    return input_channels, cnn_output_size, out_freq\n",
    "\n",
    "class DataLoader(object):\n",
    "    def __init__(self, dataset='mnist'):\n",
    "        assert dataset in DATASETS\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def load_data(self, batch_size=100, num_workers=4, root='./data/'):\n",
    "\n",
    "        if self.dataset == 'mnist':\n",
    "            #transform_train = transforms.ToTensor()\n",
    "            #transform_test = transforms.ToTensor()\n",
    "            class AddGaussianNoise(object):\n",
    "                def __init__(self, mean=0., std=1.):\n",
    "                    self.std = std\n",
    "                    self.mean = mean\n",
    "\n",
    "                def __call__(self, tensor):\n",
    "                    output = tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "                    return output.clamp(0., 1.)\n",
    "\n",
    "                def __repr__(self):\n",
    "                    return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
    "\n",
    "            transform_train = transforms.Compose([\n",
    "               transforms.ToTensor(),\n",
    "               #AddGaussianNoise(0., 0.2)\n",
    "               #transforms.Normalize((0.1307,), (0.3081,))\n",
    "            ])\n",
    "            transform_test = transforms.Compose([\n",
    "               transforms.ToTensor(),\n",
    "               #AddGaussianNoise(0., 0.2)\n",
    "               #transforms.Normalize((0.1307,), (0.3081,))\n",
    "            ])\n",
    "            classes = [i for i in range(10)]\n",
    "            dataset_class = dsets.MNIST\n",
    "\n",
    "        elif self.dataset == 'cifar10':\n",
    "            transform_train = transforms.Compose([\n",
    "                transforms.RandomCrop(32, padding=4),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "            ])\n",
    "            transform_test = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "            ])\n",
    "            classes = ('plane', 'car', 'bird', 'cat',\n",
    "                       'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "            dataset_class = dsets.CIFAR10\n",
    "\n",
    "        elif self.dataset == 'cub':\n",
    "\n",
    "            transform_train = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                  transforms.RandomResizedCrop(224),\n",
    "                                                  transforms.RandomHorizontalFlip(),\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                                       std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "            transform_test = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                 transforms.Resize(224),\n",
    "                                                 transforms.CenterCrop(224),\n",
    "                                                 transforms.ToTensor(),\n",
    "                                                 transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                                      std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "            dataset_class = CUB\n",
    "            classes = list(range(200))\n",
    "\n",
    "        elif self.dataset == 'zero_shot_cub':\n",
    "\n",
    "            transform_train = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                  transforms.RandomResizedCrop(224),\n",
    "                                                  transforms.RandomHorizontalFlip(),\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                                       std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "            transform_test = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                 transforms.Resize(224),\n",
    "                                                 transforms.CenterCrop(224),\n",
    "                                                 transforms.ToTensor(),\n",
    "                                                 transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                                      std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "            dataset_class = ZeroShotCUB\n",
    "            classes = list(range(200))            \n",
    "            \n",
    "            \n",
    "\n",
    "        elif self.dataset == 'awa2':\n",
    "            transform_train = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                  transforms.RandomResizedCrop(224),\n",
    "                                                  transforms.RandomHorizontalFlip(),\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                                       std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "            transform_test = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                 transforms.Resize(224),\n",
    "                                                 transforms.CenterCrop(224),\n",
    "                                                 transforms.ToTensor(),\n",
    "                                                 transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                                                      std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "            dataset_class = AWA2\n",
    "            classes = list(range(50))\n",
    "\n",
    "        elif self.dataset == 'apyfeatures':\n",
    "            transform_train = transforms.ToTensor()\n",
    "            transform_test = transforms.ToTensor()\n",
    "\n",
    "            dataset_class = APYFeatures\n",
    "            classes = list(range(32))\n",
    "\n",
    "        elif self.dataset == 'imagenetfeatures':\n",
    "            transform_train = transforms.ToTensor()\n",
    "            transform_test = transforms.ToTensor()\n",
    "\n",
    "            dataset_class = ImageNetFeatures\n",
    "            classes = list(range(1000))\n",
    "\n",
    "        train_dataset = dataset_class(root=root,\n",
    "                                      train=True,\n",
    "                                      transform=transform_train,\n",
    "                                      download=True)\n",
    "\n",
    "        test_dataset = dataset_class(root=root,\n",
    "                                     train=False,\n",
    "                                     transform=transform_test)\n",
    "\n",
    "        val_size = int(len(train_dataset) * 0.1)\n",
    "        train_size = len(train_dataset) - val_size\n",
    "\n",
    "        train_dataset, val_dataset = torch.utils.data.dataset.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   shuffle=True,\n",
    "                                                   num_workers=num_workers)\n",
    "\n",
    "        val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 shuffle=False,\n",
    "                                                 num_workers=num_workers)\n",
    "\n",
    "        test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  shuffle=False,\n",
    "                                                  num_workers=num_workers)\n",
    "\n",
    "        dataloaders = {'train': train_loader,\n",
    "                       'val': val_loader,\n",
    "                       'test': test_loader}\n",
    "\n",
    "        return dataloaders, classes\n",
    "\n",
    "class CUB(Dataset):\n",
    "    \"\"\"CUB200-2011 dataset.\"\"\"\n",
    "    attribute_file = 'attributes/class_attribute_labels_continuous.txt'\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, normalize=True,\n",
    "                 download=None):\n",
    "        self.root = os.path.join(root, 'cub')\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.data_dir = os.path.join(self.root, 'images')\n",
    "\n",
    "        train_test_split = pd.read_csv(os.path.join(self.root, 'train_test_split.txt'),\n",
    "                                       sep=' ', index_col=0, header=None)\n",
    "        if train:\n",
    "            is_train_image = 1\n",
    "        else:\n",
    "            is_train_image = 0\n",
    "        self.img_ids = train_test_split[train_test_split[1] == is_train_image].index.tolist()\n",
    "        self.id_to_img = pd.read_csv(os.path.join(self.root, 'images.txt'),\n",
    "                                     sep=' ', index_col=0, header=None)\n",
    "\n",
    "        raw_mtx = np.loadtxt(os.path.join(self.root,\n",
    "                                          self.attribute_file))\n",
    "        raw_mtx[raw_mtx == -1] = 0\n",
    "        raw_mtx = raw_mtx / raw_mtx.max()\n",
    "        self.attribute_mtx = torch.tensor(raw_mtx, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_ids[idx]\n",
    "        img_name = self.id_to_img[self.id_to_img.index == img_id].values[0][0]\n",
    "        img_path = os.path.join(self.data_dir, img_name)\n",
    "\n",
    "        img = imageio.imread(img_path, pilmode='RGB')\n",
    "        label = int(img_name[:3]) - 1\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label, img_path\n",
    "\n",
    "    \n",
    "class ZeroShotCUB(Dataset):\n",
    "    \"\"\"CUB200-2011 dataset.\"\"\"\n",
    "    attribute_file = 'attributes/class_attribute_labels_continuous.txt'\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, normalize=True,\n",
    "                 download=None):\n",
    "        self.root = os.path.join(root, 'cub')\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.data_dir = os.path.join(self.root, 'images')\n",
    "\n",
    "        train_test_split = pd.read_csv(os.path.join(self.root, 'zero_attr_train_test_split.txt'),\n",
    "                                       sep=' ', index_col=0, header=None)\n",
    "        if train:\n",
    "            is_train_image = 1\n",
    "        else:\n",
    "            is_train_image = 0\n",
    "        self.img_ids = train_test_split[train_test_split[1] == is_train_image].index.tolist()\n",
    "        self.id_to_img = pd.read_csv(os.path.join(self.root, 'images.txt'),\n",
    "                                     sep=' ', index_col=0, header=None)\n",
    "\n",
    "        raw_mtx = np.loadtxt(os.path.join(self.root,\n",
    "                                          self.attribute_file))\n",
    "        raw_mtx[raw_mtx == -1] = 0\n",
    "        raw_mtx = raw_mtx / raw_mtx.max()\n",
    "        self.attribute_mtx = torch.tensor(raw_mtx, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_ids[idx]\n",
    "        img_name = self.id_to_img[self.id_to_img.index == img_id].values[0][0]\n",
    "        img_path = os.path.join(self.data_dir, img_name)\n",
    "\n",
    "        img = imageio.imread(img_path, pilmode='RGB')\n",
    "        label = int(img_name[:3]) - 1\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label, img_path\n",
    "    \n",
    "    \n",
    "class AWA2(Dataset):\n",
    "    \"\"\"Animals with Attributes 2 dataset.\"\"\"\n",
    "    split_file = 'train_test_classification_split.txt'\n",
    "    data_dir = 'awa2'\n",
    "    attribute_file = 'predicate-matrix-continuous.txt'\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, normalize=True,\n",
    "                 download=None):\n",
    "        self.root = os.path.join(root, self.data_dir)\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "\n",
    "        meta_data = pd.read_csv(os.path.join(self.root,\n",
    "                                             self.split_file),\n",
    "                                sep=' ', index_col=0, header=None)\n",
    "        if train:\n",
    "            is_train_image = 1\n",
    "        else:\n",
    "            is_train_image = 0\n",
    "        self.img_ids = meta_data[meta_data[3] == is_train_image].index.tolist()\n",
    "        self.id_to_img = meta_data\n",
    "\n",
    "        raw_mtx = np.loadtxt(os.path.join(self.root,\n",
    "                                          self.attribute_file))\n",
    "        raw_mtx[raw_mtx == -1] = 0\n",
    "        raw_mtx = raw_mtx / raw_mtx.max()\n",
    "        self.attribute_mtx = torch.tensor(raw_mtx, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_ids[idx]\n",
    "        img_meta_data = self.id_to_img[self.id_to_img.index == img_id]\n",
    "        img_name = img_meta_data.values[0][0]\n",
    "        img_path = os.path.join(self.root, img_name)\n",
    "\n",
    "        img = imageio.imread(img_path, pilmode='RGB')\n",
    "        label = img_meta_data.values[0][1] - 1\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "# device = torch.device('cpu')\n",
    "\n",
    "# create dataloader objects for train, val and test\n",
    "dl = DataLoader(dataset=dataset)\n",
    "# dataloaders, classes = dl.load_data(4, 4, data_path)# 128 insted of \n",
    "dataloaders, classes = dl.load_data(64, 4, data_path)# 128 insted of \n",
    "\n",
    "# attributes (312 column vectors with 200 rows) -> each class can be described with 312 attributes\n",
    "# percentage of time, human annotator thought, the attribute was present\n",
    "attribute_mtx = dataloaders['train'].dataset.dataset.attribute_mtx\n",
    "\n",
    "# create binary encoding for class attributes\n",
    "attribute_mtx[attribute_mtx < 0.5] = 0.0\n",
    "attribute_mtx[attribute_mtx >= 0.5] = 1.0\n",
    "attribute_mtx = attribute_mtx.to(device) # cuda\n",
    "attribute_size = attribute_mtx.size(1) # number of available attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Models\n",
    "Here, we continue by defining the various models that our uRDTC consists of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Conv2d(in_channels, 20, kernel_size=3, stride=1),\n",
    "                                 nn.ReLU(True),\n",
    "                                 nn.BatchNorm2d(20),\n",
    "                                 nn.Conv2d(20, 50, kernel_size=5, stride=2),\n",
    "                                 nn.ReLU(True),\n",
    "                                 nn.BatchNorm2d(50),\n",
    "                                 nn.Conv2d(50, 100, kernel_size=5, stride=2),\n",
    "                                 nn.ReLU(True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class DropoutCNN(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 20, kernel_size=3, stride=1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, kernel_size=5, stride=2)\n",
    "        self.conv3 = nn.Conv2d(50, 100, kernel_size=5, stride=2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.dropout2d(F.relu(self.conv1(x)), 0.2)\n",
    "        x = F.dropout2d(F.relu(self.conv2(x)), 0.2)\n",
    "        x = F.dropout2d(F.relu(self.conv3(x)), 0.2)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def get_cnn(in_channels, type='cnn', pretrained_cnn_weights=None,\n",
    "            freeze_weights=False, default_pretrained=False):\n",
    "    TYPES = ['cnn', 'dropoutcnn', 'resnet152'] # TYPES = ['cnn', 'shallowcnn', 'resnet', 'resnet152']\n",
    "    assert type in TYPES\n",
    "\n",
    "    if type == 'cnn':\n",
    "        cnn = CNN(in_channels)\n",
    "    if type == 'dropoutcnn':\n",
    "        cnn = DropoutCNN(in_channels)\n",
    "#     if type == 'resnet152':\n",
    "#         cnn = models.resnet152(pretrained=default_pretrained)\n",
    "    else:\n",
    "        cnn = Identity()\n",
    "\n",
    "    # if pretrained_cnn_weights:\n",
    "    #     if type == 'resnet152':\n",
    "    #         cnn.fc = nn.Linear(cnn.fc.in_features, pretrained_cnn_weights['fc.weight'].size(0))\n",
    "    #     cnn.load_state_dict(pretrained_cnn_weights)\n",
    "    if pretrained_cnn_weights:\n",
    "        cnn.load_state_dict(pretrained_cnn_weights)\n",
    "    \n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OC(nn.Module):\n",
    "    def __init__(self, model_type, num_classes, cnn_type, input_channels, cnn_out_size,\n",
    "                 dataset, decision_size=2, max_iters=20, attribute_size=20, attribute_mtx=None, attribute_coef=0.5, hidden_size=100,\n",
    "                 tau_initial=5, tau_target=0.5, use_pretrained=False, shallow=False, strategy='aRDTC'):\n",
    "        super(OC, self).__init__()\n",
    "        assert model_type in ['xoc'] #, 'ioc']\n",
    "        self.model_type = model_type\n",
    "        self.num_classes = num_classes\n",
    "        self.attribute_size = attribute_size\n",
    "        self.attribute_mtx = attribute_mtx\n",
    "        self.attribute_coef = attribute_coef if attribute_mtx is not None else 0.\n",
    "        self.decision_size = decision_size # change keyword default to 3?\n",
    "        self.tau_initial = tau_initial\n",
    "        self.tau_target = tau_target\n",
    "        self.max_iters = max_iters\n",
    "        self.shallow = shallow\n",
    "        self.stats = defaultdict(list)\n",
    "        self.reduced_vocab_size = 2\n",
    "        self.strategy = strategy\n",
    "\n",
    "        self.no_lstm = False\n",
    "\n",
    "        #self.init_attribute_matrix(attribute_mtx, attribute_size, attribute_coef, use_bin_attr)\n",
    "\n",
    "        self.cnn = self.init_cnn(cnn_type, input_channels, dataset, use_pretrained)\n",
    "        self.init_network(hidden_size, decision_size, num_classes, attribute_size, cnn_out_size, shallow)\n",
    "\n",
    "        self.init_losses()\n",
    "\n",
    "\n",
    "\n",
    "        self.phase = 'train'\n",
    "\n",
    "        # for stats\n",
    "        self.logits_list = []\n",
    "        self.sigmas_list = []\n",
    "#         self.labels_list\n",
    "        self.binary_features_list = []\n",
    "        self.labels_list = []\n",
    "        self.used_attributes_list = []\n",
    "        self.certain_attrs = []\n",
    "        self.attribute_accuracies = []\n",
    "        self.drop_ratios = []\n",
    "        self.mean_sigmas = []\n",
    "        \n",
    "\n",
    "    def init_network(self, hidden_size, decision_size, num_classes, attribute_size, cnn_out_size, shallow):\n",
    "        assert decision_size > 1\n",
    "\n",
    "        # LSTM initialization parameters\n",
    "        if self.no_lstm:\n",
    "            self.init_h0 = nn.Parameter(torch.zeros(attribute_size * decision_size), requires_grad=False)\n",
    "            self.init_c0 = nn.Parameter(torch.zeros(attribute_size * decision_size), requires_grad=False)\n",
    "        else:\n",
    "            self.init_h0 = nn.Parameter(torch.zeros(hidden_size).uniform_(-0.01, 0.01), requires_grad=True)\n",
    "            self.init_c0 = nn.Parameter(torch.zeros(hidden_size).uniform_(-0.01, 0.01), requires_grad=True)\n",
    "\n",
    "        if self.no_lstm:\n",
    "            self.lstm = lambda x, y: (None, (x.squeeze(), x.squeeze()))\n",
    "        else:\n",
    "            self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "\n",
    "        if self.no_lstm:\n",
    "            classifier_in = attribute_size * decision_size\n",
    "        else:\n",
    "            classifier_in = attribute_size * decision_size\n",
    "\n",
    "        self.classifier = nn.Sequential(#nn.BatchNorm1d(classifier_in) if not self.no_lstm else Identity(),\n",
    "                                        nn.Linear(classifier_in, hidden_size),\n",
    "                                        nn.ReLU(inplace=True),\n",
    "                                        nn.BatchNorm1d(hidden_size),\n",
    "                                        nn.Linear(hidden_size, num_classes))\n",
    "\n",
    "        if self.model_type == 'xoc':\n",
    "            if self.no_lstm:\n",
    "                feat_select_in_size = attribute_size * decision_size\n",
    "            else:\n",
    "                feat_select_in_size = hidden_size\n",
    "            feat_select_out_size = attribute_size\n",
    "            pre_lstm_size = attribute_size * decision_size * 2\n",
    "\n",
    "            bin_feat_type = 'shallow' if shallow else 'dropoutmlp' #'mlp'\n",
    "            feat_select_type = 'mlp_small'\n",
    "\n",
    "        elif self.model_type == 'ioc':\n",
    "            bin_feat_type = 'identity'\n",
    "            feat_select_type = 'mlp_big'\n",
    "\n",
    "            if not shallow:\n",
    "                feat_select_in_size = cnn_out_size + hidden_size\n",
    "                feat_select_out_size = decision_size\n",
    "                pre_lstm_size = feat_select_out_size\n",
    "            else:\n",
    "                feat_select_in_size = hidden_size\n",
    "                feat_select_out_size = cnn_out_size * decision_size\n",
    "                pre_lstm_size = decision_size\n",
    "\n",
    "        if feat_select_type == 'mlp_small':\n",
    "            self.feature_selection = nn.Sequential(nn.BatchNorm1d(feat_select_in_size) if not self.no_lstm else Identity(),\n",
    "                                                   nn.Linear(feat_select_in_size , hidden_size),\n",
    "                                                   nn.ReLU(inplace=True),\n",
    "                                                   nn.BatchNorm1d(hidden_size),\n",
    "                                                   nn.Linear(hidden_size, feat_select_out_size))\n",
    "        elif feat_select_type == 'mlp_big':\n",
    "            self.feature_selection = nn.Sequential(nn.BatchNorm1d(feat_select_in_size) if not self.no_lstm else Identity(),\n",
    "                                                   nn.Linear(feat_select_in_size, hidden_size),\n",
    "                                                   nn.ReLU(inplace=True),\n",
    "                                                   nn.BatchNorm1d(hidden_size),\n",
    "                                                   nn.Linear(hidden_size, hidden_size),\n",
    "                                                   nn.ReLU(inplace=True),\n",
    "                                                   nn.BatchNorm1d(hidden_size),\n",
    "                                                   nn.Linear(hidden_size, feat_select_out_size))\n",
    "\n",
    "        if bin_feat_type == 'identity':\n",
    "            self.binary_features = Identity()\n",
    "        elif bin_feat_type == 'shallow':\n",
    "            class AddZeros(nn.Module):\n",
    "                def __init__(self):\n",
    "                    super().__init__()\n",
    "\n",
    "                def forward(self, x):\n",
    "                    zeros = torch.zeros_like(x).unsqueeze(2)\n",
    "                    return torch.cat((x.unsqueeze(2), zeros), dim=2)\n",
    "\n",
    "            self.binary_features = AddZeros()\n",
    "        elif bin_feat_type == 'mlp':\n",
    "            self.binary_features = nn.Sequential(nn.BatchNorm1d(cnn_out_size), # use dropout\n",
    "                                                 nn.Linear(cnn_out_size, hidden_size),\n",
    "                                                 nn.ReLU(inplace=True),\n",
    "                                                 nn.BatchNorm1d(hidden_size), # use dropout\n",
    "                                                 nn.Linear(hidden_size, hidden_size),\n",
    "                                                 nn.ReLU(inplace=True),\n",
    "                                                 nn.BatchNorm1d(hidden_size), # use dropout\n",
    "                                                 nn.Linear(hidden_size, attribute_size * self.reduced_vocab_size))\n",
    "        elif bin_feat_type == 'dropoutmlp':\n",
    "            self.binary_features = nn.Sequential(\n",
    "                                                nn.Linear(cnn_out_size, hidden_size),\n",
    "                                                nn.ReLU(inplace=False),\n",
    "                                                nn.Dropout(0.2, inplace=False),\n",
    "                                                nn.Linear(hidden_size, hidden_size),\n",
    "                                                nn.ReLU(inplace=False),\n",
    "                                                nn.Dropout(0.2, inplace=False),\n",
    "                                                nn.Linear(hidden_size, attribute_size * self.reduced_vocab_size)\n",
    "                                                )\n",
    "\n",
    "        if self.no_lstm:\n",
    "            self.pre_lstm = Identity()\n",
    "        else:\n",
    "            self.pre_lstm = nn.Sequential(#nn.BatchNorm1d(pre_lstm_size),\n",
    "                                          nn.Linear(pre_lstm_size, hidden_size),\n",
    "                                          nn.ReLU(inplace=True),\n",
    "                                          nn.BatchNorm1d(hidden_size))\n",
    "\n",
    "\n",
    "        # Temperature parameters\n",
    "        self.binary_features.tau = nn.Parameter(torch.tensor([self.tau_initial], dtype=torch.float), requires_grad=True)\n",
    "        self.feature_selection.tau = nn.Parameter(torch.tensor([self.tau_initial], dtype=torch.float), requires_grad=True)\n",
    "        #self.init_weights()\n",
    "\n",
    "    \n",
    "    \n",
    "    def get_attribute_uncertainty(self, image_features, n=10, batch_size=64):\n",
    "        outputs = torch.zeros((n, batch_size, attribute_size * self.reduced_vocab_size), device=device)\n",
    "        \n",
    "        if self.phase == 'train':\n",
    "            for i in range(n):\n",
    "                outputs[i] = F.softmax(self.binary_features(image_features))\n",
    "#                 outputs[i] = self.binary_features(image_features)\n",
    "\n",
    "        if self.phase == 'test':\n",
    "            for layer in self.binary_features:\n",
    "                if isinstance(layer, torch.nn.modules.dropout._DropoutNd):\n",
    "                    layer.train()\n",
    "#             self.binary_features.train()\n",
    "            for i in range(n):\n",
    "                outputs[i] = F.softmax(self.binary_features(image_features))\n",
    "#                 outputs[i] = self.binary_features(image_features)\n",
    "\n",
    "            for layer in self.binary_features:\n",
    "                if isinstance(layer, torch.nn.modules.dropout._DropoutNd):\n",
    "                    layer.eval()\n",
    "#             self.binary_features.eval()\n",
    "        \n",
    "        sigmas = outputs.var(dim=0)\n",
    "#         sigmas += (0.01**2 * 0.5)/(2 * image_features.size(0) * weight_decay)\n",
    "            \n",
    "            \n",
    "        return sigmas\n",
    "    \n",
    "    def get_attribute_uncertainty_new(self, image_features, n=10, batch_size=64):\n",
    "        outputs = torch.zeros((n, batch_size, attribute_size * self.reduced_vocab_size), device=device)\n",
    "        \n",
    "        if self.phase == 'train':\n",
    "            for i in range(n):\n",
    "                outputs[i] = F.softmax(self.binary_features(image_features), dim=1)\n",
    "#                 outputs[i] = self.binary_features(image_features)\n",
    "\n",
    "        if self.phase == 'test':\n",
    "            for layer in self.binary_features:\n",
    "                if isinstance(layer, torch.nn.modules.dropout._DropoutNd):\n",
    "                    layer.train()\n",
    "#             self.binary_features.train()\n",
    "            for i in range(n):\n",
    "                outputs[i] = F.softmax(self.binary_features(image_features), dim=1)\n",
    "#                 outputs[i] = self.binary_features(image_features)\n",
    "\n",
    "            for layer in self.binary_features:\n",
    "                if isinstance(layer, torch.nn.modules.dropout._DropoutNd):\n",
    "                    layer.eval()\n",
    "#             self.binary_features.eval()\n",
    "        \n",
    "        decision_sigma = outputs.var(dim=0)\n",
    "        attribute_sigma = decision_sigma.view(batch_size, -1, 2).mean(dim=2)\n",
    "#         attribute_sigma += (0.01**2 * 0.5)/(2 * batch_size * weight_decay)\n",
    "            \n",
    "        return attribute_sigma\n",
    "  \n",
    "    def init_attribute_matrix(self, attribute_mtx, attribute_size, attribute_coef, use_bin_attr):\n",
    "        if attribute_coef > 0.:\n",
    "            if use_bin_attr:\n",
    "                attribute_mtx[attribute_mtx < 0.5] = 0.\n",
    "                attribute_mtx[attribute_mtx >= 0.5] = 1.\n",
    "            self.attribute_mtx = nn.Parameter(attribute_mtx, requires_grad=False)\n",
    "            self.attribute_size = attribute_mtx.size(1)\n",
    "        else:\n",
    "            self.attribute_mtx = None\n",
    "            self.attribute_size = attribute_size\n",
    "\n",
    "    def toggle_update_schedule(self):\n",
    "        # TODO: see a few lines below\n",
    "        #self.update_binary_features = not self.update_binary_features\n",
    "        pass\n",
    "\n",
    "    def get_param_groups(self):\n",
    "        cnn_params = []\n",
    "        tree_params = []\n",
    "        for n, p in self.named_parameters():\n",
    "            if p.requires_grad:\n",
    "                # TODO: introduce parameter that allows to switch between training alternatingly\n",
    "                # Currently commented out, so both groups contain the same parameters\n",
    "                \"\"\"\n",
    "                if n.startswith('cnn') or n.startswith('binary_features'):\n",
    "                    print('CNN', n)\n",
    "                    cnn_params.append(p)\n",
    "                else:\n",
    "                    print('OTHER', n)\n",
    "                    tree_params.append(p)\n",
    "                \"\"\"\n",
    "                cnn_params.append(p)\n",
    "                tree_params.append(p)\n",
    "        return tree_params, cnn_params\n",
    "\n",
    "    def set_optimizer(self, optimizers):\n",
    "        self.tree_optimizer = optimizers[0]\n",
    "        self.cnn_optimizer = optimizers[1]\n",
    "\n",
    "    def set_scheduler(self, schedulers):\n",
    "        self.tree_scheduler = schedulers[0]\n",
    "        self.cnn_scheduler = schedulers[1]\n",
    "\n",
    "    def get_optimizer(self):\n",
    "        if self.update_binary_features:\n",
    "            return self.cnn_optimizer\n",
    "        else:\n",
    "            return self.tree_optimizer\n",
    "\n",
    "    def get_scheduler(self):\n",
    "        if self.update_binary_features:\n",
    "            return self.cnn_scheduler\n",
    "        else:\n",
    "            return self.tree_scheduler\n",
    "\n",
    "    def init_losses(self):\n",
    "        self.cls_loss = nn.CrossEntropyLoss()\n",
    "        self.attr_loss = nn.BCEWithLogitsLoss()\n",
    "        self.update_binary_features = False\n",
    "\n",
    "    def init_cnn(self, cnn_type, input_channels, dataset, use_pretrained):\n",
    "        if cnn_type == 'None':\n",
    "            cnn = Identity()\n",
    "        else:\n",
    "            if use_pretrained:\n",
    "                # TODO add data_path and change state dict name \n",
    "                # cnn_state_dict = torch.load('pretrained/{}_{}.pth'.format(dataset, cnn_type))\n",
    "#                 cnn_state_dict = torch.load('pretrained/cub_resnet152.pkl')# .format(dataset, cnn_type)\n",
    "                cnn_state_dict = torch.load('pretrained/{}_resnet152.pkl'.format(dataset))# .format(dataset, cnn_type)\n",
    "\n",
    "                cnn = get_cnn(input_channels, cnn_type, cnn_state_dict, freeze_weights=True)\n",
    "            else:\n",
    "                cnn = get_cnn(input_channels, cnn_type)\n",
    "\n",
    "        return cnn\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight.data)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.fill_(0.1)\n",
    "\n",
    "    def set_tau(self, epoch):\n",
    "        annealing_factor = epoch / 100\n",
    "        self.tau = self.tau_initial\n",
    "        self.tau -= (self.tau_initial - self.tau_target) * annealing_factor\n",
    "        self.tau = max(self.tau, self.tau_target)\n",
    "\n",
    "    def process_images_new(self, images):\n",
    "        batch_size = images.size(0)\n",
    "        img_feats = self.cnn(images)\n",
    "        img_feats = img_feats.view(img_feats.size(0), -1)\n",
    "        image_features = self.binary_features(img_feats) \n",
    "        with torch.no_grad():\n",
    "            attribute_uncertainties = self.get_attribute_uncertainty_new(img_feats, n=5, batch_size=images.size(0))\n",
    "        \n",
    "        if self.model_type == 'xoc':\n",
    "            attribute_logits = image_features.view(-1, 2)\n",
    "\n",
    "\n",
    "            attributes_softmax = F.softmax(attribute_logits / self.binary_features.tau, dim=1)\n",
    "            attributes_hard = self.argmax(attributes_softmax, dim=1)\n",
    "            image_features = attributes_hard.view(images.size(0), -1, 2)\n",
    "\n",
    "            # TODO: generalize to different decision sizes\n",
    "            bin_attribute_logits = attribute_logits - attribute_logits[:, 1].unsqueeze(-1)\n",
    "            self.attribute_logits = bin_attribute_logits[:, 0].view(images.size(0), -1)\n",
    "\n",
    "            self.collect_hist_stats('AttributesSoft', F.softmax(attribute_logits, dim=1))\n",
    "            self.collect_hist_stats('AttributesSoftTemp', attributes_softmax)\n",
    "            self.collect_hist_stats('AttributesHard', attributes_hard.max(dim=1)[1])\n",
    "\n",
    "        return image_features, attribute_uncertainties\n",
    "\n",
    "\n",
    "    def process_images(self, images):\n",
    "        batch_size = images.size(0)\n",
    "        img_feats = self.cnn(images)\n",
    "        img_feats = img_feats.view(img_feats.size(0), -1)\n",
    "        image_features = self.binary_features(img_feats)\n",
    "        # print(image_features.size())\n",
    "        ################## remove attrs code\n",
    "#         sigmas = self.get_attribute_uncertainty_batch(img_feats,n=100, batch_size=batch_size)\n",
    "        \n",
    "        if self.strategy == 'remRDTC':\n",
    "            with torch.no_grad():\n",
    "                sigmas = self.get_attribute_uncertainty(img_feats, n=5, batch_size=images.size(0))\n",
    "            uncertain_attrs = (sigmas > 0.03925).float() # get binary uncertain attrs\n",
    "            certain_attrs = 1. - uncertain_attrs\n",
    "            mask = certain_attrs.detach()\n",
    "            inv_mask = 1-mask\n",
    "            min_value = image_features.min()\n",
    "            image_features = image_features * mask # put zeros where uncertain attts are\n",
    "            image_features = image_features - (inv_mask.detach()*min_value.detach()) #*-500\n",
    "\n",
    "#         sigmas.detach()\n",
    "#         sigmas.cuda()\n",
    "#         self.mean_sigmas.append(sigmas.mean().item())\n",
    "#         drop_ratio = (sigmas>0.005).float().sum()/(images.size(0)*attribute_size*2.)\n",
    "#         min_value = image_features.min()\n",
    "#         min_value.detach()\n",
    "#         self.drop_ratios.append(drop_ratio)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #############################################################\n",
    "#         if not self.training:\n",
    "\n",
    "#             self.sigmas_list.append(sigmas)\n",
    "            # self.logits_list.append(image_features)\n",
    "            # image_features = torch.cat((attribute_logits, sigmas),1)\n",
    "        \n",
    "        \n",
    "        ################## remove attrs\n",
    "#         uncertain_attrs = (sigmas > 0.005).float() # get binary uncertain attrs\n",
    "#         certain_attrs = 1. - uncertain_attrs\n",
    "#         mask = certain_attrs.detach()#(torch.FloatTensor(image_features.size()).uniform_() > 0.050).float().to(device)\n",
    "        if self.strategy == 'randRDTC':\n",
    "            mask = (torch.FloatTensor(image_features.size()).uniform_() > 0.050).float().to(device)\n",
    "            inv_mask = 1-mask\n",
    "#         self.drop_ratios.append((inv_mask.sum()/39936.0).item())\n",
    "#         mask.detach()\n",
    "            min_value = image_features.min()\n",
    "            image_features = image_features * mask # put zeros where uncertain attts are\n",
    "            image_features = image_features - (inv_mask.detach()*min_value.detach()) #*-500\n",
    "        ##############################################################\n",
    "\n",
    "        if self.model_type == 'xoc':\n",
    "            attribute_logits = image_features.view(-1, 2)\n",
    "\n",
    "\n",
    "            attributes_softmax = F.softmax(attribute_logits / self.binary_features.tau, dim=1)\n",
    "            attributes_hard = self.argmax(attributes_softmax, dim=1)\n",
    "            image_features = attributes_hard.view(images.size(0), -1, 2)\n",
    "\n",
    "            # TODO: generalize to different decision sizes\n",
    "            bin_attribute_logits = attribute_logits - attribute_logits[:, 1].unsqueeze(-1)\n",
    "            self.attribute_logits = bin_attribute_logits[:, 0].view(images.size(0), -1)\n",
    "\n",
    "            self.collect_hist_stats('AttributesSoft', F.softmax(attribute_logits, dim=1))\n",
    "            self.collect_hist_stats('AttributesSoftTemp', attributes_softmax)\n",
    "            self.collect_hist_stats('AttributesHard', attributes_hard.max(dim=1)[1])\n",
    "\n",
    "        return image_features\n",
    "\n",
    "    def make_decision(self, lstm_out, binary_features, iter, sigma=[], max_uncertainty=0.2):\n",
    "        if self.model_type == 'xoc':\n",
    "            # Perform categorical feature selection\n",
    "            selection_logits = self.feature_selection(lstm_out)\n",
    "            \n",
    "            if self.strategy == 'remRDTC':\n",
    "                \n",
    "                uncertain_attributes = (sigma > 2e-4).float()\n",
    "#                 dummy = torch.zeros((sigma.size()), device=device)\n",
    "#                 dummy[uncertain_attributes] = -np.inf\n",
    "# #                 print(np.quantile(sigma.cpu().numpy(),0.99))\n",
    "# #                 attribute_uncertainties = torch.rand(binary_features.size(0), attribute_size, device=device, requires_grad=False)\n",
    "#                 self.mean_sigmas.append(sigma.mean().item())\n",
    "\n",
    "                \n",
    "                certain_attributes = 1. - uncertain_attributes\n",
    "                selection_logits = certain_attributes.detach() * selection_logits + uncertain_attributes.detach() * -100\n",
    "#             else:\n",
    "#                 new_selection_logits = selection_logits    \n",
    "#                 selection_probs = torch.softmax((selection_logits+dummy)/0.01, dim=1)\n",
    "    \n",
    "                if self.training:\n",
    "                    hard_selection = F.gumbel_softmax(selection_logits, tau=self.feature_selection.tau, hard=True)\n",
    "                else:\n",
    "#                     print(sigma.mean())\n",
    "                    hard_selection = self.argmax(selection_logits, dim=1)\n",
    "#                     print(hard_selection)\n",
    "\n",
    "            \n",
    "            else: # if another strategy is used\n",
    "                if self.training:\n",
    "                    hard_selection = F.gumbel_softmax(selection_logits, tau=self.feature_selection.tau, hard=True)\n",
    "                else:\n",
    "                    hard_selection = self.argmax(selection_logits, dim=1)\n",
    "\n",
    "\n",
    "            # Get single decision\n",
    "            self.saved_attribute_selection = hard_selection.max(dim=1)[1]\n",
    "            \n",
    "\n",
    "            decision = (hard_selection.unsqueeze(2) * binary_features).view(-1, self.attribute_size * self.decision_size)\n",
    "            # print(decision[0])\n",
    "        elif self.model_type == 'ioc':\n",
    "            if not self.shallow:\n",
    "                features = torch.cat((lstm_out, binary_features), dim=1)\n",
    "                selection_logits = self.feature_selection(features)\n",
    "            else:\n",
    "                shallow_weights = self.feature_selection(lstm_out)\n",
    "                shallow_weights = shallow_weights.view(lstm_out.size(0), -1, self.decision_size)\n",
    "                selection_logits = torch.bmm(binary_features.unsqueeze(1), shallow_weights)\n",
    "                selection_logits = selection_logits.squeeze()\n",
    "\n",
    "            soft_decision = F.softmax(selection_logits / self.tau_selection, dim=1)\n",
    "            hard_selection = self.argmax(soft_decision, dim=1)\n",
    "            decision = hard_selection\n",
    "\n",
    "        # Collect statistics\n",
    "        self.collect_hist_stats('SelectionSoft', F.softmax(selection_logits, dim=1).max(dim=1)[0], iter)\n",
    "        self.collect_hist_stats('SelectionSoftTemp', F.softmax(selection_logits / self.feature_selection.tau, dim=1).max(dim=1)[0], iter)\n",
    "        self.collect_hist_stats('SelectionHard', hard_selection.max(dim=1)[1], iter)\n",
    "\n",
    "        return decision\n",
    "\n",
    "    def get_initial_state(self, batch_size):\n",
    "        h0 = self.init_h0.view(1, 1, -1).expand(-1, batch_size, -1)\n",
    "        c0 = self.init_c0.view(1, 1, -1).expand(-1, batch_size, -1)\n",
    "        state = (h0.contiguous(), c0.contiguous())\n",
    "        return state\n",
    "\n",
    "    def argmax(self, y_soft, dim):\n",
    "        index = y_soft.max(dim, keepdim=True)[1]\n",
    "        y_hard = torch.zeros_like(y_soft).scatter_(dim, index, 1.0)\n",
    "        argmax = y_hard - y_soft.detach() + y_soft\n",
    "        return argmax\n",
    "\n",
    "    def collect_hist_stats(self, name, data, i=None):\n",
    "        # TODO: investigate performance impact of collecting these statistics,\n",
    "        # make option to disable and/or autodisable if tree is too large\n",
    "        if 'Hard' in name:\n",
    "            stat_str = 'Hist/' + name\n",
    "            data = data.detach().cpu()\n",
    "            self.stats[stat_str].append(data)\n",
    "            if i is not None:\n",
    "                stat_str += str(i)\n",
    "                self.stats[stat_str].append(data)\n",
    "\n",
    "    def get_hist_stats(self, reset=True):\n",
    "        stats = self.stats\n",
    "        if reset:\n",
    "            self.stats = defaultdict(list)\n",
    "        #return None\n",
    "        return stats\n",
    "\n",
    "    def reset_stats(self):\n",
    "        self.unique_attributes = [set() for i in range(self.max_iters)]\n",
    "        if self.attribute_coef > 0.:\n",
    "            self.attr_pred_correct = [0 for i in range(self.max_iters)]\n",
    "\n",
    "    def update_unique_attributes(self, unique_attributes, iter):\n",
    "        for attr in unique_attributes:\n",
    "            self.unique_attributes[iter].add(attr.item())\n",
    "\n",
    "    def get_unique_attributes(self):\n",
    "        uniq_per_iter = []\n",
    "        for i in range(self.max_iters):\n",
    "            iter_set = self.unique_attributes[i]\n",
    "            for j in range(i+1):\n",
    "                if j == i:\n",
    "                    continue\n",
    "                iter_set = iter_set.union(self.unique_attributes[j])\n",
    "            uniq_per_iter.append(len(iter_set))\n",
    "        return uniq_per_iter\n",
    "\n",
    "    def update_attr_preds(self, attr_correct, iter):\n",
    "        self.attr_pred_correct[iter] += attr_correct\n",
    "\n",
    "    def get_attr_acc(self, total_cnt):\n",
    "        correct_cumsum = np.cumsum(self.attr_pred_correct)\n",
    "        cnt_per_iter = (np.arange(self.max_iters) + 1) * total_cnt\n",
    "        return correct_cumsum / cnt_per_iter\n",
    "\n",
    "    def init_tree_stats(self):\n",
    "        # TODO: investigate performance impact of collecting these statistics,\n",
    "        # make option to disable and/or autodisable if tree is too large\n",
    "\n",
    "        # Would be nice if this worked with sparse tensors\n",
    "        n_possible_states = self.reduced_vocab_size** self.max_iters\n",
    "        self.label_stats = torch.zeros((n_possible_states * self.reduced_vocab_size,\n",
    "                                        self.num_classes), dtype=torch.int32)\n",
    "                                       #layout=torch.sparse_coo)\n",
    "        self.selection_stats = torch.zeros((n_possible_states,\n",
    "                                            self.attribute_size),\n",
    "                                           dtype=torch.int32)\n",
    "                                           #layout=torch.sparse_coo)\n",
    "\n",
    "    def update_tree_stats(self, attribute_selection, attribute_decisions, labels, iter):\n",
    "        # TODO: investigate performance impact of collecting these statistics,\n",
    "        # make option to disable and/or autodisable if tree is too large\n",
    "\n",
    "        if iter == 0:\n",
    "            self.batch_states = torch.zeros_like(labels)\n",
    "            for i in range(labels.size(0)):\n",
    "                self.label_stats[self.batch_states[i], labels[i]] += 1\n",
    "\n",
    "        for i in range(labels.size(0)):\n",
    "            self.selection_stats[self.batch_states[i], attribute_selection[i]] += 1\n",
    "            self.batch_states[i] += (attribute_decisions[i] + 1) * self.decision_size ** iter\n",
    "            self.label_stats[self.batch_states[i], labels[i]] += 1\n",
    "\n",
    "    def run_iteration(self, binary_features, state, decision_hist, iter, sigma=[]): # also pass sigma here\n",
    "        lstm_out = state[0].squeeze(0)\n",
    "\n",
    "        # Make binary decision\n",
    "        decision = self.make_decision(lstm_out, binary_features, iter, sigma)\n",
    "\n",
    "        if decision_hist is None:\n",
    "            decision_hist = decision\n",
    "        else:\n",
    "            decision_hist = (decision_hist + decision).clamp(0., 1.)\n",
    "\n",
    "        scaled_dh = decision_hist / decision_hist.sum(dim=1).unsqueeze(1).detach()\n",
    "        if self.no_lstm:\n",
    "            lstm_in = scaled_dh\n",
    "        else:\n",
    "            lstm_in = torch.cat((scaled_dh, decision), dim=1)\n",
    "\n",
    "        # Update LSTM state\n",
    "        lstm_in = self.pre_lstm(lstm_in).unsqueeze(1)\n",
    "        _, state = self.lstm(lstm_in, state)\n",
    "\n",
    "        # Get current classification\n",
    "        classifier_in = scaled_dh\n",
    "        #classifier_in = state[1].squeeze(0)\n",
    "        #classifier_in = torch.cat((decision_hist, self.lstm_state_bn(lstm_state)), dim=1)\n",
    "        classification = self.classifier(classifier_in)\n",
    "\n",
    "        return classification, state, decision_hist\n",
    "\n",
    "    def tree_rollout(self, images, labels, keep_tree_stats=False):\n",
    "        # Set initial state\n",
    "        state = self.get_initial_state(images.size(0))\n",
    "\n",
    "        # Get categorical features once\n",
    "#         binary_features = self.process_images(images)\n",
    "        \n",
    "        binary_features, attribute_uncertainties = self.process_images_new(images)\n",
    "#         print(alt_binary_features.size())\n",
    "#         print(attribute_uncertainties.size())\n",
    "        # collect attribute stats\n",
    "\n",
    "#         attr_acc = (binary_features[:,:,0] == attribute_mtx[labels]).sum().long() / 19968.0 #/ (312*labels.size(0))\n",
    "#         attr_acc = (binary_features[:,:,0] == attribute_mtx[labels]).sum().long() / float((attribute_size*labels.size(0)))    \n",
    "#         print(attr_acc)\n",
    "#         self.attribute_accuracies.append(attr_acc.item())\n",
    "#         self.mean_sigmas.append(attribute_uncertainties.mean().item())\n",
    "#         uncertain_attributes = (attribute_uncertainties > 2e-4).float()\n",
    "#         self.drop_ratios.append((uncertain_attributes.sum()/19968.0).item())\n",
    "\n",
    "\n",
    "        ######################### extended vocab code \n",
    "        if self.strategy == 'extRDTC':\n",
    "#             with torch.no_grad():\n",
    "#                 img_feats = self.cnn(images)\n",
    "#                 img_feats = img_feats.view(img_feats.size(0), -1)\n",
    "#                 sigmas = self.get_attribute_uncertainty(img_feats, n=5, batch_size=images.size(0))\n",
    "#                 attribute_sigma = self.get_attribute_uncertainty_new(img_feats, n=5, batch_size=images.size(0))\n",
    "#                 print(attribute_sigma.size())\n",
    "            if not self.training:\n",
    "                self.sigmas_list.append(attribute_uncertainties)\n",
    "#                 self.labels_list.append(labels)\n",
    "                self.binary_features_list.append(binary_features)\n",
    "                self.labels_list.append(labels)\n",
    "\n",
    "\n",
    "        \n",
    "#             self.mean_sigmas.append(attribute_uncertainties.mean().item())\n",
    "#             sigmas = (sigmas > 0.0002).float() # 0.03925,0.06\n",
    "# #             sigmas = (sigmas > 0.05).float() # 0.005\n",
    "#             sigmas_new = torch.zeros(images.size(0), attribute_size,1, device=device)\n",
    "#             sigmas_new += sigmas.view(images.size(0),-1,2)[:,:,0].unsqueeze(2)\n",
    "#             sigmas_new += sigmas.view(images.size(0),-1,2)[:,:,1].unsqueeze(2)\n",
    "#             sigmas_new = (sigmas_new > 0.0).float() # <- denotes uncertain attributes\n",
    "#             print(sigmas_new.size())\n",
    "            uncertain_attributes = (attribute_uncertainties>2e-5).float().unsqueeze(2)\n",
    "#             print(uncertain_attributes.size())\n",
    "#             print()\n",
    "#             self.drop_ratios.append((uncertain_attributes.sum()/19968.0).item())\n",
    "\n",
    "            # obtain uncertainty and append to decision\n",
    "            new_attribute_decisions = torch.cat([binary_features, torch.zeros_like(uncertain_attributes, device=device)], dim=2)\n",
    "            certain_decisions = 1. - uncertain_attributes\n",
    "            uncertain_onehot = torch.tensor([[0., 0., 1.]], device=device).repeat(images.size(0), attribute_size, 1)\n",
    "            uncertain_attrs_removed = certain_decisions.detach() * new_attribute_decisions\n",
    "            shaped_uncertain_attrs = uncertain_attributes.detach() * uncertain_onehot\n",
    "            final_attribute_decisions = uncertain_attrs_removed + shaped_uncertain_attrs\n",
    "            binary_features = final_attribute_decisions\n",
    "#         ######################### extended vocab code end\n",
    "        \n",
    "        \n",
    "\n",
    "        loss = 0\n",
    "        j = 0\n",
    "        # stats\n",
    "        all_classifications = []\n",
    "        all_chosen_attr = []\n",
    "        all_attribute_preds = []\n",
    "\n",
    "        decision_hist = None\n",
    "        while j < self.max_iters:\n",
    "            classification, state, decision_hist = self.run_iteration(binary_features, state, decision_hist, j+1, sigma=attribute_uncertainties)\n",
    "            loss += (1. - self.attribute_coef) * self.cls_loss(classification, labels)\n",
    "            all_classifications.append(classification)\n",
    "\n",
    "            self.update_unique_attributes(self.saved_attribute_selection.unique(), j)\n",
    "\n",
    "            if self.model_type == 'xoc' and self.attribute_coef > 0.:\n",
    "                chosen_attribtutes = self.saved_attribute_selection\n",
    "                attribute_logits = self.attribute_logits\n",
    "\n",
    "                attribute_target = self.attribute_mtx[labels, :].gather(1, chosen_attribtutes.unsqueeze(1)).squeeze()\n",
    "                attribute_pred = attribute_logits.gather(1, chosen_attribtutes.unsqueeze(1)).squeeze()\n",
    "                loss += self.attribute_coef * self.attr_loss(attribute_pred,\n",
    "                                                             attribute_target)\n",
    "                \n",
    "\n",
    "\n",
    "                attribute_pred_bin = (attribute_pred > 0.).long()\n",
    "                self.update_attr_preds((attribute_pred_bin == attribute_target).sum().item(), j)\n",
    "\n",
    "                \n",
    "            if keep_tree_stats:\n",
    "                attribute_pred = self.attribute_logits.gather(1, self.saved_attribute_selection.unsqueeze(1)).squeeze()\n",
    "                self.update_tree_stats(self.saved_attribute_selection, (attribute_pred > 0.).long(),labels, j)\n",
    "\n",
    "                # all_chosen_attr.append(self.saved_attribute_selection)\n",
    "                all_attribute_preds.append((attribute_pred > 0.).long())\n",
    "\n",
    "            j += 1\n",
    "        \n",
    "            all_chosen_attr.append(self.saved_attribute_selection)\n",
    "\n",
    "\n",
    "        self.tmp_saved_chosen_attr = torch.stack(all_chosen_attr, dim=1)\n",
    "\n",
    "        if keep_tree_stats:\n",
    "            self.tmp_saved_cls = torch.stack(all_classifications, dim=1)\n",
    "#             self.tmp_saved_chosen_attr = torch.stack(all_chosen_attr, dim=1)\n",
    "            self.tmp_saved_attr_pred = torch.stack(all_attribute_preds, dim=1)\n",
    "        # else:\n",
    "        #     self.tmp_saved_chosen_attr = None\n",
    "\n",
    "        loss = loss / self.max_iters\n",
    "                ####################################\n",
    "        if binary_features.size(0)==64:\n",
    "            # self.used_attributes_list.append(self.tmp_saved_chosen_attr)\n",
    "            # self.certain_attrs.append(certain_decisions)\n",
    "#             print(self.tmp_saved_chosen_attr.size())\n",
    "            chosen_attributes_binary = torch.tensor([[1 if x in [int(attr) for attr in self.tmp_saved_chosen_attr[row,:]] else 0 for x in range(312)] for row in range(64)])\n",
    "#             ###chosen_attributes_binary = torch.tensor([1 if x in [int(attr) for attr in self.tmp_saved_chosen_attr[:,x]] else 0 for x in range(312)], device=device)\n",
    "            self.used_attributes_list.append(chosen_attributes_binary)\n",
    "#             print(chosen_attributes_binary.size())\n",
    "        \n",
    "\n",
    "        return all_classifications, loss, self.tmp_saved_chosen_attr\n",
    "\n",
    "    def forward(self, images, labels, keep_tree_stats=False):\n",
    "        classification, loss, chosen_attribtutes = self.tree_rollout(images, labels, keep_tree_stats)\n",
    "        # classification, loss, chosen_attributes = self.tree_rollout(images, labels, keep_tree_stats)\n",
    "\n",
    "        return classification, loss#, chosen_attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "After defining our models, we can continue by training it. For this, we first set some hyperparameters and then continue by defining a trainer class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake input arguments\n",
    "model_type = 'xoc'\n",
    "cnn_type = 'uncertain'\n",
    "# cnn_type = 'resnet'\n",
    "attribute_coef = 0.2\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.#0.0001\n",
    "step_size = 50\n",
    "num_epochs = 2\n",
    "max_iters = 10\n",
    "hidden_size = 1000\n",
    "cnn_out_size = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, dataloaders, num_epochs, device, log_freq, log_path): # todo remove stats dict\n",
    "\n",
    "        self.model = model\n",
    "        self.dataloaders = dataloaders\n",
    "        self.num_epochs = num_epochs\n",
    "        self.device = device\n",
    "        self.log_freq = log_freq\n",
    "        self.log_path = log_path\n",
    "        \n",
    "        self.logger = SummaryWriter(self.log_path)\n",
    "\n",
    "        #### TODO remove this workaround and use tensorboard\n",
    "#         with open('/content/drive/My Drive/rdtc/data/' + 'logs/' + 'stats_dict.json') as json_file:\n",
    "#             self.stats_dict = json.load(json_file)\n",
    "        \n",
    "        self.classifications_dict = {'correct':{'num':0, 'uncertainty':0},\n",
    "                                     'incorrect':{'num':0, 'uncertainty':0}}\n",
    "\n",
    "        self.uncertainty_stats = {'epoch_{}'.format(epoch):{'used_attributes':[],'sigmas':[], 'num_attrs_discarded':0} for epoch in range(num_epochs+2)}\n",
    "        self.mean_attr_accs = []\n",
    "        self.mean_drop_ratio = []\n",
    "        self.mean_sigmas = []\n",
    "        ############\n",
    "\n",
    "    def train(self):\n",
    "        self.model.phase = 'train'\n",
    "        self.train_model(self.dataloaders['train'])\n",
    "\n",
    "    def test(self):\n",
    "        self.model.phase = 'test'\n",
    "        self.test_model(self.dataloaders['test'], 'test', None, hard=False) # was: hard=True\n",
    "        self.model.phase = 'train'\n",
    "#         return self.model.label_stats, self.model.selection_stats\n",
    "\n",
    "    def topk_correct(self, output, target, topk=(1,)):\n",
    "        maxk = max(topk)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        target_masks = []\n",
    "        target_cnt = []\n",
    "        for i in range(self.model.num_classes):\n",
    "            target_masks.append((target == i).unsqueeze(0))\n",
    "            target_cnt.append(target_masks[i].sum().item())\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = [(correct[:k] * tm).view(-1).float().sum(0, keepdim=True).item() for tm in target_masks]\n",
    "            res.append(np.array(correct_k))\n",
    "        return res, np.array(target_cnt)\n",
    "\n",
    "    def log_stats(self, phase, epoch, epoch_stats, hist_stats,\n",
    "                  unique_attr_stats, attr_acc):\n",
    "        for k in range(len(epoch_stats[0])):\n",
    "        # for k in range(1):\n",
    "\n",
    "            self.logger.add_scalar('Top1Accuracy{}/{}'.format(k+1, phase), epoch_stats[0][k], epoch)\n",
    "            # self.logger.add_scalar('Top5Accuracy{}/{}'.format(k+1, phase), epoch_stats[1][k], epoch)\n",
    "            # self.logger.add_scalar('Top1MeanClassAccuracy{}/{}'.format(k+1, phase), epoch_stats[3][k], epoch)\n",
    "            # self.logger.add_scalar('Top5MeanClassAccuracy{}/{}'.format(k+1, phase), epoch_stats[4][k], epoch)\n",
    "            # if unique_attr_stats is not None:\n",
    "            #     self.logger.add_scalar('UniqueAttributes{}/{}'.format(k+1, phase), unique_attr_stats[k], epoch)\n",
    "            # if attr_acc is not None:\n",
    "            #     self.logger.add_scalar('AttributeAccuracy{}/{}'.format(k+1, phase), attr_acc[k], epoch)\n",
    "        self.logger.add_scalar('Loss/'+phase, epoch_stats[2], epoch)\n",
    "\n",
    "        if hist_stats is not None:\n",
    "            for name, data in hist_stats.items():\n",
    "                data = torch.cat(data, dim=0).flatten()\n",
    "                if name.startswith('SelectionHard'):\n",
    "                    bins = self.model.attribute_size\n",
    "                elif name.startswith('AttributesHard'):\n",
    "                    bins = self.model.decision_size\n",
    "                else:\n",
    "                    bins = 'tensorflow'\n",
    "                self.logger.add_histogram(name, data, epoch, bins=bins)\n",
    "\n",
    "    def test_model(self, data_loader, phase, epoch, hard=False):\n",
    "        # Test the Model\n",
    "        self.model.eval()  # Change model to 'eval' mode (BN uses moving mean/var).\n",
    "        n_stats = self.model.max_iters if hasattr(self.model, 'max_iters') else 1\n",
    "        correct_1 = np.zeros((n_stats, self.model.num_classes))\n",
    "        correct_5 = np.zeros((n_stats, self.model.num_classes))\n",
    "        total = 0\n",
    "        total_cnt = np.zeros((1, self.model.num_classes))\n",
    "        total_loss = 0\n",
    "\n",
    "        if isinstance(self.model, OC):\n",
    "            self.model.reset_stats()\n",
    "            if hard:\n",
    "                self.model.init_tree_stats()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for idx, data in enumerate(data_loader):\n",
    "                if len(data) == 2:\n",
    "                    images, labels = data\n",
    "                    attributes = None\n",
    "                else:\n",
    "                    images, labels, attributes = data\n",
    "                    #attributes = attributes.to(self.device)\n",
    "                images = images.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                \n",
    "                classification, loss = self.model(images, labels, hard)\n",
    "                #####################################\n",
    "#                 print(labels.size())\n",
    "#                 print(labels[0].item())\n",
    "                #####################################\n",
    "\n",
    "                # Collect stats\n",
    "                total_loss += loss.item()\n",
    "                total += labels.size(0)\n",
    "                for k in range(len(classification)):\n",
    "                    ######################\n",
    "                    # print(classification[k].data)\n",
    "                    # print(labels[k])\n",
    "                    # print()\n",
    "                    # print(classification[k].data.size())\n",
    "                    # print(labels.size())\n",
    "                    # print()\n",
    "                    # values, indices = torch.max(classification[k], -1)\n",
    "                    # for i in range(classification[k].size(0)):\n",
    "\n",
    "                        # print(indices[i].item(),labels[i].item())\n",
    "                        # if indices[i].item()==labels[i].item():\n",
    "                        #     self.classifications_dict['correct']+=1\n",
    "                        # if indices[i].item()!=labels[i].item():\n",
    "                        #     self.classifications_dict['incorrect']+=1              \n",
    "          \n",
    "                    ######################\n",
    "                    ctopk, target_cnt = self.topk_correct(classification[k].data, labels, (1, 5))\n",
    "                    c1, c5 = ctopk\n",
    "                    # print(target_cnt)\n",
    "                    correct_1[k] += c1\n",
    "                    correct_5[k] += c5\n",
    "                total_cnt[0] += target_cnt\n",
    "\n",
    "                \n",
    "     \n",
    "        stats = [correct_1.sum(axis=1) / total, correct_5.sum(axis=1) / total, total_loss / total, (correct_1 / total_cnt).mean(axis=1), (correct_5 / total_cnt).mean(axis=1)]\n",
    "        print('Accuracy ({}), Top1: {:.2%}, Top5: {:.2%}'.format(phase, stats[0][-1], stats[1][-1]))\n",
    "        self.model.train()  # Change model to 'train' mode\n",
    "\n",
    "        unique_attr_stats = None\n",
    "        attr_acc = None\n",
    "        if epoch is not None:\n",
    "            if isinstance(self.model, OC):\n",
    "                hist_stats = self.model.get_hist_stats()\n",
    "                unique_attr_stats = self.model.get_unique_attributes()\n",
    "                if self.model.attribute_coef > 0.:\n",
    "                    attr_acc = self.model.get_attr_acc(total)\n",
    "                else:\n",
    "                    attr_acc = None\n",
    "            else:\n",
    "                hist_stats = None\n",
    "            self.log_stats(phase, epoch, stats, hist_stats, unique_attr_stats, attr_acc)\n",
    "\n",
    "        return stats[0][-1], stats, unique_attr_stats, attr_acc\n",
    "\n",
    "    def train_model(self, data_laoder):\n",
    "        max_accuracy = 0\n",
    "        max_agg_accuracy = 0\n",
    "        max_ma_accuracy = 0\n",
    "        max_ma_agg_accuracy = 0\n",
    "\n",
    "        if isinstance(self.model, OC):\n",
    "            self.model.reset_stats()\n",
    "\n",
    "        # Train the Model       \n",
    "        for epoch in range(self.num_epochs):\n",
    "            #self.model.set_tau(epoch)\n",
    "            optimizer = self.model.get_optimizer()\n",
    "            n_stats = self.model.max_iters if hasattr(self.model, 'max_iters') else 1\n",
    "            correct_1 = np.zeros((n_stats, self.model.num_classes))\n",
    "            correct_5 = np.zeros((n_stats, self.model.num_classes))\n",
    "            total = 0\n",
    "            total_cnt = np.zeros((1, self.model.num_classes))\n",
    "            total_loss = 0\n",
    "\n",
    "            for i, data in enumerate(data_laoder):\n",
    "                \n",
    "                if len(data) == 2:\n",
    "                    images, labels = data\n",
    "                    attributes = None\n",
    "                else:\n",
    "                    images, labels, attributes = data\n",
    "                    #attributes = attributes.to(self.device)\n",
    "                images = images.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                classification, loss = self.model(images, labels)\n",
    "                \n",
    "\n",
    "                if loss.grad_fn is not None:\n",
    "                \n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # Collect stats\n",
    "                total_loss += loss.item()\n",
    "                total += labels.size(0)\n",
    "                for k in range(len(classification)):\n",
    "                    ctopk, target_cnt = self.topk_correct(classification[k].data, labels, (1, 5))\n",
    "                    c1, c5 = ctopk\n",
    "                    correct_1[k] += c1\n",
    "                    correct_5[k] += c5\n",
    "                total_cnt[0] += target_cnt\n",
    "\n",
    "                if (i+1) % self.log_freq == 0:\n",
    "                    print('Epoch [{}/{}], Iter [{}/{}] Loss: {:.4f}'\n",
    "                            .format(epoch+1, self.num_epochs, i+1, len(data_laoder)//images.size(0),\n",
    "                                    loss.item()))\n",
    "                    ##### TODO remove workaround and use tensurboard\n",
    "                    # self.stats_dict[configuration]['losses'].append(loss.item())\n",
    "            \n",
    "        # with open(data_path + '/logs/' + 'stats_dict.json', 'w') as json_file:\n",
    "        #     json.dump(self.stats_dict, json_file)\n",
    "        #     print('stats dict saved...')\n",
    "                    #############################################\n",
    "\n",
    "            self.model.get_scheduler().step()\n",
    "            # if isinstance(self.model, NeuralDecisionForest) or isinstance(self.model, OC):\n",
    "            #     self.model.toggle_update_schedule()\n",
    "\n",
    "            stats = [correct_1.sum(axis=1) / total, correct_5.sum(axis=1) / total, total_loss / total, (correct_1 / total_cnt).mean(axis=1), (correct_5 / total_cnt).mean(axis=1)]\n",
    "\n",
    "            if isinstance(self.model, OC):\n",
    "                hist_stats = self.model.get_hist_stats()\n",
    "                unique_attr_stats = self.model.get_unique_attributes()\n",
    "                if self.model.attribute_coef > 0.:\n",
    "                    attr_acc = self.model.get_attr_acc(total)\n",
    "                else:\n",
    "                    attr_acc = None\n",
    "            else:\n",
    "                hist_stats = None\n",
    "                unique_attr_stats = None\n",
    "                attr_acc = None\n",
    "            self.log_stats('train', epoch, stats, hist_stats, unique_attr_stats, attr_acc)\n",
    "            print('Accuracy (train), Top1: {:.2%}, Top5: {:.2%}'.format(stats[0][-1], stats[1][-1]))\n",
    "            self.model.phase = 'test'\n",
    "            val_accuracy, val_stats, _, _ = self.test_model(self.dataloaders['val'],\n",
    "                                                            'val', epoch+1)\n",
    "            val_agg_accuracy = val_stats[0].sum()\n",
    "            val_ma_accuracy = val_stats[3][-1]\n",
    "            val_ma_agg_accuracy = val_stats[3].sum()\n",
    "\n",
    "            # reset model stats\n",
    "            model.sigmas_list = []\n",
    "            model.labels_list = []\n",
    "            model.used_attributes_list = []\n",
    "            model.attribute_accuracies = []\n",
    "            model.drop_ratios = []\n",
    "#             self.model.phase = 'test'\n",
    "            _, test_stats, unique_attr_stats, attr_acc = self.test_model(self.dataloaders['test'], 'test', epoch+1)\n",
    "            \n",
    "#             if model.drop_ratios[0].size(0) == 64:\n",
    "            self.mean_drop_ratio.append(sum(model.drop_ratios)/(len(model.drop_ratios)+1))\n",
    "            mean_attribute_accuracy = sum(model.attribute_accuracies)/(len(model.attribute_accuracies)+1)\n",
    "            self.mean_sigmas.append(sum(model.mean_sigmas)/(len(model.mean_sigmas)+1))\n",
    "            self.mean_attr_accs.append(mean_attribute_accuracy)\n",
    "#             print(mean_attribute_accuracy)\n",
    "#             print()\n",
    "            # # collect uncertainty stats\n",
    "            # self.uncertainty_stats['epoch_{}'.format(epoch)]['used_attributes']=self.model.used_attributes_list\n",
    "            # self.model.used_attributes_list = []\n",
    "            # self.uncertainty_stats['epoch_{}'.format(epoch)]['sigmas']=self.model.sigmas_list\n",
    "            # self.model.sigmas_list = []           \n",
    "            \n",
    "            \n",
    "            \n",
    "            self.model.phase = 'train'\n",
    "            if val_accuracy > max_accuracy:\n",
    "                max_accuracy = val_accuracy\n",
    "#                 self.save_model('best', test_stats, 0, unique_attr_stats, attr_acc, epoch)\n",
    "            if val_ma_accuracy > max_ma_accuracy:\n",
    "                max_ma_accuracy = val_ma_accuracy\n",
    "#                 self.save_model('best_ma', test_stats, 3, unique_attr_stats, attr_acc, epoch)\n",
    "            if val_agg_accuracy > max_agg_accuracy and isinstance(self.model, OC):\n",
    "                max_agg_accuracy = val_agg_accuracy\n",
    "                self.save_model('best_agg', test_stats, 0, unique_attr_stats, attr_acc, epoch)\n",
    "            if val_ma_agg_accuracy > max_ma_agg_accuracy and isinstance(self.model, OC):\n",
    "                max_ma_agg_accuracy = val_ma_agg_accuracy\n",
    "#                 self.save_model('best_ma_agg', test_stats, 3, unique_attr_stats, attr_acc, epoch)\n",
    "\n",
    "            self.save_model('latest', test_stats, 0, unique_attr_stats, attr_acc, epoch)\n",
    "        # with open(data_path + '/logs/' + 'stats_dict.json', 'w') as json_file:\n",
    "        #     json.dump(self.stats_dict, json_file)\n",
    "        #     print('stats dict saved...')\n",
    "\n",
    "\n",
    "    def write_stats_file(self, stats_list, name, epoch, is_float=True):\n",
    "        fstr = '{:.2f}' if is_float else '{}'\n",
    "        with open(os.path.join(self.log_path, '{}.txt'.format(name)), 'a') as f:\n",
    "            acc_str = [fstr.format(100*c1 if is_float else c1) for c1 in stats_list]\n",
    "            f.write('{} '.format(epoch) + ' '.join(acc_str))\n",
    "            f.write('\\n')\n",
    "\n",
    "    def save_model(self, name, test_stats, stats_idx, unique_attr_stats, attr_acc, epoch):\n",
    "        torch.save(self.model.state_dict(),\n",
    "                   os.path.join(self.log_path, '{}.pth'.format(name)))\n",
    "        \n",
    "        # save state dict for vision model separately\n",
    "        torch.save(self.model.cnn.state_dict(), os.path.join(self.log_path, '{}_vision_model.pth'.format(name)))\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.write_stats_file(test_stats[stats_idx], name, epoch)\n",
    "\n",
    "        # if isinstance(self.model, NeuralDecisionForest):\n",
    "        #     _, test_stats_hard, _, _ = self.test_model(self.dataloaders['test'],\n",
    "        #                                                'test', epoch+1, hard=True)\n",
    "        #     self.write_stats_file(test_stats_hard[stats_idx], name+'_hard', epoch)\n",
    "\n",
    "        if unique_attr_stats is not None:\n",
    "            self.write_stats_file(unique_attr_stats, name+'_uniqattr', epoch,\n",
    "                                  is_float=False)\n",
    "\n",
    "        if attr_acc is not None:\n",
    "            self.write_stats_file(attr_acc, name+'_attracc', epoch)\n",
    "\n",
    "        if name != 'latest':\n",
    "            print('Saved {} model'.format(name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's instance our models..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the configuraion parameters of our dataset\n",
    "in_channels, cnn_out_size, log_freq = get_dataset_config(dataset, 'cnn', 40 )\n",
    "cnn_out_size = 2048\n",
    "\n",
    "# initiate the observer classifier model\n",
    "model = OC('xoc', len(classes), 'dropoutcnn', in_channels,\n",
    "            cnn_out_size, dataset, 3, 40, # 13 worked\n",
    "            attribute_size, attribute_mtx, attribute_coef,\n",
    "            hidden_size, tau_initial=5,\n",
    "            use_pretrained=False, shallow=False)\n",
    "\n",
    "# load pretrained resnet backbone\n",
    "model.cnn = models.resnet152(pretrained=False)\n",
    "# model.cnn.fc = nn.Linear(model.cnn.fc.in_features, torch.load('/home/swezel/projects/urdtc/pretrained/cub_resnet152.pkl')['fc.weight'].size(0))\n",
    "# model.cnn.load_state_dict(torch.load('/home/swezel/projects/urdtc/pretrained/cub_resnet152.pkl'))\n",
    "model.cnn.fc = nn.Linear(model.cnn.fc.in_features, torch.load('/home/swezel/projects/urdtc/pretrained/{}_resnet152.pkl'.format(dataset))['fc.weight'].size(0))\n",
    "model.cnn.load_state_dict(torch.load('/home/swezel/projects/urdtc/pretrained/{}_resnet152.pkl'.format(dataset)))\n",
    "\n",
    "\n",
    "model.cnn.fc = nn.Identity()\n",
    "\n",
    "# set attribute head\n",
    "model.binary_features = nn.Sequential(nn.BatchNorm1d(cnn_out_size),\n",
    "                                        nn.Linear(cnn_out_size, hidden_size),\n",
    "                                        nn.ReLU(inplace=True),\n",
    "                                        nn.BatchNorm1d(hidden_size),\n",
    "                                        nn.Dropout(0.5, inplace=False), # dropout after batchnorm\n",
    "                                        nn.Linear(hidden_size, hidden_size),\n",
    "                                        nn.ReLU(inplace=True),\n",
    "                                        nn.BatchNorm1d(hidden_size),\n",
    "                                        nn.Dropout(0.5, inplace=False),\n",
    "                                        nn.Linear(hidden_size, attribute_size * 2))\n",
    "\n",
    "model.binary_features.tau = nn.Parameter(torch.tensor([5], dtype=torch.float), requires_grad=True)\n",
    "model.to(device);\n",
    "\n",
    "# freeze resnet backbone for faster training but make all other weights trainable\n",
    "for param in model.lstm.parameters():\n",
    "    param.requires_grad=True\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad=True\n",
    "for param in model.feature_selection.parameters():\n",
    "    param.requires_grad=True\n",
    "for param in model.binary_features.parameters():\n",
    "    param.requires_grad=True\n",
    "for param in model.pre_lstm.parameters():\n",
    "    param.requires_grad=True\n",
    "    \n",
    "for param in model.cnn.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.cnn.fc.parameters():\n",
    "    param.requires_grad=True\n",
    "    \n",
    "# initiate optimizers\n",
    "tree_params, cnn_params = model.get_param_groups()\n",
    "tree_optimizer = torch.optim.Adam(tree_params, lr = learning_rate, weight_decay=weight_decay)\n",
    "cnn_optimizer = torch.optim.Adam(cnn_params, lr = learning_rate, weight_decay=weight_decay)\n",
    "optimizer = [tree_optimizer, cnn_optimizer]\n",
    "# and schedulers\n",
    "tree_scheduler = torch.optim.lr_scheduler.StepLR(tree_optimizer, step_size=step_size, gamma=0.1)\n",
    "cnn_scheduler = torch.optim.lr_scheduler.StepLR(cnn_optimizer, step_size=step_size, gamma=0.1)\n",
    "scheduler = [tree_scheduler, cnn_scheduler]\n",
    "\n",
    "model.set_optimizer(optimizer)\n",
    "# model.init_tree_stats()\n",
    "model.set_scheduler(scheduler)\n",
    "##h\n",
    "# model.strategy = 'randRDTC'\n",
    "# model.strategy = 'remRDTC'\n",
    "model.strategy = 'extRDTC'\n",
    "##hook\n",
    "# model.strategy = 'aRDTC'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and finally train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Iter [10/1] Loss: 4.4890\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-175-ba9870471734>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/../log/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-28e3bb35b834>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-28e3bb35b834>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, data_laoder)\u001b[0m\n\u001b[1;32m    192\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m                 \u001b[0mclassification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/uoc/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-171-ba16290fb377>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, labels, keep_tree_stats)\u001b[0m\n\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_tree_stats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m         \u001b[0mclassification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchosen_attribtutes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_rollout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_tree_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    713\u001b[0m         \u001b[0;31m# classification, loss, chosen_attributes = self.tree_rollout(images, labels, keep_tree_stats)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-171-ba16290fb377>\u001b[0m in \u001b[0;36mtree_rollout\u001b[0;34m(self, images, labels, keep_tree_stats)\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# self.certain_attrs.append(certain_decisions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[0;31m#             print(self.tmp_saved_chosen_attr.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             \u001b[0mchosen_attributes_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtmp_saved_chosen_attr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m312\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;31m#             ###chosen_attributes_binary = torch.tensor([1 if x in [int(attr) for attr in self.tmp_saved_chosen_attr[:,x]] else 0 for x in range(312)], device=device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mused_attributes_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchosen_attributes_binary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-171-ba16290fb377>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# self.certain_attrs.append(certain_decisions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[0;31m#             print(self.tmp_saved_chosen_attr.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             \u001b[0mchosen_attributes_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtmp_saved_chosen_attr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m312\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;31m#             ###chosen_attributes_binary = torch.tensor([1 if x in [int(attr) for attr in self.tmp_saved_chosen_attr[:,x]] else 0 for x in range(312)], device=device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mused_attributes_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchosen_attributes_binary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-171-ba16290fb377>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# self.certain_attrs.append(certain_decisions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[0;31m#             print(self.tmp_saved_chosen_attr.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             \u001b[0mchosen_attributes_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtmp_saved_chosen_attr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m312\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;31m#             ###chosen_attributes_binary = torch.tensor([1 if x in [int(attr) for attr in self.tmp_saved_chosen_attr[:,x]] else 0 for x in range(312)], device=device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mused_attributes_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchosen_attributes_binary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-171-ba16290fb377>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# self.certain_attrs.append(certain_decisions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[0;31m#             print(self.tmp_saved_chosen_attr.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             \u001b[0mchosen_attributes_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtmp_saved_chosen_attr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m312\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;31m#             ###chosen_attributes_binary = torch.tensor([1 if x in [int(attr) for attr in self.tmp_saved_chosen_attr[:,x]] else 0 for x in range(312)], device=device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mused_attributes_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchosen_attributes_binary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model, dataloaders, 10, device, log_freq, data_path + '/../log/')\n",
    "torch.cuda.empty_cache()\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "[0.008769466024165487, 0.01692436178943709, 0.019500222350673183, 0.020969420833432156, 0.02276958377383973, 0.02337871055604647, 0.02356651112558725, 0.0230303270863774, 0.022462570806965232, 0.022027091447101986]\n",
      "\n",
      "[1.4856674289163531e-05, 4.453562348558458e-05, 6.280758732873519e-05, 7.567543573304952e-05, 8.675725339989109e-05, 9.542724129258997e-05, 0.00010176273999800186, 0.00010816451014353676, 0.00011275476479622468, 0.00011742354715490427]\n"
     ]
    }
   ],
   "source": [
    "print(trainer.mean_attr_accs)\n",
    "print()\n",
    "print(trainer.mean_drop_ratio)\n",
    "print()\n",
    "print(trainer.mean_sigmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels, cnn_out_size, log_freq = get_dataset_config(dataset, 'cnn', 40 )\n",
    "# cnn_out_size=2048\n",
    "model.load_state_dict(torch.load(data_path + '/../log/extRDTC_best_agg.pth'))#,  map_location=lambda storage, loc: storage)\n",
    "model.cnn.load_state_dict(torch.load(data_path + '/../log/extRDTC_best_agg_vision_model.pth'))\n",
    "# model.train()\n",
    "# model.eval()\n",
    "# print(model.n_possible_states)\n",
    "trainer = Trainer(model, dataloaders, 3, device, log_freq, data_path + '/../log/')\n",
    "# model.reset_stats()\n",
    "# model.init_tree_stats()\n",
    "trainer.test();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulated_error = torch.zeros(312, device=device)\n",
    "accumulated_sigmas = torch.zeros(312, device=device)\n",
    "accumulated_usage = torch.zeros(312, device=device)\n",
    "num_batches = len(model.binary_features_list)\n",
    "batch_size = model.binary_features_list[0].size(0)\n",
    "\n",
    "\n",
    "for batch_index in range(num_batches):\n",
    "    if model.binary_features_list[batch_index].size(0)==64:\n",
    "\n",
    "        # iterate over single batch\n",
    "        for i in range(batch_size):\n",
    "            predicted_attributes = model.binary_features_list[batch_index][i].T[0]  \n",
    "            class_label = model.labels_list[batch_index][i].item()\n",
    "            ground_truth_attributes = attribute_mtx[class_label]\n",
    "\n",
    "            diff = (ground_truth_attributes - predicted_attributes)**2\n",
    "            accumulated_error += diff\n",
    "\n",
    "            accumulated_sigmas += sigmas[batch_index][i]#[:312]\n",
    "            # print(model.used_attributes_list[batch_index][i])\n",
    "            accumulated_usage += model.used_attributes_list[batch_index][i].cuda()\n",
    "# for i in range(len(model.used_attributes_list)):\n",
    "#     accumulated_usage += model.used_attributes_list[i][:312]\n",
    "\n",
    "\n",
    "\n",
    "mean_accumulated_error = accumulated_error/(batch_size * num_batches)\n",
    "mean_accumulated_sigmas = accumulated_sigmas/(batch_size * num_batches)\n",
    "mean_accumulated_usage = accumulated_usage/(batch_size * num_batches)# (batch_size * num_batches)\n",
    "\n",
    "\n",
    "\n",
    "# print(accumulated_error.mean(dim=-1).size())\n",
    "error_and_sigma = torch.stack([mean_accumulated_error, mean_accumulated_sigmas, mean_accumulated_usage], dim=0)\n",
    "d = {'misclassification\\nrate':error_and_sigma[0].cpu().numpy(), 'uncertainty':error_and_sigma[1].cpu().numpy(), 'usage':error_and_sigma[2].cpu().numpy()}\n",
    "df = pd.DataFrame(d)\n",
    "# df.head()\n",
    "df_short = df.loc[df['usage']>0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.5,  1.5,  2.5,  3.5,  4.5,  5.5,  6.5,  7.5,  8.5,  9.5, 10.5,\n",
       "        11.5, 12.5, 13.5, 14.5, 15.5, 16.5, 17.5, 18.5, 19.5, 20.5, 21.5,\n",
       "        22.5, 23.5, 24.5, 25.5, 26.5, 27.5, 28.5, 29.5, 30.5, 31.5, 32.5,\n",
       "        33.5, 34.5, 35.5, 36.5, 37.5, 38.5, 39.5, 40.5]),\n",
       " [Text(0.5, 0, '0'),\n",
       "  Text(1.5, 0, '1'),\n",
       "  Text(2.5, 0, '4'),\n",
       "  Text(3.5, 0, '6'),\n",
       "  Text(4.5, 0, '7'),\n",
       "  Text(5.5, 0, '13'),\n",
       "  Text(6.5, 0, '14'),\n",
       "  Text(7.5, 0, '16'),\n",
       "  Text(8.5, 0, '25'),\n",
       "  Text(9.5, 0, '31'),\n",
       "  Text(10.5, 0, '41'),\n",
       "  Text(11.5, 0, '44'),\n",
       "  Text(12.5, 0, '45'),\n",
       "  Text(13.5, 0, '50'),\n",
       "  Text(14.5, 0, '111'),\n",
       "  Text(15.5, 0, '117'),\n",
       "  Text(16.5, 0, '119'),\n",
       "  Text(17.5, 0, '126'),\n",
       "  Text(18.5, 0, '132'),\n",
       "  Text(19.5, 0, '147'),\n",
       "  Text(20.5, 0, '158'),\n",
       "  Text(21.5, 0, '163'),\n",
       "  Text(22.5, 0, '175'),\n",
       "  Text(23.5, 0, '178'),\n",
       "  Text(24.5, 0, '182'),\n",
       "  Text(25.5, 0, '193'),\n",
       "  Text(26.5, 0, '195'),\n",
       "  Text(27.5, 0, '203'),\n",
       "  Text(28.5, 0, '206'),\n",
       "  Text(29.5, 0, '208'),\n",
       "  Text(30.5, 0, '213'),\n",
       "  Text(31.5, 0, '218'),\n",
       "  Text(32.5, 0, '220'),\n",
       "  Text(33.5, 0, '230'),\n",
       "  Text(34.5, 0, '253'),\n",
       "  Text(35.5, 0, '260'),\n",
       "  Text(36.5, 0, '266'),\n",
       "  Text(37.5, 0, '277'),\n",
       "  Text(38.5, 0, '281'),\n",
       "  Text(39.5, 0, '287'),\n",
       "  Text(40.5, 0, '311')])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x72 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.colors as clr\n",
    "sns.set(rc={'figure.figsize':(15,1)})\n",
    "\n",
    "# cmap = clr.LinearSegmentedColormap.from_list('custom blue', [\"#EAD296\", \"#F67941\", \"#AC454A\", \"#5A005B\", \"#4999F2\"], N=256)\n",
    "cmap = clr.LinearSegmentedColormap.from_list('custom blue', [\"#EAD296\", \"#F67941\", \"#AC454A\"], N=256)\n",
    "\n",
    "sns.heatmap(df_short.to_numpy().T, #annot=True,\n",
    "            xticklabels=df.loc[df['usage']>0].index,\n",
    "            yticklabels=['misclassification rate', 'uncertainty', 'usage'],\n",
    "           cmap=sns.color_palette(\"YlOrBr\"))\n",
    "plt.xticks(rotation=90)\n",
    "# plt.show()\n",
    "# plt.savefig(figure_path + 'attr_heatmap_short.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc={'figure.figsize':(6,5)})\n",
    "sns.heatmap(df_short.corr(), annot=True, center = 0.5, cmap=cmap)#sns.color_palette(\"icefire\"))\n",
    "# plt.show()\n",
    "\n",
    "plt.savefig(figure_path + 'corr_matrix.pdf',bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x='misclassification\\nrate', y='uncertainty',\n",
    "#                 hue='usage',\n",
    "                size='usage',\n",
    "                legend=False,\n",
    "                color='#AC454A',\n",
    "#                 cmap=cmap,\n",
    "                linewidth=0,\n",
    "                data=df_short)\n",
    "\n",
    "\n",
    "# sns.FacetGrid(df_short, row=\"error\", col=\"uncertainty\", hue=\"usage\")\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "plt.savefig(figure_path + 'error_sigma_corr_all.pdf',bbox_inches='tight')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
